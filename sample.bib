
% Journals

% First the Full Name is given, then the abbreviation used in the AMS Math
% Reviews, with an indication if it could not be found there.
% Note the 2nd overwrites the 1st, so swap them if you want the full name.

 %{AMS}
 @String{AMSTrans = "American Mathematical Society Translations" }
 @String{AMSTrans = "Amer. Math. Soc. Transl." }
 @String{BullAMS = "Bulletin of the American Mathematical Society" }
 @String{BullAMS = "Bull. Amer. Math. Soc." }
 @String{ProcAMS = "Proceedings of the American Mathematical Society" }
 @String{ProcAMS = "Proc. Amer. Math. Soc." }
 @String{TransAMS = "Transactions of the American Mathematical Society" }
 @String{TransAMS = "Trans. Amer. Math. Soc." }

 %ACM
 @String{CACM = "Communications of the {ACM}" }
 @String{CACM = "Commun. {ACM}" }
 @String{CompServ = "Comput. Surveys" }
 @String{JACM = "J. ACM" }
 @String{ACMMathSoft = "{ACM} Transactions on Mathematical Software" }
 @String{ACMMathSoft = "{ACM} Trans. Math. Software" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newsletter" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newslett." }

 @String{AmerSocio = "American Journal of Sociology" }
 @String{AmerStatAssoc = "Journal of the American Statistical Association" }
 @String{AmerStatAssoc = "J. Amer. Statist. Assoc." }
 @String{ApplMathComp = "Applied Mathematics and Computation" }
 @String{ApplMathComp = "Appl. Math. Comput." }
 @String{AmerMathMonthly = "American Mathematical Monthly" }
 @String{AmerMathMonthly = "Amer. Math. Monthly" }
 @String{BIT = "{BIT}" }
 @String{BritStatPsych = "British Journal of Mathematical and Statistical
          Psychology" }
 @String{BritStatPsych = "Brit. J. Math. Statist. Psych." }
 @String{CanMathBull = "Canadian Mathematical Bulletin" }
 @String{CanMathBull = "Canad. Math. Bull." }
 @String{CompApplMath = "Journal of Computational and Applied Mathematics" }
 @String{CompApplMath = "J. Comput. Appl. Math." }
 @String{CompPhys = "Journal of Computational Physics" }
 @String{CompPhys = "J. Comput. Phys." }
 @String{CompStruct = "Computers and Structures" }
 @String{CompStruct = "Comput. \& Structures" }
 @String{CompJour = "The Computer Journal" }
 @String{CompJour = "Comput. J." }
 @String{CompSysSci = "Journal of Computer and System Sciences" }
 @String{CompSysSci = "J. Comput. System Sci." }
 @String{Computing = "Computing" }
 @String{ContempMath = "Contemporary Mathematics" }
 @String{ContempMath = "Contemp. Math." }
 @String{Crelle = "Crelle's Journal" }
 @String{GiornaleMath = "Giornale di Mathematiche" }
 @String{GiornaleMath = "Giorn. Mat." } % didn't find in AMS MR., ibid.

 %IEEE
 @String{Computer = "{IEEE} Computer" }
 @String{IEEETransComp = "{IEEE} Transactions on Computers" }
 @String{IEEETransComp = "{IEEE} Trans. Comput." }
 @String{IEEETransAC = "{IEEE} Transactions on Automatic Control" }
 @String{IEEETransAC = "{IEEE} Trans. Automat. Control" }
 @String{IEEESpec = "{IEEE} Spectrum" } % didn't find in AMS MR
 @String{ProcIEEE = "Proceedings of the {IEEE}" }
 @String{ProcIEEE = "Proc. {IEEE}" } % didn't find in AMS MR
 @String{IEEETransAeroElec = "{IEEE} Transactions on Aerospace and Electronic
     Systems" }
 @String{IEEETransAeroElec = "{IEEE} Trans. Aerospace Electron. Systems" }

 @String{IMANumerAna = "{IMA} Journal of Numerical Analysis" }
 @String{IMANumerAna = "{IMA} J. Numer. Anal." }
 @String{InfProcLet = "Information Processing Letters" }
 @String{InfProcLet = "Inform. Process. Lett." }
 @String{InstMathApp = "Journal of the Institute of Mathematics and
     its Applications" }
 @String{InstMathApp = "J. Inst. Math. Appl." }
 @String{IntControl = "International Journal of Control" }
 @String{IntControl = "Internat. J. Control" }
 @String{IntNumerEng = "International Journal for Numerical Methods in
     Engineering" }
 @String{IntNumerEng = "Internat. J. Numer. Methods Engrg." }
 @String{IntSuper = "International Journal of Supercomputing Applications" }
 @String{IntSuper = "Internat. J. Supercomputing Applic." } % didn't find
%% in AMS MR
 @String{Kibernetika = "Kibernetika" }
 @String{JResNatBurStand = "Journal of Research of the National Bureau
     of Standards" }
 @String{JResNatBurStand = "J. Res. Nat. Bur. Standards" }
 @String{LinAlgApp = "Linear Algebra and its Applications" }
 @String{LinAlgApp = "Linear Algebra Appl." }
 @String{MathAnaAppl = "Journal of Mathematical Analysis and Applications" }
 @String{MathAnaAppl = "J. Math. Anal. Appl." }
 @String{MathAnnalen = "Mathematische Annalen" }
 @String{MathAnnalen = "Math. Ann." }
 @String{MathPhys = "Journal of Mathematical Physics" }
 @String{MathPhys = "J. Math. Phys." }
 @String{MathComp = "Mathematics of Computation" }
 @String{MathComp = "Math. Comp." }
 @String{MathScand = "Mathematica Scandinavica" }
 @String{MathScand = "Math. Scand." }
 @String{TablesAidsComp = "Mathematical Tables and Other Aids to Computation" }
 @String{TablesAidsComp = "Math. Tables Aids Comput." }
 @String{NumerMath = "Numerische Mathematik" }
 @String{NumerMath = "Numer. Math." }
 @String{PacificMath = "Pacific Journal of Mathematics" }
 @String{PacificMath = "Pacific J. Math." }
 @String{ParDistComp = "Journal of Parallel and Distributed Computing" }
 @String{ParDistComp = "J. Parallel and Distrib. Comput." } % didn't find
%% in AMS MR
 @String{ParComputing = "Parallel Computing" }
 @String{ParComputing = "Parallel Comput." }
 @String{PhilMag = "Philosophical Magazine" }
 @String{PhilMag = "Philos. Mag." }
 @String{ProcNAS = "Proceedings of the National Academy of Sciences
                    of the USA" }
 @String{ProcNAS = "Proc. Nat. Acad. Sci. U. S. A." }
 @String{Psychometrika = "Psychometrika" }
 @String{QuartMath = "Quarterly Journal of Mathematics, Oxford, Series (2)" }
 @String{QuartMath = "Quart. J. Math. Oxford Ser. (2)" }
 @String{QuartApplMath = "Quarterly of Applied Mathematics" }
 @String{QuartApplMath = "Quart. Appl. Math." }
 @String{RevueInstStat = "Review of the International Statisical Institute" }
 @String{RevueInstStat = "Rev. Inst. Internat. Statist." }

 %SIAM
 @String{JSIAM = "Journal of the Society for Industrial and Applied
     Mathematics" }
 @String{JSIAM = "J. Soc. Indust. Appl. Math." }
 @String{JSIAMB = "Journal of the Society for Industrial and Applied
     Mathematics, Series B, Numerical Analysis" }
 @String{JSIAMB = "J. Soc. Indust. Appl. Math. Ser. B Numer. Anal." }
 @String{SIAMAlgMeth = "{SIAM} Journal on Algebraic and Discrete Methods" }
 @String{SIAMAlgMeth = "{SIAM} J. Algebraic Discrete Methods" }
 @String{SIAMAppMath = "{SIAM} Journal on Applied Mathematics" }
 @String{SIAMAppMath = "{SIAM} J. Appl. Math." }
 @String{SIAMComp = "{SIAM} Journal on Computing" }
 @String{SIAMComp = "{SIAM} J. Comput." }
 @String{SIAMMatrix = "{SIAM} Journal on Matrix Analysis and Applications" }
 @String{SIAMMatrix = "{SIAM} J. Matrix Anal. Appl." }
 @String{SIAMNumAnal = "{SIAM} Journal on Numerical Analysis" }
 @String{SIAMNumAnal = "{SIAM} J. Numer. Anal." }
 @String{SIAMReview = "{SIAM} Review" }
 @String{SIAMReview = "{SIAM} Rev." }
 @String{SIAMSciStat = "{SIAM} Journal on Scientific and Statistical
     Computing" }
 @String{SIAMSciStat = "{SIAM} J. Sci. Statist. Comput." }

 @String{SoftPracExp = "Software Practice and Experience" }
 @String{SoftPracExp = "Software Prac. Experience" } % didn't find in AMS MR
 @String{StatScience = "Statistical Science" }
 @String{StatScience = "Statist. Sci." }
 @String{Techno = "Technometrics" }
 @String{USSRCompMathPhys = "{USSR} Computational Mathematics and Mathematical
     Physics" }
 @String{USSRCompMathPhys = "{U. S. S. R.} Comput. Math. and Math. Phys." }
 @String{VLSICompSys = "Journal of {VLSI} and Computer Systems" }
 @String{VLSICompSys = "J. {VLSI} Comput. Syst." }
 @String{ZAngewMathMech = "Zeitschrift fur Angewandte Mathematik und
     Mechanik" }
 @String{ZAngewMathMech = "Z. Angew. Math. Mech." }
 @String{ZAngewMathPhys = "Zeitschrift fur Angewandte Mathematik und Physik" }
 @String{ZAngewMathPhys = "Z. Angew. Math. Phys." }

% Publishers % ================================================= |

 @String{Academic = "Academic Press" }
 @String{ACMPress = "{ACM} Press" }
 @String{AdamHilger = "Adam Hilger" }
 @String{AddisonWesley = "Addison-Wesley" }
 @String{AllynBacon = "Allyn and Bacon" }
 @String{AMS = "American Mathematical Society" }
 @String{Birkhauser = "Birkha{\"u}ser" }
 @String{CambridgePress = "Cambridge University Press" }
 @String{Chelsea = "Chelsea" }
 @String{ClaredonPress = "Claredon Press" }
 @String{DoverPub = "Dover Publications" }
 @String{Eyolles = "Eyolles" }
 @String{HoltRinehartWinston = "Holt, Rinehart and Winston" }
 @String{Interscience = "Interscience" }
 @String{JohnsHopkinsPress = "The Johns Hopkins University Press" }
 @String{JohnWileySons = "John Wiley and Sons" }
 @String{Macmillan = "Macmillan" }
 @String{MathWorks = "The Math Works Inc." }
 @String{McGrawHill = "McGraw-Hill" }
 @String{NatBurStd = "National Bureau of Standards" }
 @String{NorthHolland = "North-Holland" }
 @String{OxfordPress = "Oxford University Press" }  %address Oxford or London?
 @String{PergamonPress = "Pergamon Press" }
 @String{PlenumPress = "Plenum Press" }
 @String{PrenticeHall = "Prentice-Hall" }
 @String{SIAMPub = "{SIAM} Publications" }
 @String{Springer = "Springer-Verlag" }
 @String{TexasPress = "University of Texas Press" }
 @String{VanNostrand = "Van Nostrand" }
 @String{WHFreeman = "W. H. Freeman and Co." }

%Entries

@Article{Abril07,
  author        = "Patricia S. Abril and Robert Plant",
  title         = "The patent holder's dilemma: Buy, sell, or troll?",
  journal       = "Communications of the ACM",
  volume        = "50",
  number        = "1",
  month         = jan,
  year          = "2007",
  pages         = "36--44",
  doi           = "10.1145/1188913.1188915",
  url           = "http://doi.acm.org/10.1145/1219092.1219093",
  note          = "",
}

@Article{Cohen07,
  author        = "Sarah Cohen and Werner Nutt and Yehoshua Sagic",
  title         = "Deciding equivalances among conjunctive aggregate queries",
  journal       = JACM,
  articleno     = "5",
  numpages      = "50",
  volume        = "54",
  number        = "2",
  month         = apr,
  year          = "2007",
  doi           = "10.1145/1219092.1219093",
  url           = "http://doi.acm.org/10.1145/1219092.1219093",
  acmid         = "1219093",
  note          = "",
}


@periodical{JCohen96,
  key =          "Cohen",
  editor =       "Jacques Cohen",
  title =        "Special issue: Digital Libraries",
  journal =      CACM,
  volume =       "39",
  number =       "11",
  month =        nov,
  year =         "1996",
}


@Book{Kosiur01,
  author =       "David Kosiur",
  title =        "Understanding Policy-Based Networking",
  publisher =    "Wiley",
  year =         "2001",
  address =      "USA",
  edition =      "2.",
  editor =       "",
  volume =       "",
  number =       "",
  series =       "",
  month =        "",
  note =         "",
}


@Book{Harel79,
  author =       "David Harel",
  year =         "1979",
  title =        "First-Order Dynamic Logic",
  series =       "Lecture Notes in Computer Science",
  volume =       "68",
  address =      "New York, NY",
  publisher =    "Springer-Verlag",
  doi =          "10.1007/3-540-09237-4",
  url =          "http://dx.doi.org/10.1007/3-540-09237-4",
  editor =       "",
  number =       "",
  month =        "",
  note =         "",
}

@inbook{Editor00,
  author       = {Peter Eston}, 
  title        = {The title of the work},
  chapter      = 8,
  pages        = {201-213},
  publisher    = {The name of the publisher},
  doi =          "10.1007/3-540-09237-4",
  year         = 1993,
  volume       = 4,
  series       = 5,
  address      = {The address of the publisher},
  edition      = 3,
  month        = 7,
  note         = {An optional note}
}

%
@InBook{Editor00a,
  author =       "",
  editor =       "Ian Editor",
  title =        "The title of book two",
  subtitle =     "The book subtitle",
  series =       "The name of the series two",
  year =         "2008",
  address =      "Chicago",
  edition =      "2nd.",
  publisher =    "University of Chicago Press",
  doi =          "10.1007/3-540-09237-4",
  url =          "http://dx.doi.org/10.1007/3-540-09456-9",
  volume =       "",
  chapter =      "100",
  pages        = {201-213},
  number =       "",
  type =         "",
  month =        "",
  note =         "",
}


% incollection (has an editor, title, and possibly a booktitle)
@Incollection{Spector90,
  author =       "Asad Z. Spector",
  title =        "Achieving application requirements",
  booktitle =    "Distributed Systems",
  publisher =    "ACM Press",
  address =      "New York, NY",
  year =         "1990",
  edition =      "2nd.",
  chapter =      "",
  editor =       "Sape Mullender",
  pages =        "19--33",
  doi =          "10.1145/90417.90738",
  url =          "http://doi.acm.org/10.1145/90417.90738",
  volume =       "",
  number =       "",
  series =       "",
  type =         "",
  month =        "",
  note =         "",
}


% incollection (has an editor, title, and possibly a booktitle)
@Incollection{Douglass98,
  author =       "Bruce P. Douglass and David Harel and Mark B. Trakhtenbrot",
  title =        "Statecarts in use: structured analysis and object-orientation",
  series =       "Lecture Notes in Computer Science",
  booktitle =    "Lectures on Embedded Systems",
  publisher =    "Springer-Verlag",
  address =      "London",
  volume =       "1494",
  year =         "1998",
  chapter =      "",
  editor =       "Grzegorz Rozenberg and Frits W. Vaandrager",
  pages =        "368--394",
  doi =          "10.1007/3-540-65193-4_29",
  url =          "http://dx.doi.org/10.1007/3-540-65193-4_29",
  edition =      "",
  number =       "",
  type =         "",
  month =        "",
  note =         "",
}


@Book{Knuth97,
  author =       "Donald E. Knuth",
  title =        "The Art of Computer Programming, Vol. 1: Fundamental Algorithms (3rd. ed.)",
  publisher =    "Addison Wesley Longman Publishing Co., Inc.",
  year =         "1997",
  address =      "USA",
  edition =      "",
  editor =       "",
  volume =       "",
  number =       "",
  series =       "",
  month =        "",
  note =         "",
}


@Book{Knuth98,
  author =       "Donald E. Knuth",
  year =         "1998",
  title =        "The Art of Computer Programming",
  series =       "Fundamental Algorithms",
  volume =       "1",
  edition =      "3rd",
  address =      "",
  publisher =    "Addison Wesley Longman Publishing Co., Inc.",
  doi =          "",
  url =          "",
  editor =       "",
  number =       "",
  month =        "",
  note =         "(book)",
}

%Inbook{Knuth97,
%  author =       "Donald E. Knuth",
%  title =        "The Art of Computer Programming",
%  booktitle =    "the booktitle",
%  edition =      "3",
%  volume =       "1",
%  year =         "1997",
%  publisher =    "Addison Wesley Longman Publishing Co., Inc.",
%  editor =       "",
%  number =       "",
%  series =       "Fundamental Algorithms",
%  type =         "",
%  chapter =      "",
%  pages =        "",
%  address =      "",
%  month =        "",
%  note =         "(inbook)",
%}

%INBOOK{DK:73-inbook-full,
%   author = "Donald E. Knuth",
%   title = "Fundamental Algorithms (inbook w series)",
%   volume = 1,
%   series = "The Art of Computer Programming",
%   publisher = "Addison-Wesley",
%   address = "Reading, Massachusetts",
%   edition = "Second",
%   month = "10~" # jan,
%   year = "1973",
%   type = "Section",
%   chapter = "1.2",
%   pages = "10--119",
%   note = "Full INBOOK entry (w series)",
%}

%INcollection{DK:74-incoll,
%   author = "Donald E. Knuth",
%   title = "Fundamental Algorithms (incoll)",
%   volume = 1,
%   booktitle = "The Art of Computer Programming",
%   publisher = "Addison-Wesley",
%   address = "Reading, Massachusetts",
%   month = "10~" # jan,
%   year = "1974",
%   pages = "10--119",
%   editor = "Bernard Rous",
%   note = "This is a full incoll entry with an editor",
%}

%INcollection{DK:75-incollws,
%   author = "Donald E. Knuth",
%   title = "Fundamental Algorithms (incoll w series)",
%   volume = 1,
%   booktitle = "The Art of Computer Programming",
%   series = "The Art of Computer Programming",
%   publisher = "Addison-Wesley",
%   address = "Reading, Massachusetts",
%   month = "10~" # jan,
%   year = "1975",
%   pages = "10--119",
%   editor = "Bernard Rous",
%   note = "This is a full incoll entry with an editor and series",
%}


@incollection{GM05,
Author= "Dan Geiger and Christopher Meek",
Title= "Structured Variational Inference Procedures and their Realizations (as incol)",
Year= 2005,
Booktitle="Proceedings of Tenth International Workshop on Artificial Intelligence and Statistics, {\rm The Barbados}",
Publisher="The Society for Artificial Intelligence and Statistics",
Month= jan,
Editors= "Z. Ghahramani and R. Cowell"
}

@Inproceedings{Smith10,
  author =       "Stan W. Smith",
  title =        "An experiment in bibliographic mark-up: Parsing metadata for XML export",
  booktitle =    "Proceedings of the 3rd. annual workshop on Librarians and Computers",
  series =       "LAC '10",
  editor =       "Reginald N. Smythe and Alexander Noble",
  volume =       "3",
  year =         "2010",
  publisher =    "Paparazzi Press",
  address =      "Milan Italy",
  pages =        "422--431",
  doi =          "10.1038/nphys1170",
  url =          "https://dx.doi.org/10.1038/nphys1170",
  number =       "",
  month =        "",
  organization = "",
  note =         "",
}

@Inproceedings{VanGundy07,
  author =       "Matthew Van Gundy and Davide Balzarotti and Giovanni Vigna",
  year =         "2007",
  title =        "Catch me, if you can: Evading network signatures with web-based polymorphic worms",
  booktitle =    "Proceedings of the first USENIX workshop on Offensive Technologies",
  series =       "WOOT '07",
  publisher =    "USENIX Association",
  address =      "Berkley, CA",
  articleno =    "7",
  numpages =     "9",
  editor =       "",
  volume =       "",
  number =       "",
  pages =        "",
  month =        "",
  organization = "",
  note =         "",
}

@Inproceedings{VanGundy08,
  author =       "Matthew Van Gundy and Davide Balzarotti and Giovanni Vigna",
  year =         "2008",
  title =        "Catch me, if you can: Evading network signatures with web-based polymorphic worms",
  booktitle =    "Proceedings of the first USENIX workshop on Offensive Technologies",
  series =       "WOOT '08",
  publisher =    "USENIX Association",
  address =      "Berkley, CA",
  articleno =    "7",
  numpages =     "2",
  editor =       "",
  volume =       "",
  number =       "",
  pages =        "99-100",
  month =        "",
  organization = "",
  note =         "",
}

@Inproceedings{VanGundy09,
  author =       "Matthew Van Gundy and Davide Balzarotti and Giovanni Vigna",
  year =         "2009",
  title =        "Catch me, if you can: Evading network signatures with web-based polymorphic worms",
  booktitle =    "Proceedings of the first USENIX workshop on Offensive Technologies",
  series =       "WOOT '09",
  publisher =    "USENIX Association",
  address =      "Berkley, CA",
  articleno =    "",
  numpages =     "",
  editor =       "",
  volume =       "",
  number =       "",
  pages =        "90--100",
  month =        "",
  organization = "",
  note =         "",
}

@Inproceedings{Andler79,
  author =       "Sten Andler",
  title =        "Predicate Path expressions",
  booktitle =    "Proceedings of the 6th. ACM SIGACT-SIGPLAN symposium on Principles of Programming Languages",
  series =       "POPL '79",
  year =         "1979",
  publisher =    "ACM Press",
  address =      "New York, NY",
  pages =        "226--236",
  doi =          "10.1145/567752.567774",
  url =          "http://doi.acm.org/10.1145/567752.567774",
  editor =       "",
  volume =       "",
  number =       "",
  month =        "",
  organization = "",
  note =         "",
}

@Techreport{Harel78,
  author =       "David Harel",
  year =         "1978",
  title =        "LOGICS of Programs: AXIOMATICS and DESCRIPTIVE POWER",
  institution =  "Massachusetts Institute of Technology",
  type =         "MIT Research Lab Technical Report",
  number =       "TR-200",
  address =      "Cambridge, MA",
  month =        "",
  note =         "",
}

@MASTERSTHESIS{anisi03,
author = {David A. Anisi},
title = {Optimal Motion Control of a Ground Vehicle},
school = {Royal Institute of Technology (KTH), Stockholm, Sweden},
intitution = {FOI-R-0961-SE, Swedish Defence Research Agency (FOI)},
year = {2003},
}


@Phdthesis{Clarkson85,
  author =       "Kenneth L. Clarkson",
  year =         "1985",
  title =        "Algorithms for Closest-Point Problems (Computational Geometry)",
  school =       "Stanford University",
  address =      "Palo Alto, CA",
  note =         "UMI Order Number: AAT 8506171",
  type =         "",
  month =        "",
}


@online{Thornburg01,
  author =       "Harry Thornburg",
  year =         "2001",
  title =        "Introduction to Bayesian Statistics",
  url =          "http://ccrma.stanford.edu/~jos/bayes/bayes.html",
  organization = "Stanford University",
  month =        mar,
  lastaccessed = "March 2, 2005",
}


@online{Ablamowicz07,
  author =       "Rafal Ablamowicz and Bertfried Fauser",
  year =         "2007",
  title =        "CLIFFORD: a Maple 11 Package for Clifford Algebra Computations, version 11",
  url =          "http://math.tntech.edu/rafal/cliff11/index.html",
  lastaccessed = "February 28, 2008",
  organization = "Tennessee Technological University",
}


@misc{Poker06,
  author =       "Poker-Edge.Com",
  year =         "2006",
  month =        mar,
  title =        "Stats and Analysis",
  lastaccessed = "June 7, 2006",
  url =          "http://www.poker-edge.com/stats.php",
}

@misc{Obama08,
  author        = "Barack Obama",
  year          = "2008",
  title         = "A more perfect union",
  howpublished  = "Video",
  day           = "5",
  url           = "http://video.google.com/videoplay?docid=6528042696351994555",
  month         = mar,
  lastaccessed  = "March 21, 2008",
  note          =  "",
}

@misc{JoeScientist001,
  author =       "Joseph Scientist",
  year =         "2009",
  title =        "The fountain of youth",
  note =         "Patent No. 12345, Filed July 1st., 2008, Issued Aug. 9th., 2009",
  url =          "",
  howpublished = "",
  month =        aug,
  lastaccessed = "",
}


@Inproceedings{Novak03,
  author =       "Dave Novak",
  title =        "Solder man",
  booktitle =    "ACM SIGGRAPH 2003 Video Review on Animation theater Program: Part I - Vol. 145 (July 27--27, 2003)",
  year =         "2003",
  publisher =    "ACM Press",
  address =      "New York, NY",
  pages =        "4",
  month =        "March 21, 2008",
  doi =          "99.9999/woot07-S422",
  url =          "http://video.google.com/videoplay?docid=6528042696351994555",
  note =         "",
  howpublished = "Video",
  editor =       "",
  volume =       "",
  number =       "",
  series =       "",
  organization = "",
}


@article{Lee05,
  author =       "Newton Lee",
  year =         "2005",
  title =        "Interview with Bill Kinder: January 13, 2005",
  journal =      "Comput. Entertain.",
  eid =          "4",
  volume =       "3",
  number =       "1",
  month =        "Jan.-March",
  doi =          "10.1145/1057270.1057278",
  url =          "http://doi.acm.org/10.1145/1057270.1057278",
  howpublished = "Video",
  note =         "",
}

@article{Rous08,
  author =       "Bernard Rous",
  year =         "2008",
  title =        "The Enabling of Digital Libraries",
  journal =      "Digital Libraries",
  volume =       "12",
  number =       "3",
  month =        jul,
  articleno =    "5",
  doi =          "",
  url =          "",
  howpublished = "",
  note =         "To appear",
}

@article{384253,
 author = {Werneck,, Renato and Setubal,, Jo\~{a}o and da Conceic\~{a}o,, Arlindo},
 title = {(old) Finding minimum congestion spanning trees},
 journal = {J. Exp. Algorithmics},
 volume = {5},
 year = {2000},
 issn = {1084-6654},
 pages = {11},
 doi = {http://doi.acm.org/10.1145/351827.384253},
 publisher = {ACM},
 address = {New York, NY, USA},
 }


@article{Werneck:2000:FMC:351827.384253,
 author = {Werneck, Renato and Setubal, Jo\~{a}o and da Conceic\~{a}o, Arlindo},
 title = {(new) Finding minimum congestion spanning trees},
 journal = {J. Exp. Algorithmics},
 volume = {5},
 month = dec,
 year = {2000},
 issn = {1084-6654},
 articleno = {11},
 url = {http://portal.acm.org/citation.cfm?id=351827.384253},
 doi = {10.1145/351827.384253},
 acmid = {384253},
 publisher = {ACM},
 address = {New York, NY, USA},
}

@article{1555162,
 author = {Conti, Mauro and Di Pietro, Roberto and Mancini, Luigi V. and Mei, Alessandro},
 title = {(old) Distributed data source verification in wireless sensor networks},
 journal = {Inf. Fusion},
 volume = {10},
 number = {4},
 year = {2009},
 issn = {1566-2535},
 pages = {342--353},
 doi = {http://dx.doi.org/10.1016/j.inffus.2009.01.002},
 publisher = {Elsevier Science Publishers B. V.},
 address = {Amsterdam, The Netherlands, The Netherlands},
 }

@article{Conti:2009:DDS:1555009.1555162,
 author = {Conti, Mauro and Di Pietro, Roberto and Mancini, Luigi V. and Mei, Alessandro},
 title = {(new) Distributed data source verification in wireless sensor networks},
 journal = {Inf. Fusion},
 volume = {10},
 number = {4},
 month = oct,
 year = {2009},
 issn = {1566-2535},
 pages = {342--353},
 numpages = {12},
 url = {http://portal.acm.org/citation.cfm?id=1555009.1555162},
 doi = {10.1016/j.inffus.2009.01.002},
 acmid = {1555162},
 publisher = {Elsevier Science Publishers B. V.},
 address = {Amsterdam, The Netherlands, The Netherlands},
 keywords = {Clone detection, Distributed protocol, Securing data fusion, Wireless sensor networks},
}

@inproceedings{Li:2008:PUC:1358628.1358946,
 author = {Li, Cheng-Lun and Buyuktur, Ayse G. and Hutchful, David K. and Sant, Natasha B. and Nainwal, Satyendra K.},
 title = {Portalis: using competitive online interactions to support aid initiatives for the homeless},
 booktitle = {CHI '08 extended abstracts on Human factors in computing systems},
 year = {2008},
 isbn = {978-1-60558-012-X},
 location = {Florence, Italy},
 pages = {3873--3878},
 numpages = {6},
 url = {http://portal.acm.org/citation.cfm?id=1358628.1358946},
 doi = {10.1145/1358628.1358946},
 acmid = {1358946},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {cscw, distributed knowledge acquisition, incentive design, online games, recommender systems, reputation systems, user studies, virtual community},
}

@book{Hollis:1999:VBD:519964,
 author = {Hollis, Billy S.},
 title = {Visual Basic 6: Design, Specification, and Objects with Other},
 year = {1999},
 isbn = {0130850845},
 edition = {1st},
 publisher = {Prentice Hall PTR},
 address = {Upper Saddle River, NJ, USA},
 }


@book{Goossens:1999:LWC:553897,
 author = {Goossens, Michel and Rahtz, S. P. and Moore, Ross and Sutor, Robert S.},
 title = {The  Latex Web Companion: Integrating TEX, HTML, and XML},
 year = {1999},
 isbn = {0201433117},
 edition = {1st},
 publisher = {Addison-Wesley Longman Publishing Co., Inc.},
 address = {Boston, MA, USA},
 }

% need to test genres for errant isbn output

% techreport
@techreport{897367,
 author = {Buss, Jonathan F. and Rosenberg, Arnold L. and Knott, Judson D.},
 title = {Vertex Types in Book-Embeddings},
 year = {1987},
 source = {http://www.ncstrl.org:8900/ncstrl/servlet/search?formname=detail\&id=oai%3Ancstrlh%3Aumass_cs%3Ancstrl.umassa_cs%2F%2FUM-CS-1987-018},
 publisher = {University of Massachusetts},
 address = {Amherst, MA, USA},
 }

@techreport{Buss:1987:VTB:897367,
 author = {Buss, Jonathan F. and Rosenberg, Arnold L. and Knott, Judson D.},
 title = {Vertex Types in Book-Embeddings},
 year = {1987},
 source = {http://www.ncstrl.org:8900/ncstrl/servlet/search?formname=detail\&id=oai%3Ancstrlh%3Aumass_cs%3Ancstrl.umassa_cs%2F%2FUM-CS-1987-018},
 publisher = {University of Massachusetts},
 address = {Amherst, MA, USA},
 }

% whole proceedings

@proceedings{Czerwinski:2008:1358628,
 author = {},
 note = {General Chair-Czerwinski, Mary and General Chair-Lund, Arnie and Program Chair-Tan, Desney},
 title = {CHI '08: CHI '08 extended abstracts on Human factors in computing systems},
 year = {2008},
 isbn = {978-1-60558-012-X},
 location = {Florence, Italy},
 order_no = {608085},
 publisher = {ACM},
 address = {New York, NY, USA},
 }

% phdthesis

@phdthesis{Clarkson:1985:ACP:911891,
 author = {Clarkson, Kenneth Lee},
 advisor = {Yao, Andrew C.},
 title = {Algorithms for Closest-Point Problems (Computational Geometry)},
 year = {1985},
 note = {AAT 8506171},
 school = {Stanford University},
 address = {Stanford, CA, USA},
 }
% school is being picked up -- but not publisher (which is OK)
% Also -- the title is NOT being output in italics !!! Arrrrgh! - I fixed it. :-)


%%% compare with 'old'
%%% atsign-Phdthesis{Clarkson85,
%%%  author =       "Kenneth L. Clarkson",
%%%  year =         "1985",
%%%  title =        "Algorithms for Closest-Point Problems (Computational Geometry)",
%%%  school =       "Stanford University",
%%%  address =      "Palo Alto, CA",
%%%  note =         "UMI Order Number: AAT 8506171",
%%%  type =         "",
%%%  month =        "",
%%%}

% A bibliography
@Article{1984:1040142,
 key = {{$\!\!$}},
 journal = {SIGCOMM Comput. Commun. Rev.},
 year = {1984},
 issn = {0146-4833},
 volume = {13-14},
 number = {5-1},
 issue_date = {January/April 1984},
 publisher = {ACM},
 address = {New York, NY, USA},
 }


% grinder
@inproceedings{2004:ITE:1009386.1010128,
 key = {IEEE},
 title = {IEEE TCSC Executive Committee},
 booktitle = {Proceedings of the IEEE International Conference on Web Services},
 series = {ICWS '04},
 year = {2004},
 isbn = {0-7695-2167-3},
 pages = {21--22},
 url = {http://dx.doi.org/10.1109/ICWS.2004.64},
 doi = {http://dx.doi.org/10.1109/ICWS.2004.64},
 acmid = {1010128},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
}

% div book
@book{Mullender:1993:DS(:302430,
 editor = {Mullender, Sape},
 title = {Distributed systems (2nd Ed.)},
 year = {1993},
 isbn = {0-201-62427-3},
 publisher = {ACM Press/Addison-Wesley Publishing Co.},
 address = {New York, NY, USA},
 }

% master thesis (as techreport and thesis)

@techreport{Petrie:1986:NAD:899644,
 author = {Petrie, Charles J.},
 title = {New Algorithms for Dependency-Directed Backtracking (Master's thesis)},
 year = {1986},
 source = {http://www.ncstrl.org:8900/ncstrl/servlet/search?formname=detail\&id=oai%3Ancstrlh%3Autexas_cs%3AUTEXAS_CS%2F%2FAI86-33},
 publisher = {University of Texas at Austin},
 address = {Austin, TX, USA},
 }

@MASTERSTHESIS{Petrie:1986:NAD:12345,
 author = {Petrie, Charles J.},
 title = {New Algorithms for Dependency-Directed Backtracking (Master's thesis)},
 year = {1986},
 source = {http://www.ncstrl.org:8900/ncstrl/servlet/search?formname=detail\&id=oai%3Ancstrlh%3Autexas_cs%3AUTEXAS_CS%2F%2FAI86-33},
 school = {University of Texas at Austin},
 address = {Austin, TX, USA},
 }




@BOOK{book-minimal,
   author = "Donald E. Knuth",
   title = "Seminumerical Algorithms",
   publisher = "Addison-Wesley",
   year = "1981",
}

% incollection (has an editor, title, and possibly a booktitle)
@INcollection{KA:2001,
 author = {Kong, Wei-Chang},
 Title = {The implementation of electronic commerce in SMEs in Singapore (as Incoll)},
 booktitle = {E-commerce and cultural values},
 year = {2001},
 isbn = {1-59140-056-2},
 pages = {51--74},
 numpages = {24},
 url = {http://portal.acm.org/citation.cfm?id=887006.887010},
 acmid = {887010},
 publisher = {IGI Publishing},
 address = {Hershey, PA, USA},
}


% with bibfield 'type' before chapter (note no editor)
@INBOOK{KAGM:2001,
 author = {Kong, Wei-Chang},
 type = {Name of Chapter:},
 chapter = {The implementation of electronic commerce in SMEs in Singapore (Inbook-w-chap-w-type)},
 title = {E-commerce and cultural values},
 year = {2001},
 isbn = {1-59140-056-2},
 pages = {51--74},
 numpages = {24},
 url = {http://portal.acm.org/citation.cfm?id=887006.887010},
 acmid = {887010},
 publisher = {IGI Publishing},
 address = {Hershey, PA, USA},
}

%%% Notes! This is because the atsign-INBOOK citation type specifies EITHER
%%% editor or author, but not both. In my experiments with the harvard/dcu
%%% bibtex style (and presumably this applies to other styles too), bibtex
%%% ignores the editor information if author information exists in an
%%% atsign-INBOOK entry. atsign-INCOLLECTION is far more commonly used in my references,
%%% and in the absence of an editor I believe most bibtex styles will just
%%% ommit the editor from the reference - the chapter information will not
%%% end up in the in-text citation as you suggest it should be but at least
%%% there is a place to put the editor if necessary.



% was 'Inbook' -- changed to incollection - (editor is different to author) - need to tell Asad to codify as such.
@incollection{Kong:2002:IEC:887006.887010,
  author =      {Kong, Wei-Chang},
  editor =      {Theerasak Thanasankit},
  title =       {Chapter 9},
  booktitle =   {E-commerce and cultural values (Incoll-w-text (chap 9) 'title')},
  year =        {2002},
  address =     {Hershey, PA, USA},
  publisher =   {IGI Publishing},
  url =         {http://portal.acm.org/citation.cfm?id=887006.887010},
  pages =       {51--74},
  numpages =    {24},
  acmid =       {887010},
  isbn =        {1-59140-056-2},
  number =      "",
  type =        "",
  month =       "",
  note =        "",
}

% incol when the chapter is 'text' - due to presence of editor (different to author)
@incollection{Kong:2003:IEC:887006.887011,
 author = {Kong, Wei-Chang},
 title = {The implementation of electronic commerce in SMEs in Singapore (Incoll)},
 booktitle = {E-commerce and cultural values},
 editor = {Thanasankit, Theerasak},
 year = {2003},
 isbn = {1-59140-056-2},
 pages = {51--74},
 numpages = {24},
 url = {http://portal.acm.org/citation.cfm?id=887006.887010},
 acmid = {887010},
 publisher = {IGI Publishing},
 address = {Hershey, PA, USA},
}

% ------ test
%incollection{Kong:2003:IEC:887006.887010,
% author = {Kong, Wei-Chang},
% chapter = {The implementation of electronic commerce in SMEs in Singapore (Incoll-text-in-chap)},
% booktitle = {booktitle E-commerce and cultural values},
% title =   {The title},
% editor = {Thanasankit, Theerasak},
% year = {2003},
% isbn = {1-59140-056-2},
% pages = {51--74},
% numpages = {24},
% url = {http://portal.acm.org/citation.cfm?id=887006.887010},
% acmid = {887010},
% publisher = {IGI Publishing},
% address = {Hershey, PA, USA},
%}


% ---------





% Need inbook with num in chapter

% and inbook with number in chapter
@InBook{Kong:2004:IEC:123456.887010,
  author =      {Kong, Wei-Chang},
  editor =      {Theerasak Thanasankit},
  title =       {E-commerce and cultural values - (InBook-num-in-chap)},
  chapter =     {9},
  year =        {2004},
  address =     {Hershey, PA, USA},
  publisher =   {IGI Publishing},
  url =         {http://portal.acm.org/citation.cfm?id=887006.887010},
  pages =       {51--74},
  numpages =    {24},
  acmid =       {887010},
  isbn =        {1-59140-056-2},
  number =      "",
  type =        "",
  month =       "",
  note =        "",
}


% and inbook with text in chapter
@Inbook{Kong:2005:IEC:887006.887010,
  author =      {Kong, Wei-Chang},
  editor =      {Theerasak Thanasankit},
  title =       {E-commerce and cultural values (Inbook-text-in-chap)},
  chapter =     {The implementation of electronic commerce in SMEs in Singapore},
  year =        {2005},
  address =     {Hershey, PA, USA},
  publisher =   {IGI Publishing},
  url =         {http://portal.acm.org/citation.cfm?id=887006.887010},
  type =        {Chapter:},
  pages =       {51--74},
  numpages =    {24},
  acmid =       {887010},
  isbn =        {1-59140-056-2},
  number =      "",
  month =       "",
  note =        "",
}


% and inbook with a num and type field
@Inbook{Kong:2006:IEC:887006.887010,
  author =      {Kong, Wei-Chang},
  editor =      {Theerasak Thanasankit},
  title =       {E-commerce and cultural values (Inbook-num chap)},
  chapter =     {22},
  year =        {2006},
  address =     {Hershey, PA, USA},
  publisher =   {IGI Publishing},
  url =         {http://portal.acm.org/citation.cfm?id=887006.887010},
  type =        {Chapter (in type field)},
  pages =       {51--74},
  numpages =    {24},
  acmid =       {887010},
  isbn =        {1-59140-056-2},
  number =      "",
  month =       "",
  note =        "",
}


% and incol coz we have a BLANK chapter - due to presence of editor
%atIncollection{Kong:2006:IEC:887006.887011,
%  author =     {Kong, Wei-Chang},
%  editor =     {Theerasak Thanasankit},
%  title =      "The title"
%  booktitle =  {E-commerce and cultural values (Incol-coz-blank-chap)},
%  year =       {2006},
%  address =    {Hershey, PA, USA},
%  publisher =  {IGI Publishing},
%  url =        {http://portal.acm.org/citation.cfm?id=887006.887010},
%  type =       {Type!},
%  chapter =    {},
%  pages =      {51--74},
%  numpages =   {24},
%  acmid =      {887010},
%  isbn =       {1-59140-056-2},
%  number =     "",
%  month =      "",
%  note =       "",
%}

@article{SaeediMEJ10,
            author = {Mehdi Saeedi and Morteza Saheb Zamani and Mehdi Sedighi},
            title = {A library-based synthesis methodology for reversible logic},
            journal = {Microelectron. J.},
            volume = {41},
            number = {4},
            month = apr,
            year = {2010},
            pages = {185--194},
}

@ARTICLE{SaeediJETC10,
            author = {Mehdi Saeedi and Morteza Saheb Zamani and Mehdi Sedighi and Zahra Sasanian},
            title = {Synthesis of Reversible Circuit Using Cycle-Based Approach},
            journal = {J. Emerg. Technol. Comput. Syst.},
            volume = {6},
            number = {4},
            month = dec,
            year = {2010}
            }

% Asad's new version
@article{Kirschmer:2010:AEI:1958016.1958018,
 author = {Kirschmer, Markus and Voight, John},
 title = {Algorithmic Enumeration of Ideal Classes for Quaternion Orders},
 journal = {SIAM J. Comput.},
 issue_date = {January 2010},
 volume = {39},
 number = {5},
 month = jan,
 year = {2010},
 issn = {0097-5397},
 pages = {1714--1747},
 numpages = {34},
 url = {http://dx.doi.org/10.1137/080734467},
 doi = {https://doi.org/10.1137/080734467},
 acmid = {1958018},
 publisher = {Society for Industrial and Applied Mathematics},
 address = {Philadelphia, PA, USA},
 keywords = {ideal classes, maximal orders, number theory, quaternion algebras},
}


% incol due to presence of booktitle
@incollection{Hoare:1972:CIN:1243380.1243382,
 author = {Hoare, C. A. R.},
 title = {Chapter II: Notes on data structuring},
 booktitle = {Structured programming (incoll)},
 editor = {Dahl, O. J. and Dijkstra, E. W. and Hoare, C. A. R.},
 year = {1972},
 isbn = {0-12-200550-3},
 pages = {83--174},
 numpages = {92},
 url = {http://portal.acm.org/citation.cfm?id=1243380.1243382},
 acmid = {1243382},
 publisher = {Academic Press Ltd.},
 address = {London, UK, UK},
}

% incol due to presence of booktitle
@incollection{Lee:1978:TQA:800025.1198348,
 author = {Lee, Jan},
 title = {Transcript of question and answer session},
 booktitle = {History of programming languages I (incoll)},
 editor = {Wexelblat, Richard L.},
 year = {1981},
 isbn = {0-12-745040-8},
 pages = {68--71},
 numpages = {4},
 url = {http://doi.acm.org/10.1145/800025.1198348},
 doi = {http://doi.acm.org/10.1145/800025.1198348},
 acmid = {1198348},
 publisher = {ACM},
 address = {New York, NY, USA},
}

% incol due to booktitle
@incollection{Dijkstra:1979:GSC:1241515.1241518,
 author = {Dijkstra, E.},
 title = {Go to statement considered harmful},
 booktitle = {Classics in software engineering (incoll)},
 year = {1979},
 isbn = {0-917072-14-6},
 pages = {27--33},
 numpages = {7},
 url = {http://portal.acm.org/citation.cfm?id=1241515.1241518},
 acmid = {1241518},
 publisher = {Yourdon Press},
 address = {Upper Saddle River, NJ, USA},
}

% incol due to booktitle
@incollection{Wenzel:1992:TVA:146022.146089,
 author = {Wenzel, Elizabeth M.},
 title = {Three-dimensional virtual acoustic displays},
 booktitle = {Multimedia interface design (incoll)},
 year = {1992},
 isbn = {0-201-54981-6},
 pages = {257--288},
 numpages = {32},
 url = {http://portal.acm.org/citation.cfm?id=146022.146089},
 doi = {10.1145/146022.146089},
 acmid = {146089},
 publisher = {ACM},
 address = {New York, NY, USA},
}

% incol due to booktitle
@incollection{Mumford:1987:MES:54905.54911,
 author = {Mumford, E.},
 title = {Managerial expert systems and organizational change: some critical research issues},
 booktitle = {Critical issues in information systems research (incoll)},
 year = {1987},
 isbn = {0-471-91281-6},
 pages = {135--155},
 numpages = {21},
 url = {http://portal.acm.org/citation.cfm?id=54905.54911},
 acmid = {54911},
 publisher = {John Wiley \& Sons, Inc.},
 address = {New York, NY, USA},
}

@book{McCracken:1990:SSC:575315,
 author = {McCracken, Daniel D. and Golden, Donald G.},
 title = {Simplified Structured COBOL with Microsoft/MicroFocus COBOL},
 year = {1990},
 isbn = {0471514071},
 publisher = {John Wiley \& Sons, Inc.},
 address = {New York, NY, USA},
}

% Let's include Boris / BBeeton entries  (multi-volume works)

@book {MR781537,
    AUTHOR = {H{\"o}rmander, Lars},
     TITLE = {The analysis of linear partial differential operators. {III}},
    SERIES = {Grundlehren der Mathematischen Wissenschaften [Fundamental
              Principles of Mathematical Sciences]},
    VOLUME = {275},
      NOTE = {Pseudodifferential operators},
PUBLISHER = {Springer-Verlag},
   ADDRESS = {Berlin, Germany},
      YEAR = {1985},
     PAGES = {viii+525},
      ISBN = {3-540-13828-5},
   MRCLASS = {35-02 (35Sxx 47G05 58G15)},
  MRNUMBER = {781536 (87d:35002a)},
MRREVIEWER = {Min You Qi},
}

@book {MR781536,
    AUTHOR = {H{\"o}rmander, Lars},
     TITLE = {The analysis of linear partial differential operators. {IV}},
    SERIES = {Grundlehren der Mathematischen Wissenschaften [Fundamental
              Principles of Mathematical Sciences]},
    VOLUME = {275},
      NOTE = {Fourier integral operators},
PUBLISHER = {Springer-Verlag},
   ADDRESS = {Berlin, Germany},
      YEAR = {1985},
     PAGES = {vii+352},
      ISBN = {3-540-13829-3},
   MRCLASS = {35-02 (35Sxx 47G05 58G15)},
  MRNUMBER = {781537 (87d:35002b)},
MRREVIEWER = {Min You Qi},
}

%%%%%%%%%%%%%%%%%%%%%% Start of Aptara sample bib entries

% acmsmall-sam.bib
@InProceedings{Adya-01,
  author        = {A. Adya and P. Bahl and J. Padhye and A.Wolman and L. Zhou},
  title         = {A multi-radio unification protocol for {IEEE} 802.11 wireless networks},
  booktitle     = {Proceedings of the IEEE 1st International Conference on Broadnets Networks (BroadNets'04)},
  publisher     = "IEEE",
  address       = "Los Alamitos, CA",
  year          = {2004},
  pages         = "210--217"
}

@article{Akyildiz-01,
  author        = {I. F. Akyildiz and W. Su and Y. Sankarasubramaniam and E. Cayirci},
  title         = {Wireless Sensor Networks: A Survey},
  journal       = {Comm. ACM},
  volume        = 38,
  number        = "4",
  year          = {2002},
  pages         = "393--422"
}

@article{Akyildiz-02,
  author        = {I. F. Akyildiz and T. Melodia and K. R. Chowdhury},
  title         = {A Survey on Wireless Multimedia Sensor Networks},
  journal       = {Computer Netw.},
  volume        = 51,
  number        = "4",
  year          = {2007},
  pages         = "921--960"
}

@InProceedings{Bahl-02,
  author        = {P. Bahl and R. Chancre and J. Dungeon},
  title         = {{SSCH}: Slotted Seeded Channel Hopping for Capacity Improvement in {IEEE} 802.11 Ad-Hoc Wireless Networks},
  booktitle     = {Proceeding of the 10th International Conference on Mobile Computing and Networking (MobiCom'04)},
  publisher     = "ACM",
  address       = "New York, NY",
  year          = {2004},
  pages         = "112--117"
}

@misc{CROSSBOW,
  key       = {CROSSBOW},
  title     = {{XBOW} Sensor Motes Specifications},
  note      = {http://www.xbow.com},
  year      = 2008
}

@article{Culler-01,
  author        = {D. Culler and D. Estrin and M. Srivastava},
  title         = {Overview of Sensor Networks},
  journal       = {IEEE Comput.},
  volume        = 37,
  number        = "8 (Special Issue on Sensor Networks)",
  publisher     = "IEEE",
  address       = "Los Alamitos, CA",
  year          = {2004},
  pages         = "41--49"
}

@misc{Harvard-01,
    key         = {Harvard CodeBlue},
    title       = {{CodeBlue}: Sensor Networks for Medical Care},
    note        = {http://www.eecs.harvard.edu/mdw/ proj/codeblue/},
    year        = 2008
}

@InProceedings{Natarajan-01,
    author      = {A. Natarajan and M. Motani and B. de Silva and K. Yap and K. C. Chua},
    title       = {Investigating Network Architectures for Body Sensor Networks},
    booktitle   = {Network Architectures},
    editor      = {G. Whitcomb and P. Neece},
    publisher   = "Keleuven Press",
    address     = "Dayton, OH",
    year        = {2007},
    pages       = "322--328",
    eprint      = "960935712",
    primaryclass = "cs",
}

@techreport{Tzamaloukas-01,
  author        = {A. Tzamaloukas and J. J. Garcia-Luna-Aceves},
  title         = {Channel-Hopping Multiple Access},
  number =        {I-CA2301},
  institution =   {Department of Computer Science, University of California},
  address =       {Berkeley, CA},
  year          = {2000}
}

@BOOK{Zhou-06,
  author        = {G. Zhou and J. Lu and C.-Y. Wan and M. D. Yarvis and J. A. Stankovic},
  title         = {Body Sensor Networks},
  publisher     = "MIT Press",
  address       = "Cambridge, MA",
  year          = {2008}
}

@mastersthesis{ko94,
author = "Jacob Kornerup",
title = "Mapping Powerlists onto Hypercubes",
school = "The University of Texas at Austin",
note = "(In preparation)",
year = "1994"}
%month = "dec",}

@PhdThesis{gerndt:89,
  author =       "Michael Gerndt",
  title =        "Automatic Parallelization for Distributed-Memory
                  Multiprocessing Systems",
  school =       "University of Bonn",
  year =         1989,
  address =      "Bonn, Germany",
  month =        dec
}

@article{6:1:1,
author = "J. E. {Archer, Jr.} and R. Conway and F. B. Schneider",
title = "User recovery and reversal in interactive systems",
journal = "ACM Trans. Program. Lang. Syst.",
volume =  "6",
number = "1",
month = jan,
year = 1984,
pages = "1--19"}

@article{7:1:137,
author = "D. D. Dunlop and V. R. Basili",
title = "Generalizing specifications for uniformly implemented loops",
journal = "ACM Trans. Program. Lang. Syst.",
volume =  "7",
number = "1",
month = jan,
year = 1985,
pages = "137--158"}

@article{7:2:183,
author = "J. Heering and P. Klint",
title = "Towards monolingual programming environments",
journal = "ACM Trans. Program. Lang. Syst.",
volume =  "7",
number = "2",
month = apr,
year = 1985,
pages = "183--213"}

@book{knuth:texbook,
author = "Donald E. Knuth",
title = "The {\TeX{}book}",
publisher = "Addison-Wesley",
address = "Reading, MA.",
year = 1984}

@article{6:3:380,
author = "E. Korach and D.  Rotem and N. Santoro",
title = "Distributed algorithms for finding centers and medians in networks",
journal = "ACM Trans. Program. Lang. Syst.",
volume =  "6",
number = "3",
month = jul,
year = 1984,
pages = "380--401"}

@book{lamport:latex,
author = "Leslie Lamport",
title = "\it {\LaTeX}: A Document Preparation System",
publisher = "Addison-Wesley",
address = "Reading, MA.",
year = 1986}

@article{7:3:359,
author = "F. Nielson",
title = "Program transformations in a denotational setting",
journal = "ACM Trans. Program. Lang. Syst.",
volume =  "7",
number = "3",
month = jul,
year = 1985,
pages = "359--379"}

%testing
@BOOK{test,
   author = "Donald E. Knuth",
   title = "Seminumerical Algorithms",
   volume = 2,
   series = "The Art of Computer Programming",
   publisher = "Addison-Wesley",
   address = "Reading, MA",
   edition = "2nd",
   month = "10~" # jan,
   year = "1981",
}

@inproceedings{reid:scribe,
author = "Brian K. Reid",
title = "A high-level approach to computer document formatting",
booktitle = "Proceedings of the 7th Annual Symposium on Principles of
  Programming Languages",
month = jan,
year = 1980,
publisher = "ACM",
address = "New York",
pages = "24--31"}

@article{Zhou:2010:MMS:1721695.1721705,
 author = {Zhou, Gang and Wu, Yafeng and Yan, Ting and He, Tian and Huang, Chengdu and Stankovic, John A. and Abdelzaher, Tarek F.},
 title = {A multifrequency MAC specially designed for wireless sensor network applications},
 journal = {ACM Trans. Embed. Comput. Syst.},
 issue_date = {March 2010},
 volume = 9,
 number = 4,
 month = {April},
 year = 2010,
 issn = {1539-9087},
 pages = {39:1--39:41},
 articleno = 39,
 numpages = 41,
 url = {http://doi.acm.org/10.1145/1721695.1721705},
 doi = {10.1145/1721695.1721705},
 acmid = 1721705,
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Wireless sensor networks, media access control, multi-channel, radio interference, time synchronization},
}


@online{TUGInstmem,
  key =          {TUG},
  year  =        2017,
  title =        "Institutional members of the {\TeX} Users Group",
  url =          "http://wwtug.org/instmem.html",
  lastaccessed = "May 27, 2017",
}

@online{CTANacmart,
  author =    {Boris Veytsman},
  title =  {acmart---{C}lass for typesetting publications of {ACM}},
  url =    {http://www.ctan.org/pkg/acmart},
  lastaccessed = {May 27, 2017}
  }

@ARTICLE{bowman:reasoning,
    author = {Bowman, Mic and Debray, Saumya K. and Peterson, Larry L.},
    title = {Reasoning About Naming Systems},
    journal = {ACM Trans. Program. Lang. Syst.},
    volume = {15},
    number = {5},
    pages = {795-825},
    month = {November},
    year = {1993},
    doi = {10.1145/161468.161471},
}

@ARTICLE{braams:babel,
    author = {Braams, Johannes},
    title = {Babel, a Multilingual Style-Option System for Use with LaTeX's Standard Document Styles},
    journal = {TUGboat},
    volume = {12},
    number = {2},
    pages = {291-301},
    month = {June},
    year = {1991},
}

@INPROCEEDINGS{clark:pct,
  AUTHOR = "Malcolm Clark",
  TITLE = "Post Congress Tristesse",
  BOOKTITLE = "TeX90 Conference Proceedings",
  PAGES = "84-89",
  ORGANIZATION = "TeX Users Group",
  MONTH = "March",
  YEAR = {1991}
}

@ARTICLE{herlihy:methodology,
    author = {Herlihy, Maurice},
    title = {A Methodology for Implementing Highly Concurrent Data Objects},
    journal = {ACM Trans. Program. Lang. Syst.},
    volume = {15},
    number = {5},
    pages = {745-770},
    month = {November},
    year = {1993},
    doi = {10.1145/161468.161469},
}

@BOOK{salas:calculus,
  AUTHOR = "S.L. Salas and Einar Hille",
  TITLE = "Calculus: One and Several Variable",
  PUBLISHER = "John Wiley and Sons",
  ADDRESS = "New York",
  YEAR = "1978"
}

@MANUAL{Fear05,
  title =        {Publication quality tables in {\LaTeX}},
  author =       {Simon Fear},
  month =        {April},
  year =         2005,
  note =         {\url{http://www.ctan.org/pkg/booktabs}}
}

@Manual{Amsthm15,
  title =        {Using the amsthm Package},
  organization = {American Mathematical Society},
  month =        {April},
  year =         2015,
  note =         {\url{http://www.ctan.org/pkg/amsthm}}
}

@ArtifactSoftware{R,
    title = {R: A Language and Environment for Statistical Computing},
    author = {{R Core Team}},
    organization = {R Foundation for Statistical Computing},
    address = {Vienna, Austria},
    year = {2019},
    url = {https://www.R-project.org/},
}

@ArtifactDataset{UMassCitations,
 author    =  {Sam Anzaroot and Andrew McCallum},
 title     =  {{UMass} Citation Field Extraction Dataset},
 year      = 2013,
 url       =
    {http://www.iesl.cs.umass.edu/data/data-umasscitationfield},
 lastaccessed = {May 27, 2019}
}


@online{abbasiDiffusionAugmentedCoresetExpansion2024,
  title = {Diffusion-{{Augmented Coreset Expansion}} for {{Scalable Dataset Distillation}}},
  author = {Abbasi, Ali and Imani, Shima and An, Chenyang and Mahalingam, Gayathri and Shrivastava, Harsh and Diesendruck, Maurice and Pirsiavash, Hamed and Sharma, Pramod and Kolouri, Soheil},
  date = {2024-12-05},
  eprint = {2412.04668},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2412.04668},
  url = {http://arxiv.org/abs/2412.04668},
  urldate = {2025-04-17},
  abstract = {With the rapid scaling of neural networks, data storage and communication demands have intensified. Dataset distillation has emerged as a promising solution, condensing information from extensive datasets into a compact set of synthetic samples by solving a bilevel optimization problem. However, current methods face challenges in computational efficiency, particularly with high-resolution data and complex architectures. Recently, knowledge-distillation-based dataset condensation approaches have made this process more computationally feasible. Yet, with the recent developments of generative foundation models, there is now an opportunity to achieve even greater compression, enhance the quality of distilled data, and introduce valuable diversity into the data representation. In this work, we propose a two-stage solution. First, we compress the dataset by selecting only the most informative patches to form a coreset. Next, we leverage a generative foundation model to dynamically expand this compressed set in real-time—enhancing the resolution of these patches and introducing controlled variability to the coreset. Our extensive experiments demonstrate the robustness and efficiency of our approach across a range of dataset distillation benchmarks. We demonstrate a significant improvement of over 10\% compared to the state-of-the-art on several large-scale dataset distillation benchmarks. The code will be released soon.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/DAADAMS/Zotero/storage/EGTQUUV6/Abbasi et al. - 2024 - Diffusion-Augmented Coreset Expansion for Scalable Dataset Distillation.pdf}
}

@article{aggarwalNewApproachOnline2001,
  title = {A New Approach to Online Generation of Association Rules},
  author = {Aggarwal, C.C. and Yu, P.S.},
  date = {2001-07},
  journaltitle = {IEEE Transactions on Knowledge and Data Engineering},
  volume = {13},
  number = {4},
  pages = {527--540},
  issn = {1558-2191},
  doi = {10.1109/69.940730},
  url = {https://ieeexplore.ieee.org/document/940730/?arnumber=940730},
  urldate = {2025-01-15},
  abstract = {We discuss the problem of online mining of association rules in a large database of sales transactions. The online mining is performed by preprocessing the data effectively in order to make it suitable for repeated online queries. We store the preprocessed data in such a way that online processing may be done by applying a graph theoretic search algorithm whose complexity is proportional to the size of the output. The result is an online algorithm which is independent of the size of the transactional data and the size of the preprocessed data. The algorithm is almost instantaneous in the size of the output. The algorithm also supports techniques for quickly discovering association rules from large itemsets. The algorithm is capable of finding rules with specific items in the antecedent or consequent. These association rules are presented in a compact form, eliminating redundancy. The use of nonredundant association rules helps significantly in the reduction of irrelevant noise in the data mining process.},
  eventtitle = {{{IEEE Transactions}} on {{Knowledge}} and {{Data Engineering}}},
  keywords = {Association rules,Data mining,Itemsets,Marketing and sales,Noise reduction,Promotion - marketing,Transaction databases},
  file = {/Users/DAADAMS/Zotero/storage/I4I7585U/Aggarwal and Yu - 2001 - A new approach to online generation of association rules.pdf;/Users/DAADAMS/Zotero/storage/SADH8LMA/940730.html}
}

@article{ahmedDataSummarizationSurvey2019,
  title = {Data Summarization: A Survey},
  shorttitle = {Data Summarization},
  author = {Ahmed, Mohiuddin},
  date = {2019-02-01},
  journaltitle = {Knowledge and Information Systems},
  shortjournal = {Knowl Inf Syst},
  volume = {58},
  number = {2},
  pages = {249--273},
  issn = {0219-3116},
  doi = {10.1007/s10115-018-1183-0},
  url = {https://doi.org/10.1007/s10115-018-1183-0},
  urldate = {2025-02-03},
  abstract = {Summarization has been proven to be a useful and effective technique supporting data analysis of large amounts of data. Knowledge discovery from data (KDD) is time consuming, and summarization is an important step to expedite KDD tasks by intelligently reducing the size of processed data. In this paper, different summarization techniques for structured and unstructured data are discussed. The key finding of this survey is that not all summarization techniques create a summary suitable for further analysis. It is highlighted that sampling techniques are a viable way of creating a summary for further knowledge discovery such as anomaly detection from summary. Also different summary evaluation metrics are discussed.},
  langid = {english},
  keywords = {Cyber security,Machine learning,Natural language processing,Semantics,Statistics,Structured data,Summarization,Unstructured data},
  file = {/Users/DAADAMS/Zotero/storage/9AZY32LD/Ahmed - 2019 - Data summarization a survey.pdf}
}

@article{ahmedSemanticProbabilisticLayers,
  title = {Semantic {{Probabilistic Layers}} for {{Neuro-Symbolic Learning}}},
  author = {Ahmed, Kareem and Teso, Stefano and Chang, Kai-Wei},
  abstract = {We design a predictive layer for structured-output prediction (SOP) that can be plugged into any neural network guaranteeing its predictions are consistent with a set of predefined symbolic constraints. Our Semantic Probabilistic Layer (SPL) can model intricate correlations, and hard constraints, over a structured output space all while being amenable to end-to-end learning via maximum likelihood. SPLs combine exact probabilistic inference with logical reasoning in a clean and modular way, learning complex distributions and restricting their support to solutions of the constraint. As such, they can faithfully, and efficiently, model complex SOP tasks beyond the reach of alternative neuro-symbolic approaches. We empirically demonstrate that SPLs outperform these competitors in terms of accuracy on challenging SOP tasks including hierarchical multi-label classification, pathfinding and preference learning, while retaining perfect constraint satisfaction. Our code is made publicly available on Github at github.com/KareemYousrii/SPL.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/LYKPUXYI/Ahmed et al. - Semantic Probabilistic Layers for Neuro-Symbolic L.pdf}
}

@article{ahmedSurveyAnomalyDetection2016,
  title = {A Survey of Anomaly Detection Techniques in Financial Domain},
  author = {Ahmed, Mohiuddin and Mahmood, Abdun Naser and Islam, Md Rafiqul},
  date = {2016},
  journaltitle = {Future Generation Computer Systems},
  volume = {55},
  pages = {278--288},
  publisher = {Elsevier},
  url = {https://www.sciencedirect.com/science/article/pii/S0167739X15000023},
  urldate = {2025-02-16},
  file = {/Users/DAADAMS/Zotero/storage/PYNBIQ6A/Ahmed et al. - 2016 - A survey of anomaly detection techniques in financial domain.pdf}
}

@inproceedings{al-hegamiNoveltyFrameworkKnowledge2004,
  title = {Novelty {{Framework}} for {{Knowledge Discovery}} in {{Databases}}},
  booktitle = {Data {{Warehousing}} and {{Knowledge Discovery}}},
  author = {Al-Hegami, Ahmed Sultan and Bhatnagar, Vasudha and Kumar, Naveen},
  editor = {Kambayashi, Yahiko and Mohania, Mukesh and Wöß, Wolfram},
  date = {2004},
  pages = {48--57},
  publisher = {Springer},
  location = {Berlin, Heidelberg},
  doi = {10.1007/978-3-540-30076-2_5},
  abstract = {Knowledge Discovery in Databases (KDD) is an iterative process that aims at extracting interesting, previously unknown and hidden patterns from huge databases. Use of objective measures of interestingness in popular data mining algorithms often leads to another data mining problem, although of reduced complexity. The reduction in the volume of the discovered rules is desirable in order to improve the efficiency of the overall KDD process. Subjective measures of interestingness are required to achieve this. In this paper we study novelty of the discovered rules as a subjective measure of interestingness. We propose a framework to quantify novelty of the discovered rules in terms of their deviations from the known rules. The computations are carried out using the importance that the user gives to different deviations. The computed degree of novelty is then compared with the user given threshold to report novel rules to the user. We implement the proposed framework and experiment with some public datasets. The experimental results are quite promising.},
  isbn = {978-3-540-30076-2},
  langid = {english},
  keywords = {Association Rule,Data Mining,Domain Knowledge,Knowledge Discovery,Mining Algorithm},
  file = {/Users/DAADAMS/Zotero/storage/W7CWNTW7/Al-Hegami et al. - 2004 - Novelty Framework for Knowledge Discovery in Datab.pdf}
}

@article{aligonCollaborativeFilteringApproach2015,
  title = {A Collaborative Filtering Approach for Recommending {{OLAP}} Sessions},
  author = {Aligon, Julien and Gallinucci, Enrico and Golfarelli, Matteo and Marcel, Patrick and Rizzi, Stefano},
  date = {2015},
  journaltitle = {Decision Support Systems},
  volume = {69},
  pages = {20--30},
  publisher = {Elsevier},
  url = {https://www.sciencedirect.com/science/article/pii/S016792361400270X},
  urldate = {2025-02-16},
  file = {/Users/DAADAMS/Zotero/storage/2EZVU385/Aligon et al. - 2015 - A collaborative filtering approach for recommending OLAP sessions.pdf}
}

@inproceedings{amadoRobustNeurosymbolicGoal2023,
  title = {Robust Neuro-Symbolic Goal and Plan Recognition},
  booktitle = {Proceedings of the {{AAAI Conference}} on {{Artificial Intelligence}}},
  author = {Amado, Leonardo and Pereira, Ramon Fraga and Meneguzzi, Felipe},
  date = {2023},
  volume = {37},
  number = {10},
  pages = {11937--11944},
  url = {https://ojs.aaai.org/index.php/AAAI/article/view/26408},
  urldate = {2025-06-16},
  file = {/Users/DAADAMS/Zotero/storage/L5VHE8DH/Amado et al. - 2023 - Robust neuro-symbolic goal and plan recognition.pdf}
}

@dataset{amer-yahiaReliableConversationalData2025,
  title = {Towards {{Reliable Conversational Data Analytics}}},
  author = {Amer-Yahia, Sihem and Bogojeska, Jasmina and Facchinetti, Roberta and Franceschi, Valeria and Gionis, Aristides and Hose, Katja and Koutrika, Georgia and Kouyos, Roger and Lissandrini, Matteo and Maniu, Silviu and Mirylenka, Katsiaryna and Mottin, Davide and Palpanas, Themis and Rigotti, Mattia and Velegrakis, Yannis},
  date = {2025},
  publisher = {OpenProceedings.org},
  doi = {10.48786/EDBT.2025.78},
  url = {https://openproceedings.org/2025/conf/edbt/paper-160.pdf},
  urldate = {2025-09-08},
  abstract = {Conversational AI systems for data analytics aim to enable the extraction of analytical insights by means of conversational interfaces. Such interfaces are powered by a mix of query modalities and machine learning methods for analytics, and are relying on Large Language Models (LLMs) for natural language generation. However, critical challenges hinder their adoption. The question we discuss is how to devise reliable Conversational Data Analytics (CDA) systems producing timely, consistent, and verifiable answers. To reach this goal, we identify five properties that impose a paradigm shift in the way systems are built and in the way they interact with users. To illustrate that shift, we describe a prototypical CDA system. Realizing these properties involves either extending existing components, or redesigning components from scratch; both solutions require overcoming data management challenges and conducting a tight integration with advanced data management and machine learning techniques.},
  langid = {english},
  version = {1},
  keywords = {Database Technology},
  file = {/Users/DAADAMS/Zotero/storage/IZ5UIMI3/Amer-Yahia et al. - 2025 - Towards Reliable Conversational Data Analytics.pdf}
}

@article{amirHIGHLIGHTSSummarizingAgent,
  title = {{{HIGHLIGHTS}}: {{Summarizing Agent Behavior}} to {{People}}},
  author = {Amir, Dan and Amir, Ofra},
  abstract = {People increasingly interact with autonomous agents. This paper introduces and formalizes the problem of automatically generating a summary of an agent’s behavior with the goal of increasing people’s familiarity with the agent’s capabilities and limitations. In contrast with prior approaches which developed methods for explaining a single decision made by an agent, our approach aims to provide users with a summary that describes the agent’s behavior in different situations. We hypothesize that reviewing such summaries could help people in tasks such as choosing between agents or determining the level of autonomy to grant to an agent. We develop “HIGHLIGHTS”, an algorithm that produces a summary of an agent’s behavior by extracting important trajectories from simulations of the agent. We conducted a human-subject experiment to evaluate whether HIGHLIGHTS summaries help people assess the capabilities of agents. Our results show that participants were more successful at evaluating the capabilities of agents when presented with HIGHLIGHTS summaries compared to baseline summaries, and rated them as more helpful. We also explore a variant of the HIGHLIGHTS algorithm which aims to increase the diversity of states included in the summary, and show that this modification further improves people’s ability to assess agents’ capabilities.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/Y56DN3CH/Amir and Amir - HIGHLIGHTS Summarizing Agent Behavior to People.pdf}
}

@article{amsterdamerCrowdMinerMiningAssociation2013,
  title = {{{CrowdMiner}}: Mining Association Rules from the Crowd},
  shorttitle = {{{CrowdMiner}}},
  author = {Amsterdamer, Yael and Grossman, Yael and Milo, Tova and Senellart, Pierre},
  date = {2013-08-28},
  journaltitle = {Proceedings of the VLDB Endowment},
  shortjournal = {Proc. VLDB Endow.},
  volume = {6},
  number = {12},
  pages = {1250--1253},
  issn = {2150-8097},
  doi = {10.14778/2536274.2536288},
  url = {https://dl.acm.org/doi/10.14778/2536274.2536288},
  urldate = {2024-12-08},
  abstract = {This demo presents CrowdMiner , a system enabling the mining of interesting data patterns from the crowd. While traditional data mining techniques have been used extensively for finding patterns in classic databases, they are not always suitable for the crowd, mainly because humans tend to remember only simple trends and summaries rather than exact details. To address this, CrowdMiner employs a novel crowd-mining algorithm, designed specifically for this context. The algorithm iteratively chooses appropriate questions to ask the crowd, while aiming to maximize the knowledge gain at each step. We demonstrate CrowdMiner through a WellBeing portal, constructed interactively by mining the crowd, and in particular the conference participants, for common health related practices and trends.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/FLX3WKLN/Amsterdamer et al. - 2013 - CrowdMiner mining association rules from the crowd.pdf}
}

@article{aoneTrainableSummarizerKnowledge1999,
  title = {A Trainable Summarizer with Knowledge Acquired from Robust {{NLP}} Techniques},
  author = {Aone, Chinatsu},
  date = {1999},
  journaltitle = {Advances in automatic text summarization},
  pages = {71--80},
  publisher = {The Mit Press},
  url = {https://cir.nii.ac.jp/crid/1571135650129558656},
  urldate = {2025-02-16}
}

@inproceedings{asaiClassicalPlanningDeep2018,
  title = {Classical Planning in Deep Latent Space: {{Bridging}} the Subsymbolic-Symbolic Boundary},
  shorttitle = {Classical Planning in Deep Latent Space},
  booktitle = {Proceedings of the Aaai Conference on Artificial Intelligence},
  author = {Asai, Masataro and Fukunaga, Alex},
  date = {2018},
  volume = {32},
  number = {1},
  url = {https://ojs.aaai.org/index.php/AAAI/article/view/12077},
  urldate = {2024-03-19},
  file = {/Users/DAADAMS/Zotero/storage/5XFSRZKD/Asai and Fukunaga - 2018 - Classical planning in deep latent space Bridging .pdf}
}

@article{ayemowaSystematicReviewLiterature2024,
  title = {A Systematic Review of the Literature on Deep Learning Approaches for Cross-Domain Recommender Systems},
  author = {Ayemowa, Matthew O. and Ibrahim, Roliana and Bena, Yunusa Adamu},
  date = {2024-12-01},
  journaltitle = {Decision Analytics Journal},
  shortjournal = {Decision Analytics Journal},
  volume = {13},
  pages = {100518},
  issn = {2772-6622},
  doi = {10.1016/j.dajour.2024.100518},
  url = {https://www.sciencedirect.com/science/article/pii/S277266222400122X},
  urldate = {2025-09-08},
  abstract = {The increase in online information and the expanding diversity of user preferences require developing improved recommender systems. Cross-domain recommender systems (CDRS) have emerged as a favorable solution to solve issues related to cold start, data sparsity, and diversity by leveraging knowledge from the source domains. This systematic literature review delves into the latest deep learning approaches utilized for CDRS, comprehensively analyzing state-of-the-art techniques, methodologies, metrics, datasets, and applications. We systematically review selected primary studies from popular databases covering sixty-eight publications from 2019 to March 2024. The review process involved selecting relevant studies based on the predefined inclusion and exclusion criteria to ensure the inclusion of high-quality research. Key deep learning (DL) models explored include neural collaborative filtering, convolutional neural networks, recurrent neural networks, variational autoencoder, and generative adversarial networks. We also examine the hybrid models that integrate DL with traditional machine learning techniques to enhance recommendation performance. Our findings reveal that DL approaches significantly improve accuracy, cold start, and data sparsity. This review also identifies current trends and future research directions, emphasizing the potential of Artificial Intelligence (AI), transfer learning, and reinforcement learning in advancing CDRS. In our analysis, we discovered that the domains mainly utilized are movies, books, and music, respectively, and the most widely used evaluation metrics are root mean square error (RMSE) and normalized discounted cumulative gain (NDCG). Research challenges and future scope are also highlighted to assist the researchers and practitioners seeking to develop robust cross-domain recommender systems using DL techniques.},
  keywords = {Cross-domain,Decision making,Deep learning,Predictive analytics,Recommender systems,Users behavior analysis},
  file = {/Users/DAADAMS/Zotero/storage/ZG3YR67A/Ayemowa et al. - 2024 - A systematic review of the literature on deep learning approaches for cross-domain recommender syste.pdf;/Users/DAADAMS/Zotero/storage/SELIG6F5/S277266222400122X.html}
}

@article{babuSPARTANModelbasedSemantic2001,
  title = {{{SPARTAN}}: A Model-Based Semantic Compression System for Massive Data Tables},
  shorttitle = {{{SPARTAN}}},
  author = {Babu, Shivnath and Garofalakis, Minos and Rastogi, Rajeev},
  date = {2001-06},
  journaltitle = {ACM SIGMOD Record},
  shortjournal = {SIGMOD Rec.},
  volume = {30},
  number = {2},
  pages = {283--294},
  issn = {0163-5808},
  doi = {10.1145/376284.375693},
  url = {https://dl.acm.org/doi/10.1145/376284.375693},
  urldate = {2025-02-16},
  abstract = {While a variety of lossy compression schemes have been developed for certain forms of digital data (e.g., images, audio, video), the area of lossy compression techniques for arbitrary data tables has been left relatively unexplored. Nevertheless, such techniques are clearly motivated by the ever-increasing data collection rates of modern enterprises and the need for effective, guaranteed-quality approximate answers to queries over massive relational data sets. In this paper, we propose               SPARTAN               , a system that takes advantage of attribute semantics and data-mining models to perform lossy compression of massive data tables.               SPARTAN               is based on the novel idea of exploiting predictive data correlations and prescribed error tolerances for individual attributes to construct concise and accurate               Classification and Regression Tree (CaRT)               models for entire columns of a table. More precisely,               SPARTAN               selects a certain subset of attributes for which no values are explicitly stored in the compressed table; instead, concise CaRTs that predict these values (within the prescribed error bounds) are maintained. To restrict the huge search space and construction cost of possible CaRT predictors,               SPARTAN               employs sophisticated learning techniques and novel combinatorial optimization algorithms. Our experimentation with several real-life data sets offers convincing evidence of the effectiveness of               SPARTAN               's model-based approach —               SPARTAN               is able to consistently yield substantially better compression ratios than existing semantic or syntactic compression tools (e.g., gzip) while utilizing only small data samples for model inference.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/9PASXCBI/Babu et al. - 2001 - SPARTAN a model-based semantic compression system for massive data tables.pdf}
}

@online{baekResearchAgentIterativeResearch2024,
  title = {{{ResearchAgent}}: {{Iterative Research Idea Generation}} over {{Scientific Literature}} with {{Large Language Models}}},
  shorttitle = {{{ResearchAgent}}},
  author = {Baek, Jinheon and Jauhar, Sujay Kumar and Cucerzan, Silviu and Hwang, Sung Ju},
  date = {2024-04-11},
  eprint = {2404.07738},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2404.07738},
  urldate = {2024-04-29},
  abstract = {Scientific Research, vital for improving human life, is hindered by its inherent complexity, slow pace, and the need for specialized experts. To enhance its productivity, we propose a ResearchAgent, a large language modelpowered research idea writing agent, which automatically generates problems, methods, and experiment designs while iteratively refining them based on scientific literature. Specifically, starting with a core paper as the primary focus to generate ideas, our ResearchAgent is augmented not only with relevant publications through connecting information over an academic graph but also entities retrieved from an entity-centric knowledge store based on their underlying concepts, mined and shared across numerous papers. In addition, mirroring the human approach to iteratively improving ideas with peer discussions, we leverage multiple ReviewingAgents that provide reviews and feedback iteratively. Further, they are instantiated with human preference-aligned large language models whose criteria for evaluation are derived from actual human judgments. We experimentally validate our ResearchAgent on scientific publications across multiple disciplines, showcasing its effectiveness in generating novel, clear, and valid research ideas based on human and model-based evaluation results.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/DAADAMS/Zotero/storage/ZGYXE8BY/Baek et al. - 2024 - ResearchAgent Iterative Research Idea Generation .pdf}
}

@inproceedings{barelATENAAutonomousSystem2019,
  title = {{{ATENA}}: {{An Autonomous System}} for {{Data Exploration Based}} on {{Deep Reinforcement Learning}}},
  shorttitle = {{{ATENA}}},
  booktitle = {Proceedings of the 28th {{ACM International Conference}} on {{Information}} and {{Knowledge Management}}},
  author = {Bar El, Ori and Milo, Tova and Somech, Amit},
  date = {2019-11-03},
  pages = {2873--2876},
  publisher = {ACM},
  location = {Beijing China},
  doi = {10.1145/3357384.3357845},
  url = {https://dl.acm.org/doi/10.1145/3357384.3357845},
  urldate = {2024-12-08},
  abstract = {Exploratory Data Analysis (EDA), is an important yet challenging task, that requires profound analytical skills and familiarity with the data domain. While Deep Reinforcement Learning (DRL) is nowadays used to solve AI challenges previously considered to be intractable, to our knowledge such solutions have not yet been applied to EDA.},
  eventtitle = {{{CIKM}} '19: {{The}} 28th {{ACM International Conference}} on {{Information}} and {{Knowledge Management}}},
  isbn = {978-1-4503-6976-3},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/T7Q6SZC4/Bar El et al. - 2019 - ATENA An Autonomous System for Data Exploration Based on Deep Reinforcement Learning.pdf}
}

@inproceedings{barelATENAAutonomousSystem2019a,
  title = {{{ATENA}}: {{An Autonomous System}} for {{Data Exploration Based}} on {{Deep Reinforcement Learning}}},
  shorttitle = {{{ATENA}}},
  booktitle = {Proceedings of the 28th {{ACM International Conference}} on {{Information}} and {{Knowledge Management}}},
  author = {Bar El, Ori and Milo, Tova and Somech, Amit},
  date = {2019-11-03},
  pages = {2873--2876},
  publisher = {ACM},
  location = {Beijing China},
  doi = {10.1145/3357384.3357845},
  url = {https://dl.acm.org/doi/10.1145/3357384.3357845},
  urldate = {2025-02-16},
  eventtitle = {{{CIKM}} '19: {{The}} 28th {{ACM International Conference}} on {{Information}} and {{Knowledge Management}}},
  isbn = {978-1-4503-6976-3},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/RT379S7Z/Bar El et al. - 2019 - ATENA An Autonomous System for Data Exploration Based on Deep Reinforcement Learning.pdf}
}

@inproceedings{barelAutomaticallyGeneratingData2020,
  title = {Automatically {{Generating Data Exploration Sessions Using Deep Reinforcement Learning}}},
  booktitle = {Proceedings of the 2020 {{ACM SIGMOD International Conference}} on {{Management}} of {{Data}}},
  author = {Bar El, Ori and Milo, Tova and Somech, Amit},
  date = {2020-06-11},
  pages = {1527--1537},
  publisher = {ACM},
  location = {Portland OR USA},
  doi = {10.1145/3318464.3389779},
  url = {https://dl.acm.org/doi/10.1145/3318464.3389779},
  urldate = {2024-12-08},
  abstract = {Exploratory Data Analysis (EDA) is an essential yet highly demanding task. To get a head start before exploring a new dataset, data scientists often prefer to view existing EDA notebooks – illustrative, curated exploratory sessions, on the same dataset, that were created by fellow data scientists who shared them online. Unfortunately, such notebooks are not always available (e.g., if the dataset is new or confidential). To address this, we present ATENA, a system that takes an input dataset and auto-generates a compelling exploratory session, presented in an EDA notebook. We shape EDA into a control problem, and devise a novel Deep Reinforcement Learning (DRL) architecture to effectively optimize the notebook generation. Though ATENA uses a limited set of EDA operations, our experiments show that it generates useful EDA notebooks, allowing users to gain actual insights.},
  eventtitle = {{{SIGMOD}}/{{PODS}} '20: {{International Conference}} on {{Management}} of {{Data}}},
  isbn = {978-1-4503-6735-6},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/3Y3TFVJL/Bar El et al. - 2020 - Automatically Generating Data Exploration Sessions Using Deep Reinforcement Learning.pdf}
}

@inproceedings{barelAutomaticallyGeneratingData2020a,
  title = {Automatically {{Generating Data Exploration Sessions Using Deep Reinforcement Learning}}},
  booktitle = {Proceedings of the 2020 {{ACM SIGMOD International Conference}} on {{Management}} of {{Data}}},
  author = {Bar El, Ori and Milo, Tova and Somech, Amit},
  date = {2020-06-11},
  pages = {1527--1537},
  publisher = {ACM},
  location = {Portland OR USA},
  doi = {10.1145/3318464.3389779},
  url = {https://dl.acm.org/doi/10.1145/3318464.3389779},
  urldate = {2025-02-16},
  eventtitle = {{{SIGMOD}}/{{PODS}} '20: {{International Conference}} on {{Management}} of {{Data}}},
  isbn = {978-1-4503-6735-6},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/JV4HLQNG/Bar El et al. - 2020 - Automatically Generating Data Exploration Sessions Using Deep Reinforcement Learning.pdf}
}

@inproceedings{barelAutomaticallyGeneratingData2020b,
  title = {Automatically {{Generating Data Exploration Sessions Using Deep Reinforcement Learning}}},
  booktitle = {Proceedings of the 2020 {{ACM SIGMOD International Conference}} on {{Management}} of {{Data}}},
  author = {Bar El, Ori and Milo, Tova and Somech, Amit},
  date = {2020-06-11},
  pages = {1527--1537},
  publisher = {ACM},
  location = {Portland OR USA},
  doi = {10.1145/3318464.3389779},
  url = {https://dl.acm.org/doi/10.1145/3318464.3389779},
  urldate = {2025-02-16},
  eventtitle = {{{SIGMOD}}/{{PODS}} '20: {{International Conference}} on {{Management}} of {{Data}}},
  isbn = {978-1-4503-6735-6},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/44BECS77/Bar El et al. - 2020 - Automatically Generating Data Exploration Sessions Using Deep Reinforcement Learning.pdf}
}

@inproceedings{barzilayInformationFusionContext1999,
  title = {Information Fusion in the Context of Multi-Document Summarization},
  booktitle = {Proceedings of the 37th Annual Meeting of the {{Association}} for {{Computational Linguistics}}},
  author = {Barzilay, Regina and McKeown, Kathleen and Elhadad, Michael},
  date = {1999},
  pages = {550--557},
  url = {https://aclanthology.org/P99-1071.pdf},
  urldate = {2025-02-16},
  file = {/Users/DAADAMS/Zotero/storage/FISZMFSX/Barzilay et al. - 1999 - Information fusion in the context of multi-document summarization.pdf}
}

@article{barzilayUsingLexicalChains1997,
  title = {Using Lexical Chains for Text Summarization},
  author = {Barzilay, Regina and Elhadad, Michael},
  date = {1997},
  file = {/Users/DAADAMS/Zotero/storage/4LGMZDBN/Barzilay and Elhadad - 1997 - Using lexical chains for text summarization.pdf}
}

@article{battleCharacterizingExploratoryVisual2019,
  title = {Characterizing {{Exploratory Visual Analysis}}: {{A Literature Review}} and {{Evaluation}} of {{Analytic Provenance}} in {{Tableau}}},
  shorttitle = {Characterizing {{Exploratory Visual Analysis}}},
  author = {Battle, Leilani and Heer, Jeffrey},
  date = {2019-06},
  journaltitle = {Computer Graphics Forum},
  shortjournal = {Computer Graphics Forum},
  volume = {38},
  number = {3},
  pages = {145--159},
  issn = {0167-7055, 1467-8659},
  doi = {10.1111/cgf.13678},
  url = {https://onlinelibrary.wiley.com/doi/10.1111/cgf.13678},
  urldate = {2025-09-11},
  abstract = {Supporting exploratory visual analysis (EVA) is a central goal of visualization research, and yet our understanding of the process is arguably vague and piecemeal. We contribute a consistent definition of EVA through review of the relevant literature, and an empirical evaluation of existing assumptions regarding how analysts perform EVA using Tableau, a popular visual analysis tool. We present the results of a study where 27 Tableau users answered various analysis questions across 3 datasets. We measure task performance, identify recurring patterns across participants’ analyses, and assess variance from task specificity and dataset. We find striking differences between existing assumptions and the collected data. Participants successfully completed a variety of tasks, with over 80\% accuracy across focused tasks with measurably correct answers. The observed cadence of analyses is surprisingly slow compared to popular assumptions from the database community. We find significant overlap in analyses across participants, showing that EVA behaviors can be predictable. Furthermore, we find few structural differences between behavior graphs for open-ended and more focused exploration tasks.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/JL4ZC56W/Battle and Heer - 2019 - Characterizing Exploratory Visual Analysis A Literature Review and Evaluation of Analytic Provenanc.pdf}
}

@article{baxendaleMachinemadeIndexTechnical1958,
  title = {Machine-Made Index for Technical Literature—an Experiment},
  author = {Baxendale, Phyllis B.},
  date = {1958},
  journaltitle = {IBM Journal of research and development},
  volume = {2},
  number = {4},
  pages = {354--361},
  publisher = {IBM},
  url = {https://ieeexplore.ieee.org/abstract/document/5392648/},
  urldate = {2025-02-16}
}

@online{bertelootAssociationRulesMining2023,
  title = {Association {{Rules Mining}} with {{Auto-Encoders}}},
  author = {Berteloot, Théophile and Khoury, Richard and Durand, Audrey},
  date = {2023-04-26},
  eprint = {2304.13717},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2304.13717},
  url = {http://arxiv.org/abs/2304.13717},
  urldate = {2024-12-23},
  abstract = {Association rule mining is one of the most studied research fields of data mining, with applications ranging from grocery basket problems to explainable classification systems. Classical association rule mining algorithms have several limitations, especially with regards to their high execution times and number of rules produced. Over the past decade, neural network solutions have been used to solve various optimization problems, such as classification, regression or clustering. However there are still no efficient way association rules using neural networks. In this paper, we present an auto-encoder solution to mine association rule called ARM-AE. We compare our algorithm to FP-Growth and NSGAII on three categorical datasets, and show that our algorithm discovers high support and confidence rule set and has a better execution time than classical methods while preserving the quality of the rule set produced.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Databases,Computer Science - Machine Learning},
  file = {/Users/DAADAMS/Zotero/storage/ANCRXF34/Berteloot et al. - 2023 - Association Rules Mining with Auto-Encoders.pdf}
}

@unpublished{bettiniSystemNeuralDiversity2023,
  title = {System Neural Diversity: Measuring Behavioral Heterogeneity in Multi-Agent Learning},
  shorttitle = {System Neural Diversity},
  author = {Bettini, Matteo and Shankar, Ajay and Prorok, Amanda},
  date = {2023},
  eprint = {2305.02128},
  eprinttype = {arXiv},
  url = {https://arxiv.org/abs/2305.02128},
  urldate = {2024-09-11},
  file = {/Users/DAADAMS/Zotero/storage/D8R6782W/Bettini et al. - 2023 - System neural diversity measuring behavioral heterogeneity in multi-agent learning.pdf}
}

@software{blueghostyiBlueGhostYiDMRec2025,
  title = {{{BlueGhostYi}}/{{DMRec}}},
  author = {BlueGhostYi},
  date = {2025-08-06T03:07:56Z},
  origdate = {2025-04-11T03:57:18Z},
  url = {https://github.com/BlueGhostYi/DMRec},
  urldate = {2025-09-08},
  abstract = {[SIGIR2025] Towards Distribution Matching between Collaborative and Language Spaces for Generative Recommendation}
}

@inproceedings{boultUnifyingFrameworkFormal2021,
  title = {Towards a Unifying Framework for Formal Theories of Novelty},
  booktitle = {Proceedings of the {{AAAI}} Conference on Artificial Intelligence},
  author = {Boult, Terrance and Grabowicz, Przemyslaw and Prijatelj, Derek and Stern, Roni and Holder, Lawrence and Alspector, Joshua and Jafarzadeh, Mohsen M. and Ahmad, Toqueer and Dhamija, Akshay and Li, Chunchun},
  date = {2021},
  volume = {35},
  number = {17},
  pages = {15047--15052},
  url = {https://ojs.aaai.org/index.php/AAAI/article/view/17766},
  urldate = {2024-05-07},
  file = {/Users/DAADAMS/Zotero/storage/MJPEIW5C/Boult et al. - 2021 - Towards a unifying framework for formal theories o.pdf}
}

@inproceedings{brancasReliableSQLSynthesis2024,
  title = {Towards Reliable {{SQL}} Synthesis: {{Fuzzing-based}} Evaluation and Disambiguation},
  shorttitle = {Towards Reliable {{SQL}} Synthesis},
  booktitle = {International {{Conference}} on {{Fundamental Approaches}} to {{Software Engineering}}},
  author = {Brancas, Ricardo and Terra-Neves, Miguel and Ventura, Miguel and Manquinho, Vasco and Martins, Ruben},
  date = {2024},
  pages = {232--254},
  publisher = {Springer Nature Switzerland Cham},
  url = {https://library.oapen.org/bitstream/handle/20.500.12657/89913/1/978-3-031-57259-3.pdf#page=246},
  urldate = {2025-08-28},
  file = {/Users/DAADAMS/Zotero/storage/4JF5EMXF/Brancas et al. - 2024 - Towards reliable SQL synthesis Fuzzing-based evaluation and disambiguation.pdf}
}

@inproceedings{breunigDataBubblesQuality2001,
  title = {Data Bubbles: Quality Preserving Performance Boosting for Hierarchical Clustering},
  shorttitle = {Data Bubbles},
  booktitle = {Proceedings of the 2001 {{ACM SIGMOD}} International Conference on {{Management}} of Data},
  author = {Breunig, Markus M. and Kriegel, Hans-Peter and Kröger, Peer and Sander, Jörg},
  date = {2001-05},
  pages = {79--90},
  publisher = {ACM},
  location = {Santa Barbara California USA},
  doi = {10.1145/375663.375672},
  url = {https://dl.acm.org/doi/10.1145/375663.375672},
  urldate = {2025-02-16},
  eventtitle = {{{SIGMOD}}/{{PODS01}}: {{ACM SIGMOD International Conference}} on {{Management}} of {{Data}}},
  isbn = {978-1-58113-332-5},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/W3VU7WS6/Breunig et al. - 2001 - Data bubbles quality preserving performance boosting for hierarchical clustering.pdf}
}

@incollection{breunigFastHierarchicalClustering2000,
  title = {Fast {{Hierarchical Clustering Based}} on {{Compressed Data}} and {{OPTICS}}},
  booktitle = {Principles of {{Data Mining}} and {{Knowledge Discovery}}},
  author = {Breunig, Markus M. and Kriegel, Hans-Peter and Sander, Jörg},
  editor = {Zighed, Djamel A. and Komorowski, Jan and Żytkow, Jan},
  editora = {Goos, G. and Hartmanis, J. and Van Leeuwen, J.},
  editoratype = {redactor},
  date = {2000},
  volume = {1910},
  pages = {232--242},
  publisher = {Springer Berlin Heidelberg},
  location = {Berlin, Heidelberg},
  doi = {10.1007/3-540-45372-5_23},
  url = {http://link.springer.com/10.1007/3-540-45372-5_23},
  urldate = {2025-02-16},
  isbn = {978-3-540-41066-9 978-3-540-45372-7},
  file = {/Users/DAADAMS/Zotero/storage/FQJA673E/Breunig et al. - 2000 - Fast Hierarchical Clustering Based on Compressed Data and OPTICS.pdf}
}

@article{browneSurveyMonteCarlo2012,
  title = {A {{Survey}} of {{Monte Carlo Tree Search Methods}}},
  author = {Browne, Cameron B. and Powley, Edward and Whitehouse, Daniel and Lucas, Simon M. and Cowling, Peter I. and Rohlfshagen, Philipp and Tavener, Stephen and Perez, Diego and Samothrakis, Spyridon and Colton, Simon},
  date = {2012-03},
  journaltitle = {IEEE Transactions on Computational Intelligence and AI in Games},
  shortjournal = {IEEE Trans. Comput. Intell. AI Games},
  volume = {4},
  number = {1},
  pages = {1--43},
  issn = {1943-068X, 1943-0698},
  doi = {10.1109/TCIAIG.2012.2186810},
  url = {http://ieeexplore.ieee.org/document/6145622/},
  urldate = {2024-03-15},
  abstract = {Monte Carlo Tree Search (MCTS) is a recently proposed search method that combines the precision of tree search with the generality of random sampling. It has received considerable interest due to its spectacular success in the difficult problem of computer Go, but has also proved beneficial in a range of other domains. This paper is a survey of the literature to date, intended to provide a snapshot of the state of the art after the first five years of MCTS research. We outline the core algorithm’s derivation, impart some structure on the many variations and enhancements that have been proposed, and summarise the results from the key game and non-game domains to which MCTS methods have been applied. A number of open research questions indicate that the field is ripe for future work.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/EXHRBXNA/Browne et al. - 2012 - A Survey of Monte Carlo Tree Search Methods.pdf}
}

@inproceedings{brownLibratusSuperhumanAI2017,
  title = {Libratus: {{The Superhuman AI}} for {{No-Limit Poker}}},
  shorttitle = {Libratus},
  booktitle = {Proceedings of the {{Twenty-Sixth International Joint Conference}} on {{Artificial Intelligence}}},
  author = {Brown, Noam and Sandholm, Tuomas},
  date = {2017-08},
  pages = {5226--5228},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  location = {Melbourne, Australia},
  doi = {10.24963/ijcai.2017/772},
  url = {https://www.ijcai.org/proceedings/2017/772},
  urldate = {2024-03-15},
  abstract = {No-limit Texas Hold’em is the most popular variant of poker in the world. Heads-up no-limit Texas Hold’em is the main benchmark challenge for AI in imperfect-information games. We present Libratus, the first—and so far only—AI to defeat top human professionals in that game. Libratus’s architecture features three main modules, each of which has new algorithms: pre-computing a solution to an abstraction of the game which provides a high-level blueprint for the strategy of the AI, a new nested subgame-solving algorithm which repeatedly calculates a more detailed strategy as play progresses, and a self-improving module which augments the pre-computed blueprint over time.},
  eventtitle = {Twenty-{{Sixth International Joint Conference}} on {{Artificial Intelligence}}},
  isbn = {978-0-9992411-0-3},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/B424932V/Brown and Sandholm - 2017 - Libratus The Superhuman AI for No-Limit Poker.pdf}
}

@inproceedings{brownRegretBasedPruningExtensiveForm2015,
  title = {Regret-{{Based Pruning}} in {{Extensive-Form Games}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Brown, Noam and Sandholm, Tuomas},
  date = {2015},
  volume = {28},
  publisher = {Curran Associates, Inc.},
  url = {https://proceedings.neurips.cc/paper/2015/hash/c54e7837e0cd0ced286cb5995327d1ab-Abstract.html},
  urldate = {2024-03-15},
  abstract = {Counterfactual Regret Minimization (CFR) is a leading algorithm for finding a Nash equilibrium in large zero-sum imperfect-information games. CFR is an iterative algorithm that repeatedly traverses the game tree, updating regrets at each information set.We introduce an improvement to CFR that prunes any path of play in the tree, and its descendants, that has negative regret. It revisits that sequence at the earliest subsequent CFR iteration where the regret could have become positive, had that path been explored on every iteration. The new algorithm maintains CFR's convergence guarantees while making iterations significantly faster---even if previously known pruning techniques are used in the comparison. This improvement carries over to CFR+, a recent variant of CFR. Experiments show an order of magnitude speed improvement, and the relative speed improvement increases with the size of the game.},
  file = {/Users/DAADAMS/Zotero/storage/A9HK978S/Brown and Sandholm - 2015 - Regret-Based Pruning in Extensive-Form Games.pdf}
}

@article{caiAttributeorientedInductionRelational1989,
  title = {Attribute-Oriented Induction in Relational Databases},
  author = {Cai, Yandong},
  date = {1989},
  publisher = {Simon Fraser University},
  url = {https://summit.sfu.ca/_flysystem/fedora/sfu_migrate/4542/b14435287.pdf},
  urldate = {2025-02-16},
  file = {/Users/DAADAMS/Zotero/storage/WYZQQYIT/Cai - 1989 - Attribute-oriented induction in relational databases.pdf}
}

@inproceedings{carbonellUseMMRDiversitybased1998,
  title = {The Use of {{MMR}}, Diversity-Based Reranking for Reordering Documents and Producing Summaries},
  booktitle = {Proceedings of the 21st Annual International {{ACM SIGIR}} Conference on {{Research}} and Development in Information Retrieval},
  author = {Carbonell, Jaime and Goldstein, Jade},
  date = {1998-08},
  pages = {335--336},
  publisher = {ACM},
  location = {Melbourne Australia},
  doi = {10.1145/290941.291025},
  url = {https://dl.acm.org/doi/10.1145/290941.291025},
  urldate = {2025-02-16},
  eventtitle = {{{SIGIR98}}: 21st {{Annual ACM}}/{{SIGIR International Conference}} on {{Research}} and {{Development}} in {{Information Retrieval}}},
  isbn = {978-1-58113-015-7},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/Z6YPASFR/Carbonell and Goldstein - 1998 - The use of MMR, diversity-based reranking for reordering documents and producing summaries.pdf}
}

@article{chandolaSummarizationCompressingData2007,
  title = {Summarization – Compressing Data into an Informative Representation},
  author = {Chandola, Varun and Kumar, Vipin},
  date = {2007-08-03},
  journaltitle = {Knowledge and Information Systems},
  shortjournal = {Knowl Inf Syst},
  volume = {12},
  number = {3},
  pages = {355--378},
  issn = {0219-1377, 0219-3116},
  doi = {10.1007/s10115-006-0039-1},
  url = {http://link.springer.com/10.1007/s10115-006-0039-1},
  urldate = {2025-02-03},
  abstract = {In this paper, we formulate the problem of summarization of a data set of transactions with categorical attributes as an optimization problem involving two objective functions – compaction gain and information loss. We propose metrics to characterize the output of any summarization algorithm. We investigate two approaches to address this problem. The first approach is an adaptation of clustering and the second approach makes use of frequent itemsets from the association analysis domain. We illustrate one application of summarization in the field of network data where we show how our technique can be effectively used to summarize network traffic into a compact but meaningful representation. Specifically, we evaluate our proposed algorithms on the 1998 DARPA Off-Line Intrusion Detection Evaluation data and network data generated by SKAION Corp for the ARDA information assurance program.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/RL556HEB/Chandola and Kumar - 2007 - Summarization – compressing data into an informative representation.pdf}
}

@article{chandolaSummarizationCompressingData2007a,
  title = {Summarization–Compressing Data into an Informative Representation},
  author = {Chandola, Varun and Kumar, Vipin},
  date = {2007},
  journaltitle = {Knowledge and Information Systems},
  volume = {12},
  pages = {355--378},
  publisher = {Springer},
  url = {https://idp.springer.com/authorize/casa?redirect_uri=https://link.springer.com/article/10.1007/s10115-006-0039-1&casa_token=DeElbo7p9bsAAAAA:5rAgm5IG_vgJT3b436CvqEec2KnBCN6TskQMmDmbsiiX307unDwNe155vDJH-lxjQrfCKztcWhQSr7My_Q},
  urldate = {2025-02-03},
  file = {/Users/DAADAMS/Zotero/storage/5ZR4ZUKW/Chandola and Kumar - 2007 - Summarization–compressing data into an informative representation.pdf}
}

@article{chandolaSummarizationCompressingData2007b,
  title = {Summarization–Compressing Data into an Informative Representation},
  author = {Chandola, Varun and Kumar, Vipin},
  date = {2007},
  journaltitle = {Knowledge and Information Systems},
  volume = {12},
  pages = {355--378},
  publisher = {Springer},
  url = {https://idp.springer.com/authorize/casa?redirect_uri=https://link.springer.com/article/10.1007/s10115-006-0039-1&casa_token=pQNmPtsj-iwAAAAA:r0JPqtk85uWNObqE_oxtQnpx8gplvS62ZGbIWkghXsE5T0PpODn36fQC2rwljVkTPgLvwEEpJXU8RD4O},
  urldate = {2025-02-07},
  file = {/Users/DAADAMS/Zotero/storage/4HQIB9L5/Chandola and Kumar - 2007 - Summarization–compressing data into an informative representation.pdf}
}

@article{chandolaSummarizationCompressingData2007c,
  title = {Summarization–Compressing Data into an Informative Representation},
  author = {Chandola, Varun and Kumar, Vipin},
  date = {2007},
  journaltitle = {Knowledge and Information Systems},
  volume = {12},
  pages = {355--378},
  publisher = {Springer},
  url = {https://idp.springer.com/authorize/casa?redirect_uri=https://link.springer.com/article/10.1007/s10115-006-0039-1&casa_token=I48XDyjlo4EAAAAA:5sLYe3iIntAWy64ELfkvkp6nRxYsSDbvNE_e2HizPkFagw6QdBJc26LI57Vautl01eHtFq2kuHdsrKdI3A},
  urldate = {2025-02-16},
  file = {/Users/DAADAMS/Zotero/storage/ZT7HX5TR/Chandola and Kumar - 2007 - Summarization–compressing data into an informative representation.pdf}
}

@dataset{chansonAutomaticGenerationComparison2022,
  title = {Automatic Generation of Comparison Notebooks for Interactive Data Exploration},
  author = {Chanson, Alexandre and Labroche, Nicolas and Marcel, Patrick and Rizzi, Stefano and T'Kindt, Vincent},
  date = {2022},
  publisher = {OpenProceedings.org},
  doi = {10.48786/EDBT.2022.15},
  url = {https://openproceedings.org/2022/conf/edbt/paper-69.pdf},
  urldate = {2025-09-10},
  abstract = {We consider the problem of generating SQL notebooks of comparison queries for Exploratory Data Analysis (EDA). A comparison query allows to find insights in a dataset by specifying the comparison of subsets of data. In this paper, we study the problem of generating sequences of comparison queries that are insightful and coherent. We propose exact and approximate resolution approaches, and study their efficiency and effectiveness on artificial and real datasets, as well as with a user study.},
  langid = {english},
  version = {1},
  keywords = {Database Technology},
  file = {/Users/DAADAMS/Zotero/storage/S6WV5R2J/Chanson et al. - 2022 - Automatic generation of comparison notebooks for interactive data exploration.pdf}
}

@inproceedings{chansonInterestingnessMeasuresExploratory2025a,
  title = {Interestingness {{Measures}} for~{{Exploratory Data Analysis}}: A~{{Survey}}},
  shorttitle = {Interestingness {{Measures}} for~{{Exploratory Data Analysis}}},
  booktitle = {New {{Trends}} in {{Database}} and {{Information Systems}}},
  author = {Chanson, Alexandre and Labroche, Nicolas and Marcel, Patrick and Perlata, Verónika and Vassiliadis, Panos},
  editor = {Tekli, Joe and Gamper, Johann and Chbeir, Richard and Manolopoulos, Yannis and Sassi, Salma and Ivanovic, Mirjana and Vargas-Solar, Genoveva and Zumpano, Ester},
  date = {2025},
  pages = {14--24},
  publisher = {Springer Nature Switzerland},
  location = {Cham},
  doi = {10.1007/978-3-031-70421-5_2},
  abstract = {Exploratory Data Analysis (EDA) is the tedious activity of interactively analyzing a dataset to extract insights. Many approaches aiming at supporting EDA were recently proposed. They all rely on interestingness measures to score the importance of insights. This paper surveys and categorizes the different interestingness measures proposed in the literature for approaches aiming at automating EDA. The lessons learned from this survey allow to point out promising research directions.},
  isbn = {978-3-031-70421-5},
  langid = {english},
  keywords = {EDA,Insights,Interestingness measures},
  file = {/Users/DAADAMS/Zotero/storage/VU2EJ8QB/Chanson et al. - 2025 - Interestingness Measures for Exploratory Data Analysis a Survey.pdf}
}

@article{chaudhuriAutomatedQuestionGeneration2018,
  title = {Automated {{Question Generation}} on {{Tabular Data}} for {{Conversational Data Exploration}}},
  author = {Chaudhuri, Ritwik},
  date = {2018},
  abstract = {Exploratory data analysis (EDA) is an essential step for analyzing a dataset to derive insights. Several EDA techniques have been explored in the literature. Many of them leverage visualizations through various plots. But it is not easy to interpret them for a non-technical user, and producing appropriate visualizations is also tough when there are a large number of columns. Few other works provide a view of some interesting slices of data but it is still difficult for the user to draw relevant insights from them. Of late, conversational data exploration is gaining a lot of traction among non-technical users. It helps the user to explore the dataset without having deep technical knowledge about the data. Towards this, we propose a system that recommends interesting questions in natural language based on relevant slices of a dataset in a conversational setting. Specifically, given a dataset, we pick a select set of interesting columns and identify interesting slices of such columns and column combinations based on few interestingness measures. We use our own fine-tuned variation of a pre-trained language model(T5) to generate natural language questions in a specific manner. We then slot-fill values in the generated questions and rank them for recommendations. We show the utility of our proposed system in a coversational setting with a collection of real datasets.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/PAXR5XDD/Chaudhuri - 2018 - Automated Question Generation on Tabular Data for Conversational Data Exploration.pdf}
}

@article{chaudhuriAutomatedRankingDatabase,
  title = {Automated {{Ranking}} of {{Database Query Results}}},
  author = {Chaudhuri, Surajit and Agrawal, Sanjay and Das, Gautam},
  abstract = {Ranking and returning the most relevant results of a query is a popular paradigm in Information Retrieval. We discuss challenges and investigate several approaches to enable ranking in databases, including adaptations of known techniques from information retrieval. We present results of preliminary experiments.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/PUS772X6/Chaudhuri et al. - Computer Science Dept Stanford University.pdf}
}

@article{chaudhuriProbabilisticInformationRetrieval2006,
  title = {Probabilistic Information Retrieval Approach for Ranking of Database Query Results},
  author = {Chaudhuri, Surajit and Das, Gautam and Hristidis, Vagelis and Weikum, Gerhard},
  date = {2006-09},
  journaltitle = {ACM Transactions on Database Systems},
  shortjournal = {ACM Trans. Database Syst.},
  volume = {31},
  number = {3},
  pages = {1134--1168},
  issn = {0362-5915, 1557-4644},
  doi = {10.1145/1166074.1166085},
  url = {https://dl.acm.org/doi/10.1145/1166074.1166085},
  urldate = {2025-04-22},
  abstract = {We investigate the problem of ranking the answers to a database query when many tuples are returned. In particular, we present methodologies to tackle the problem for conjunctive and range queries, by adapting and applying principles of probabilistic models from information retrieval for structured data. Our solution is domain independent and leverages data and workload statistics and correlations. We evaluate the quality of our approach with a user survey on a real database. Furthermore, we present and experimentally evaluate algorithms to efficiently retrieve the top ranked results, which demonstrate the feasibility of our ranking system.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/JIIJUFE8/Chaudhuri et al. - 2006 - Probabilistic information retrieval approach for ranking of database query results.pdf}
}

@online{chenEquivalentTransformationUser2022,
  title = {Towards {{Equivalent Transformation}} of {{User Preferences}} in {{Cross Domain Recommendation}}},
  author = {Chen, Xu and Zhang, Ya and Tsang, Ivor and Pan, Yuangang and Su, Jingchao},
  date = {2022-03-17},
  eprint = {2009.06884},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2009.06884},
  url = {http://arxiv.org/abs/2009.06884},
  urldate = {2025-09-10},
  abstract = {Cross domain recommendation (CDR) is one popular research topic in recommender systems. This paper focuses on a popular scenario for CDR where different domains share the same set of users but no overlapping items. The majority of recent methods have explored the shared-user representation to transfer knowledge across domains. However, the idea of shared-user representation resorts to learn the overlapped features of user preferences and suppresses the domain-specific features. Other works try to capture the domain-specific features by an MLP mapping but require heuristic human knowledge of choosing samples to train the mapping. In this paper, we attempt to learn both features of user preferences in a more principled way. We assume that each user's preferences in one domain can be expressed by the other one, and these preferences can be mutually converted to each other with the so-called equivalent transformation. Based on this assumption, we propose an equivalent transformation learner (ETL) which models the joint distribution of user behaviors across domains. The equivalent transformation in ETL relaxes the idea of shared-user representation and allows the learned preferences in different domains to preserve the domain-specific features as well as the overlapped features. Extensive experiments on three public benchmarks demonstrate the effectiveness of ETL compared with recent state-of-the-art methods. Codes and data are available online:\textasciitilde\textbackslash url\{https://github.com/xuChenSJTU/ETL-master\}},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Information Retrieval},
  file = {/Users/DAADAMS/Zotero/storage/PDYYWTDT/Chen et al. - 2022 - Towards Equivalent Transformation of User Preferences in Cross Domain Recommendation.pdf}
}

@article{chenGraphOptimalTransport,
  title = {Graph {{Optimal Transport}} for {{Cross-Domain Alignment}}},
  author = {Chen, Liqun and Gan, Zhe and Cheng, Yu and Li, Linjie and Carin, Lawrence and Liu, Jingjing},
  abstract = {Cross-domain alignment between two sets of entities (e.g., objects in an image, words in a sentence) is fundamental to both computer vision and natural language processing. Existing methods mainly focus on designing advanced attention mechanisms to simulate soft alignment, with no training signals to explicitly encourage alignment. The learned attention matrices are also dense and lacks interpretability. We propose Graph Optimal Transport (GOT), a principled framework that germinates from recent advances in Optimal Transport (OT). In GOT, cross-domain alignment is formulated as a graph matching problem, by representing entities into a dynamically-constructed graph. Two types of OT distances are considered: (i) Wasserstein distance (WD) for node (entity) matching; and (ii) Gromov-Wasserstein distance (GWD) for edge (structure) matching. Both WD and GWD can be incorporated into existing neural network models, effectively acting as a dropin regularizer. The inferred transport plan also yields sparse and self-normalized alignment, enhancing the interpretability of the learned model. Experiments show consistent outperformance of GOT over baselines across a wide range of tasks, including image-text retrieval, visual question answering, image captioning, machine translation, and text summarization.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/YXHKAPQN/Chen et al. - Graph Optimal Transport for Cross-Domain Alignment.pdf}
}

@software{chenLiqunChen0606GraphOptimalTransport2025,
  title = {{{LiqunChen0606}}/{{Graph-Optimal-Transport}}},
  author = {Chen, Liqun},
  date = {2025-07-25T03:22:49Z},
  origdate = {2020-07-21T14:41:27Z},
  url = {https://github.com/LiqunChen0606/Graph-Optimal-Transport},
  urldate = {2025-09-08},
  abstract = {Code for ICML 2020 "Graph Optimal Transport for Cross-Domain Alignment"}
}

@article{chenNovelCrossDomainRecommendation2024,
  title = {A {{Novel Cross-Domain Recommendation}} with {{Evolution Learning}}},
  author = {Chen, Yi-Cheng and Lee, Wang-Chien},
  date = {2024-02-29},
  journaltitle = {ACM Transactions on Internet Technology},
  shortjournal = {ACM Trans. Internet Technol.},
  volume = {24},
  number = {1},
  pages = {1--23},
  issn = {1533-5399, 1557-6051},
  doi = {10.1145/3639567},
  url = {https://dl.acm.org/doi/10.1145/3639567},
  urldate = {2025-09-08},
  abstract = {In this “info-plosion” era, recommendation systems (or recommenders) play a significant role in finding interesting items in the surge of online digital activities and e-commerce. Several techniques have been widely applied for recommendation systems, but the cold-start and sparsity problems remain a major challenge. The cold-start~problem occurs when generating recommendations for new users and items without sufficient information. Sparsity refers to the problem of having a large amount of users and items but with few transactions or interactions. In this article, a novel cross-domain recommendation model, Cross-Domain Evolution Learning Recommendation (abbreviated as CD-ELR), is developed to communicate the information from different domains in order to tackle the cold-start and sparsity issues by integrating matrix factorization and recurrent neural network. We introduce an evolutionary concept to describe the preference variation of users over time. Furthermore, several optimization methods are developed for combining the domain features for precision recommendation. Experimental results show that CD-ELR outperforms existing state-of-the-art recommendation baselines. Finally, we conduct experiments on several real-world datasets to demonstrate the practicability of the proposed CD-ELR.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/6WH4SA5A/Chen and Lee - 2024 - A Novel Cross-Domain Recommendation with Evolution Learning.pdf}
}

@article{chenSymphonyNaturalLanguage2023,
  title = {Symphony: {{Towards Natural Language Query Answering}} over {{Multi-modal Data Lakes}}},
  author = {Chen, Zui and Gu, Zihui and Cao, Lei and Fan, Ju and Madden, Sam and Tang, Nan},
  date = {2023},
  abstract = {Wouldn’t it be great if we could query large, diverse data lakes of tables, text, and databases as easily as using Siri or Alexa? The problem is hard from two perspectives: integrating data lakes requires data normalization/transformation, schema matching, and entity resolution and is notoriously hard, with high human cost. Even if successful, such integration efforts typically do not support arbitrary SQL queries over the integrated data set. In this paper, we propose Symphony, a novel system that enables users to easily query complex, multi-modal data lakes without performing upfront integration. For ease of use, Symphony adopts a natural language (NL) interface. To avoid integration, it employs a unified representation for multi-modal datasets, called cross-modality representation learning. When a user poses an NL query, Symphony discovers which tables or textual data should be retrieved based on the learned cross-modal representations, decomposes a complicated NL query into NL sub-queries on-demand, evaluates each sub-query on one data source and combines the results from these sub-queries. A preliminary evaluation shows that the resulting system is able to effectively answer questions over tables and text extracted from Wikipedia.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/85JPUKBL/Chen et al. - 2023 - Symphony Towards Natural Language Query Answering.pdf}
}

@inproceedings{choiReviewBasedDomainDisentanglement2022,
  title = {Review-{{Based Domain Disentanglement}} without {{Duplicate Users}} or {{Contexts}} for {{Cross-Domain Recommendation}}},
  booktitle = {Proceedings of the 31st {{ACM International Conference}} on {{Information}} \& {{Knowledge Management}}},
  author = {Choi, Yoonhyuk and Choi, Jiho and Ko, Taewook and Byun, Hyungho and Kim, Chong-Kwon},
  date = {2022-10-17},
  eprint = {2110.12648},
  eprinttype = {arXiv},
  eprintclass = {cs},
  pages = {293--303},
  doi = {10.1145/3511808.3557434},
  url = {http://arxiv.org/abs/2110.12648},
  urldate = {2025-09-08},
  abstract = {A cross-domain recommendation has shown promising results in solving data-sparsity and cold-start problems. Despite such progress, existing methods focus on domain-shareable information (overlapped users or same contexts) for a knowledge transfer, and they fail to generalize well without such requirements. To deal with these problems, we suggest utilizing review texts that are general to most e-commerce systems. Our model (named SER) uses three text analysis modules, guided by a single domain discriminator for disentangled representation learning. Here, we suggest a novel optimization strategy that can enhance the quality of domain disentanglement, and also debilitates detrimental information of a source domain. Also, we extend the encoding network from a single to multiple domains, which has proven to be powerful for review-based recommender systems. Extensive experiments and ablation studies demonstrate that our method is efficient, robust, and scalable compared to the state-of-the-art single and cross-domain recommendation methods.},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Information Retrieval},
  file = {/Users/DAADAMS/Zotero/storage/TKR4CH2I/Choi et al. - 2022 - Review-Based Domain Disentanglement without Duplicate Users or Contexts for Cross-Domain Recommendat.pdf}
}

@software{chuangDataDesignerCOAST2025,
  title = {Data-{{Designer}}/{{COAST}}},
  author = {Chuang, Zhao},
  date = {2025-07-27T08:27:55Z},
  origdate = {2023-02-02T10:05:03Z},
  url = {https://github.com/Data-Designer/COAST},
  urldate = {2025-09-08}
}

@unpublished{cideronQdrlEfficientMixing2020,
  title = {Qd-Rl: {{Efficient}} Mixing of Quality and Diversity in Reinforcement Learning},
  shorttitle = {Qd-Rl},
  author = {Cideron, Geoffrey and Pierrot, Thomas and Perrin, Nicolas and Beguir, Karim and Sigaud, Olivier},
  date = {2020},
  eprint = {2006.08505},
  eprinttype = {arXiv},
  pages = {28--73},
  url = {https://www.researchgate.net/profile/Thomas-Pierrot-3/publication/342198149_QD-RL_Efficient_Mixing_of_Quality_and_Diversity_in_Reinforcement_Learning/links/5ef0d333a6fdcc73be945a29/QD-RL-Efficient-Mixing-of-Quality-and-Diversity-in-Reinforcement-Learning.pdf},
  urldate = {2024-09-11},
  file = {/Users/DAADAMS/Zotero/storage/IDBZ4FIN/Cideron et al. - 2020 - Qd-rl Efficient mixing of quality and diversity in reinforcement learning.pdf}
}

@online{cohenMaximumEntropyDiverse2019,
  title = {Maximum {{Entropy Diverse Exploration}}: {{Disentangling Maximum Entropy Reinforcement Learning}}},
  shorttitle = {Maximum {{Entropy Diverse Exploration}}},
  author = {Cohen, Andrew and Yu, Lei and Qiao, Xingye and Tong, Xiangrong},
  date = {2019-11-03},
  eprint = {1911.00828},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/1911.00828},
  urldate = {2024-09-03},
  abstract = {Two hitherto disconnected threads of research, diverse exploration (DE) and maximum entropy RL have addressed a wide range of problems facing reinforcement learning algorithms via ostensibly distinct mechanisms. In this work, we identify a connection between these two approaches. First, a discriminator-based diversity objective is put forward and connected to commonly used divergence measures. We then extend this objective to the maximum entropy framework and propose an algorithm Maximum Entropy Diverse Exploration (MEDE) which provides a principled method to learn diverse behaviors. A theoretical investigation shows that the set of policies learned by MEDE capture the same modalities as the optimal maximum entropy policy. In effect, the proposed algorithm disentangles the maximum entropy policy into its diverse, constituent policies. Experiments show that MEDE is superior to the state of the art in learning high performing and diverse policies.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/DAADAMS/Zotero/storage/PWPCXYB2/Cohen et al. - 2019 - Maximum Entropy Diverse Exploration Disentangling.pdf;/Users/DAADAMS/Zotero/storage/B8FF5RPY/1911.html}
}

@inproceedings{conroyTextSummarizationHidden2001,
  title = {Text Summarization via Hidden {{Markov}} Models},
  booktitle = {Proceedings of the 24th Annual International {{ACM SIGIR}} Conference on {{Research}} and Development in Information Retrieval},
  author = {Conroy, John M. and O'leary, Dianne P.},
  date = {2001-09},
  pages = {406--407},
  publisher = {ACM},
  location = {New Orleans Louisiana USA},
  doi = {10.1145/383952.384042},
  url = {https://dl.acm.org/doi/10.1145/383952.384042},
  urldate = {2025-02-16},
  eventtitle = {{{SIGIR01}}: 24th {{ACM}}/{{SIGIR International Conference}} on {{Research}} and {{Development}} in {{Information Retrieval}}},
  isbn = {978-1-58113-331-8},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/BPVIUP7K/Conroy and O'leary - 2001 - Text summarization via hidden Markov models.pdf}
}

@article{copulDemonstratingTabEETabular2024,
  title = {Demonstrating {{TabEE}}: {{Tabular Embedding Explanations}}},
  shorttitle = {Demonstrating {{TabEE}}},
  author = {Copul, Roni and Frost, Nave and Milo, Tova and Razmadze, Kathy},
  date = {2024-08},
  journaltitle = {Proceedings of the VLDB Endowment},
  shortjournal = {Proc. VLDB Endow.},
  volume = {17},
  number = {12},
  pages = {4285--4288},
  issn = {2150-8097},
  doi = {10.14778/3685800.3685856},
  url = {https://dl.acm.org/doi/10.14778/3685800.3685856},
  urldate = {2024-12-08},
  abstract = {We present TabEE, Tabular Embedding Explanations, a framework designed to generate explanations for interpreting tabular embedding models. Our framework aims to furnish both local and global explanations for the original data, facilitating the detection of potential flaws in embedding models. TabEE is versatile and compatible with any tabular embedding algorithm, as it adheres to the black box perspective of embedding models. The generated explanations also enable comparisons between multiple embedding models. This demonstration illustrates the effectiveness of TabEE in providing interpretable insights into tabular embedding models, contributing to improved model understanding and credibility assessment.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/A2W3AP2R/Copul et al. - 2024 - Demonstrating TabEE Tabular Embedding Explanations.pdf}
}

@online{correaClassicalPlanningLLMGenerated2025,
  title = {Classical {{Planning}} with {{LLM-Generated Heuristics}}: {{Challenging}} the {{State}} of the {{Art}} with {{Python Code}}},
  shorttitle = {Classical {{Planning}} with {{LLM-Generated Heuristics}}},
  author = {Corrêa, Augusto B. and Pereira, André G. and Seipp, Jendrik},
  date = {2025-03-24},
  eprint = {2503.18809},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2503.18809},
  url = {http://arxiv.org/abs/2503.18809},
  urldate = {2025-06-16},
  abstract = {In recent years, large language models (LLMs) have shown remarkable capabilities in various artificial intelligence problems. However, they fail to plan reliably, even when prompted with a detailed definition of the planning task. Attempts to improve their planning capabilities, such as chain-of-thought prompting, fine-tuning, and explicit “reasoning” still yield incorrect plans and usually fail to generalize to larger tasks. In this paper, we show how to use LLMs to generate correct plans, even for out-of-distribution tasks of increasing size. For a given planning domain, we ask an LLM to generate several domain-dependent heuristic functions in the form of Python code, evaluate them on a set of training tasks within a greedy best-first search, and choose the strongest one. The resulting LLM-generated heuristics solve many more unseen test tasks than state-of-the-art domain-independent heuristics for classical planning. They are even competitive with the strongest learning algorithm for domain-dependent planning. These findings are especially remarkable given that our proof-of-concept implementation is based on an unoptimized Python planner and the baselines all build upon highly optimized C++ code. In some domains, the LLM-generated heuristics expand fewer states than the baselines, revealing that they are not only efficiently computable, but sometimes even more informative than the state-of-the-art heuristics. Overall, our results show that sampling a set of planning heuristic function programs can significantly improve the planning capabilities of LLMs.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {/Users/DAADAMS/Zotero/storage/E4LKDGDJ/Corrêa et al. - 2025 - Classical Planning with LLM-Generated Heuristics Challenging the State of the Art with Python Code.pdf}
}

@article{cowlingEnsembleDeterminizationMonte2012,
  title = {Ensemble {{Determinization}} in {{Monte Carlo Tree Search}} for the {{Imperfect Information Card Game Magic}}: {{The Gathering}}},
  shorttitle = {Ensemble {{Determinization}} in {{Monte Carlo Tree Search}} for the {{Imperfect Information Card Game Magic}}},
  author = {Cowling, Peter I. and Ward, Colin D. and Powley, Edward J.},
  date = {2012-12},
  journaltitle = {IEEE Transactions on Computational Intelligence and AI in Games},
  shortjournal = {IEEE Trans. Comput. Intell. AI Games},
  volume = {4},
  number = {4},
  pages = {241--257},
  issn = {1943-068X, 1943-0698},
  doi = {10.1109/TCIAIG.2012.2204883},
  url = {http://ieeexplore.ieee.org/document/6218176/},
  urldate = {2024-03-15},
  abstract = {In this paper, we examine the use of Monte Carlo Tree Search (MCTS) for a variant of one of the most popular and profitable games in the world: the card game Magic: The Gathering (M:TG). The game tree for M:TG has a range of distinctive features, which we discuss here, and has incomplete information through the opponent’s hidden cards, and randomness through card drawing from a shuffled deck. We investigate a wide range of approaches that use determinization, where all hidden and random information is assumed known to all players, alongside Monte Carlo Tree Search. We consider a number of variations to the rollout strategy using a range of levels of sophistication and expert knowledge, and decaying reward to encourage play urgency. We examine the effect of utilising various pruning strategies in order to increase the information gained from each determinization, alongside methods that increase the relevance of random choices. Additionally we deconstruct the move generation procedure into a binary yes/no decision tree and apply MCTS to this finer grained decision process. We compare our modifications to a basic MCTS approach for Magic: The Gathering using fixed decks, and show that significant improvements in playing strength can be obtained.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/URS62NBJ/Cowling et al. - 2012 - Ensemble Determinization in Monte Carlo Tree Searc.pdf}
}

@inproceedings{dalkilicInformationDependencies2000,
  title = {Information Dependencies},
  booktitle = {Proceedings of the Nineteenth {{ACM SIGMOD-SIGACT-SIGART}} Symposium on {{Principles}} of Database Systems  - {{PODS}} '00},
  author = {Dalkilic, Mehmet M. and Roberston, Edward L.},
  date = {2000},
  pages = {245--253},
  publisher = {ACM Press},
  location = {Dallas, Texas, United States},
  doi = {10.1145/335168.336059},
  url = {http://portal.acm.org/citation.cfm?doid=335168.336059},
  urldate = {2024-07-30},
  abstract = {This paper uses the tools of information theory to examine and reason about the information content of the attributes within a relation instance. For tw o sets of attributes X and Y , an information dependency measure  InD measure  characterizes the uncertain ty remaining about the values for the set Y when the values for the set X are kno wn. A variety of arithmetic inequalities  InD inequalities  are shown to hold among InD measures; InD inequalities hold in any relation instance. Numeric constraints  InD constraints  on InD measures, consistent with the InD inequalities, can be applied to relation instances. Remarkably, functional and multivalued dependencies correspond to setting certain constrain ts to zero, with Armstrong's axioms shown to be consequences of the arithmetic inequalities applied to constraints. As an analog of completeness, for any set of constrain ts consisten t with the inequalities, we may construct a relation instance that appro ximates these constraints within any positiv e . InD measures suggest many valuable applications in areas such as data mining.},
  eventtitle = {The Nineteenth {{ACM SIGMOD-SIGACT-SIGART}} Symposium},
  isbn = {978-1-58113-214-4},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/9HEQSTKE/Dalkilic and Roberston - 2000 - Information dependencies.pdf}
}

@inproceedings{davidsonASQPRLDemoLearning2024,
  title = {{{ASQP-RL Demo}}: {{Learning Approximation Sets}} for {{Exploratory Queries}}},
  shorttitle = {{{ASQP-RL Demo}}},
  booktitle = {Companion of the 2024 {{International Conference}} on {{Management}} of {{Data}}},
  author = {Davidson, Susan B. and Milo, Tova and Razmadze, Kathy and Zeevi, Gal},
  date = {2024-06-09},
  pages = {452--455},
  publisher = {ACM},
  location = {Santiago AA Chile},
  doi = {10.1145/3626246.3654741},
  url = {https://dl.acm.org/doi/10.1145/3626246.3654741},
  urldate = {2024-12-08},
  abstract = {We demonstrate the Approximate Selection Query Processing (ASQPRL) system, which uses Reinforcement Learning to select a subset of a large external dataset to process locally in a notebook during data exploration. Given a query workload over an external database and notebook memory size, the system translates the workload to select-project-join (non-aggregate) queries and finds a subset of each relation such that the data subset – called the approximation set – fits into the notebook memory and maximizes query result quality. The data subset can then be loaded into the notebook, and rapidly queried by the analyst. Our demonstration shows how ASQP-RL can be used during data exploration and achieve comparable results to external queries over the large dataset at significantly reduced query times. It also shows how ASQP-RL can be used for aggregation queries, achieving surprisingly good results compared to state-of-the-art techniques.},
  eventtitle = {{{SIGMOD}}/{{PODS}} '24: {{International Conference}} on {{Management}} of {{Data}}},
  isbn = {979-8-4007-0422-2},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/D56FL4KS/Davidson et al. - 2024 - ASQP-RL Demo Learning Approximation Sets for Exploratory Queries.pdf}
}

@online{degiacomoPlanningTemporallyExtended2022,
  title = {Planning for {{Temporally Extended Goals}} in {{Pure-Past Linear Temporal Logic}}: {{A Polynomial Reduction}} to {{Standard Planning}}},
  shorttitle = {Planning for {{Temporally Extended Goals}} in {{Pure-Past Linear Temporal Logic}}},
  author = {De Giacomo, Giuseppe and Favorito, Marco and Fuggitti, Francesco},
  date = {2022-05-31},
  eprint = {2204.09960},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2204.09960},
  urldate = {2024-05-07},
  abstract = {We study temporally extended goals expressed in Pure-Past ltl (ppltl). ppltl is particularly interesting for expressing goals since it allows to express sophisticated tasks as in the Formal Methods literature, while the worst-case computational complexity of Planning in both deterministic and nondeterministic domains (FOND) remains the same as for classical reachability goals. However, while the theory of planning for ppltl goals is well understood, practical tools have not been specifically investigated. In this paper, we make a significant leap forward in the construction of actual tools to handle ppltl goals. We devise a technique to polynomially translate planning for ppltl goals into standard planning. We show the formal correctness of the translation, its complexity, and its practical effectiveness through some comparative experiments. As a result, our translation enables state-of-the-art tools, such as FD or MyND, to handle ppltl goals seamlessly, maintaining the impressive performances they have for classical reachability goals.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence},
  file = {/Users/DAADAMS/Zotero/storage/EJDY9ZBB/De Giacomo et al. - 2022 - Planning for Temporally Extended Goals in Pure-Pas.pdf}
}

@article{deutchExplainEDExplanationsEDA2020,
  title = {{{ExplainED}}: Explanations for {{EDA}} Notebooks},
  shorttitle = {{{ExplainED}}},
  author = {Deutch, Daniel and Gilad, Amir and Milo, Tova and Somech, Amit},
  date = {2020-08},
  journaltitle = {Proceedings of the VLDB Endowment},
  shortjournal = {Proc. VLDB Endow.},
  volume = {13},
  number = {12},
  pages = {2917--2920},
  issn = {2150-8097},
  doi = {10.14778/3415478.3415508},
  url = {https://dl.acm.org/doi/10.14778/3415478.3415508},
  urldate = {2024-12-08},
  abstract = {Exploratory Data Analysis (EDA) is an essential yet highly demanding task. To get a head start before exploring a new dataset, data scientists often prefer to view existing EDA notebooks – illustrative exploratory sessions that were created by fellow data scientists who examined the same dataset and shared their notebooks via online platforms. Unfortunately, creating an illustrative, well-documented notebook is cumbersome and time-consuming, therefore users sometimes share their notebook without explaining their exploratory steps and their results. Such notebooks are difficult to follow and to understand.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/7VLVT28C/Deutch et al. - 2020 - ExplainED explanations for EDA notebooks.pdf}
}

@online{deutchFEDEXExplainabilityFramework2022,
  title = {{{FEDEX}}: {{An Explainability Framework}} for {{Data Exploration Steps}}},
  shorttitle = {{{FEDEX}}},
  author = {Deutch, Daniel and Gilad, Amir and Milo, Tova and Mualem, Amit and Somech, Amit},
  date = {2022-09-13},
  eprint = {2209.06260},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2209.06260},
  url = {http://arxiv.org/abs/2209.06260},
  urldate = {2024-12-08},
  abstract = {When exploring a new dataset, Data Scientists often apply analysis queries, look for insights in the resulting dataframe, and repeat to apply further queries. We propose in this paper a novel solution that assists data scientists in this laborious process. In a nutshell, our solution pinpoints the most interesting (sets of) rows in each obtained dataframe. Uniquely, our definition of interest is based on the contribution of each row to the interestingness of different columns of the entire dataframe, which, in turn, is defined using standard measures such as diversity and exceptionality. Intuitively, interesting rows are ones that explain why (some column of) the analysis query result is interesting as a whole. Rows are correlated in their contribution and so the interesting score for a set of rows may not be directly computed based on that of individual rows. We address the resulting computational challenge by restricting attention to semantically-related sets, based on multiple notions of semantic relatedness; these sets serve as more informative explanations. Our experimental study across multiple real-world datasets shows the usefulness of our system in various scenarios.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Databases},
  file = {/Users/DAADAMS/Zotero/storage/DZABRIZA/Deutch et al. - 2022 - FEDEX An Explainability Framework for Data Exploration Steps.pdf}
}

@inproceedings{deutchQPlainQueryExplanation2016,
  title = {{{QPlain}}: {{Query}} by Explanation},
  shorttitle = {{{QPlain}}},
  booktitle = {2016 {{IEEE}} 32nd {{International Conference}} on {{Data Engineering}} ({{ICDE}})},
  author = {Deutch, Daniel and Gilad, Amir},
  date = {2016},
  pages = {1358--1361},
  publisher = {IEEE},
  url = {https://ieeexplore.ieee.org/abstract/document/7498344/},
  urldate = {2025-02-16},
  file = {/Users/DAADAMS/Zotero/storage/LY96BQW4/Deutch and Gilad - 2016 - QPlain Query by explanation.pdf}
}

@article{dibiaData2visAutomaticGeneration2019,
  title = {Data2vis: {{Automatic}} Generation of Data Visualizations Using Sequence-to-Sequence Recurrent Neural Networks},
  shorttitle = {Data2vis},
  author = {Dibia, Victor and Demiralp, Çağatay},
  date = {2019},
  journaltitle = {IEEE computer graphics and applications},
  volume = {39},
  number = {5},
  pages = {33--46},
  publisher = {IEEE},
  url = {https://ieeexplore.ieee.org/abstract/document/8744242/},
  urldate = {2025-02-16},
  file = {/Users/DAADAMS/Zotero/storage/EFLQRS6K/Dibia and Demiralp - 2019 - Data2vis Automatic generation of data visualizations using sequence-to-sequence recurrent neural ne.pdf}
}

@article{dibowski28SeptemberOktober2021,
  title = {28. {{September}} - 2. {{Oktober}} 2020},
  author = {Dibowski, Henrik and Schmid, Stefan},
  date = {2021},
  publisher = {[object Object]},
  issn = {1617-5468},
  doi = {10.18420/INF2020_02},
  url = {http://dl.gi.de/handle/20.500.12116/34726},
  urldate = {2024-03-19},
  abstract = {Knowledge graphs as fundamental pillar of artificial intelligence are experiencing a strong demand. In contrast to machine learning and deep learning, knowledge graphs do not require large amounts of (training) data and offer a bigger potential for a multitude of domains and problems. This article shows the application of knowledge graphs for the semantic description and management of data in a data lake, which improves the findability and reusability of data, and enables the automatic processing by algorithms. Since knowledge graphs contain both the data as well as its semantically described schema (ontology), they enable novel ontology-driven software architectures, in which the domain knowledge and business logic can completely reside on the knowledge graph level. This article further introduces such a use caseȷ an ontology-driven frontend implementation, which is able to fully adapt itself based on the underlying knowledge graph schema and dynamically render information in the desired manner.},
  isbn = {9783885797012},
  langid = {english},
  keywords = {Artificial Intelligence,Data Catalog,Knowledge Graph,Knowledge Representation,Ontology,Ontology-Driven UIs,Semantic Data Lake,Semantic Layer,Semantic Search},
  file = {/Users/DAADAMS/Zotero/storage/AKECNVBW/Dibowski and Schmid - 2021 - 28. September - 2. Oktober 2020.pdf}
}

@article{difallahOLTPBenchExtensibleTestbed2013,
  title = {{{OLTP-Bench}}: An Extensible Testbed for Benchmarking Relational Databases},
  shorttitle = {{{OLTP-Bench}}},
  author = {Difallah, Djellel Eddine and Pavlo, Andrew and Curino, Carlo and Cudre-Mauroux, Philippe},
  date = {2013-12},
  journaltitle = {Proceedings of the VLDB Endowment},
  shortjournal = {Proc. VLDB Endow.},
  volume = {7},
  number = {4},
  pages = {277--288},
  issn = {2150-8097},
  doi = {10.14778/2732240.2732246},
  url = {https://dl.acm.org/doi/10.14778/2732240.2732246},
  urldate = {2025-02-24},
  abstract = {Benchmarking is an essential aspect of any database management system (DBMS) effort. Despite several recent advancements, such as pre-configured cloud database images and database-as-a-service (DBaaS) offerings, the deployment of a comprehensive testing platform with a diverse set of datasets and workloads is still far from being trivial. In many cases, researchers and developers are limited to a small number of workloads to evaluate the performance characteristics of their work. This is due to the lack of a universal benchmarking infrastructure, and to the difficulty of gaining access to real data and workloads. This results in lots of unnecessary engineering efforts and makes the performance evaluation results difficult to compare. To remedy these problems, we present OLTP-Bench, an extensible “batteries included” DBMS benchmarking testbed. The key contributions of OLTP-Bench are its ease of use and extensibility, support for tight control of transaction mixtures, request rates, and access distributions over time, as well as the ability to support all major DBMSs and DBaaS platforms. Moreover, it is bundled with fifteen workloads that all differ in complexity and system demands, including four synthetic workloads, eight workloads from popular benchmarks, and three workloads that are derived from real-world applications. We demonstrate through a comprehensive set of experiments conducted on popular DBMS and DBaaS offerings the different features provided by OLTP-Bench and the effectiveness of our testbed in characterizing the performance of database services.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/EVY8BYTW/Difallah et al. - 2013 - OLTP-Bench an extensible testbed for benchmarking relational databases.pdf}
}

@article{difallahOLTPBenchExtensibleTestbed2013a,
  title = {{{OLTP-Bench}}: An Extensible Testbed for Benchmarking Relational Databases},
  shorttitle = {{{OLTP-Bench}}},
  author = {Difallah, Djellel Eddine and Pavlo, Andrew and Curino, Carlo and Cudre-Mauroux, Philippe},
  date = {2013-12},
  journaltitle = {Proceedings of the VLDB Endowment},
  shortjournal = {Proc. VLDB Endow.},
  volume = {7},
  number = {4},
  pages = {277--288},
  issn = {2150-8097},
  doi = {10.14778/2732240.2732246},
  url = {https://dl.acm.org/doi/10.14778/2732240.2732246},
  urldate = {2025-02-24},
  abstract = {Benchmarking is an essential aspect of any database management system (DBMS) effort. Despite several recent advancements, such as pre-configured cloud database images and database-as-a-service (DBaaS) offerings, the deployment of a comprehensive testing platform with a diverse set of datasets and workloads is still far from being trivial. In many cases, researchers and developers are limited to a small number of workloads to evaluate the performance characteristics of their work. This is due to the lack of a universal benchmarking infrastructure, and to the difficulty of gaining access to real data and workloads. This results in lots of unnecessary engineering efforts and makes the performance evaluation results difficult to compare. To remedy these problems, we present OLTP-Bench, an extensible “batteries included” DBMS benchmarking testbed. The key contributions of OLTP-Bench are its ease of use and extensibility, support for tight control of transaction mixtures, request rates, and access distributions over time, as well as the ability to support all major DBMSs and DBaaS platforms. Moreover, it is bundled with fifteen workloads that all differ in complexity and system demands, including four synthetic workloads, eight workloads from popular benchmarks, and three workloads that are derived from real-world applications. We demonstrate through a comprehensive set of experiments conducted on popular DBMS and DBaaS offerings the different features provided by OLTP-Bench and the effectiveness of our testbed in characterizing the performance of database services.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/QGXPK4X2/Difallah et al. - 2013 - OLTP-Bench an extensible testbed for benchmarking relational databases.pdf}
}

@article{dimitriadouAIDEActiveLearningBased2016,
  title = {{{AIDE}}: {{An Active Learning-Based Approach}} for {{Interactive Data Exploration}}},
  shorttitle = {{{AIDE}}},
  author = {Dimitriadou, Kyriaki and Papaemmanouil, Olga and Diao, Yanlei},
  date = {2016-11-01},
  journaltitle = {IEEE Transactions on Knowledge and Data Engineering},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  volume = {28},
  number = {11},
  pages = {2842--2856},
  issn = {1041-4347},
  doi = {10.1109/TKDE.2016.2599168},
  url = {http://ieeexplore.ieee.org/document/7539596/},
  urldate = {2025-01-28},
  abstract = {In this paper, we argue that database systems be augmented with an automated data exploration service that methodically steers users through the data in a meaningful way. Such an automated system is crucial for deriving insights from complex datasets found in many big data applications such as scientific and healthcare applications as well as for reducing the human effort of data exploration. Towards this end, we present AIDE, an Automatic Interactive Data Exploration framework that assists users in discovering new interesting data patterns and eliminate expensive ad-hoc exploratory queries. AIDE relies on a seamless integration of classification algorithms and data management optimization techniques that collectively strive to accurately learn the user interests based on his relevance feedback on strategically collected samples. We present a number of exploration techniques as well as optimizations that minimize the number of samples presented to the user while offering interactive performance. AIDE can deliver highly accurate query predictions for very common conjunctive queries with small user effort while, given a reasonable number of samples, it can predict with high accuracy complex disjunctive queries. It provides interactive performance as it limits the user wait time per iteration of exploration to less than a few seconds.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/MNPN7J47/Dimitriadou et al. - 2016 - AIDE An Active Learning-Based Approach for Interactive Data Exploration.pdf}
}

@article{dimitriadouAIDEActiveLearningBased2016a,
  title = {{{AIDE}}: {{An Active Learning-Based Approach}} for {{Interactive Data Exploration}}},
  shorttitle = {{{AIDE}}},
  author = {Dimitriadou, Kyriaki and Papaemmanouil, Olga and Diao, Yanlei},
  date = {2016-11-01},
  journaltitle = {IEEE Transactions on Knowledge and Data Engineering},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  volume = {28},
  number = {11},
  pages = {2842--2856},
  issn = {1041-4347},
  doi = {10.1109/TKDE.2016.2599168},
  url = {http://ieeexplore.ieee.org/document/7539596/},
  urldate = {2025-02-05},
  abstract = {In this paper, we argue that database systems be augmented with an automated data exploration service that methodically steers users through the data in a meaningful way. Such an automated system is crucial for deriving insights from complex datasets found in many big data applications such as scientific and healthcare applications as well as for reducing the human effort of data exploration. Towards this end, we present AIDE, an Automatic Interactive Data Exploration framework that assists users in discovering new interesting data patterns and eliminate expensive ad-hoc exploratory queries. AIDE relies on a seamless integration of classification algorithms and data management optimization techniques that collectively strive to accurately learn the user interests based on his relevance feedback on strategically collected samples. We present a number of exploration techniques as well as optimizations that minimize the number of samples presented to the user while offering interactive performance. AIDE can deliver highly accurate query predictions for very common conjunctive queries with small user effort while, given a reasonable number of samples, it can predict with high accuracy complex disjunctive queries. It provides interactive performance as it limits the user wait time per iteration of exploration to less than a few seconds.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/N3QAE8DF/Dimitriadou et al. - 2016 - AIDE An Active Learning-Based Approach for Interactive Data Exploration.pdf}
}

@article{dimitriadouAIDEActiveLearningbased2016b,
  title = {{{AIDE}}: An Active Learning-Based Approach for Interactive Data Exploration},
  shorttitle = {{{AIDE}}},
  author = {Dimitriadou, Kyriaki and Papaemmanouil, Olga and Diao, Yanlei},
  date = {2016},
  journaltitle = {IEEE Transactions on Knowledge and Data Engineering},
  volume = {28},
  number = {11},
  pages = {2842--2856},
  publisher = {IEEE},
  url = {https://ieeexplore.ieee.org/abstract/document/7539596/},
  urldate = {2025-02-16},
  file = {/Users/DAADAMS/Zotero/storage/92K3SJQK/Dimitriadou et al. - 2016 - AIDE an active learning-based approach for interactive data exploration.pdf}
}

@inproceedings{dimitriadouExplorebyexampleAutomaticQuery2014a,
  title = {Explore-by-Example: An Automatic Query Steering Framework for Interactive Data Exploration},
  shorttitle = {Explore-by-Example},
  booktitle = {Proceedings of the 2014 {{ACM SIGMOD International Conference}} on {{Management}} of {{Data}}},
  author = {Dimitriadou, Kyriaki and Papaemmanouil, Olga and Diao, Yanlei},
  date = {2014-06-18},
  pages = {517--528},
  publisher = {ACM},
  location = {Snowbird Utah USA},
  doi = {10.1145/2588555.2610523},
  url = {https://dl.acm.org/doi/10.1145/2588555.2610523},
  urldate = {2025-02-05},
  abstract = {Interactive Data Exploration (IDE) is a key ingredient of a diverse set of discovery-oriented applications, including ones from scientific computing and evidence-based medicine. In these applications, data discovery is a highly ad hoc interactive process where users execute numerous exploration queries using varying predicates aiming to balance the trade-off between collecting all relevant information and reducing the size of returned data. Therefore, there is a strong need to support these human-in-the-loop applications by assisting their navigation in the data to find interesting objects.},
  eventtitle = {{{SIGMOD}}/{{PODS}}'14: {{International Conference}} on {{Management}} of {{Data}}},
  isbn = {978-1-4503-2376-5},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/VUBRJS3Z/Dimitriadou et al. - 2014 - Explore-by-example an automatic query steering framework for interactive data exploration.pdf}
}

@inproceedings{dingQuickInsightsQuickAutomatic2019,
  title = {{{QuickInsights}}: {{Quick}} and {{Automatic Discovery}} of {{Insights}} from {{Multi-Dimensional Data}}},
  shorttitle = {{{QuickInsights}}},
  booktitle = {Proceedings of the 2019 {{International Conference}} on {{Management}} of {{Data}}},
  author = {Ding, Rui and Han, Shi and Xu, Yong and Zhang, Haidong and Zhang, Dongmei},
  date = {2019-06-25},
  pages = {317--332},
  publisher = {ACM},
  location = {Amsterdam Netherlands},
  doi = {10.1145/3299869.3314037},
  url = {https://dl.acm.org/doi/10.1145/3299869.3314037},
  urldate = {2025-02-03},
  abstract = {Discovering interesting data patterns is a common and important analytical need in data, with increasing user demand for automated discovery abilities. However, automatically discovering interesting patterns from multi-dimensional data remains challenging. Existing techniques focus on mining individual types of patterns. There is a lack of unified formulation for different pattern types, as well as general mining frameworks to derive them effectively and efficiently. We present a novel technique QuickInsights, which quickly and automatically discovers interesting patterns from multi-dimensional data. QuickInsights proposes a unified formulation of interesting patterns, called insights, and designs a systematic mining framework to discover high-quality insights efficiently. We demonstrate the effectiveness and efficiency of QuickInsights through our evaluation on 447 real datasets as well as user studies on both expert users and non-expert users. QuickInsights is released in Microsoft Power BI.},
  eventtitle = {{{SIGMOD}}/{{PODS}} '19: {{International Conference}} on {{Management}} of {{Data}}},
  isbn = {978-1-4503-5643-5},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/B9JUE58Q/Ding et al. - 2019 - QuickInsights Quick and Automatic Discovery of Insights from Multi-Dimensional Data.pdf}
}

@inproceedings{djenouriGPUbasedBioinspiredModel2017,
  title = {{{GPU-based}} Bio-Inspired Model for Solving Association Rules Mining Problem},
  booktitle = {2017 25th {{Euromicro International Conference}} on {{Parallel}}, {{Distributed}} and {{Network-Based Processing}} ({{PDP}})},
  author = {Djenouri, Youcef and Bendjoudi, Ahcene and Djenouri, Djamel and Comuzzi, Marco},
  date = {2017},
  pages = {262--269},
  publisher = {IEEE},
  url = {https://ieeexplore.ieee.org/abstract/document/7912657/},
  urldate = {2024-12-23},
  file = {/Users/DAADAMS/Zotero/storage/P2HBGGAW/Djenouri et al. - 2017 - GPU-based bio-inspired model for solving association rules mining problem.pdf;/Users/DAADAMS/Zotero/storage/62JRBM5K/scholar.html}
}

@online{dorazioAlternativeFunctionApproximation2020,
  title = {Alternative {{Function Approximation Parameterizations}} for {{Solving Games}}: {{An Analysis}} of \$f\$-{{Regression Counterfactual Regret Minimization}}},
  shorttitle = {Alternative {{Function Approximation Parameterizations}} for {{Solving Games}}},
  author = {D'Orazio, Ryan and Morrill, Dustin and Wright, James R. and Bowling, Michael},
  date = {2020-05-01},
  eprint = {1912.02967},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1912.02967},
  urldate = {2024-03-15},
  abstract = {Function approximation is a powerful approach for structuring large decision problems that has facilitated great achievements in the areas of reinforcement learning and game playing. Regression counterfactual regret minimization (RCFR) is a simple algorithm for approximately solving imperfect information games with normalized rectified linear unit (ReLU) parameterized policies. In contrast, the more conventional softmax parameterization is standard in the field of reinforcement learning and yields a regret bound with a better dependence on the number of actions. We derive approximation error-aware regret bounds for (Φ, f )-regret matching, which applies to a general class of link functions and regret objectives. These bounds recover a tighter bound for RCFR and provide a theoretical justification for RCFR implementations with alternative policy parameterizations (f -RCFR), including softmax. We provide exploitability bounds for f -RCFR with the polynomial and exponential link functions in zero-sum imperfect information games and examine empirically how the link function interacts with the severity of the approximation. We find that the previously studied ReLU parameterization performs better when the approximation error is small while the softmax parameterization can perform better when the approximation error is large.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Science and Game Theory,Computer Science - Machine Learning},
  file = {/Users/DAADAMS/Zotero/storage/3G49UCTP/D'Orazio et al. - 2020 - Alternative Function Approximation Parameterizatio.pdf}
}

@inproceedings{dragomirCentroidbasedSummarizationMultiple2000,
  title = {Centroid-Based Summarization of Multiple Documents: Sentence Extraction, Utility-Based Evaluation, and User Studies},
  shorttitle = {Centroid-Based Summarization of Multiple Documents},
  booktitle = {{{ANLP}}/{{NAACL Workshop}} on {{Summarization}}},
  author = {Dragomir, Radev and Hongyan, Jing and Malgorzata, Budzikowska},
  date = {2000},
  volume = {10},
  number = {1117575.1117578}
}

@inproceedings{drosouReDRIVEResultdrivenDatabase2011,
  title = {{{ReDRIVE}}: Result-Driven Database Exploration through Recommendations},
  shorttitle = {{{ReDRIVE}}},
  booktitle = {Proceedings of the 20th {{ACM}} International Conference on {{Information}} and Knowledge Management},
  author = {Drosou, Marina and Pitoura, Evaggelia},
  date = {2011-10-24},
  pages = {1547--1552},
  publisher = {ACM},
  location = {Glasgow Scotland, UK},
  doi = {10.1145/2063576.2063798},
  url = {https://dl.acm.org/doi/10.1145/2063576.2063798},
  urldate = {2025-03-31},
  abstract = {Typically, users interact with database systems by formulating queries. However, many times users do not have a clear understanding of their information needs or the exact content of the database, thus, their queries are of an exploratory nature. In this paper, we propose assisting users in database exploration by recommending to them additional items that are highly related with the items in the result of their original query. Such items are computed based on the most interesting sets of attribute values (or faSets) that appear in the result of the original user query. The interestingness of a faSet is defined based on its frequency both in the query result and in the database instance. Database frequency estimations rely on a novel approach that employs an ǫ-tolerance closed rare faSets representation. We report evaluation results of the efficiency and effectiveness of our approach on both real and synthetic datasets.},
  eventtitle = {{{CIKM}} '11: {{International Conference}} on {{Information}} and {{Knowledge Management}}},
  isbn = {978-1-4503-0717-8},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/UFXUZXG5/Drosou and Pitoura - 2011 - ReDRIVE result-driven database exploration through recommendations.pdf}
}

@article{drosouYmaldbExploringRelational2013,
  title = {Ymaldb: Exploring Relational Databases via Result-Driven Recommendations},
  shorttitle = {Ymaldb},
  author = {Drosou, Marina and Pitoura, Evaggelia},
  date = {2013},
  journaltitle = {The VLDB Journal},
  volume = {22},
  number = {6},
  pages = {849--874},
  publisher = {Springer},
  url = {https://idp.springer.com/authorize/casa?redirect_uri=https://link.springer.com/article/10.1007/s00778-013-0311-4&casa_token=_95ap7BkCHgAAAAA:QxTiALvUkDAHVI4YtjKbg0V88WogQQM34DmzcLGTgCs5ORhy_PYn0D1yCOBuOou0OIoFu80qXZAfla3n},
  urldate = {2025-02-13},
  file = {/Users/DAADAMS/Zotero/storage/RLW58QMR/s00778-013-0311-4.html}
}

@article{dushkinQueryDrivenData,
  title = {Query {{Driven Data Labeling}} with {{Experts}}: {{Why Pay Twice}}?},
  author = {Dushkin, Eyal and Gershtein, Shay and Milo, Tova and Novgorodov, Slava},
  abstract = {Data has become a major priority for customer facing businesses of all sizes. Companies put a lot of effort and money into storing, cleaning, organizing, enriching and processing data to better meet user needs. Usually in large scale systems such as big ecommerce sites these tasks involve machine learning methods, relying on training data annotated by domain experts. Since domain experts are an expensive resource in terms of monetary costs and latency, it is desired to design algorithms that minimize the interaction with them.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/3WMBE6L2/Dushkin et al. - Query Driven Data Labeling with Experts Why Pay Twice.pdf}
}

@article{edmundsonNewMethodsAutomatic1969,
  title = {New {{Methods}} in {{Automatic Extracting}}},
  author = {Edmundson, H. P.},
  date = {1969-04},
  journaltitle = {Journal of the ACM},
  shortjournal = {J. ACM},
  volume = {16},
  number = {2},
  pages = {264--285},
  issn = {0004-5411, 1557-735X},
  doi = {10.1145/321510.321519},
  url = {https://dl.acm.org/doi/10.1145/321510.321519},
  urldate = {2025-02-16},
  abstract = {This paper describes new methods of automatically extracting documents for screening purposes, i.e. the computer selection of sentences having the greatest potential for conveying to the reader the substance of the document. While previous work has focused on one component of sentence significance, namely, the presence of high-frequency content words (key words), the methods described here also treat three additional components: pragmatic words (cue words); title and heading words; and structural indicators (sentence location).             The research has resulted in an operating system and a research methodology. The extracting system is parameterized to control and vary the influence of the above four components. The research methodology includes procedures for the compilation of the required dictionaries, the setting of the control parameters, and the comparative evaluation of the automatic extracts with manually produced extracts. The results indicate that the three newly proposed components dominate the frequency component in the production of better extracts.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/SU28P87J/Edmundson - 1969 - New Methods in Automatic Extracting.pdf}
}

@inproceedings{eichmannIDEBenchBenchmarkInteractive2020,
  title = {{{IDEBench}}: {{A Benchmark}} for {{Interactive Data Exploration}}},
  shorttitle = {{{IDEBench}}},
  booktitle = {Proceedings of the 2020 {{ACM SIGMOD International Conference}} on {{Management}} of {{Data}}},
  author = {Eichmann, Philipp and Zgraggen, Emanuel and Binnig, Carsten and Kraska, Tim},
  date = {2020-06-11},
  pages = {1555--1569},
  publisher = {ACM},
  location = {Portland OR USA},
  doi = {10.1145/3318464.3380574},
  url = {https://dl.acm.org/doi/10.1145/3318464.3380574},
  urldate = {2025-02-05},
  abstract = {In recent years, many query processing techniques have been developed to better support interactive data exploration (IDE) of large structured datasets. To evaluate and compare database engines in terms of how well they support such workloads, experimenters have mostly used self-designed evaluation procedures rather than established benchmarks. In this paper we argue that this is due to the fact that the workloads and metrics of popular analytical benchmarks such as TPC-H or TPC-DS were designed for traditional performance reporting scenarios, and do not capture distinctive IDE characteristics. Guided by the findings of several user studies we present a new benchmark called IDEBench, designed to evaluate database engines based on common IDE workflows and metrics that matter to the end-user. We demonstrate the applicability of IDEBench through a number of experiments with five different database engines, and present and discuss our findings.},
  eventtitle = {{{SIGMOD}}/{{PODS}} '20: {{International Conference}} on {{Management}} of {{Data}}},
  isbn = {978-1-4503-6735-6},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/SGI2JY3U/Eichmann et al. - 2020 - IDEBench A Benchmark for Interactive Data Exploration.pdf}
}

@inproceedings{einyCostEffectiveLLMUtilization2024,
  title = {Cost-{{Effective LLM Utilization}} for {{Machine Learning Tasks}} over {{Tabular Data}}},
  booktitle = {Proceedings of the {{Conference}} on {{Governance}}, {{Understanding}} and {{Integration}} of {{Data}} for {{Effective}} and {{Responsible AI}}},
  author = {Einy, Yael and Milo, Tova and Novgorodov, Slava},
  date = {2024-06-09},
  pages = {45--49},
  publisher = {ACM},
  location = {Santiago AA Chile},
  doi = {10.1145/3665601.3669848},
  url = {https://dl.acm.org/doi/10.1145/3665601.3669848},
  urldate = {2024-12-08},
  abstract = {Classic machine learning (ML) models excel in modeling tabular datasets but lack broader world knowledge due to the absence of pre-training, an area where Large Language Models (LLMs) stand out. This paper presents an effective method that bridges the gap, leveraging LLMs to enrich tabular data to enhance the performance of classical ML models. Despite the previously limited success of direct LLM application to tabular tasks due to their high computational demands, our approach selectively enriches datasets with essential world knowledge, balancing performance improvement with costeffectiveness. This work advances the capabilities of traditional ML models and opens new avenues for research at the convergence of classical ML and LLMs, marking the onset of a new era in cost-effective data enrichment.},
  eventtitle = {{{SIGMOD}}/{{PODS}} '24: {{International Conference}} on {{Management}} of {{Data}}},
  isbn = {979-8-4007-0694-3},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/VU4URLAM/Einy et al. - 2024 - Cost-Effective LLM Utilization for Machine Learning Tasks over Tabular Data.pdf}
}

@article{eirinakiQuerieCollaborativeDatabase2013,
  title = {Querie: {{Collaborative}} Database Exploration},
  shorttitle = {Querie},
  author = {Eirinaki, Magdalini and Abraham, Suju and Polyzotis, Neoklis and Shaikh, Naushin},
  date = {2013},
  journaltitle = {IEEE Transactions on knowledge and data engineering},
  volume = {26},
  number = {7},
  pages = {1778--1790},
  publisher = {IEEE},
  url = {https://ieeexplore.ieee.org/abstract/document/6515114/},
  urldate = {2025-02-16},
  file = {/Users/DAADAMS/Zotero/storage/5C93UHP5/Eirinaki et al. - 2013 - Querie Collaborative database exploration.pdf}
}

@article{evansSimilaritybasedMultilingualMultidocument2005,
  title = {Similarity-Based Multilingual Multi-Document Summarization},
  author = {Evans, David Kirk and McKeown, Kathleen and Klavans, Judith L.},
  date = {2005},
  file = {/Users/DAADAMS/Zotero/storage/QJNP2ZB5/Evans et al. - 2005 - Similarity-based multilingual multi-document summarization.pdf}
}

@article{fisterjrNarmVizNovelMethod2024,
  title = {{{NarmViz}}: {{A}} Novel Method for Visualization of Time Series Numerical Association Rules for Smart Agriculture},
  shorttitle = {{{NarmViz}}},
  author = {Fister Jr, Iztok and Fister, Iztok and Podgorelec, Vili and Salcedo-Sanz, Sancho and Holzinger, Andreas},
  date = {2024},
  journaltitle = {Expert Systems},
  volume = {41},
  number = {3},
  pages = {e13503},
  issn = {1468-0394},
  doi = {10.1111/exsy.13503},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/exsy.13503},
  urldate = {2025-01-07},
  abstract = {Numerical association rule mining (NARM) is a popular method under the umbrella of data mining, focused on finding relationships between attributes in transaction databases. Numerical association rules for time series are a new paradigm that extends the applicability of NARM to the domain of time series. Association rule mining algorithms result in numerous rules, the interpretation of which is sometimes not easy for human experts. Therefore, various visualization methods have been developed to improve the explanation results of the rule mining process. This article is a novel contribution to the development of a new visualization method capable of presenting the association rules for time series developed according to the principles of explainable artificial intelligence. The experiments are conducted in the context of smart agriculture (i.e., agricultural time series data), and show the great potential of the proposed visualization method for the future.},
  langid = {english},
  keywords = {association rule mining,explainable artificial intelligence,smart agriculture,time series,visualization},
  file = {/Users/DAADAMS/Zotero/storage/G5ZET3G7/Fister Jr et al. - 2024 - NarmViz A novel method for visualization of time series numerical association rules for smart agric.pdf;/Users/DAADAMS/Zotero/storage/8QK33WMI/exsy.html}
}

@online{gadreDataCompSearchNext2023,
  title = {{{DataComp}}: {{In}} Search of the next Generation of Multimodal Datasets},
  shorttitle = {{{DataComp}}},
  author = {Gadre, Samir Yitzhak and Ilharco, Gabriel and Fang, Alex and Hayase, Jonathan and Smyrnis, Georgios and Nguyen, Thao and Marten, Ryan and Wortsman, Mitchell and Ghosh, Dhruba and Zhang, Jieyu and Orgad, Eyal and Entezari, Rahim and Daras, Giannis and Pratt, Sarah and Ramanujan, Vivek and Bitton, Yonatan and Marathe, Kalyani and Mussmann, Stephen and Vencu, Richard and Cherti, Mehdi and Krishna, Ranjay and Koh, Pang Wei and Saukh, Olga and Ratner, Alexander and Song, Shuran and Hajishirzi, Hannaneh and Farhadi, Ali and Beaumont, Romain and Oh, Sewoong and Dimakis, Alex and Jitsev, Jenia and Carmon, Yair and Shankar, Vaishaal and Schmidt, Ludwig},
  date = {2023-04-27},
  url = {https://arxiv.org/abs/2304.14108v5},
  urldate = {2024-03-19},
  abstract = {Multimodal datasets are a critical component in recent breakthroughs such as Stable Diffusion and GPT-4, yet their design does not receive the same research attention as model architectures or training algorithms. To address this shortcoming in the ML ecosystem, we introduce DataComp, a testbed for dataset experiments centered around a new candidate pool of 12.8 billion image-text pairs from Common Crawl. Participants in our benchmark design new filtering techniques or curate new data sources and then evaluate their new dataset by running our standardized CLIP training code and testing the resulting model on 38 downstream test sets. Our benchmark consists of multiple compute scales spanning four orders of magnitude, which enables the study of scaling trends and makes the benchmark accessible to researchers with varying resources. Our baseline experiments show that the DataComp workflow leads to better training sets. In particular, our best baseline, DataComp-1B, enables training a CLIP ViT-L/14 from scratch to 79.2\% zero-shot accuracy on ImageNet, outperforming OpenAI's CLIP ViT-L/14 by 3.7 percentage points while using the same training procedure and compute. We release DataComp and all accompanying code at www.datacomp.ai.},
  langid = {english},
  organization = {arXiv.org},
  file = {/Users/DAADAMS/Zotero/storage/EJR4J4JP/Gadre et al. - 2023 - DataComp In search of the next generation of mult.pdf}
}

@inproceedings{gaoDBAugurAdversarialbasedTrend2023,
  title = {{{DBAugur}}: {{An Adversarial-based Trend Forecasting System}} for {{Diversified Workloads}}},
  shorttitle = {{{DBAugur}}},
  booktitle = {2023 {{IEEE}} 39th {{International Conference}} on {{Data Engineering}} ({{ICDE}})},
  author = {Gao, Yuanning and Huang, Xiuqi and Zhou, Xuanhe and Gao, Xiaofeng and Li, Guoliang and Chen, Guihai},
  date = {2023-04},
  pages = {27--39},
  publisher = {IEEE},
  location = {Anaheim, CA, USA},
  doi = {10.1109/ICDE55515.2023.00385},
  url = {https://ieeexplore.ieee.org/document/10184689/},
  urldate = {2025-02-24},
  abstract = {Trend forecasting is vital to optimize the workload performance. It becomes even more urgent with an increasing number of applications and database configurations. However, DBAs mainly target at historical workloads and may give suboptimal configuration advice when the workload trends have changed. Although there are some studies on trend forecasting, they have several limitations. First, they mainly predict the changes of query numbers, which do not combine other critical factors (e.g., disk utilization) and cannot fully reflect the future workload trends. Besides, there are numerous queries in the workloads and exact clustering algorithms like K-means cannot effectively merge similar queries which contain noises like time shifts. Second, basic machine learning models like RNN may have relatively low prediction accuracy on complex workloads (e.g., no cycles but random bursts). Third, real-world workloads may have diverse patterns, while previous models cannot efficiently and reliably predict for all the different workload patterns.},
  eventtitle = {2023 {{IEEE}} 39th {{International Conference}} on {{Data Engineering}} ({{ICDE}})},
  isbn = {979-8-3503-2227-9},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/M4ZNJXE8/Gao et al. - 2023 - DBAugur An Adversarial-based Trend Forecasting System for Diversified Workloads.pdf}
}

@article{gengInterestingnessMeasuresData2006,
  title = {Interestingness Measures for Data Mining: {{A}} Survey},
  shorttitle = {Interestingness Measures for Data Mining},
  author = {Geng, Liqiang and Hamilton, Howard J.},
  date = {2006-09-30},
  journaltitle = {ACM Computing Surveys},
  shortjournal = {ACM Comput. Surv.},
  volume = {38},
  number = {3},
  pages = {9},
  issn = {0360-0300, 1557-7341},
  doi = {10.1145/1132960.1132963},
  url = {https://dl.acm.org/doi/10.1145/1132960.1132963},
  urldate = {2024-06-28},
  abstract = {Interestingness measures play an important role in data mining, regardless of the kind of patterns being mined. These measures are intended for selecting and ranking patterns according to their potential interest to the user. Good measures also allow the time and space costs of the mining process to be reduced. This survey reviews the interestingness measures for rules and summaries, classifies them from several perspectives, compares their properties, identifies their roles in the data mining process, gives strategies for selecting appropriate measures for applications, and identifies opportunities for future research in this area.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/IKBIFY6Q/Geng and Hamilton - 2006 - Interestingness measures for data mining A survey.pdf}
}

@article{gengInterestingnessMeasuresData2006a,
  title = {Interestingness Measures for Data Mining: {{A}} Survey},
  shorttitle = {Interestingness Measures for Data Mining},
  author = {Geng, Liqiang and Hamilton, Howard J.},
  date = {2006-09-30},
  journaltitle = {ACM Computing Surveys},
  shortjournal = {ACM Comput. Surv.},
  volume = {38},
  number = {3},
  pages = {9},
  issn = {0360-0300, 1557-7341},
  doi = {10.1145/1132960.1132963},
  url = {https://dl.acm.org/doi/10.1145/1132960.1132963},
  urldate = {2025-02-13},
  abstract = {Interestingness measures play an important role in data mining, regardless of the kind of patterns being mined. These measures are intended for selecting and ranking patterns according to their potential interest to the user. Good measures also allow the time and space costs of the mining process to be reduced. This survey reviews the interestingness measures for rules and summaries, classifies them from several perspectives, compares their properties, identifies their roles in the data mining process, gives strategies for selecting appropriate measures for applications, and identifies opportunities for future research in this area.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/ZYUP6L83/Geng and Hamilton - 2006 - Interestingness measures for data mining A survey.pdf}
}

@article{ghazanfariSequentialAssociationRule2020,
  title = {Sequential {{Association Rule Mining}} for {{Autonomously Extracting Hierarchical Task Structures}} in {{Reinforcement Learning}}},
  author = {Ghazanfari, Behzad and Afghah, Fatemeh and Taylor, Matthew E.},
  date = {2020},
  journaltitle = {IEEE Access},
  volume = {8},
  pages = {11782--11799},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2020.2965930},
  url = {https://ieeexplore.ieee.org/document/8957114?denied=},
  urldate = {2025-01-13},
  abstract = {Reinforcement learning (RL) techniques, while often powerful, can suffer from slow learning speeds, particularly in high dimensional spaces or in environments with sparse rewards. The decomposition of tasks into a hierarchical structure holds the potential to significantly speed up learning, generalization, and transfer learning. However, the current task decomposition techniques often cannot extract hierarchical task structures without relying on high-level knowledge provided by an expert (e.g., using dynamic Bayesian networks (DBNs) in factored Markov decision processes), which is not necessarily available in autonomous systems. In this paper, we propose a novel method based on Sequential Association Rule Mining that can extract Hierarchical Structure of Tasks in Reinforcement Learning (SARM-HSTRL) in an autonomous manner for both Markov decision processes (MDPs) and factored MDPs. The proposed method leverages association rule mining to discover the causal and temporal relationships among states in different trajectories and extracts a task hierarchy that captures these relationships among sub-goals as termination conditions of different sub-tasks. We prove that the extracted hierarchical policy offers a hierarchically optimal policy in MDPs and factored MDPs. It should be noted that SARM-HSTRL extracts this hierarchical optimal policy without having dynamic Bayesian networks in scenarios with a single task trajectory and also with multiple tasks' trajectories. Furthermore, we show theoretically and empirically that the extracted hierarchical task structure is consistent with trajectories and provides the most efficient, reliable, and compact structure under appropriate assumptions. The numerical results compare the performance of the proposed SARM-HSTRL method with conventional HRL algorithms in terms of the accuracy in detecting the sub-goals, the validity of the extracted hierarchies, and the speed of learning in several testbeds. The key capabilities of SARM-HSTRL including handling multiple tasks and autonomous hierarchical task extraction can lead to the application of this HRL method in reusing, transferring, and generalization of knowledge in different domains.},
  eventtitle = {{{IEEE Access}}},
  keywords = {Association rule mining,Autonomous systems,Bayes methods,extracting task structure,hierarchical reinforcement learning,Markov processes,Reinforcement learning,Reliability,Task analysis,Trajectory},
  annotation = {Read\_Status: Read\\
Read\_Status\_Date: 2025-01-13T05:34:24.006Z},
  file = {/Users/DAADAMS/Zotero/storage/CREYEIEC/Ghazanfari et al. - 2020 - Sequential Association Rule Mining for Autonomously Extracting Hierarchical Task Structures in Reinf.pdf;/Users/DAADAMS/Zotero/storage/XVEIRYJX/8957114.html}
}

@incollection{giacomettiRecommendingMultidimensionalQueries2009,
  title = {Recommending {{Multidimensional Queries}}},
  booktitle = {Data {{Warehousing}} and {{Knowledge Discovery}}},
  author = {Giacometti, Arnaud and Marcel, Patrick and Negre, Elsa},
  editor = {Pedersen, Torben Bach and Mohania, Mukesh K. and Tjoa, A Min},
  date = {2009},
  volume = {5691},
  pages = {453--466},
  publisher = {Springer Berlin Heidelberg},
  location = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-03730-6_36},
  url = {http://link.springer.com/10.1007/978-3-642-03730-6_36},
  urldate = {2025-02-16},
  isbn = {978-3-642-03729-0 978-3-642-03730-6},
  file = {/Users/DAADAMS/Zotero/storage/6RSUR8AM/Giacometti et al. - 2009 - Recommending Multidimensional Queries.pdf}
}

@article{guoDADANDualAdversarial2024,
  title = {{{DA-DAN}}: {{A Dual Adversarial Domain Adaption Network}} for {{Unsupervised Non-overlapping Cross-domain Recommendation}}},
  shorttitle = {{{DA-DAN}}},
  author = {Guo, Lei and Liu, Hao and Zhu, Lei and Guan, Weili and Cheng, Zhiyong},
  date = {2024-03-31},
  journaltitle = {ACM Transactions on Information Systems},
  shortjournal = {ACM Trans. Inf. Syst.},
  volume = {42},
  number = {2},
  pages = {1--27},
  issn = {1046-8188, 1558-2868},
  doi = {10.1145/3617825},
  url = {https://dl.acm.org/doi/10.1145/3617825},
  urldate = {2025-09-08},
  abstract = {Unsupervised Non-overlapping Cross-domain Recommendation (UNCR) is the task that recommends source domain items to the target domain users, which is more challenging as the users are non-overlapped, and its learning process is unsupervised. Unsupervised Non-overlapping Cross-domain Recommendation UNCR is still unsolved due to the following: (1) Previous studies need extra auxiliary information to learn transferable features when aligning two domains, which is unrealistic and hard to obtain due to privacy concerns. (2) Since the adoption of the shared network, existing works cannot well eliminate the domain-specific features in the common feature space, which may incorporate domain noise and harm the cross-domain recommendation. In this work, we propose a domain adaption-based method, namely DA-DAN, to address the above challenges. Specifically, to let DA-DAN be free of auxiliary information, we learn users’ preferences by only exploring their sequential patterns, and propose an improved self-attention layer to model them. To well eliminate the domain-specific features from the common feature space, we resort to a dual generative adversarial network with a multi-target adversarial loss, where two generators and discriminators are leveraged to model each domain separately. Experimental results on three real-world datasets demonstrate the advantage of DA-DAN compared with the state-of-the-art recommendation baselines. Moreover, our source codes have been publicly released.                                1},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/MLMM4539/Guo et al. - 2024 - DA-DAN A Dual Adversarial Domain Adaption Network for Unsupervised Non-overlapping Cross-domain Rec.pdf}
}

@online{guoUraniaVisualizingData2023,
  title = {Urania: {{Visualizing Data Analysis Pipelines}} for {{Natural Language-Based Data Exploration}}},
  shorttitle = {Urania},
  author = {Guo, Yi and Cao, Nan and Qi, Xiaoyu and Li, Haoyang and Shi, Danqing and Zhang, Jing and Chen, Qing and Weiskopf, Daniel},
  date = {2023-06-13},
  eprint = {2306.07760},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2306.07760},
  url = {http://arxiv.org/abs/2306.07760},
  urldate = {2024-12-08},
  abstract = {Exploratory Data Analysis (EDA) is an essential yet tedious process for examining a new dataset. To facilitate it, natural language interfaces (NLIs) can help people intuitively explore the dataset via data-oriented questions. However, existing NLIs primarily focus on providing accurate answers to questions, with few offering explanations or presentations of the data analysis pipeline used to uncover the answer. Such presentations are crucial for EDA as they enhance the interpretability and reliability of the answer, while also helping users understand the analysis process and derive insights. To fill this gap, we introduce Urania, a natural language interactive system that is able to visualize the data analysis pipelines used to resolve input questions. It integrates a natural language interface that allows users to explore data via questions, and a novel dataaware question decomposition algorithm that resolves each input question into a data analysis pipeline. This pipeline is visualized in the form of a datamation, with animated presentations of analysis operations and their corresponding data changes. Through two quantitative experiments and expert interviews, we demonstrated that our data-aware question decomposition algorithm outperforms the state-of-the-art technique in terms of execution accuracy, and that Urania can help people explore datasets better. In the end, we discuss the observations from the studies and the potential future works.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Human-Computer Interaction},
  file = {/Users/DAADAMS/Zotero/storage/PFSD9LRQ/Guo et al. - 2023 - Urania Visualizing Data Analysis Pipelines for Natural Language-Based Data Exploration.pdf}
}

@inproceedings{ha-thucQualitythresholdDataSummarization2008,
  title = {A Quality-Threshold Data Summarization Algorithm},
  booktitle = {2008 {{IEEE International Conference}} on {{Research}}, {{Innovation}} and {{Vision}} for the {{Future}} in {{Computing}} and {{Communication Technologies}}},
  author = {Ha-Thuc, Viet and Nguyen, Duc-Cuong and Srinivasan, Padmini},
  date = {2008},
  pages = {240--246},
  publisher = {IEEE},
  url = {https://ieeexplore.ieee.org/abstract/document/4586362/},
  urldate = {2025-02-16}
}

@article{han16ExplorationPower,
  title = {16 {{Exploration}} of the {{Power}} of {{Attribute-Oriented Induction}} in {{Data Mining}}},
  author = {Han, Jiawei and Fu, Yongjian},
  journaltitle = {Ad… ces in Know Ledge Discover and Data M ining. Cambridge: AAAI/'\&I1T Press, 1g96},
  pages = {399--42l},
  publisher = {Citeseer},
  url = {https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=ceeb1f8094691f9a589b07ecffd1643f8fc213ed},
  urldate = {2025-02-16},
  file = {/Users/DAADAMS/Zotero/storage/JN8YBXST/Han and Fu - 16 Exploration of the Power of Attribute-Oriented Induction in Data Mining.pdf}
}

@inproceedings{hanDBLearnSystemPrototype1994,
  title = {{{DBLearn}}: A System Prototype for Knowledge Discovery in Relational Databases},
  shorttitle = {{{DBLearn}}},
  booktitle = {Proceedings of the 1994 {{ACM SIGMOD}} International Conference on {{Management}} of Data},
  author = {Han, Jiawei and Fu, Yongjian and Huang, Yue and Cai, Yandong and Cercone, Nick},
  date = {1994-05-24},
  pages = {516},
  publisher = {ACM},
  location = {Minneapolis Minnesota USA},
  doi = {10.1145/191839.191979},
  url = {https://dl.acm.org/doi/10.1145/191839.191979},
  urldate = {2025-02-16},
  eventtitle = {{{SIGMOD}}/{{PODS94}}: {{Joint ACM SIGMOD International Conference}} on {{Management}} of {{Data}} and {{ACM SIGMOD}} \& {{ACM Symposium Principles}} of {{Database Systems}}},
  isbn = {978-0-89791-639-4},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/UPRGTBC3/Han et al. - 1994 - DBLearn a system prototype for knowledge discovery in relational databases.pdf}
}

@inproceedings{hanDBMinerSystemMining1996,
  title = {{{DBMiner}}: {{A System}} for {{Mining Knowledge}} in {{Large Relational Databases}}.},
  shorttitle = {{{DBMiner}}},
  booktitle = {{{KDD}}},
  author = {Han, Jiawei and Fu, Yongjian and Wang, Wei and Chiang, Jenny and Gong, Wan and Koperski, Krzysztof and Li, Deyi and Lu, Yijun and Rajan, Amynmohamed and Stefanovic, Nebojsa},
  date = {1996},
  volume = {96},
  pages = {250--255},
  url = {https://cdn.aaai.org/KDD/1996/KDD96-041.pdf},
  urldate = {2025-02-16},
  file = {/Users/DAADAMS/Zotero/storage/PTJHDTEK/Han et al. - 1996 - DBMiner A System for Mining Knowledge in Large Relational Databases..pdf}
}

@inproceedings{hanKnowledgeDiscoveryDatabases1992,
  title = {Knowledge Discovery in Databases: {{An}} Attribute-Oriented Approach},
  shorttitle = {Knowledge Discovery in Databases},
  booktitle = {{{VLDB}}},
  author = {Han, Jiawei and Cai, Yandong and Cercone, Nick},
  date = {1992},
  volume = {18},
  pages = {574--559},
  url = {http://hanj.cs.illinois.edu/pdf/vldb92.pdf},
  urldate = {2025-02-16},
  file = {/Users/DAADAMS/Zotero/storage/DHVZYUG6/Han et al. - 1992 - Knowledge discovery in databases An attribute-oriented approach.pdf}
}

@online{hendrickxMachineLearningReject2024,
  title = {Machine {{Learning}} with a {{Reject Option}}: {{A}} Survey},
  shorttitle = {Machine {{Learning}} with a {{Reject Option}}},
  author = {Hendrickx, Kilian and Perini, Lorenzo and Van der Plas, Dries and Meert, Wannes and Davis, Jesse},
  date = {2024-02-21},
  eprint = {2107.11277},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2107.11277},
  url = {http://arxiv.org/abs/2107.11277},
  urldate = {2024-09-23},
  abstract = {Machine learning models always make a prediction, even when it is likely to be inaccurate. This behavior should be avoided in many decision support applications, where mistakes can have severe consequences. Albeit already studied in 1970, machine learning with rejection recently gained interest. This machine learning subfield enables machine learning models to abstain from making a prediction when likely to make a mistake. This survey aims to provide an overview on machine learning with rejection. We introduce the conditions leading to two types of rejection, ambiguity and novelty rejection, which we carefully formalize. Moreover, we review and categorize strategies to evaluate a model's predictive and rejective quality. Additionally, we define the existing architectures for models with rejection and describe the standard techniques for learning such models. Finally, we provide examples of relevant application domains and show how machine learning with rejection relates to other machine learning research areas.},
  pubstate = {prepublished},
  keywords = {68T02,Computer Science - Artificial Intelligence,Computer Science - Machine Learning,I.2.6},
  annotation = {Read\_Status: To Read\\
Read\_Status\_Date: 2024-12-09T00:54:31.212Z},
  file = {/Users/DAADAMS/Zotero/storage/E7KIBSZ8/Hendrickx et al. - 2024 - Machine Learning with a Reject Option A survey.pdf;/Users/DAADAMS/Zotero/storage/W2BPJU2B/2107.html}
}

@article{heraguemiMultiswarmBatAlgorithm2016,
  title = {Multi-Swarm Bat Algorithm for Association Rule Mining Using Multiple Cooperative Strategies},
  author = {Heraguemi, Kamel Eddine and Kamel, Nadjet and Drias, Habiba},
  date = {2016-12},
  journaltitle = {Applied Intelligence},
  shortjournal = {Appl Intell},
  volume = {45},
  number = {4},
  pages = {1021--1033},
  issn = {0924-669X, 1573-7497},
  doi = {10.1007/s10489-016-0806-y},
  url = {http://link.springer.com/10.1007/s10489-016-0806-y},
  urldate = {2024-12-23},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/SN3QGG87/Heraguemi et al. - 2016 - Multi-swarm bat algorithm for association rule mining using multiple cooperative strategies.pdf}
}

@article{hildermanEvfaolruRataionnkinofgIDntiescreosvteirnegdneKsnsOMweleadsgueres,
  title = {{{EvfaolruRataionnkinofg IDntiescreosvteirnegdneKsns oMweleadsgueres}}},
  author = {Hilderman, Robert J and Hamilton, Howard J},
  abstract = {When mining a large database, the number of patterns discovered can easily exceed the capabilities of a human user to identify interesting results. To address this problem, various techniques have been suggested to reduce and/or order the patterns prior to presenting them to the user. In this paper, our focus is on ranking summaries generated from a single dataset, where attributes can be generalized in many different ways and to many levels of granularity according to taxonomic hierarchies. We theoretically and empirically evaluate thirteen diversity measures used as heuristic measures of interestingness for ranking summaries generated from databases. The thirteen diversity measures have previously been utilized in various disciplines, such as information theory, statistics, ecology, and economics. We describe ve principles that any measure must satisfy to be considered useful for ranking summaries. Theoretical results show that only four of the thirteen diversity measures satisfy all of the principles. We then analyze the distribution of the index values generated by each of the thirteen diversity measures. Empirical results, obtained using synthetic data, show that the distribution of index values generated tend to be highly skewed about the mean, median, and middle index values. The objective of this work is to gain some insight into the behaviour that can be expected from each of the measures in practice.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/2DTXN8AF/Hilderman and Hamilton - EvfaolruRataionnkinofg IDntiescreosvteirnegdneKsns.pdf}
}

@software{HKUDSRLMRec2025,
  title = {{{HKUDS}}/{{RLMRec}}},
  date = {2025-09-05T11:17:32Z},
  origdate = {2023-10-23T07:18:57Z},
  url = {https://github.com/HKUDS/RLMRec},
  urldate = {2025-09-08},
  abstract = {[WWW'2024] "RLMRec: Representation Learning with Large Language Models for Recommendation"},
  organization = {✨Data Intelligence Lab@HKU✨},
  keywords = {collaborative-filtering,graph-neural-networks,large-language-models,recommendation,recommender-systems}
}

@article{hograferSteeringbyexampleProgressiveVisual2022,
  title = {Steering-by-Example for {{Progressive Visual Analytics}}},
  author = {Hogräfer, Marius and Angelini, Marco and Santucci, Giuseppe and Schulz, Hans-Jörg},
  date = {2022-12-31},
  journaltitle = {ACM Transactions on Intelligent Systems and Technology},
  shortjournal = {ACM Trans. Intell. Syst. Technol.},
  volume = {13},
  number = {6},
  pages = {1--26},
  issn = {2157-6904, 2157-6912},
  doi = {10.1145/3531229},
  url = {https://dl.acm.org/doi/10.1145/3531229},
  urldate = {2025-09-11},
  abstract = {Progressive visual analytics allows users to interact with early, partial results of long-running computations on large datasets. In this context, computational steering is often brought up as a means to prioritize the progressive computation. This is meant to focus computational resources on data subspaces of interest so as to ensure their computation is completed before all others. Yet, current approaches to select a region of the view space and then to prioritize its corresponding data subspace either require a one-to-one mapping between view and data space, or they need to establish and maintain computationally costly index structures to trace complex mappings between view and data space. We present steering-by-example, a novel interactive steering approach for progressive visual analytics, which allows prioritizing data subspaces for the progression by generating a relaxed query from a set of selected data items. Our approach works independently of the particular visualization technique and without additional index structures. First benchmark results show that steering-by-example considerably improves Precision and Recall for prioritizing unprocessed data for a selected view region, clearly outperforming random uniform sampling.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/LBK7EGD3/Hogräfer et al. - 2022 - Steering-by-example for Progressive Visual Analytics.pdf}
}

@unpublished{hollensteinHowOfflineMeasures2020,
  title = {How Do {{Offline Measures}} for {{Exploration}} in {{Reinforcement Learning}} Behave?},
  author = {Hollenstein, Jakob J. and Auddy, Sayantan and Saveriano, Matteo and Renaudo, Erwan and Piater, Justus},
  date = {2020},
  eprint = {2010.15533},
  eprinttype = {arXiv},
  url = {https://arxiv.org/abs/2010.15533},
  urldate = {2024-09-11},
  file = {/Users/DAADAMS/Zotero/storage/HYKT47PR/Hollenstein et al. - 2020 - How do Offline Measures for Exploration in Reinforcement Learning behave.pdf}
}

@inproceedings{hollerPlanGoalRecognition2018,
  title = {Plan and {{Goal Recognition}} as {{HTN Planning}}},
  booktitle = {2018 {{IEEE}} 30th {{International Conference}} on {{Tools}} with {{Artificial Intelligence}} ({{ICTAI}})},
  author = {Holler, Daniel and Behnke, Gregor and Bercher, Pascal and Biundo, Susanne},
  date = {2018-11},
  pages = {466--473},
  publisher = {IEEE},
  location = {Volos, Greece},
  doi = {10.1109/ICTAI.2018.00078},
  url = {https://ieeexplore.ieee.org/document/8576076/},
  urldate = {2025-06-16},
  abstract = {Plan- and Goal Recognition (PGR) is the task of inferring the goals and plans of an agent based on its actions. A few years ago, an approach has been introduced that successfully exploits the performance of planning systems to solve it. That way, no specialized solvers are needed and PGR benefits from present and future research in planning. The approach uses classical planning systems and needs to plan (at least) once for every possible goal. However, models in PGR are often structured in a hierarchical way, similar to Hierarchical Task Networks (HTNs). These models are strictly more expressive than those in classical planning and can describe partially ordered sets of tasks or multiple goals with interleaving plans. We present the approach PGR as HTN Planning that enables the recognition of complex agent behavior by using unmodified, off-the-shelf HTN planners. Planning is thereby needed only once, regardless of how many possible goals there are. Our evaluation shows that current planning systems are able to handle large models with thousands of possible goals and that the approach results in high recognition rates.},
  eventtitle = {2018 {{IEEE}} 30th {{International Conference}} on {{Tools}} with {{Artificial Intelligence}} ({{ICTAI}})},
  isbn = {978-1-5386-7449-9},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/7KJRT2VS/Holler et al. - 2018 - Plan and Goal Recognition as HTN Planning.pdf}
}

@article{hoplarosDataSummarizationNetwork2014,
  title = {Data Summarization for Network Traffic Monitoring},
  author = {Hoplaros, Demetris and Tari, Zahir and Khalil, Ibrahim},
  date = {2014},
  journaltitle = {Journal of network and computer applications},
  volume = {37},
  pages = {194--205},
  publisher = {Elsevier},
  url = {https://www.sciencedirect.com/science/article/pii/S1084804513000593},
  urldate = {2025-02-07},
  file = {/Users/DAADAMS/Zotero/storage/UJ8KD58S/Hoplaros et al. - 2014 - Data summarization for network traffic monitoring.pdf}
}

@article{hoplarosDataSummarizationNetwork2014a,
  title = {Data Summarization for Network Traffic Monitoring},
  author = {Hoplaros, Demetris and Tari, Zahir and Khalil, Ibrahim},
  date = {2014},
  journaltitle = {Journal of network and computer applications},
  volume = {37},
  pages = {194--205},
  publisher = {Elsevier},
  url = {https://www.sciencedirect.com/science/article/pii/S1084804513000593},
  urldate = {2025-02-16},
  file = {/Users/DAADAMS/Zotero/storage/BLQHA3WK/Hoplaros et al. - 2014 - Data summarization for network traffic monitoring.pdf}
}

@online{HttpsRepositoryEssex,
  title = {{{https://repository.essex.ac.uk/4117/1/MCTS-Survey.pdf}}},
  url = {https://repository.essex.ac.uk/4117/1/MCTS-Survey.pdf},
  urldate = {2024-03-15}
}

@online{HttpsWwwSteveblackburn,
  title = {{{https://www.steveblackburn.org/pubs/papers/lbo-ispass-2022.pdf}}},
  url = {https://www.steveblackburn.org/pubs/papers/lbo-ispass-2022.pdf},
  urldate = {2024-07-22}
}

@article{huangOptimizationActiveLearningbased2018,
  title = {Optimization for Active Learning-Based Interactive Database Exploration},
  author = {Huang, Enhui and Peng, Liping and Palma, Luciano Di and Abdelkafi, Ahmed and Liu, Anna and Diao, Yanlei},
  date = {2018-09},
  journaltitle = {Proceedings of the VLDB Endowment},
  shortjournal = {Proc. VLDB Endow.},
  volume = {12},
  number = {1},
  pages = {71--84},
  issn = {2150-8097},
  doi = {10.14778/3275536.3275542},
  url = {https://dl.acm.org/doi/10.14778/3275536.3275542},
  urldate = {2025-01-28},
  abstract = {There is an increasing gap between the fast growth of data and the limited human ability to comprehend data. Consequently, there has been a growing demand of data management tools that can bridge this gap and help the user retrieve high-value content from data more effectively. In this work, we aim to build interactive data exploration as a new database service, using an approach called “explore-by-example”. In particular, we cast the explore-by-example problem in a principled “active learning” framework, and bring the properties of important classes of database queries to bear on the design of new algorithms and optimizations for active learningbased database exploration. These new techniques allow the database system to overcome fundamental limitations of traditional active learning, in particular, the slow convergence problem. Evaluation results using real-world datasets and user interest patterns show that our new system significantly outperforms state-of-the-art active learning techniques and data exploration systems in accuracy while achieving desired efficiency for interactive performance.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/HWJJ9Y99/Huang et al. - 2018 - Optimization for active learning-based interactive database exploration.pdf}
}

@thesis{huangOptimizationActiveLearningbased2018a,
  type = {phdthesis},
  title = {Optimization for Active Learning-Based Interactive Database Exploration},
  author = {Huang, Enhui and Peng, Liping and Di Palma, Luciano and Abdelkafi, Ahmed and Liu, Anna and Diao, Yanlei},
  date = {2018},
  institution = {Ecole Polytechnique; University of Massachusetts Amherst},
  url = {https://inria.hal.science/hal-01870560/},
  urldate = {2025-02-16},
  file = {/Users/DAADAMS/Zotero/storage/8PXEVD4Q/Huang et al. - 2018 - Optimization for active learning-based interactive database exploration.pdf}
}

@article{huangSibylForecastingTimeEvolving2024,
  title = {Sibyl: {{Forecasting Time-Evolving Query Workloads}}},
  shorttitle = {Sibyl},
  author = {Huang, Hanxian and Siddiqui, Tarique and Alotaibi, Rana and Curino, Carlo and Leeka, Jyoti and Jindal, Alekh and Zhao, Jishen and Camacho-Rodríguez, Jesús and Tian, Yuanyuan},
  date = {2024-03-12},
  journaltitle = {Proceedings of the ACM on Management of Data},
  shortjournal = {Proc. ACM Manag. Data},
  volume = {2},
  number = {1},
  pages = {1--27},
  issn = {2836-6573},
  doi = {10.1145/3639308},
  url = {https://dl.acm.org/doi/10.1145/3639308},
  urldate = {2025-02-24},
  abstract = {HANXIAN HUANG, University of California San Diego, USA TARIQUE SIDDIQUI, Microsoft Research, USA RANA ALOTAIBI, Microsoft Gray Systems Lab, USA CARLO CURINO, Microsoft Gray Systems Lab, USA JYOTI LEEKA, Microsoft, USA ALEKH JINDAL, SmartApps, USA JISHEN ZHAO, University of California San Diego, USA JESÚS CAMACHO-RODRÍGUEZ, Microsoft Gray Systems Lab, USA YUANYUAN TIAN, Microsoft Gray Systems Lab, USA Database systems often rely on historical query traces to perform workload-based performance tuning. However, real production workloads are time-evolving, making historical queries ineffective for optimizing future workloads. To address this challenge, we propose Sibyl, an end-to-end machine learning-based framework that accurately forecasts a sequence of future queries, with the entire query statements, in various prediction windows. Drawing insights from real-workloads, we propose template-based featurization techniques and develop a stacked-LSTM with an encoder-decoder architecture for accurate forecasting of query workloads. We also develop techniques to improve forecasting accuracy over large prediction windows and achieve high scalability over large workloads with high variability in arrival rates of queries. Finally, we propose techniques to handle workload drifts. Our evaluation on four real workloads demonstrates that Sibyl can forecast workloads with an 87.3\% median F1 score, and can result in 1.7× and 1.3× performance improvement when applied to materialized view selection and index selection applications, respectively. CCS Concepts: • Information systems → Data management systems.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/KGY9FKMY/Huang et al. - 2024 - Sibyl Forecasting Time-Evolving Query Workloads.pdf}
}

@online{huLoRALowRankAdaptation2021,
  title = {{{LoRA}}: {{Low-Rank Adaptation}} of {{Large Language Models}}},
  shorttitle = {{{LoRA}}},
  author = {Hu, Edward J. and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  date = {2021-10-16},
  eprint = {2106.09685},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2106.09685},
  url = {http://arxiv.org/abs/2106.09685},
  urldate = {2024-03-15},
  abstract = {An important paradigm of natural language processing consists of large-scale pre-training on general domain data and adaptation to particular tasks or domains. As we pre-train larger models, full fine-tuning, which retrains all model parameters, becomes less feasible. Using GPT-3 175B as an example -- deploying independent instances of fine-tuned models, each with 175B parameters, is prohibitively expensive. We propose Low-Rank Adaptation, or LoRA, which freezes the pre-trained model weights and injects trainable rank decomposition matrices into each layer of the Transformer architecture, greatly reducing the number of trainable parameters for downstream tasks. Compared to GPT-3 175B fine-tuned with Adam, LoRA can reduce the number of trainable parameters by 10,000 times and the GPU memory requirement by 3 times. LoRA performs on-par or better than fine-tuning in model quality on RoBERTa, DeBERTa, GPT-2, and GPT-3, despite having fewer trainable parameters, a higher training throughput, and, unlike adapters, no additional inference latency. We also provide an empirical investigation into rank-deficiency in language model adaptation, which sheds light on the efficacy of LoRA. We release a package that facilitates the integration of LoRA with PyTorch models and provide our implementations and model checkpoints for RoBERTa, DeBERTa, and GPT-2 at https://github.com/microsoft/LoRA.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/DAADAMS/Zotero/storage/NSAHNR8L/Hu et al. - 2021 - LoRA Low-Rank Adaptation of Large Language Models.pdf;/Users/DAADAMS/Zotero/storage/KEGUCZRS/2106.html}
}

@inproceedings{idreosOverviewDataExploration2015,
  title = {Overview of {{Data Exploration Techniques}}},
  booktitle = {Proceedings of the 2015 {{ACM SIGMOD International Conference}} on {{Management}} of {{Data}}},
  author = {Idreos, Stratos and Papaemmanouil, Olga and Chaudhuri, Surajit},
  date = {2015-05-27},
  pages = {277--281},
  publisher = {ACM},
  location = {Melbourne Victoria Australia},
  doi = {10.1145/2723372.2731084},
  url = {https://dl.acm.org/doi/10.1145/2723372.2731084},
  urldate = {2024-08-07},
  abstract = {Data exploration is about efficiently extracting knowledge from data even if we do not know exactly what we are looking for. In this tutorial, we survey recent developments in the emerging area of database systems tailored for data exploration. We discuss new ideas on how to store and access data as well as new ideas on how to interact with a data system to enable users and applications to quickly figure out which data parts are of interest. In addition, we discuss how to exploit lessons-learned from past research, the new challenges data exploration crafts, emerging applications and future research directions.},
  eventtitle = {{{SIGMOD}}/{{PODS}}'15: {{International Conference}} on {{Management}} of {{Data}}},
  isbn = {978-1-4503-2758-9},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/2YBVSI8S/Idreos et al. - 2015 - Overview of Data Exploration Techniques.pdf}
}

@inproceedings{jagadishItcompressIterativeSemantic2004,
  title = {Itcompress: {{An}} Iterative Semantic Compression Algorithm},
  shorttitle = {Itcompress},
  booktitle = {Proceedings. 20th {{International Conference}} on {{Data Engineering}}},
  author = {Jagadish, H. V. and Ng, Raymond T. and Ooi, Beng Chin and Tung, Anthony KH},
  date = {2004},
  pages = {646--657},
  publisher = {IEEE},
  url = {https://ieeexplore.ieee.org/abstract/document/1320034/},
  urldate = {2025-02-16},
  file = {/Users/DAADAMS/Zotero/storage/7R3D3UFX/Jagadish et al. - 2004 - Itcompress An iterative semantic compression algorithm.pdf}
}

@inproceedings{jagadishSemanticCompressionPattern1999,
  title = {Semantic Compression and Pattern Extraction with Fascicles},
  booktitle = {{{VLDB}}},
  author = {Jagadish, H. V. and Madar, Jason and Ng, Raymond T.},
  date = {1999},
  volume = {99},
  pages = {186--97},
  url = {http://www.vldb.org/conf/1999/P16.pdf},
  urldate = {2025-02-16},
  file = {/Users/DAADAMS/Zotero/storage/XX7ZYTWS/Jagadish et al. - 1999 - Semantic compression and pattern extraction with fascicles.pdf}
}

@article{jinInverseOptimalControl2021,
  title = {Inverse {{Optimal Control}} from {{Incomplete Trajectory Observations}}},
  author = {Jin, Wanxin and Kulić, Dana and Mou, Shaoshuai and Hirche, Sandra},
  date = {2021-06},
  journaltitle = {The International Journal of Robotics Research},
  shortjournal = {The International Journal of Robotics Research},
  volume = {40},
  number = {6--7},
  eprint = {1803.07696},
  eprinttype = {arXiv},
  eprintclass = {cs},
  pages = {848--865},
  issn = {0278-3649, 1741-3176},
  doi = {10.1177/0278364921996384},
  url = {http://arxiv.org/abs/1803.07696},
  urldate = {2025-09-08},
  abstract = {This article develops a methodology that enables learning an objective function of an optimal control system from incomplete trajectory observations. The objective function is assumed to be a weighted sum of features (or basis functions) with unknown weights, and the observed data is a segment of a trajectory of system states and inputs. The proposed technique introduces the concept of the recovery matrix to establish the relationship between any available segment of the trajectory and the weights of given candidate features. The rank of the recovery matrix indicates whether a subset of relevant features can be found among the candidate features and the corresponding weights can be learned from the segment data. The recovery matrix can be obtained iteratively and its rank non-decreasing property shows that additional observations may contribute to the objective learning. Based on the recovery matrix, a method for using incomplete trajectory observations to learn the weights of selected features is established, and an incremental inverse optimal control algorithm is developed by automatically finding the minimal required observation. The effectiveness of the proposed method is demonstrated on a linear quadratic regulator system and a simulated robot manipulator.},
  langid = {english},
  keywords = {Computer Science - Robotics,Computer Science - Systems and Control},
  file = {/Users/DAADAMS/Zotero/storage/HHE7VKIV/Jin et al. - 2021 - Inverse Optimal Control from Incomplete Trajectory Observations.pdf}
}

@article{joglekarInteractiveDataExploration2017,
  title = {Interactive Data Exploration with Smart Drill-Down},
  author = {Joglekar, Manas and Garcia-Molina, Hector and Parameswaran, Aditya},
  date = {2017},
  journaltitle = {IEEE Transactions on Knowledge and Data Engineering},
  volume = {31},
  number = {1},
  pages = {46--60},
  publisher = {IEEE},
  url = {https://ieeexplore.ieee.org/abstract/document/7885129/},
  urldate = {2025-02-13},
  file = {/Users/DAADAMS/Zotero/storage/7DA6DZ5L/PMC5308207.html}
}

@online{kambhampatiLLMsCantPlan2024,
  title = {{{LLMs Can}}'t {{Plan}}, {{But Can Help Planning}} in {{LLM-Modulo Frameworks}}},
  author = {Kambhampati, Subbarao and Valmeekam, Karthik and Guan, Lin and Verma, Mudit and Stechly, Kaya and Bhambri, Siddhant and Saldyt, Lucas and Murthy, Anil},
  date = {2024-06-11},
  eprint = {2402.01817},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2402.01817},
  url = {http://arxiv.org/abs/2402.01817},
  urldate = {2024-09-23},
  abstract = {There is considerable confusion about the role of Large Language Models (LLMs) in planning and reasoning tasks. On one side are over-optimistic claims that LLMs can indeed do these tasks with just the right prompting or self-verification strategies. On the other side are perhaps over-pessimistic claims that all that LLMs are good for in planning/reasoning tasks are as mere translators of the problem specification from one syntactic format to another, and ship the problem off to external symbolic solvers. In this position paper, we take the view that both these extremes are misguided. We argue that auto-regressive LLMs cannot, by themselves, do planning or self-verification (which is after all a form of reasoning), and shed some light on the reasons for misunderstandings in the literature. We will also argue that LLMs should be viewed as universal approximate knowledge sources that have much more meaningful roles to play in planning/reasoning tasks beyond simple front-end/back-end format translators. We present a vision of \{\textbackslash bf LLM-Modulo Frameworks\} that combine the strengths of LLMs with external model-based verifiers in a tighter bi-directional interaction regime. We will show how the models driving the external verifiers themselves can be acquired with the help of LLMs. We will also argue that rather than simply pipelining LLMs and symbolic components, this LLM-Modulo Framework provides a better neuro-symbolic approach that offers tighter integration between LLMs and symbolic components, and allows extending the scope of model-based planning/reasoning regimes towards more flexible knowledge, problem and preference specifications.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  annotation = {Read\_Status: To Read\\
Read\_Status\_Date: 2024-12-09T00:54:05.783Z},
  file = {/Users/DAADAMS/Zotero/storage/K9495QA3/Kambhampati et al. - 2024 - LLMs Can't Plan, But Can Help Planning in LLM-Modulo Frameworks.pdf;/Users/DAADAMS/Zotero/storage/BY8UHZGG/2402.html}
}

@article{karkusQMDPNetDeepLearning,
  title = {{{QMDP-Net}}: {{Deep Learning}} for {{Planning}} under {{Partial Observability}}},
  author = {Karkus, Peter and Hsu, David and Lee, Wee Sun},
  abstract = {This paper introduces the QMDP-net, a neural network architecture for planning under partial observability. The QMDP-net combines the strengths of model-free learning and model-based planning. It is a recurrent policy network, but it represents a policy for a parameterized set of tasks by connecting a model with a planning algorithm that solves the model, thus embedding the solution structure of planning in a network learning architecture. The QMDP-net is fully differentiable and allows for end-to-end training. We train a QMDPnet on different tasks so that it can generalize to new ones in the parameterized task set and “transfer” to other similar tasks beyond the set. In preliminary experiments, QMDP-net showed strong performance on several robotic tasks in simulation. Interestingly, while QMDP-net encodes the QMDP algorithm, it sometimes outperforms the QMDP algorithm in the experiments, as a result of end-to-end learning.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/6JB3QX49/Karkus et al. - QMDP-Net Deep Learning for Planning under Partial.pdf}
}

@inproceedings{kashyapFACeTORCostdrivenExploration2010,
  title = {{{FACeTOR}}: Cost-Driven Exploration of Faceted Query Results},
  shorttitle = {{{FACeTOR}}},
  booktitle = {Proceedings of the 19th {{ACM}} International Conference on {{Information}} and Knowledge Management},
  author = {Kashyap, Abhijith and Hristidis, Vagelis and Petropoulos, Michalis},
  date = {2010-10-26},
  pages = {719--728},
  publisher = {ACM},
  location = {Toronto ON Canada},
  doi = {10.1145/1871437.1871530},
  url = {https://dl.acm.org/doi/10.1145/1871437.1871530},
  urldate = {2025-04-22},
  abstract = {Faceted navigation is being increasingly employed as an effective technique for exploring large query results on structured databases. This technique of mitigating information-overload leverages metadata of the query results to provide users with facet conditions that can be used to progressively refine the user’s query and filter the query results. However, the number of facet conditions can be quite large, thereby increasing the burden on the user. We present the FACeTOR system that proposes a cost-based approach to faceted navigation. At each step of the navigation, the user is presented with a subset of all possible facet conditions that are selected such that the overall expected navigation cost is minimized and every result is guaranteed to be reachable by a facet condition. We prove that the problem of selecting the optimal facet conditions at each navigation step is NP-Hard, and subsequently present two intuitive heuristics employed by FACeTOR. Our user study at Amazon Mechanical Turk shows that FACeTOR reduces the user navigation time compared to the cutting edge commercial and academic faceted search algorithms. The user study also confirms the validity of our cost model. We also present the results of an extensive experimental evaluation on the performance of the proposed approach using two real datasets. FACeTOR is available at http://db.cse.buffalo.edu/facetor/.},
  eventtitle = {{{CIKM}} '10: {{International Conference}} on {{Information}} and {{Knowledge Management}}},
  isbn = {978-1-4503-0099-5},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/5WV6EVPK/Kashyap et al. - 2010 - FACeTOR cost-driven exploration of faceted query results.pdf}
}

@online{kaushikNumericalAssociationRule2023,
  title = {Numerical {{Association Rule Mining}}: {{A Systematic Literature Review}}},
  shorttitle = {Numerical {{Association Rule Mining}}},
  author = {Kaushik, Minakshi and Sharma, Rahul and Jr, Iztok Fister and Draheim, Dirk},
  date = {2023-07-02},
  eprint = {2307.00662},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2307.00662},
  url = {http://arxiv.org/abs/2307.00662},
  urldate = {2025-01-21},
  abstract = {Numerical association rule mining (NARM) is a widely used variant of the association rule mining (ARM) technique, and it has been extensively used in discovering patterns in numerical data. Initially, researchers and scientists incorporated numerical attributes in ARM using various discretization approaches; however, over time, a plethora of alternative methods have emerged in this field. Unfortunately, the increase of alternative methods has resulted into a significant knowledge gap in understanding diverse techniques employed in NARM – this paper attempts to bridge this knowledge gap by conducting a comprehensive systematic literature review (SLR). We provide an in-depth study of diverse methods, algorithms, metrics, and datasets derived from 1,140 scholarly articles published from the inception of NARM in the year 1996 to 2022. Out of them, 68 articles are extensively reviewed in accordance with inclusion, exclusion, and quality criteria. To the best of our knowledge, this SLR is the first of its kind to provide an exhaustive analysis of the current literature and previous surveys on NARM. The paper discusses important research issues, the current status, and the future possibilities of NARM. On the basis of this SLR, the article also presents a novel discretization measure that contributes by providing a partitioning of numerical data that meets well human perception of partitions. CCS Concepts: • Information systems → Association rules; Data mining; • Computing methodologies → Bio-inspired approaches; Machine learning; • General and reference → Surveys and overviews.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Databases,Computer Science - Machine Learning},
  file = {/Users/DAADAMS/Zotero/storage/G83686Q7/Kaushik et al. - 2023 - Numerical Association Rule Mining A Systematic Literature Review.pdf}
}

@article{kaushikSystematicAssessmentNumerical2021,
  title = {A {{Systematic Assessment}} of {{Numerical Association Rule Mining Methods}}},
  author = {Kaushik, Minakshi and Sharma, Rahul and Peious, Sijo Arakkal and Shahin, Mahtab and Yahia, Sadok Ben and Draheim, Dirk},
  date = {2021-06-22},
  journaltitle = {SN Computer Science},
  shortjournal = {SN COMPUT. SCI.},
  volume = {2},
  number = {5},
  pages = {348},
  issn = {2661-8907},
  doi = {10.1007/s42979-021-00725-2},
  url = {https://doi.org/10.1007/s42979-021-00725-2},
  urldate = {2025-01-07},
  abstract = {In data mining, the classical association rule mining techniques deal with binary attributes; however, real-world data have a variety of attributes (numerical, categorical, Boolean). To deal with the variety of data attributes, the classical association rule mining technique was extended to numerical association rule mining. Initially, the concept of numerical association rule mining started with the discretization method, and later, many other methods, e.g., optimization, distribution are proposed in state-of-the-art. Different authors have presented various algorithms for each numerical association rule mining method; therefore, it is hard to select a suitable algorithm for a numerical association rule mining task. In this article, we present a systematic assessment of various numerical association rule mining methods and we provide a meta-study of thirty numerical association rule mining algorithms. We investigate how far the discretization techniques have been used in the numerical association rule mining methods.},
  langid = {english},
  keywords = {Association rule mining,Data mining,Knowledge discovery in databases,Numerical association rule mining,Quantitative association rule mining},
  file = {/Users/DAADAMS/Zotero/storage/Y3A26JER/Kaushik et al. - 2021 - A Systematic Assessment of Numerical Association Rule Mining Methods.pdf}
}

@article{kayaFuzzyOLAPAssociation2005,
  title = {Fuzzy {{OLAP}} Association Rules Mining-Based Modular Reinforcement Learning Approach for Multiagent Systems},
  author = {Kaya, M. and Alhajj, R.},
  date = {2005-04},
  journaltitle = {IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)},
  volume = {35},
  number = {2},
  pages = {326--338},
  issn = {1941-0492},
  doi = {10.1109/TSMCB.2004.843278},
  url = {https://ieeexplore.ieee.org/document/1408061/?arnumber=1408061},
  urldate = {2025-01-13},
  abstract = {Multiagent systems and data mining have recently attracted considerable attention in the field of computing. Reinforcement learning is the most commonly used learning process for multiagent systems. However, it still has some drawbacks, including modeling other learning agents present in the domain as part of the state of the environment, and some states are experienced much less than others, or some state-action pairs are never visited during the learning phase. Further, before completing the learning process, an agent cannot exhibit a certain behavior in some states that may be experienced sufficiently. In this study, we propose a novel multiagent learning approach to handle these problems. Our approach is based on utilizing the mining process for modular cooperative learning systems. It incorporates fuzziness and online analytical processing (OLAP) based mining to effectively process the information reported by agents. First, we describe a fuzzy data cube OLAP architecture which facilitates effective storage and processing of the state information reported by agents. This way, the action of the other agent, not even in the visual environment of the agent under consideration, can simply be predicted by extracting online association rules, a well-known data mining technique, from the constructed data cube. Second, we present a new action selection model, which is also based on association rules mining. Finally, we generalize not sufficiently experienced states, by mining multilevel association rules from the proposed fuzzy data cube. Experimental results obtained on two different versions of a well-known pursuit domain show the robustness and effectiveness of the proposed fuzzy OLAP mining based modular learning approach. Finally, we tested the scalability of the approach presented in this paper and compared it with our previous work on modular-fuzzy Q-learning and ordinary Q-learning.},
  eventtitle = {{{IEEE Transactions}} on {{Systems}}, {{Man}}, and {{Cybernetics}}, {{Part B}} ({{Cybernetics}})},
  keywords = {Association rules,Control systems,data cube,data mining,Data mining,fuzziness,Fuzzy systems,Information analysis,Learning systems,modularity,multiagent systems,Multiagent systems,OLAP,reinforcement learning,Robustness,Scalability,Testing},
  annotation = {Read\_Status: Read\\
Read\_Status\_Date: 2025-01-13T03:59:50.869Z},
  file = {/Users/DAADAMS/Zotero/storage/JAB79F4V/Kaya and Alhajj - 2005 - Fuzzy OLAP association rules mining-based modular reinforcement learning approach for multiagent sys.pdf;/Users/DAADAMS/Zotero/storage/UEYNPFKK/1408061.html}
}

@inproceedings{kerenGoalRecognitionDesign2016,
  title = {Goal Recognition Design with Non-Observable Actions},
  booktitle = {Proceedings of the {{AAAI Conference}} on {{Artificial Intelligence}}},
  author = {Keren, Sarah and Gal, Avigdor and Karpas, Erez},
  date = {2016},
  volume = {30},
  number = {1},
  url = {https://ojs.aaai.org/index.php/AAAI/article/view/10403},
  urldate = {2024-03-19},
  file = {/Users/DAADAMS/Zotero/storage/E7JE4TD9/Keren et al. - 2016 - Goal recognition design with non-observable action.pdf}
}

@inproceedings{keryStoryNotebookExploratory2018,
  title = {The {{Story}} in the {{Notebook}}: {{Exploratory Data Science}} Using a {{Literate Programming Tool}}},
  shorttitle = {The {{Story}} in the {{Notebook}}},
  booktitle = {Proceedings of the 2018 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Kery, Mary Beth and Radensky, Marissa and Arya, Mahima and John, Bonnie E. and Myers, Brad A.},
  date = {2018-04-19},
  pages = {1--11},
  publisher = {ACM},
  location = {Montreal QC Canada},
  doi = {10.1145/3173574.3173748},
  url = {https://dl.acm.org/doi/10.1145/3173574.3173748},
  urldate = {2025-02-16},
  eventtitle = {{{CHI}} '18: {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  isbn = {978-1-4503-5620-6},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/MAKS94TQ/Kery et al. - 2018 - The Story in the Notebook Exploratory Data Science using a Literate Programming Tool.pdf}
}

@article{keyderSoundCompleteLandmarks,
  title = {Sound and {{Complete Landmarks}} for {{And}}/{{Or Graphs}}},
  author = {Keyder, Emil and Richter, Silvia and Helmert, Malte},
  abstract = {Landmarks for a planning problem are subgoals that are necessarily made true at some point in the execution of any plan. Since verifying that a fact is a landmark is PSPACE-complete, earlier approaches have focused on finding landmarks for the delete relaxation Π+. Furthermore, some of these approaches have approximated this set of landmarks, although it has been shown that the complete set of causal delete-relaxation landmarks can be identified in polynomial time by a simple procedure over the relaxed planning graph. Here, we give a declarative characterisation of this set of landmarks and show that the procedure computes the landmarks described by our characterisation. Building on this, we observe that the procedure can be applied to any delete-relaxation problem and take advantage of a recent compilation of the m-relaxation of a problem into a problem with no delete effects to extract landmarks that take into account delete effects in the original problem. We demonstrate that this approach finds strictly more causal landmarks than previous approaches and discuss the relationship between increased computational effort and experimental performance, using these landmarks in a recently proposed admissible landmark-counting heuristic.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/MRGSCS6V/Keyder et al. - Sound and Complete Landmarks for AndOr Graphs.pdf}
}

@incollection{kishorAssociationRuleMining2019,
  title = {Association {{Rule Mining Using}} an {{Unsupervised Neural Network}} with an {{Optimized Genetic Algorithm}}},
  booktitle = {{{ICCCE}} 2018},
  author = {Kishor, Peddi and Sammulal, Porika},
  editor = {Kumar, Amit and Mozar, Stefan},
  date = {2019},
  volume = {500},
  pages = {657--669},
  publisher = {Springer Singapore},
  location = {Singapore},
  doi = {10.1007/978-981-13-0212-1_67},
  url = {http://link.springer.com/10.1007/978-981-13-0212-1_67},
  urldate = {2024-12-23},
  abstract = {The best known and most widely utilized pattern finding algorithm in data mining applications is association rule mining (ARM). Extraction of frequent patterns is an indispensable step in ARM. Most studies in the literature have been implemented on the concept of support and confidence framework utilization. Here, we investigated an efficient and robust ARM scheme based on a self-organizing map (SOM) and an optimized genetic algorithm (OGA). A SOM is an unsupervised neural network that efficaciously produces spatially coordinated internal feature representations and detected abstractions in the input space and is the most efficient clustering technique that reveals conventional similarities in the input space by performing a topology maintaining mapping. Hence, a SOM is utilized to generate accurate clustered frequency patterns and an OGA is used to generate positive and negative association rules with multiple consequences by studying all possible patterns. Experimental analysis on various datasets has shown the robustness of our proposed ARM in comparison to traditional rule mining approaches by proving that a greater number of positive and negative association rules is generated by the proposed methodology resulting in a better performance when compared to conventional rule mining schemes.},
  isbn = {978-981-13-0211-4 978-981-13-0212-1},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/PEMHW8J6/Kishor and Sammulal - 2019 - Association Rule Mining Using an Unsupervised Neural Network with an Optimized Genetic Algorithm.pdf}
}

@incollection{kocsisBanditBasedMonteCarlo2006,
  title = {Bandit {{Based Monte-Carlo Planning}}},
  booktitle = {Machine {{Learning}}: {{ECML}} 2006},
  author = {Kocsis, Levente and Szepesvári, Csaba},
  editor = {Fürnkranz, Johannes and Scheffer, Tobias and Spiliopoulou, Myra},
  editora = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Dough and Vardi, Moshe Y. and Weikum, Gerhard},
  editoratype = {redactor},
  date = {2006},
  volume = {4212},
  pages = {282--293},
  publisher = {Springer Berlin Heidelberg},
  location = {Berlin, Heidelberg},
  doi = {10.1007/11871842_29},
  url = {http://link.springer.com/10.1007/11871842_29},
  urldate = {2024-03-15},
  abstract = {For large state-space Markovian Decision Problems MonteCarlo planning is one of the few viable approaches to find near-optimal solutions. In this paper we introduce a new algorithm, UCT, that applies bandit ideas to guide Monte-Carlo planning. In finite-horizon or discounted MDPs the algorithm is shown to be consistent and finite sample bounds are derived on the estimation error due to sampling. Experimental results show that in several domains, UCT is significantly more efficient than its alternatives.},
  isbn = {978-3-540-45375-8 978-3-540-46056-5},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/ZL5XW8CA/Kocsis and Szepesvári - 2006 - Bandit Based Monte-Carlo Planning.pdf}
}

@article{kocsisImprovedMonteCarloSearch,
  title = {Improved {{Monte-Carlo Search}}},
  author = {Kocsis, Levente and Szepesvari, Csaba and Willemson, Jan},
  abstract = {Monte-Carlo search has been successful in many non-deterministic games, and recently in deterministic games with high branching factor. One of the drawbacks of the current approaches is that even if the iterative process would last for a very long time, the selected move does not necessarily converge to a game-theoretic optimal one. In this paper we introduce a new algorithm, UCT, which extends a bandit algorithm for Monte-Carlo search. It is proven that the probability that the algorithm selects the correct move converges to 1. Moreover it is shown empirically that the algorithm converges rather fast even in comparison with alpha-beta search. Experiments in Amazons and Clobber indicate that the UCT algorithm outperforms considerably a plain Monte-Carlo version, and it is competitive against alpha-beta based game programs.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/UA35FBSJ/Kocsis et al. - Improved Monte-Carlo Search.pdf}
}

@inbook{komorowskiExploratoryDataAnalysis2016,
  title = {Exploratory {{Data Analysis}}},
  booktitle = {Secondary {{Analysis}} of {{Electronic Health Records}}},
  author = {Komorowski, Matthieu and Marshall, Dominic C. and Salciccioli, Justin D. and Crutain, Yves},
  date = {2016},
  pages = {185--203},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-319-43742-2_15},
  url = {http://link.springer.com/10.1007/978-3-319-43742-2_15},
  urldate = {2025-02-13},
  bookauthor = {{Mit Critical Data}},
  isbn = {978-3-319-43740-8 978-3-319-43742-2},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/JP4MZXF3/Komorowski et al. - 2016 - Exploratory Data Analysis.pdf}
}

@article{kraskaNorthstarInteractiveData2021,
  title = {Northstar: {{An}} Interactive Data Science System},
  shorttitle = {Northstar},
  author = {Kraska, Tim},
  date = {2021},
  publisher = {VLDB Endowment},
  url = {https://dspace.mit.edu/handle/1721.1/132273},
  urldate = {2025-02-13},
  file = {/Users/DAADAMS/Zotero/storage/ZYFKDNIY/Kraska - 2021 - Northstar An interactive data science system.pdf}
}

@inproceedings{kupiecTrainableDocumentSummarizer1995,
  title = {A Trainable Document Summarizer},
  booktitle = {Proceedings of the 18th Annual International {{ACM SIGIR}} Conference on {{Research}} and Development in Information Retrieval  - {{SIGIR}} '95},
  author = {Kupiec, Julian and Pedersen, Jan and Chen, Francine},
  date = {1995},
  pages = {68--73},
  publisher = {ACM Press},
  location = {Seattle, Washington, United States},
  doi = {10.1145/215206.215333},
  url = {http://portal.acm.org/citation.cfm?doid=215206.215333},
  urldate = {2025-02-16},
  eventtitle = {The 18th Annual International {{ACM SIGIR}} Conference},
  isbn = {978-0-89791-714-8},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/RRZWUAYZ/Kupiec et al. - 1995 - A trainable document summarizer.pdf}
}

@article{lanctotMonteCarloSampling,
  title = {Monte {{Carlo Sampling}} for {{Regret Minimization}} in {{Extensive Games}}},
  author = {Lanctot, Marc and Waugh, Kevin and Zinkevich, Martin and Bowling, Michael},
  abstract = {Sequential decision-making with multiple agents and imperfect information is commonly modeled as an extensive game. One efficient method for computing Nash equilibria in large, zero-sum, imperfect information games is counterfactual regret minimization (CFR). In the domain of poker, CFR has proven effective, particularly when using a domain-specific augmentation involving chance outcome sampling. In this paper, we describe a general family of domain-independent CFR sample-based algorithms called Monte Carlo counterfactual regret minimization (MCCFR) of which the original and poker-specific versions are special cases. We start by showing that MCCFR performs the same regret updates as CFR on expectation. Then, we introduce two sampling schemes: outcome sampling and external sampling, showing that both have bounded overall regret with high probability. Thus, they can compute an approximate equilibrium using self-play. Finally, we prove a new tighter bound on the regret for the original CFR algorithm and relate this new bound to MCCFR’s bounds. We show empirically that, although the sample-based algorithms require more iterations, their lower cost per iteration can lead to dramatically faster convergence in various games.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/2IFE93UJ/Lanctot et al. - Monte Carlo Sampling for Regret Minimization in Ex.pdf}
}

@book{lanctotMonteCarloSampling2013,
  title = {Monte {{Carlo}} Sampling and Regret Minimization for Equilibrium Computation and Decision-Making in Large Extensive Form Games},
  author = {Lanctot, Marc},
  date = {2013},
  publisher = {University of Alberta (Canada)},
  url = {https://search.proquest.com/openview/d63003bb398d303b8c36fb11af7901b2/1.pdf?pq-origsite=gscholar&cbl=18750},
  urldate = {2024-03-15},
  file = {/Users/DAADAMS/Zotero/storage/NN7TG4TM/Lanctot - 2013 - Monte Carlo sampling and regret minimization for e.pdf}
}

@online{lanctotPopulationbasedEvaluationRepeated2023,
  title = {Population-Based {{Evaluation}} in {{Repeated Rock-Paper-Scissors}} as a {{Benchmark}} for {{Multiagent Reinforcement Learning}}},
  author = {Lanctot, Marc and Schultz, John and Burch, Neil and Smith, Max Olan and Hennes, Daniel and Anthony, Thomas and Perolat, Julien},
  date = {2023-10-31},
  eprint = {2303.03196},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2303.03196},
  urldate = {2024-07-30},
  abstract = {Progress in fields of machine learning and adversarial planning has benefited significantly from benchmark domains, from checkers and the classic UCI data sets to Go and Diplomacy. In sequential decision-making, agent evaluation has largely been restricted to few interactions against experts, with the aim to reach some desired level of performance (e.g. beating a human professional player). We propose a benchmark for multiagent learning based on repeated play of the simple game Rock, Paper, Scissors along with a population of forty-three tournament entries, some of which are intentionally sub-optimal. We describe metrics to measure the quality of agents based both on average returns and exploitability. We then show that several RL, online learning, and language model approaches can learn good counter-strategies and generalize well, but ultimately lose to the top-performing bots, creating an opportunity for research in multiagent learning.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Science and Game Theory,Computer Science - Machine Learning,Computer Science - Multiagent Systems},
  file = {/Users/DAADAMS/Zotero/storage/38DSRU7K/Lanctot et al. - 2023 - Population-based Evaluation in Repeated Rock-Paper.pdf}
}

@article{lanFullyOndiskUpdatable,
  title = {A {{Fully On-disk Updatable Learned Index}}},
  author = {Lan, Hai and Culpepper, J Shane and Borovica-Gajic, Renata and Dong, Yu},
  abstract = {While in-memory learned indexes have shown promising performance as compared to B+-tree, most widely used databases in real applications still rely on disk-based operations. From our experiments, we observe that directly applying the existing in-memory learned indexes into on-disk setting suffers from several drawbacks and cannot outperform a standard B+-tree in most cases. Therefore, we make the first attempt to show how the idea of learned index can benefit the on-disk index by proposing AULID, a fully on-disk updatable learned index that can achieve state-of-the-art performance across multiple workload types. The AULID approach combines the benefits from both traditional indexing techniques and the learned indexes to reduce the I/O cost – the main overhead under disk setting. Specifically, three aspects are taken into consideration in reducing I/O costs: (1) reduce the overhead in updating the index structure; (2) induce shorter paths from root to leaf node; (3) achieve better locality to minimize the number of block reads required to complete a scan. Five principles are proposed to guide the design of AULID which shows remarkable performance gains and meanwhile is easy to implement. Our evaluation shows that AULID has comparable storage costs to a B+-tree and is much smaller than other learned indexes, and AULID is up to 2.11x, 8.63x, 1.72x, 5.51x, and 8.02x more efficient than FITing-tree, PGM, B+-tree, ALEX, and LIPP.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/BGKU5XR3/Lan et al. - A Fully On-disk Updatable Learned Index.pdf}
}

@incollection{leeMultidocumentTextSummarization2013,
  title = {Multi-Document {{Text Summarization Using Topic Model}} and {{Fuzzy Logic}}},
  booktitle = {Machine {{Learning}} and {{Data Mining}} in {{Pattern Recognition}}},
  author = {Lee, Sanghoon and Belkasim, Saeid and Zhang, Yanqing},
  editor = {Perner, Petra},
  editora = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard},
  editoratype = {redactor},
  date = {2013},
  volume = {7988},
  pages = {159--168},
  publisher = {Springer Berlin Heidelberg},
  location = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-39712-7_12},
  url = {http://link.springer.com/10.1007/978-3-642-39712-7_12},
  urldate = {2025-02-16},
  isbn = {978-3-642-39711-0 978-3-642-39712-7}
}

@article{leisHowGoodAre2015,
  title = {How Good Are Query Optimizers, Really?},
  author = {Leis, Viktor and Gubichev, Andrey and Mirchev, Atanas and Boncz, Peter and Kemper, Alfons and Neumann, Thomas},
  date = {2015-11},
  journaltitle = {Proceedings of the VLDB Endowment},
  shortjournal = {Proc. VLDB Endow.},
  volume = {9},
  number = {3},
  pages = {204--215},
  issn = {2150-8097},
  doi = {10.14778/2850583.2850594},
  url = {https://dl.acm.org/doi/10.14778/2850583.2850594},
  urldate = {2025-02-24},
  abstract = {Finding a good join order is crucial for query performance. In this paper, we introduce the Join Order Benchmark (JOB) and experimentally revisit the main components in the classic query optimizer architecture using a complex, real-world data set and realistic multi-join queries. We investigate the quality of industrial-strength cardinality estimators and find that all estimators routinely produce large errors. We further show that while estimates are essential for finding a good join order, query performance is unsatisfactory if the query engine relies too heavily on these estimates. Using another set of experiments that measure the impact of the cost model, we find that it has much less influence on query performance than the cardinality estimates. Finally, we investigate plan enumeration techniques comparing exhaustive dynamic programming with heuristic algorithms and find that exhaustive enumeration improves performance despite the sub-optimal cardinality estimates.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/VF75LB9S/Leis et al. - 2015 - How good are query optimizers, really.pdf}
}

@article{liCDCDRConditionalDiffusionbased2025,
  title = {{{CD-CDR}}: {{Conditional Diffusion-based Item Generationfor Cross-Domain Recommendation}}},
  author = {Li, Hanyu},
  date = {2025},
  abstract = {Cross-domain recommendation (CDR) has emerged as a promising direction for expanding the applicability of recommendation systems. Recent advances in CDR have demonstrated the effectiveness of the unified distribution paradigm, which leverages shared distributions to transfer knowledge across domains and employs domain-specific adapters for targeted recommendations. While this well-designed paradigm shows promising performance, existing methods require extra supervision signals (e.g. contrastive learning on domain-masked embeddings) to maintain unified distributions across domains, leading to an inherent trade-off between unified objectives and domain-specific preference modeling.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/LX75FGS2/Li - 2025 - CD-CDR Conditional Diffusion-based Item Generationfor Cross-Domain Recommendation.pdf}
}

@incollection{liEfficientQueryReverse2020,
  title = {Efficient {{Query Reverse Engineering Using Table Fragments}}},
  booktitle = {Database {{Systems}} for {{Advanced Applications}}},
  author = {Li, Meiying and Chan, Chee-Yong},
  editor = {Nah, Yunmook and Cui, Bin and Lee, Sang-Won and Yu, Jeffrey Xu and Moon, Yang-Sae and Whang, Steven Euijong},
  date = {2020},
  volume = {12114},
  pages = {406--422},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-030-59419-0_25},
  url = {https://link.springer.com/10.1007/978-3-030-59419-0_25},
  urldate = {2025-08-28},
  abstract = {Given an output table T that is the result of some unknown query on a database D, Query Reverse Engineering (QRE) computes one or more target query Q such that the result of Q on D is T. A fundamental challenge in QRE is how to efficiently compute target queries given its large search space. In this paper, we focus on the QRE problem for PJ+ queries, which is a more expressive class of queries than projectjoin queries by supporting antijoins as well as inner joins. To enhance efficiency, we propose a novel query-centric approach consisting of table partitioning, precomputation, and indexing techniques. Our experimental study demonstrates that our approach significantly outperforms the state-of-the-art solution by an average improvement factor of 120.},
  isbn = {978-3-030-59418-3 978-3-030-59419-0},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/69ETW5VT/Li and Chan - 2020 - Efficient Query Reverse Engineering Using Table Fragments.pdf}
}

@online{linAccurateEfficientDocument2024,
  title = {Towards {{Accurate}} and {{Efficient Document Analytics}} with {{Large Language Models}}},
  author = {Lin, Yiming and Hulsebos, Madelon and Ma, Ruiying and Shankar, Shreya and Zeigham, Sepanta and Parameswaran, Aditya G. and Wu, Eugene},
  date = {2024-05-07},
  eprint = {2405.04674},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2405.04674},
  url = {http://arxiv.org/abs/2405.04674},
  urldate = {2025-09-08},
  abstract = {Unstructured data formats account for over 80\% of the data currently stored, and extracting value from such formats remains a considerable challenge. In particular, current approaches for managing unstructured documents do not support ad-hoc analytical queries on document collections. Moreover, Large Language Models (LLMs) directly applied to the documents themselves, or on portions of documents through a process of Retrieval-Augmented Generation (RAG), fail to provide high-accuracy query results, and in the LLM-only case, additionally incur high costs. Since many unstructured documents in a collection often follow similar templates that impart a common semantic structure, we introduce ZenDB, a document analytics system that leverages this semantic structure, coupled with LLMs, to answer ad-hoc SQL queries on document collections. ZenDB efficiently extracts semantic hierarchical structures from such templatized documents and introduces a novel query engine that leverages these structures for accurate and cost-effective query execution. Users can impose a schema on their documents, and query it, all via SQL. Extensive experiments on three real-world document collections demonstrate ZenDB ’s benefits, achieving up to 30× cost savings compared to LLM-based baselines, while maintaining or improving accuracy, and surpassing RAG-based baselines by up to 61\% in precision and 80\% in recall, at a marginally higher cost.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Databases},
  file = {/Users/DAADAMS/Zotero/storage/QKJUXS4M/Lin et al. - 2024 - Towards Accurate and Efficient Document Analytics with Large Language Models.pdf}
}

@inproceedings{linIdentifyingTopicsPosition1997,
  title = {Identifying Topics by Position},
  booktitle = {Fifth Conference on Applied Natural Language Processing},
  author = {Lin, Chin-Yew and Hovy, Eduard},
  date = {1997},
  pages = {283--290},
  url = {https://aclanthology.org/A97-1042.pdf},
  urldate = {2025-02-16},
  file = {/Users/DAADAMS/Zotero/storage/6EWRDLG9/Lin and Hovy - 1997 - Identifying topics by position.pdf}
}

@online{LinmagitQueryBot5000Querybased,
  title = {Linmagit/{{QueryBot5000}}: {{Query-based Workload Forecasting}} for {{Self-Driving DBMS}}},
  url = {https://github.com/linmagit/QueryBot5000?tab=readme-ov-file},
  urldate = {2025-02-24},
  file = {/Users/DAADAMS/Zotero/storage/FMU8VRXN/QueryBot5000.html}
}

@inproceedings{linRougePackageAutomatic2004,
  title = {Rouge: {{A}} Package for Automatic Evaluation of Summaries},
  shorttitle = {Rouge},
  booktitle = {Text Summarization Branches Out},
  author = {Lin, Chin-Yew},
  date = {2004},
  pages = {74--81},
  url = {https://aclanthology.org/W04-1013.pdf},
  urldate = {2025-02-16},
  file = {/Users/DAADAMS/Zotero/storage/3A4ZTZBW/Lin - 2004 - Rouge A package for automatic evaluation of summaries.pdf}
}

@inproceedings{linTrainingSelectionFunction1999,
  title = {Training a Selection Function for Extraction},
  booktitle = {Proceedings of the Eighth International Conference on {{Information}} and Knowledge Management},
  author = {Lin, Chin-Yew},
  date = {1999-11},
  pages = {55--62},
  publisher = {ACM},
  location = {Kansas City Missouri USA},
  doi = {10.1145/319950.319957},
  url = {https://dl.acm.org/doi/10.1145/319950.319957},
  urldate = {2025-02-16},
  eventtitle = {{{CIKM99}}: {{Conference}} on {{Information}} and {{Knowledge Management}}},
  isbn = {978-1-58113-146-8},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/ME7CK92A/Lin - 1999 - Training a selection function for extraction.pdf}
}

@inproceedings{lipmanATENAPROGeneratingPersonalized2023,
  title = {{{ATENA-PRO}}: {{Generating Personalized Exploration Notebooks}} with {{Constrained Reinforcement Learning}}},
  shorttitle = {{{ATENA-PRO}}},
  booktitle = {Companion of the 2023 {{International Conference}} on {{Management}} of {{Data}}},
  author = {Lipman, Tavor and Milo, Tova and Somech, Amit},
  date = {2023-06-04},
  pages = {167--170},
  publisher = {ACM},
  location = {Seattle WA USA},
  doi = {10.1145/3555041.3589727},
  url = {https://dl.acm.org/doi/10.1145/3555041.3589727},
  urldate = {2024-12-08},
  abstract = {We present ATENA-PRO, a framework for generating personalized data exploration notebooks, given an input dataset and user preferences. Via a dedicated wizard interface, users first specify their information needs from the desired exploration notebook. These specifications, alongside the input dataset, are fed to a constrained Deep Reinforcement Learning (CDRL) framework. Our CDRL framework is based on ATENA, a general-purpose DRL architecture for data exploration, augmenting it with a new compliance reward scheme, and a specification-aware neural network architecture, both crucial for the generation of personalized notebooks.},
  eventtitle = {{{SIGMOD}}/{{PODS}} '23: {{International Conference}} on {{Management}} of {{Data}}},
  isbn = {978-1-4503-9507-6},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/C2CI2RNP/Lipman et al. - 2023 - ATENA-PRO Generating Personalized Exploration Notebooks with Constrained Reinforcement Learning.pdf}
}

@online{lipmanLINXLanguageDriven2024,
  title = {{{LINX}}: {{A Language Driven Generative System}} for {{Goal-Oriented Automated Data Exploration}}},
  shorttitle = {{{LINX}}},
  author = {Lipman, Tavor and Milo, Tova and Somech, Amit and Wolfson, Tomer and Zafar, Oz},
  date = {2024-06-07},
  eprint = {2406.05107},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2406.05107},
  url = {http://arxiv.org/abs/2406.05107},
  urldate = {2024-11-26},
  abstract = {Data exploration is a challenging and time-consuming process in which users examine a dataset by iteratively employing a series of queries. While in some cases the user explores a new dataset to become familiar with it, more often, the exploration process is conducted with a specific analysis goal or question in mind. To assist users in exploring a new dataset, Automated Data Exploration (ADE) systems have been devised in previous work. These systems aim to auto-generate a full exploration session, containing a sequence of queries that showcase interesting elements of the data. However, existing ADE systems are often constrained by a predefined objective function, thus always generating the same session for a given dataset. Therefore, their effectiveness in goal-oriented exploration, in which users need to answer specific questions about the data, are extremely limited.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Databases},
  file = {/Users/DAADAMS/Zotero/storage/EE38SJDN/Lipman et al. - 2024 - LINX A Language Driven Generative System for Goal-Oriented Automated Data Exploration.pdf}
}

@article{luhnAutomaticCreationLiterature1958,
  title = {The Automatic Creation of Literature Abstracts},
  author = {Luhn, Hans Peter},
  date = {1958},
  journaltitle = {IBM Journal of research and development},
  volume = {2},
  number = {2},
  pages = {159--165},
  publisher = {Ibm},
  url = {https://ieeexplore.ieee.org/abstract/document/5392672/},
  urldate = {2025-02-16}
}

@article{luiseDifferentialPropertiesSinkhorn,
  title = {Differential {{Properties}} of {{Sinkhorn Approximation}} for {{Learning}} with {{Wasserstein Distance}}},
  author = {Luise, Giulia and Rudi, Alessandro and Pontil, Massimiliano and Ciliberto, Carlo},
  abstract = {Applications of optimal transport have recently gained remarkable attention as a result of the computational advantages of entropic regularization. However, in most situations the Sinkhorn approximation to the Wasserstein distance is replaced by a regularized version that is less accurate but easy to differentiate. In this work we characterize the differential properties of the original Sinkhorn approximation, proving that it enjoys the same smoothness of its regularized version and we explicitly provide an efficient algorithm to compute its gradient. We show that this result benefits both theory and applications: on one hand, high order smoothness confers statistical guarantees to learning with Wasserstein approximations. On the other hand, the gradient formula is used to efficiently solve learning and optimization problems in practice. Promising preliminary experiments complement our analysis.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/NJVF7WLA/Luise et al. - Differential Properties of Sinkhorn Approximation for Learning with Wasserstein Distance.pdf}
}

@inproceedings{luoDeepeyeAutomaticData2018,
  title = {Deepeye: {{Towards}} Automatic Data Visualization},
  shorttitle = {Deepeye},
  booktitle = {2018 {{IEEE}} 34th International Conference on Data Engineering ({{ICDE}})},
  author = {Luo, Yuyu and Qin, Xuedi and Tang, Nan and Li, Guoliang},
  date = {2018},
  pages = {101--112},
  publisher = {IEEE},
  url = {https://ieeexplore.ieee.org/abstract/document/8509240/},
  urldate = {2025-02-16},
  file = {/Users/DAADAMS/Zotero/storage/PD9474IP/Luo et al. - 2018 - Deepeye Towards automatic data visualization.pdf}
}

@inproceedings{macqueenMethodsClassificationAnalysis1967,
  title = {Some Methods for Classification and Analysis of Multivariate Observations},
  booktitle = {Proceedings of 5-Th {{Berkeley Symposium}} on {{Mathematical Statistics}} and {{Probability}}/{{University}} of {{California Press}}},
  author = {MacQueen, J.},
  date = {1967},
  url = {http://dl1.icdst.org/pdfs/files/89776553ba539ae6ab958d2fb6b97757.pdf},
  urldate = {2025-02-16},
  file = {/Users/DAADAMS/Zotero/storage/6GDHYH2E/MacQueen - 1967 - Some methods for classification and analysis of multivariate observations.pdf}
}

@inproceedings{macqueenMethodsClassificationAnalysis1967a,
  title = {Some Methods for Classification and Analysis of Multivariate Observations},
  booktitle = {Proceedings of 5-Th {{Berkeley Symposium}} on {{Mathematical Statistics}} and {{Probability}}/{{University}} of {{California Press}}},
  author = {MacQueen, J.},
  date = {1967},
  url = {http://dl1.icdst.org/pdfs/files/89776553ba539ae6ab958d2fb6b97757.pdf},
  urldate = {2025-02-16},
  file = {/Users/DAADAMS/Zotero/storage/QDXXUNBI/MacQueen - 1967 - Some methods for classification and analysis of multivariate observations.pdf}
}

@online{manatkarILAEDAImitationLearning2024,
  title = {{{ILAEDA}}: {{An Imitation Learning Based Approach}} for {{Automatic Exploratory Data Analysis}}},
  shorttitle = {{{ILAEDA}}},
  author = {Manatkar, Abhijit and Patel, Devarsh and Patel, Hima and Manwani, Naresh},
  date = {2024-10-15},
  eprint = {2410.11276},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2410.11276},
  url = {http://arxiv.org/abs/2410.11276},
  urldate = {2024-12-08},
  abstract = {Automating end-to-end Exploratory Data Analysis (AutoEDA) is a challenging open problem, often tackled through Reinforcement Learning (RL) by learning to predict a sequence of analysis operations (FILTER, GROUP, etc). Defining rewards for each operation is a challenging task and existing methods rely on various interestingness measures to craft reward functions to capture the importance of each operation. In this work, we argue that not all of the essential features of what makes an operation important can be accurately captured mathematically using rewards. We propose an AutoEDA model trained through imitation learning from expert EDA sessions, bypassing the need for manually defined interestingness measures. Our method, based on generative adversarial imitation learning (GAIL), generalizes well across datasets, even with limited expert data. We also introduce a novel approach for generating synthetic EDA demonstrations for training. Our method outperforms the existing state-of-the-art end-to-end EDA approach on benchmarks by upto 3x, showing strong performance and generalization, while naturally capturing diverse interestingness measures in generated EDA sessions.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Databases,Computer Science - Machine Learning},
  file = {/Users/DAADAMS/Zotero/storage/UEIJG5ZH/Manatkar et al. - 2024 - ILAEDA An Imitation Learning Based Approach for Automatic Exploratory Data Analysis.pdf}
}

@article{manolescuExploringRDFGraphs,
  title = {Exploring {{RDF Graphs}} through {{Summarization}} and {{Analytic Query Discovery}}},
  author = {Manolescu, Ioana},
  abstract = {Graph data is central to many applications, ranging from social networks to scientific databases. Graph formats maximize the flexibility offered to data designers, as they are mostly schemaless and thus can be used to capture very heterogeneous-structure content. RDF, the W3C’s format for sharing open (linked) data, adds the possibility to attach semantics to data, describing applicationdomain constraints by means of ontologies; in turn, this leads to implicit data that is also part of a graph even if it is not explicitly in it.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/TW5SQHGC/Manolescu - Exploring RDF Graphs through Summarization and Analytic Query Discovery.pdf}
}

@inproceedings{maQuerybasedWorkloadForecasting2018,
  title = {Query-Based {{Workload Forecasting}} for {{Self-Driving Database Management Systems}}},
  booktitle = {Proceedings of the 2018 {{International Conference}} on {{Management}} of {{Data}}},
  author = {Ma, Lin and Van Aken, Dana and Hefny, Ahmed and Mezerhane, Gustavo and Pavlo, Andrew and Gordon, Geoffrey J.},
  date = {2018-05-27},
  pages = {631--645},
  publisher = {ACM},
  location = {Houston TX USA},
  doi = {10.1145/3183713.3196908},
  url = {https://dl.acm.org/doi/10.1145/3183713.3196908},
  urldate = {2025-02-24},
  abstract = {The first step towards an autonomous database management system (DBMS) is the ability to model the target application’s workload. This is necessary to allow the system to anticipate future workload needs and select the proper optimizations in a timely manner. Previous forecasting techniques model the resource utilization of the queries. Such metrics, however, change whenever the physical design of the database and the hardware resources change, thereby rendering previous forecasting models useless.},
  eventtitle = {{{SIGMOD}}/{{PODS}} '18: {{International Conference}} on {{Management}} of {{Data}}},
  isbn = {978-1-4503-4703-7},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/V8UW2VB2/Ma et al. - 2018 - Query-based Workload Forecasting for Self-Driving Database Management Systems.pdf}
}

@inproceedings{maQuerybasedWorkloadForecasting2018a,
  title = {Query-Based {{Workload Forecasting}} for {{Self-Driving Database Management Systems}}},
  booktitle = {Proceedings of the 2018 {{International Conference}} on {{Management}} of {{Data}}},
  author = {Ma, Lin and Van Aken, Dana and Hefny, Ahmed and Mezerhane, Gustavo and Pavlo, Andrew and Gordon, Geoffrey J.},
  date = {2018-05-27},
  pages = {631--645},
  publisher = {ACM},
  location = {Houston TX USA},
  doi = {10.1145/3183713.3196908},
  url = {https://dl.acm.org/doi/10.1145/3183713.3196908},
  urldate = {2025-02-24},
  abstract = {The first step towards an autonomous database management system (DBMS) is the ability to model the target application’s workload. This is necessary to allow the system to anticipate future workload needs and select the proper optimizations in a timely manner. Previous forecasting techniques model the resource utilization of the queries. Such metrics, however, change whenever the physical design of the database and the hardware resources change, thereby rendering previous forecasting models useless.},
  eventtitle = {{{SIGMOD}}/{{PODS}} '18: {{International Conference}} on {{Management}} of {{Data}}},
  isbn = {978-1-4503-4703-7},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/HFL3EJVY/Ma et al. - 2018 - Query-based Workload Forecasting for Self-Driving Database Management Systems.pdf}
}

@article{martinsReverseEngineeringDatabase2019,
  title = {Reverse Engineering Database Queries from Examples: {{State-of-the-art}}, Challenges, and Research Opportunities},
  shorttitle = {Reverse Engineering Database Queries from Examples},
  author = {Martins, Denis Mayr Lima},
  date = {2019-07-01},
  journaltitle = {Information Systems},
  shortjournal = {Information Systems},
  volume = {83},
  pages = {89--100},
  issn = {0306-4379},
  doi = {10.1016/j.is.2019.03.002},
  url = {https://www.sciencedirect.com/science/article/pii/S0306437918300978},
  urldate = {2025-08-28},
  abstract = {With the popularization of data access and usage, an increasing number of users without expert knowledge of databases is required to perform data interactions. Often, these users face the challenges of writing and reformulating database queries, which consume a considerable amount of time and frequently yield unsatisfactory results. To facilitate this human–database interaction, researchers have investigated the Query By Example (QBE) paradigm in which database queries are (semi) automatically discovered from data examples given by users. This paradigm allows non-database experts to formulate queries without relying on complex query languages. In this context, this work aims to present a systematic review of the recent developments, open challenges, and research opportunities of the QBE reported in the literature. This work also describes strategies employed to leverage efficient example acquisition and query reverse engineering. The obtained results show that recent research developments have focused on enhancing the expressiveness of produced queries, minimizing user interaction, and enabling efficient query learning in the context of data retrieval, exploration, integration, and analytics. Our findings indicate that future research should concentrate efforts to provide innovative solutions to the challenges of improving controllability and transparency, considering diverse user preferences in the processes of learning personalized queries, ensuring data quality, and improving the support of additional SQL features and operators.},
  keywords = {Databases,Query discovery,Query learning,Query synthesis,Reverse engineering database queries},
  file = {/Users/DAADAMS/Zotero/storage/S9JWLPKB/S0306437918300978.html}
}

@article{mccullochLogicalCalculusIdeas1943,
  title = {A Logical Calculus of the Ideas Immanent in Nervous Activity},
  author = {McCulloch, Warren S. and Pitts, Walter},
  date = {1943},
  journaltitle = {The bulletin of mathematical biophysics},
  volume = {5},
  pages = {115--133},
  publisher = {Springer},
  url = {https://idp.springer.com/authorize/casa?redirect_uri=https://link.springer.com/article/10.1007/BF02478259&casa_token=oNjv_zJ_TvcAAAAA:Y0P8SZfyyt3TAaRzBik1ArZfI7N0rCHC5nLIHca32hwOHjry5_2DLijy7wtxk1IOqPsxQhGOTh7vYsFbEQ},
  urldate = {2025-02-16},
  file = {/Users/DAADAMS/Zotero/storage/ZS6EGMKU/McCulloch and Pitts - 1943 - A logical calculus of the ideas immanent in nervous activity.pdf}
}

@inproceedings{meneguzziSurveyGoalRecognition2021,
  title = {A {{Survey}} on {{Goal Recognition}} as {{Planning}}},
  booktitle = {Proceedings of the {{Thirtieth International Joint Conference}} on {{Artificial Intelligence}}},
  author = {Meneguzzi, Felipe and Fraga Pereira, Ramon},
  date = {2021-08},
  pages = {4524--4532},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  location = {Montreal, Canada},
  doi = {10.24963/ijcai.2021/616},
  url = {https://www.ijcai.org/proceedings/2021/616},
  urldate = {2024-03-15},
  abstract = {Goal Recognition is the task of inferring an agent’s goal, from a set of hypotheses, given a model of the environment dynamic, and a sequence of observations of such agent’s behavior. While research on this problem gathered momentum as an offshoot of plan recognition, recent research has established it as a major subject of research on its own, leading to numerous new approaches that both expand the expressivity of domains in which to perform goal recognition and substantial advances to the stateof-the-art on established domain types. In this survey, we focus on the advances to goal recognition achieved in the last decade, categorizing the resulting techniques and identifying a number of opportunities for further breakthrough research.},
  eventtitle = {Thirtieth {{International Joint Conference}} on {{Artificial Intelligence}} \{\vphantom\}{{IJCAI-21}}\vphantom\{\}},
  isbn = {978-0-9992411-9-6},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/IHCWNXK5/Meneguzzi and Fraga Pereira - 2021 - A Survey on Goal Recognition as Planning.pdf}
}

@inproceedings{miloAutomatingExploratoryData2020,
  title = {Automating {{Exploratory Data Analysis}} via {{Machine Learning}}: {{An Overview}}},
  shorttitle = {Automating {{Exploratory Data Analysis}} via {{Machine Learning}}},
  booktitle = {Proceedings of the 2020 {{ACM SIGMOD International Conference}} on {{Management}} of {{Data}}},
  author = {Milo, Tova and Somech, Amit},
  date = {2020-06-11},
  pages = {2617--2622},
  publisher = {ACM},
  location = {Portland OR USA},
  doi = {10.1145/3318464.3383126},
  url = {https://dl.acm.org/doi/10.1145/3318464.3383126},
  urldate = {2024-12-08},
  abstract = {Exploratory Data Analysis (EDA) is an important initial step for any knowledge discovery process, in which data scientists interactively explore unfamiliar datasets by issuing a sequence of analysis operations (e.g. filter, aggregation, and visualization). Since EDA is long known as a difficult task, requiring profound analytical skills, experience, and domain knowledge, a plethora of systems have been devised over the last decade in order to facilitate EDA.},
  eventtitle = {{{SIGMOD}}/{{PODS}} '20: {{International Conference}} on {{Management}} of {{Data}}},
  isbn = {978-1-4503-6735-6},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/98MCTQTV/Milo and Somech - 2020 - Automating Exploratory Data Analysis via Machine Learning An Overview.pdf}
}

@inproceedings{miloDeepReinforcementLearningFramework2018,
  title = {Deep {{Reinforcement-Learning Framework}} for {{Exploratory Data Analysis}}},
  booktitle = {Proceedings of the {{First International Workshop}} on {{Exploiting Artificial Intelligence Techniques}} for {{Data Management}}},
  author = {Milo, Tova and Somech, Amit},
  date = {2018-06-10},
  pages = {1--4},
  publisher = {ACM},
  location = {Houston TX USA},
  doi = {10.1145/3211954.3211958},
  url = {https://dl.acm.org/doi/10.1145/3211954.3211958},
  urldate = {2024-12-08},
  abstract = {Deep Reinforcement Learning (DRL) is unanimously considered as a breakthrough technology, used in solving a growing number of AI challenges previously considered to be intractable. In this work, we aim to set the ground for employing DRL techniques in the context of Exploratory Data Analysis (EDA), an important yet challenging, that is critical in many application domains. We suggest an end-to-end framework architecture, coupled with an initial implementation of each component. The goal of this short paper is to encourage the exploration of DRL models and techniques for facilitating a full-fledged, autonomous solution for EDA.},
  eventtitle = {{{SIGMOD}}/{{PODS}} '18: {{International Conference}} on {{Management}} of {{Data}}},
  isbn = {978-1-4503-5851-4},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/57ISBU99/Milo and Somech - 2018 - Deep Reinforcement-Learning Framework for Exploratory Data Analysis.pdf}
}

@inproceedings{miloDeepReinforcementLearningFramework2018a,
  title = {Deep {{Reinforcement-Learning Framework}} for {{Exploratory Data Analysis}}},
  booktitle = {Proceedings of the {{First International Workshop}} on {{Exploiting Artificial Intelligence Techniques}} for {{Data Management}}},
  author = {Milo, Tova and Somech, Amit},
  date = {2018-06-10},
  pages = {1--4},
  publisher = {ACM},
  location = {Houston TX USA},
  doi = {10.1145/3211954.3211958},
  url = {https://dl.acm.org/doi/10.1145/3211954.3211958},
  urldate = {2025-02-16},
  eventtitle = {{{SIGMOD}}/{{PODS}} '18: {{International Conference}} on {{Management}} of {{Data}}},
  isbn = {978-1-4503-5851-4},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/S85T9B7R/Milo and Somech - 2018 - Deep Reinforcement-Learning Framework for Exploratory Data Analysis.pdf}
}

@inproceedings{miloNextStepSuggestionsModern2018,
  title = {Next-{{Step Suggestions}} for {{Modern Interactive Data Analysis Platforms}}},
  booktitle = {Proceedings of the 24th {{ACM SIGKDD International Conference}} on {{Knowledge Discovery}} \& {{Data Mining}}},
  author = {Milo, Tova and Somech, Amit},
  date = {2018-07-19},
  pages = {576--585},
  publisher = {ACM},
  location = {London United Kingdom},
  doi = {10.1145/3219819.3219848},
  url = {https://dl.acm.org/doi/10.1145/3219819.3219848},
  urldate = {2024-12-17},
  eventtitle = {{{KDD}} '18: {{The}} 24th {{ACM SIGKDD International Conference}} on {{Knowledge Discovery}} and {{Data Mining}}},
  isbn = {978-1-4503-5552-0},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/9FYVZ8ZN/Milo and Somech - 2018 - Next-Step Suggestions for Modern Interactive Data Analysis Platforms.pdf}
}

@inproceedings{miloNextStepSuggestionsModern2018a,
  title = {Next-{{Step Suggestions}} for {{Modern Interactive Data Analysis Platforms}}},
  booktitle = {Proceedings of the 24th {{ACM SIGKDD International Conference}} on {{Knowledge Discovery}} \& {{Data Mining}}},
  author = {Milo, Tova and Somech, Amit},
  date = {2018-07-19},
  pages = {576--585},
  publisher = {ACM},
  location = {London United Kingdom},
  doi = {10.1145/3219819.3219848},
  url = {https://dl.acm.org/doi/10.1145/3219819.3219848},
  urldate = {2025-02-16},
  eventtitle = {{{KDD}} '18: {{The}} 24th {{ACM SIGKDD International Conference}} on {{Knowledge Discovery}} and {{Data Mining}}},
  isbn = {978-1-4503-5552-0},
  langid = {english}
}

@inproceedings{miloREACTContextSensitiveRecommendations2016,
  title = {{{REACT}}: {{Context-Sensitive Recommendations}} for {{Data Analysis}}},
  shorttitle = {{{REACT}}},
  booktitle = {Proceedings of the 2016 {{International Conference}} on {{Management}} of {{Data}}},
  author = {Milo, Tova and Somech, Amit},
  date = {2016-06-26},
  pages = {2137--2140},
  publisher = {ACM},
  location = {San Francisco California USA},
  doi = {10.1145/2882903.2899392},
  url = {https://dl.acm.org/doi/10.1145/2882903.2899392},
  urldate = {2025-02-16},
  eventtitle = {{{SIGMOD}}/{{PODS}}'16: {{International Conference}} on {{Management}} of {{Data}}},
  isbn = {978-1-4503-3531-7},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/NUVXYJHJ/Milo and Somech - 2016 - REACT Context-Sensitive Recommendations for Data Analysis.pdf}
}

@online{MinimizingSimpleCumulative,
  title = {Minimizing~{{Simple}}~and~{{Cumulative~Regret}} in~{{Monte-Carlo~Tree~Search}} | {{SpringerLink}}},
  url = {https://link.springer.com/chapter/10.1007/978-3-319-14923-3_1},
  urldate = {2024-03-15},
  file = {/Users/DAADAMS/Zotero/storage/DZZHPM5B/978-3-319-14923-3_1.html}
}

@article{mokkademRecursiveAlgorithmMining2022,
  title = {A {{Recursive Algorithm}} for {{Mining Association Rules}}},
  author = {Mokkadem, Abdelkader and Pelletier, Mariane and Raimbault, Louis},
  date = {2022-07-20},
  journaltitle = {SN Computer Science},
  shortjournal = {SN COMPUT. SCI.},
  volume = {3},
  number = {5},
  pages = {384},
  issn = {2661-8907},
  doi = {10.1007/s42979-022-01266-y},
  url = {https://doi.org/10.1007/s42979-022-01266-y},
  urldate = {2025-01-07},
  abstract = {Mining frequent itemsets and association rules are an essential task within data mining and data analysis. In this paper, we introduce PrefRec, a recursive algorithm for finding frequent itemsets and association rules. Its main advantage is its recursiveness with respect to the items. It is particularly efficient for updating the mining process when new items are added to the database or when some are excluded. We present in a complete way the logic of the algorithm, and give some of its applications. After that, we carry out an experimental study on the effectiveness of PrefRec. We first compare the execution times with some very popular frequent itemset mining algorithms. Then, we do experiments to test the updating capabilities of our algorithm.},
  langid = {english},
  keywords = {Association rule,Data mining,Frequent itemset,Recursive algorithm},
  file = {/Users/DAADAMS/Zotero/storage/HA5968EB/Mokkadem et al. - 2022 - A Recursive Algorithm for Mining Association Rules.pdf}
}

@inproceedings{moreScalableClusteringDistributed2004,
  title = {Scalable Clustering: A Distributed Approach},
  shorttitle = {Scalable Clustering},
  booktitle = {2004 {{IEEE International Conference}} on {{Fuzzy Systems}} ({{IEEE Cat}}. {{No}}. {{04CH37542}})},
  author = {More, P. and Hall, Lawrence O.},
  date = {2004},
  volume = {1},
  pages = {143--148},
  publisher = {IEEE},
  url = {https://ieeexplore.ieee.org/abstract/document/1375705/},
  urldate = {2025-02-16},
  file = {/Users/DAADAMS/Zotero/storage/WWSXBHIJ/More and Hall - 2004 - Scalable clustering a distributed approach.pdf}
}

@article{neubergCausalityModelsReasoning2003,
  title = {Causality: Models, Reasoning, and Inference, by Judea Pearl, Cambridge University Press, 2000},
  shorttitle = {Causality},
  author = {Neuberg, Leland Gerson},
  date = {2003},
  journaltitle = {Econometric Theory},
  volume = {19},
  number = {4},
  pages = {675--685},
  publisher = {cambridge university press},
  url = {https://www.cambridge.org/core/journals/econometric-theory/article/causality-models-reasoning-and-inference-by-judea-pearl-cambridge-university-press-2000/DA2D9ABB0AD3DAC95AE7B3081FCDF139},
  urldate = {2025-02-16},
  file = {/Users/DAADAMS/Zotero/storage/H3EP33JE/212370297.html}
}

@article{nguyenCARIMEfficientAlgorithm2015,
  title = {{{CARIM}}: {{An Efficient Algorithm}} for {{Mining Class-Association Rules}} with {{Interestingness Measures}}.},
  shorttitle = {{{CARIM}}},
  author = {Nguyen, Loan and Vo, Bay and Hong, Tzung-Pei},
  date = {2015},
  journaltitle = {International Arab Journal of Information Technology (IAJIT)},
  volume = {12},
  url = {https://ccis2k.org/iajit/PDF/Vol%2012,%20No.%207%20(Special%20Issue)/5641.pdf},
  urldate = {2025-01-13},
  annotation = {Read\_Status: Read\\
Read\_Status\_Date: 2025-01-13T05:40:49.695Z},
  file = {/Users/DAADAMS/Zotero/storage/GNRH2GSR/Nguyen et al. - 2015 - CARIM An Efficient Algorithm for Mining Class-Association Rules with Interestingness Measures..pdf}
}

@inproceedings{nguyenInterestingnessMeasuresClassification2012,
  title = {Interestingness {{Measures}} for {{Classification Based}} on {{Association Rules}}},
  booktitle = {Computational {{Collective Intelligence}}. {{Technologies}} and {{Applications}}},
  author = {Nguyen, Loan T. T. and Vo, Bay and Hong, Tzung-Pei and Thanh, Hoang Chi},
  editor = {Nguyen, Ngoc-Thanh and Hoang, Kiem and Jȩdrzejowicz, Piotr},
  date = {2012},
  pages = {383--392},
  publisher = {Springer},
  location = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-34707-8_39},
  abstract = {This paper proposes a new algorithm for classification based on association rule with interestingness measures. The proposed algorithm uses a tree structure for maintenance of related information in each node, thus making the process of generating rules fast. Besides, the proposed algorithm can be easily extended to integrate some measures together for ranking rules. Experiments are also made to show the efficiency of the proposed approach for different settings. The mining time for different interestingness measures is varied only a little when ten measures are integrated.},
  isbn = {978-3-642-34707-8},
  langid = {english},
  keywords = {accuracy,class-association rulem,classification,integration,interestingness measure},
  file = {/Users/DAADAMS/Zotero/storage/Z4PCE8SG/Nguyen et al. - 2012 - Interestingness Measures for Classification Based on Association Rules.pdf}
}

@online{OpenAllSynced,
  title = {Open All Synced Tabs? : R/Firefox},
  url = {https://www.reddit.com/r/firefox/comments/8pfhjd/open_all_synced_tabs/},
  urldate = {2024-07-18},
  file = {/Users/DAADAMS/Zotero/storage/CNFTGKLY/open_all_synced_tabs.html}
}

@article{orvalhoSQUARESSQLSynthesizer,
  title = {{{SQUARES}} : {{A SQL Synthesizer Using Query Reverse Engineering}}},
  author = {Orvalho, Pedro and Terra-Neves, Miguel and Ventura, Miguel and Martins, Ruben and Manquinho, Vasco},
  abstract = {Nowadays, many data analysts are domain experts, but they lack programming skills. As a result, many of them can provide examples of data transformations but are unable to produce the desired query. Hence, there is an increasing need for systems capable of solving the problem of Query Reverse Engineering (QRE). Given a database and output table, these systems have to find the query that generated this table. We present SQUARES, a program synthesis tool based on input-output examples that can help data analysts to extract and transform data by synthesizing SQL queries, and table manipulation programs using the R language.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/IIPN3GLR/Orvalho et al. - SQUARES  A SQL Synthesizer Using Query Reverse Engineering.pdf}
}

@online{OSFSIMBABenchmark,
  title = {{{OSF}} | {{SIMBA Benchmark}}},
  url = {https://osf.io/vbm8z/files/osfstorage?view_only=2e06892f0c104a9e911e8e7599deb2ab},
  urldate = {2025-09-10},
  file = {/Users/DAADAMS/Zotero/storage/AYCY24L3/osfstorage.html}
}

@dataset{panevReverseEngineeringTopk2016,
  title = {Reverse {{Engineering Top-k Database Queries}} with {{PALEO}}},
  author = {Panev, Kiril and Michel, Sebastian},
  date = {2016},
  publisher = {OpenProceedings.org},
  doi = {10.5441/002/EDBT.2016.13},
  url = {https://openproceedings.org/2016/conf/edbt/paper-156.pdf},
  urldate = {2025-08-28},
  abstract = {Ranked lists are an essential methodology to succinctly summarize outstanding items, computed over database tables or crowdsourced in dedicated websites. In this work, we address the problem of reverse engineering top-k queries over a database, that is, given a relation R and a sample topk result list, our approach, named PALEO1, aims at determining an SQL query that returns the provided input result when executed over R. The core problem consists of finding predicates of the where clause that return the given items, determining the correct ranking criteria, and to evaluate the most promising candidate queries first. To capture cases where only a sample of R is available or when R is different to the relation that indeed generated the input, we put forward a probabilistic model that allows assessing the chance of a query to output tuples that are resembling or are somewhat close to the input data. We further propose an iterative candidate query execution to further eliminate unpromising queries before being executed. We report on the results of a comprehensive performance evaluation using data and queries of the TPC-H and SSB [14] benchmarks.},
  langid = {english},
  keywords = {Database Technology},
  file = {/Users/DAADAMS/Zotero/storage/NFCVHK92/Panev and Michel - 2016 - Reverse Engineering Top-k Database Queries with PALEO.pdf}
}

@inproceedings{papadopoulosHAIDESAdaptiveApproximation2025,
  title = {{{HAIDES}}: {{Adaptive Approximation}} of {{Inference Queries}} over {{Unstructured Data}}},
  shorttitle = {{{HAIDES}}},
  booktitle = {2025 {{IEEE}} 41st {{International Conference}} on {{Data Engineering}} ({{ICDE}})},
  author = {Papadopoulos, Christos C. and Simitsis, Alkis and Pedersen, Torben Bach},
  date = {2025-05},
  pages = {2394--2407},
  issn = {2375-026X},
  doi = {10.1109/ICDE65448.2025.00181},
  url = {https://ieeexplore.ieee.org/document/11113106/},
  urldate = {2025-09-11},
  abstract = {Modern analytics rely on insights derived from the execution of inference queries over vast amounts of unstructured data such as text, images, and video. Oftentimes, these queries evaluate predicates based on an expensive “oracle“ model in the likes of a deep neural network or human input that dominates the total query cost. Prior work has focused on training computationally cheap proxy models at query time that produce an approximate result. Alternatively, index-based methods apply the original oracle over a representative set of data points and generate the approximate result through an inference propagation process. Current state-of-the-art (SOTA) index-based methods require a memory -expensive index construction process which offsets their oracle cost-effectiveness and can make their usage prohibitive. In this work, we present HAIDES, an index-based, domain-agnostic framework for approximating inference on unstructured data. HAIDES consists of two main components: a coarse-to-fine framework that can be efficiently constructed using minimal memory, and a novel index adaptation component that makes use of oracle invocations during query execution in order to adaptively produce representative sets that yield high-quality approximate results. Our experimental results across three challenging domains-video, images, text-show that HAIDES (a) constructs indexes that produce performant representative sets with up to 2 orders of magnitude less memory than the SOTA baseline, while (b) requires up to 2x less oracle calls to produce the same result quality, and (c) achieves up to 10 percentage points better result quality when using the same oracle calls.},
  eventtitle = {2025 {{IEEE}} 41st {{International Conference}} on {{Data Engineering}} ({{ICDE}})},
  keywords = {Artificial neural networks,Computational modeling,Costs,Data engineering,index-based inference,Indexes,inference queries,Memory management,Training,un-structured data queries,Videos},
  file = {/Users/DAADAMS/Zotero/storage/NUWSPIUM/Papadopoulos et al. - 2025 - HAIDES Adaptive Approximation of Inference Queries over Unstructured Data.pdf}
}

@incollection{parhamExplainingBehaviorReinforcement2023,
  title = {Explaining the {{Behavior}} of {{Reinforcement Learning Agents Using Association Rules}}},
  booktitle = {Learning and {{Intelligent Optimization}}},
  author = {Parham, Zahra and De Lille, Vi Tching and Cappart, Quentin},
  editor = {Sellmann, Meinolf and Tierney, Kevin},
  date = {2023},
  volume = {14286},
  pages = {107--120},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-031-44505-7_8},
  url = {https://link.springer.com/10.1007/978-3-031-44505-7_8},
  urldate = {2025-01-09},
  isbn = {978-3-031-44504-0 978-3-031-44505-7},
  langid = {english},
  annotation = {Read\_Status: Read\\
Read\_Status\_Date: 2025-01-09T01:13:57.350Z},
  file = {/Users/DAADAMS/Zotero/storage/W6W7BUQN/Parham et al. - 2023 - Explaining the Behavior of Reinforcement Learning Agents Using Association Rules.pdf}
}

@article{parker-holderEffectiveDiversityPopulation2020,
  title = {Effective Diversity in Population Based Reinforcement Learning},
  author = {Parker-Holder, Jack and Pacchiano, Aldo and Choromanski, Krzysztof M. and Roberts, Stephen J.},
  date = {2020},
  journaltitle = {Advances in Neural Information Processing Systems},
  volume = {33},
  pages = {18050--18062},
  url = {https://proceedings.neurips.cc/paper/2020/hash/d1dc3a8270a6f9394f88847d7f0050cf-Abstract.html},
  urldate = {2024-09-11},
  file = {/Users/DAADAMS/Zotero/storage/R2S3XF5D/Parker-Holder et al. - 2020 - Effective diversity in population based reinforcement learning.pdf}
}

@incollection{patraToleranceRoughSet2011,
  title = {Tolerance {{Rough Set Theory Based Data Summarization}} for {{Clustering Large Datasets}}},
  booktitle = {Transactions on {{Rough Sets XIV}}},
  author = {Patra, Bidyut Kr. and Nandi, Sukumar},
  editor = {Peters, James F. and Skowron, Andrzej and Sakai, Hiroshi and Chakraborty, Mihir Kumar and Slezak, Dominik and Hassanien, Aboul Ella and Zhu, William},
  date = {2011},
  volume = {6600},
  pages = {139--158},
  publisher = {Springer Berlin Heidelberg},
  location = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-21563-6_8},
  url = {http://link.springer.com/10.1007/978-3-642-21563-6_8},
  urldate = {2025-02-16},
  isbn = {978-3-642-21562-9 978-3-642-21563-6}
}

@software{patrickmarcelPatrickmarcelSqlEDAqueryGenerator2025,
  title = {Patrickmarcel/{{sqlEDAqueryGenerator}}},
  author = {{patrickmarcel}},
  date = {2025-01-16T12:06:22Z},
  origdate = {2021-01-11T09:13:41Z},
  url = {https://github.com/patrickmarcel/sqlEDAqueryGenerator},
  urldate = {2025-09-10}
}

@inproceedings{PDFExtractingTopK,
  title = {({{PDF}}) {{Extracting Top-K Insights}} from {{Multi-dimensional Data}}},
  booktitle = {{{ResearchGate}}},
  doi = {10.1145/3035918.3035922},
  url = {https://www.researchgate.net/publication/316849173_Extracting_Top-K_Insights_from_Multi-dimensional_Data},
  urldate = {2025-09-11},
  abstract = {PDF | OLAP tools have been extensively used by enterprises to make better and faster decisions. Nevertheless, they require users to specify group-by... | Find, read and cite all the research you need on ResearchGate},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/WKUPJG8E/316849173_Extracting_Top-K_Insights_from_Multi-dimensional_Data.html}
}

@online{pearceImitatingHumanBehaviour2023,
  title = {Imitating {{Human Behaviour}} with {{Diffusion Models}}},
  author = {Pearce, Tim and Rashid, Tabish and Kanervisto, Anssi and Bignell, Dave and Sun, Mingfei and Georgescu, Raluca and Macua, Sergio Valcarcel and Tan, Shan Zheng and Momennejad, Ida and Hofmann, Katja and Devlin, Sam},
  date = {2023-03-03},
  eprint = {2301.10677},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  doi = {10.48550/arXiv.2301.10677},
  url = {http://arxiv.org/abs/2301.10677},
  urldate = {2024-09-23},
  abstract = {Diffusion models have emerged as powerful generative models in the text-to-image domain. This paper studies their application as observation-to-action models for imitating human behaviour in sequential environments. Human behaviour is stochastic and multimodal, with structured correlations between action dimensions. Meanwhile, standard modelling choices in behaviour cloning are limited in their expressiveness and may introduce bias into the cloned policy. We begin by pointing out the limitations of these choices. We then propose that diffusion models are an excellent fit for imitating human behaviour, since they learn an expressive distribution over the joint action space. We introduce several innovations to make diffusion models suitable for sequential environments; designing suitable architectures, investigating the role of guidance, and developing reliable sampling strategies. Experimentally, diffusion models closely match human demonstrations in a simulated robotic control task and a modern 3D gaming environment.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  annotation = {Read\_Status: To Read\\
Read\_Status\_Date: 2024-12-09T00:54:35.247Z},
  file = {/Users/DAADAMS/Zotero/storage/ENJZLY3H/Pearce et al. - 2023 - Imitating Human Behaviour with Diffusion Models.pdf;/Users/DAADAMS/Zotero/storage/CACS6UCU/2301.html}
}

@article{pereiraTemporallyExtendedGoal2024,
  title = {Temporally Extended Goal Recognition in Fully Observable Non-Deterministic Domain Models},
  author = {Pereira, Ramon Fraga and Fuggitti, Francesco and Meneguzzi, Felipe and De Giacomo, Giuseppe},
  date = {2024-01-01},
  journaltitle = {Applied Intelligence},
  shortjournal = {Appl Intell},
  volume = {54},
  number = {1},
  pages = {470--489},
  issn = {1573-7497},
  doi = {10.1007/s10489-023-05087-1},
  url = {https://doi.org/10.1007/s10489-023-05087-1},
  urldate = {2024-05-07},
  abstract = {Goal Recognition is the task of discerning the intended goal that an agent aims to achieve, given a set of goal hypotheses, a domain model, and a sequence of observations (i.e., a sample of the plan executed in the environment). Existing approaches assume that goal hypotheses comprise a single conjunctive formula over a single final state and that the environment dynamics are deterministic, preventing the recognition of temporally extended goals in more complex settings. In this paper, we expand goal recognition to temporally extended goals in Fully Observable Non-Deterministic (fond) planning domain models, focusing on goals on finite traces expressed in Linear Temporal Logic (ltl\$\$\_f\$\$) and Pure-Past Linear Temporal Logic (ppltl). We develop the first approach capable of recognizing goals in such settings and evaluate it using different ltl\$\$\_f\$\$and ppltl goals over six fond planning domain models. Empirical results show that our approach is accurate in recognizing temporally extended goals in different recognition settings.},
  langid = {english},
  keywords = {Automated planning,Goal recognition,Linear temporal logic.,Non-deterministic planning},
  file = {/Users/DAADAMS/Zotero/storage/6Z94SKEP/Pereira et al. - 2024 - Temporally extended goal recognition in fully obse.pdf;/Users/DAADAMS/Zotero/storage/KYR67DAR/s10489-023-05087-1.html}
}

@article{pereraHMABSelfdrivingHierarchy2022,
  title = {{{HMAB}}: Self-Driving Hierarchy of Bandits for Integrated Physical Database Design Tuning},
  shorttitle = {{{HMAB}}},
  author = {Perera, R. Malinga and Oetomo, Bastian and Rubinstein, Benjamin I. P. and Borovica-Gajic, Renata},
  date = {2022-10},
  journaltitle = {Proceedings of the VLDB Endowment},
  shortjournal = {Proc. VLDB Endow.},
  volume = {16},
  number = {2},
  pages = {216--229},
  issn = {2150-8097},
  doi = {10.14778/3565816.3565824},
  url = {https://dl.acm.org/doi/10.14778/3565816.3565824},
  urldate = {2024-03-15},
  abstract = {Effective physical database design tuning requires selection of several physical design structures (PDS), such as indices and materialised views, whose combination influences overall system performance in a non-linear manner. While the simplicity of combining the results of iterative searches for individual PDSs may be appealing, such a greedy approach may yield vastly suboptimal results compared to an integrated search. We propose a new self-driving approach (HMAB) based on hierarchical multi-armed bandit learners, which can work in an integrated space of multiple PDS while avoiding the full cost of combinatorial search. HMAB eschews the optimiser cost misestimates by direct performance observations through a strategic exploration, while carefully leveraging its knowledge to prune the less useful exploration paths. As an added advantage, HMAB comes with a provable guarantee on its expected performance. To the best of our knowledge, this is the first learned system to tune both indices and materialised views in an integrated manner. We find that our solution enjoys superior empirical performance relative to state-of-the-art commercial physical database design tools that search over the integrated space of materialised views and indices. Specifically, HMAB achieves up to 96\% performance gain over a state-of-the-art commercial physical database design tool when running industrial benchmarks.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/SDVFDAFJ/Perera et al. - 2022 - HMAB self-driving hierarchy of bandits for integr.pdf}
}

@article{pereraNoDBANo2023,
  title = {No {{DBA}}? {{No Regret}}! {{Multi-Armed Bandits}} for {{Index Tuning}} of {{Analytical}} and {{HTAP Workloads With Provable Guarantees}}},
  shorttitle = {No {{DBA}}?},
  author = {Perera, R. Malinga and Oetomo, Bastian and Rubinstein, Benjamin I. P. and Borovica-Gajic, Renata},
  date = {2023-12-01},
  journaltitle = {IEEE Transactions on Knowledge and Data Engineering},
  shortjournal = {IEEE Trans. Knowl. Data Eng.},
  volume = {35},
  number = {12},
  pages = {12855--12872},
  issn = {1041-4347, 1558-2191, 2326-3865},
  doi = {10.1109/TKDE.2023.3271664},
  url = {https://ieeexplore.ieee.org/document/10113193/},
  urldate = {2024-03-15},
  abstract = {Automating physical database design has remained a long-term interest in database research due to substantial performance gains afforded by optimised structures. Despite significant progress, a majority of today’s commercial solutions are highly manual, requiring offline invocation by database administrators (DBAs). This status quo is untenable: identifying representative static workloads is no longer realistic; and physical design tools remain susceptible to the query optimiser’s cost misestimates. Furthermore, modern application environments like hybrid transactional and analytical processing (HTAP) systems render analytical modelling next to impossible. We propose a self-driving approach to online index selection that does not depend on the DBA and query optimiser, and instead learns the benefits of viable structures through strategic exploration and direct performance observation. We view the problem as one of sequential decision making under uncertainty, specifically within the bandit learning setting. Multi-armed bandits balance exploration and exploitation to provably guarantee average performance that converges to policies that are optimal with perfect hindsight. Our comprehensive empirical evaluation against a state-of-the-art commercial tuning tool demonstrates up to 75\% speed-up in analytical processing environments and 59\% speed-up in HTAP environments. Lastly, our bandit framework outperforms a Monte Carlo tree search (MCTS)-based database optimiser, providing up to 24\% speed-up.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/ZP46SLBW/Perera et al. - 2023 - No DBA No Regret! Multi-Armed Bandits for Index T.pdf}
}

@inproceedings{perickComparisonDifferentSelection2012,
  title = {Comparison of Different Selection Strategies in {{Monte-Carlo Tree Search}} for the Game of {{Tron}}},
  booktitle = {2012 {{IEEE Conference}} on {{Computational Intelligence}} and {{Games}} ({{CIG}})},
  author = {Perick, Pierre and St-Pierre, David L. and Maes, Francis and Ernst, Damien},
  date = {2012-09},
  pages = {242--249},
  publisher = {IEEE},
  location = {Granada, Spain},
  doi = {10.1109/CIG.2012.6374162},
  url = {http://ieeexplore.ieee.org/document/6374162/},
  urldate = {2024-03-15},
  abstract = {Monte-Carlo Tree Search (MCTS) techniques are essentially known for their performance on turn-based games, such as Go, for which players have considerable time for choosing their moves. In this paper, we apply MCTS to the game of Tron, a simultaneous real-time two-player game. The fact that players have to react fast and that moves occur simultaneously creates an unusual setting for MCTS, in which classical selection policies such as UCB1 may be suboptimal. In this paper, we perform an empirical comparison of a wide range of selection policies for MCTS applied to Tron, with both deterministic policies (UCB1, UCB1-Tuned, UCB-V, UCBMinimal, OMC-Deterministic, MOSS) and stochastic policies (ǫngreedy, EXP3, Thompson Sampling, OMC-Stochastic, PBBM). From the experiments, we observe that UCB1-Tuned has the best behavior shortly followed by UCB1. Even if UCB-Minimal is ranked fourth, this is a remarkable result for this recently introduced selection policy found through automatic discovery of good policies on generic multi-armed bandit problems. We also show that deterministic policies perform better than stochastic ones for this problem.},
  eventtitle = {2012 {{IEEE Conference}} on {{Computational Intelligence}} and {{Games}} ({{CIG}})},
  isbn = {978-1-4673-1194-6 978-1-4673-1193-9 978-1-4673-1192-2},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/L5Z7RHDK/Perick et al. - 2012 - Comparison of different selection strategies in Mo.pdf}
}

@article{personnazDoraExplorerExploring2021,
  title = {Dora the Explorer: {{Exploring Very Large Data}} with {{Interactive Deep Reinforcement Learning Authors}}' {{Copy}}},
  author = {Personnaz, Aurélien and Amer-Yahia, Sihem and Berti-Equille, Laure and Fabricius, Maximilian and Subramanian, Srividya},
  date = {2021},
  abstract = {We demonstrate dora the explorer, a system that guides users in finding items of interest in a very large data set. dora the explorer provides users with the full spectrum of exploration modes and is driven by Data Familiarity or Curiosity, as well as User Interventions. dora the explorer is able to handle data and search scenario complexity, i.e., the difficulty to find scattered/clustered individual records in the data set, and user ability to express what s/he needs. dora the explorer relies on Deep Reinforcement Learning that combines intrinsic (curiosity) and extrinsic (familiarity) rewards. dora’s main goal is to support scientific discovery from data. We describe the system architecture and illustrate it with three demonstration scenarios on a 2.6 million galaxies SDSS, a large sky survey data set1. A video of dora the explorer is available at https://bit.ly/dora-demo, the code https://github.com/apersonnaz/rl-guided-galaxy-exploration, and the application at https://bit.ly/dora-application.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/G45MDSWB/Personnaz et al. - 2021 - Dora the explorer Exploring Very Large Data with Interactive Deep Reinforcement Learning Authors' C.pdf}
}

@inproceedings{phamTimeSequenceSummarization2009,
  title = {Time Sequence Summarization to Scale up Chronology-Dependent Applications},
  booktitle = {Proceedings of the 18th {{ACM}} Conference on {{Information}} and Knowledge Management},
  author = {Pham, Quang-Khai and Raschia, Guillaume and Mouaddib, Noureddine and Saint-Paul, Regis and Benatallah, Boualem},
  date = {2009-11-02},
  pages = {1137--1146},
  publisher = {ACM},
  location = {Hong Kong China},
  doi = {10.1145/1645953.1646098},
  url = {https://dl.acm.org/doi/10.1145/1645953.1646098},
  urldate = {2025-02-16},
  eventtitle = {{{CIKM}} '09: {{Conference}} on {{Information}} and {{Knowledge Management}}},
  isbn = {978-1-60558-512-3},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/7LTGJ5AQ/Pham et al. - 2009 - Time sequence summarization to scale up chronology-dependent applications.pdf}
}

@thesis{phamTimeSequenceSummarization2010,
  type = {phdthesis},
  title = {Time Sequence Summarization: Theory and Applications},
  shorttitle = {Time Sequence Summarization},
  author = {Pham, Quang-Khai},
  date = {2010},
  institution = {Université de Nantes},
  url = {https://theses.hal.science/tel-00538512/},
  urldate = {2025-02-16},
  file = {/Users/DAADAMS/Zotero/storage/FQSLQ9F2/Pham - 2010 - Time sequence summarization theory and applications.pdf}
}

@article{piatetsky-shapiroDiscoveryAnalysisPresentation1991,
  title = {Discovery, {{Analysis}}, and {{Presentation}} of {{Strong Rules}}},
  author = {Piatetsky-Shapiro, G.},
  date = {1991},
  journaltitle = {Knowledge Discovery in Data-bases},
  pages = {229--248},
  publisher = {AAAI Press},
  url = {https://cir.nii.ac.jp/crid/1570009749294099584},
  urldate = {2024-08-07},
  file = {/Users/DAADAMS/Zotero/storage/7QPT8ZX9/1570009749294099584.html}
}

@article{pimentelReviewNoveltyDetection2014,
  title = {A Review of Novelty Detection},
  author = {Pimentel, Marco A.F. and Clifton, David A. and Clifton, Lei and Tarassenko, Lionel},
  date = {2014-06},
  journaltitle = {Signal Processing},
  shortjournal = {Signal Processing},
  volume = {99},
  pages = {215--249},
  issn = {01651684},
  doi = {10.1016/j.sigpro.2013.12.026},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S016516841300515X},
  urldate = {2024-05-07},
  abstract = {Novelty detection is the task of classifying test data that differ in some respect from the data that are available during training. This may be seen as “one-class classification”, in which a model is constructed to describe “normal” training data. The novelty detection approach is typically used when the quantity of available “abnormal” data is insufficient to construct explicit models for non-normal classes. Application includes inference in datasets from critical systems, where the quantity of available normal data is very large, such that “normality” may be accurately modelled. In this review we aim to provide an updated and structured investigation of novelty detection research papers that have appeared in the machine learning literature during the last decade.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/RJJQTWTN/Pimentel et al. - 2014 - A review of novelty detection.pdf}
}

@article{pocoReverseEngineeringVisualizationsRecovering2017,
  title = {Reverse‐{{Engineering Visualizations}}: {{Recovering Visual Encodings}} from {{Chart Images}}},
  shorttitle = {Reverse‐{{Engineering Visualizations}}},
  author = {Poco, Jorge and Heer, Jeffrey},
  date = {2017-06},
  journaltitle = {Computer Graphics Forum},
  shortjournal = {Computer Graphics Forum},
  volume = {36},
  number = {3},
  pages = {353--363},
  issn = {0167-7055, 1467-8659},
  doi = {10.1111/cgf.13193},
  url = {https://onlinelibrary.wiley.com/doi/10.1111/cgf.13193},
  urldate = {2025-02-16},
  abstract = {Abstract             We investigate how to automatically recover visual encodings from a chart image, primarily using inferred text elements. We contribute an end‐to‐end pipeline which takes a bitmap image as input and returns a visual encoding specification as output. We present a text analysis pipeline which detects text elements in a chart, classifies their role (e.g., chart title, x‐axis label, y‐axis title, etc.), and recovers the text content using optical character recognition. We also train a Convolutional Neural Network for mark type classification. Using the identified text elements and graphical mark type, we can then infer the encoding specification of an input chart image. We evaluate our techniques on three chart corpora: a set of automatically labeled charts generated using Vega, charts from the Quartz news website, and charts extracted from academic papers. We demonstrate accurate automatic inference of text elements, mark types, and chart specifications across a variety of input chart types.},
  langid = {english}
}

@inproceedings{ponIScoreMeasuringInterestingness2007,
  title = {{{iScore}}: {{Measuring}} the {{Interestingness}} of {{Articles}} in a {{Limited User Environment}}},
  shorttitle = {{{iScore}}},
  booktitle = {2007 {{IEEE Symposium}} on {{Computational Intelligence}} and {{Data Mining}}},
  author = {Pon, Raymond K. and Cardenas, Alfonso F. and Buttler, David J. and Critchlow, Terence J.},
  date = {2007},
  pages = {354--361},
  publisher = {IEEE},
  location = {Honolulu, HI, USA},
  doi = {10.1109/CIDM.2007.368896},
  url = {http://ieeexplore.ieee.org/document/4221320/},
  urldate = {2024-07-23},
  abstract = {Search engines, such as Google, assign scores to news articles based on their relevancy to a query. However, not all relevant articles for the query may be interesting to a user. For example, if the article is old or yields little new information, the article would be uninteresting. Relevancy scores do not take into account what makes an article interesting, which would vary from user to user. Although methods such as collaborative filtering have been shown to be effective in recommendation systems, in a limited user environment there are not enough users that would make collaborative filtering effective. We present a general framework for defining and measuring the “interestingness” of articles, incorporating user-feedback. We show 21\% improvement over traditional IR methods.},
  eventtitle = {2007 {{IEEE Symposium}} on {{Computational Intelligence}} and {{Data Mining}}},
  isbn = {978-1-4244-0705-7},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/F7IBYDQC/Pon et al. - 2007 - iScore Measuring the Interestingness of Articles .pdf}
}

@online{ponsenComputingApproximateNash2014,
  title = {Computing {{Approximate Nash Equilibria}} and {{Robust Best-Responses Using Sampling}}},
  author = {Ponsen, Marc and family=Jong, given=Steven, prefix=de, useprefix=true and Lanctot, Marc},
  date = {2014-01-18},
  eprint = {1401.4591},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.1613/jair.3402},
  url = {http://arxiv.org/abs/1401.4591},
  urldate = {2024-03-15},
  abstract = {This article discusses two contributions to decision-making in complex partially observable stochastic games. First, we apply two state-of-the-art search techniques that use Monte-Carlo sampling to the task of approximating a Nash-Equilibrium (NE) in such games, namely Monte-Carlo Tree Search (MCTS) and Monte-Carlo Counterfactual Regret Minimization (MCCFR). MCTS has been proven to approximate a NE in perfect-information games. We show that the algorithm quickly finds a reasonably strong strategy (but not a NE) in a complex imperfect information game, i.e. Poker. MCCFR on the other hand has theoretical NE convergence guarantees in such a game. We apply MCCFR for the first time in Poker. Based on our experiments, we may conclude that MCTS is a valid approach if one wants to learn reasonably strong strategies fast, whereas MCCFR is the better choice if the quality of the strategy is most important. Our second contribution relates to the observation that a NE is not a best response against players that are not playing a NE. We present Monte-Carlo Restricted Nash Response (MCRNR), a sample-based algorithm for the computation of restricted Nash strategies. These are robust best-response strategies that (1) exploit non-NE opponents more than playing a NE and (2) are not (overly) exploitable by other strategies. We combine the advantages of two state-of-the-art algorithms, i.e. MCCFR and Restricted Nash Response (RNR). MCRNR samples only relevant parts of the game tree. We show that MCRNR learns quicker than standard RNR in smaller games. Also we show in Poker that MCRNR learns robust best-response strategies fast, and that these strategies exploit opponents more than playing a NE does.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Science and Game Theory},
  file = {/Users/DAADAMS/Zotero/storage/HX8Y67MM/Ponsen et al. - 2014 - Computing Approximate Nash Equilibria and Robust B.pdf;/Users/DAADAMS/Zotero/storage/PNQMC8CL/1401.html}
}

@inbook{pouzolsSummarizationAnalysisNetwork2011,
  title = {Summarization and {{Analysis}} of {{Network Traffic Flow Records}}},
  booktitle = {Mining and {{Control}} of {{Network Traffic}} by {{Computational Intelligence}}},
  author = {Pouzols, Federico Montesino and Lopez, Diego R. and Barros, Angel Barriga},
  editor = {Kacprzyk, Janusz},
  editortype = {redactor},
  date = {2011},
  volume = {342},
  pages = {147--189},
  publisher = {Springer Berlin Heidelberg},
  location = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-18084-2_4},
  url = {https://link.springer.com/10.1007/978-3-642-18084-2_4},
  urldate = {2025-02-16},
  bookauthor = {Pouzols, Federico Montesino and Lopez, Diego R. and Barros, Angel Barriga},
  isbn = {978-3-642-18083-5 978-3-642-18084-2},
  langid = {english}
}

@article{purichAdaptiveBenchmarkModeling2025,
  title = {An {{Adaptive Benchmark}} for {{Modeling User Exploration}} of {{Large Datasets}}},
  author = {Purich, Joanna and Wise, Anthony and Battle, Leilani},
  date = {2025-02-10},
  journaltitle = {Proceedings of the ACM on Management of Data},
  shortjournal = {Proc. ACM Manag. Data},
  volume = {3},
  number = {1},
  pages = {1--24},
  issn = {2836-6573},
  doi = {10.1145/3709658},
  url = {https://dl.acm.org/doi/10.1145/3709658},
  urldate = {2025-09-10},
  abstract = {In this paper, we present a new DBMS performance benchmark that can simulate user exploration with any specified dashboard design made of standard visualization and interaction components. The distinguishing feature of our SImulation-BAsed (or SIMBA) benchmark is its ability to model user analysis goals as a set of SQL queries to be generated through a valid sequence of user interactions, as well as measure the completion of analysis goals by testing for equivalence between the user’s previous queries and their goal queries. In this way, the SIMBA benchmark can simulate how an analyst opportunistically searches for interesting insights at the beginning of an exploration session and eventually hones in on specific goals towards the end. To demonstrate the versatility of the SIMBA benchmark, we use it to test the performance of four DBMSs with six different dashboard specifications and compare our results with IDEBench. Our results show how goal-driven simulation can reveal gaps in DBMS performance missed by existing benchmarking methods and across a range of data exploration scenarios. CCS Concepts: • Information systems → Database performance evaluation; • Human-centered computing → Visualization.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/CE9WKGTN/Purich et al. - 2025 - An Adaptive Benchmark for Modeling User Exploration of Large Datasets.pdf}
}

@inproceedings{qinRankingDesiredTuples2021,
  title = {Ranking {{Desired Tuples}} by {{Database Exploration}}},
  booktitle = {2021 {{IEEE}} 37th {{International Conference}} on {{Data Engineering}} ({{ICDE}})},
  author = {Qin, Xuedi and Chai, Chengliang and Luo, Yuyu and Zhao, Tianyu and Tang, Nan and Li, Guoliang and Feng, Jianhua and Yu, Xiang and Ouzzani, Mourad},
  date = {2021-04},
  pages = {1973--1978},
  publisher = {IEEE},
  location = {Chania, Greece},
  doi = {10.1109/ICDE51399.2021.00186},
  url = {https://ieeexplore.ieee.org/document/9458918/},
  urldate = {2025-02-05},
  abstract = {Database exploration – the problem of finding and ranking desired tuples – is important for data discovery and analysis. Precisely specifying SQL queries is not always feasible in practice, such as “finding and ranking off-road cars based on a combination of Price, Make, Model, Age, and Mileage.” – not only due to the query complexity (e.g., which may have many if-thenelse, and, or and not logic), but also because the user typically does not have the knowledge of all data instances.},
  eventtitle = {2021 {{IEEE}} 37th {{International Conference}} on {{Data Engineering}} ({{ICDE}})},
  isbn = {978-1-7281-9184-3},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/UUWTM4IX/Qin et al. - 2021 - Ranking Desired Tuples by Database Exploration.pdf}
}

@article{raddickTenYearsSkyserver2014,
  title = {Ten Years of Skyserver i: {{Tracking}} Web and Sql e-Science Usage},
  shorttitle = {Ten Years of Skyserver i},
  author = {Raddick, M. Jordan and Thakar, Ani R. and Szalay, Alexander S. and Santos, Rafael DC},
  date = {2014},
  journaltitle = {Computing in Science \& Engineering},
  volume = {16},
  number = {4},
  pages = {22--31},
  publisher = {IEEE},
  url = {https://ieeexplore.ieee.org/abstract/document/6774771/},
  urldate = {2024-11-05},
  file = {/Users/DAADAMS/Zotero/storage/IKI55Y8F/Raddick et al. - 2014 - Ten years of skyserver i Tracking web and sql e-science usage.pdf}
}

@article{radevIntroductionSpecialIssue2002,
  title = {Introduction to the Special Issue on Summarization},
  author = {Radev, Dragomir and Hovy, Eduard and McKeown, Kathleen},
  date = {2002},
  journaltitle = {Computational linguistics},
  volume = {28},
  number = {4},
  pages = {399--408},
  url = {https://aclanthology.org/J02-4001.pdf},
  urldate = {2025-02-16},
  file = {/Users/DAADAMS/Zotero/storage/58ZS64B5/Radev et al. - 2002 - Introduction to the special issue on summarization.pdf}
}

@article{rokhNewEvolutionaryOptimization2024,
  title = {A New Evolutionary Optimization Based on Multi-Objective Firefly Algorithm for Mining Numerical Association Rules},
  author = {Rokh, Babak and Mirvaziri, Hamid and Olyaee, MohammadHossein},
  date = {2024-05-01},
  journaltitle = {Soft Computing},
  shortjournal = {Soft Comput},
  volume = {28},
  number = {9},
  pages = {6879--6892},
  issn = {1433-7479},
  doi = {10.1007/s00500-023-09558-y},
  url = {https://doi.org/10.1007/s00500-023-09558-y},
  urldate = {2025-01-07},
  abstract = {Association rule mining (ARM) is a widely used technique in data mining for pattern discovery. However, association rule mining in numerical data poses a considerable challenge. In recent years, researchers have turned to optimization-based approaches as a potential solution. One particular area of interest in numerical association rules mining (NARM) is controlling the length of itemset intervals. In this paper, we propose a novel evolutionary algorithm based on the multi-objective firefly algorithm for efficiently mining numerical association rules (MOFNAR). MOFNAR utilizes Balance, square of cosine (SOC) and comprehensibility as objectives of evolutionary algorithm to assess rules and achieve a rule set that is both simple and accurate. We introduce the Balance measure to effectively control the intervals of numerical itemsets and eliminate misleading rules. Furthermore, we suggest a penalty approach, and the crowding-distance method is employed to maintain high diversity. Experimental results on five well-known datasets show the effectiveness of our method in discovering a simple rule set with high confidence that covers a significant percentage of the data.},
  langid = {english},
  keywords = {Artificial Intelligence,Data mining,Firefly algorithm,Multi-objective evolutionary algorithm,Numerical association rule mining},
  file = {/Users/DAADAMS/Zotero/storage/5N39R2NP/Rokh et al. - 2024 - A new evolutionary optimization based on multi-objective firefly algorithm for mining numerical asso.pdf}
}

@incollection{sarawagiDiscoverydrivenExplorationOLAP1998,
  title = {Discovery-Driven Exploration of {{OLAP}} Data Cubes},
  booktitle = {Advances in {{Database Technology}} — {{EDBT}}'98},
  author = {Sarawagi, Sunita and Agrawal, Rakesh and Megiddo, Nimrod},
  editor = {Schek, Hans-Jörg and Alonso, Gustavo and Saltor, Felix and Ramos, Isidro},
  editora = {Goos, Gerhard and Hartmanis, Juris and Van Leeuwen, Jan},
  editoratype = {redactor},
  date = {1998},
  volume = {1377},
  pages = {168--182},
  publisher = {Springer Berlin Heidelberg},
  location = {Berlin, Heidelberg},
  doi = {10.1007/BFb0100984},
  url = {http://link.springer.com/10.1007/BFb0100984},
  urldate = {2025-02-13},
  isbn = {978-3-540-64264-0 978-3-540-69709-1},
  file = {/Users/DAADAMS/Zotero/storage/IH2CA9SA/Sarawagi et al. - 1998 - Discovery-driven exploration of OLAP data cubes.pdf}
}

@incollection{sarawagiDiscoverydrivenExplorationOLAP1998a,
  title = {Discovery-Driven Exploration of {{OLAP}} Data Cubes},
  booktitle = {Advances in {{Database Technology}} — {{EDBT}}'98},
  author = {Sarawagi, Sunita and Agrawal, Rakesh and Megiddo, Nimrod},
  editor = {Schek, Hans-Jörg and Alonso, Gustavo and Saltor, Felix and Ramos, Isidro},
  editora = {Goos, Gerhard and Hartmanis, Juris and Van Leeuwen, Jan},
  editoratype = {redactor},
  date = {1998},
  volume = {1377},
  pages = {168--182},
  publisher = {Springer Berlin Heidelberg},
  location = {Berlin, Heidelberg},
  doi = {10.1007/BFb0100984},
  url = {http://link.springer.com/10.1007/BFb0100984},
  urldate = {2025-02-16},
  isbn = {978-3-540-64264-0 978-3-540-69709-1},
  file = {/Users/DAADAMS/Zotero/storage/CX8W4LT8/Sarawagi et al. - 1998 - Discovery-driven exploration of OLAP data cubes.pdf}
}

@inproceedings{sarawagiUseradaptiveExplorationMultidimensional2000,
  title = {User-Adaptive Exploration of Multidimensional Data},
  booktitle = {{{VLDB}}},
  author = {Sarawagi, Sunita},
  date = {2000},
  pages = {307--316},
  publisher = {ResearchGate GmbH},
  url = {http://repository.ias.ac.in/128428/},
  urldate = {2025-02-13},
  file = {/Users/DAADAMS/Zotero/storage/WL3QY2AT/Sarawagi - 2000 - User-adaptive exploration of multidimensional data.pdf}
}

@inproceedings{satheIntelligentRollupsMultidimensional2001,
  title = {Intelligent Rollups in Multidimensional {{OLAP}} Data},
  booktitle = {{{VLDB}}},
  author = {Sathe, Gayatri and Sarawagi, Sunita},
  date = {2001},
  pages = {307--316},
  publisher = {ResearchGate GmbH},
  url = {http://repository.ias.ac.in/128421/},
  urldate = {2025-02-13},
  file = {/Users/DAADAMS/Zotero/storage/TVPGGRWR/Sathe and Sarawagi - 2001 - Intelligent rollups in multidimensional OLAP data.pdf}
}

@article{satyanarayanVegaliteGrammarInteractive2016,
  title = {Vega-Lite: {{A}} Grammar of Interactive Graphics},
  shorttitle = {Vega-Lite},
  author = {Satyanarayan, Arvind and Moritz, Dominik and Wongsuphasawat, Kanit and Heer, Jeffrey},
  date = {2016},
  journaltitle = {IEEE transactions on visualization and computer graphics},
  volume = {23},
  number = {1},
  pages = {341--350},
  publisher = {IEEE},
  url = {https://ieeexplore.ieee.org/abstract/document/7539624/},
  urldate = {2025-02-16},
  file = {/Users/DAADAMS/Zotero/storage/FJQUCJWQ/Satyanarayan et al. - 2016 - Vega-lite A grammar of interactive graphics.pdf}
}

@article{satyanarayanVegaliteGrammarInteractive2016a,
  title = {Vega-Lite: {{A}} Grammar of Interactive Graphics},
  shorttitle = {Vega-Lite},
  author = {Satyanarayan, Arvind and Moritz, Dominik and Wongsuphasawat, Kanit and Heer, Jeffrey},
  date = {2016},
  journaltitle = {IEEE transactions on visualization and computer graphics},
  volume = {23},
  number = {1},
  pages = {341--350},
  publisher = {IEEE},
  url = {https://ieeexplore.ieee.org/abstract/document/7539624/},
  urldate = {2025-02-16},
  file = {/Users/DAADAMS/Zotero/storage/HRSKSQ2A/Satyanarayan et al. - 2016 - Vega-lite A grammar of interactive graphics.pdf}
}

@incollection{scalaIntervalbasedRelaxationGeneral2016,
  title = {Interval-Based Relaxation for General Numeric Planning},
  booktitle = {{{ECAI}} 2016},
  author = {Scala, Enrico and Haslum, Patrik and Thiébaux, Sylvie and Ramirez, Miquel},
  date = {2016},
  pages = {655--663},
  publisher = {IOS Press},
  url = {https://ebooks.iospress.nl/doi/10.3233/978-1-61499-672-9-655},
  urldate = {2025-01-09},
  annotation = {Read\_Status: In Progress\\
Read\_Status\_Date: 2025-01-09T01:54:12.003Z},
  file = {/Users/DAADAMS/Zotero/storage/GD9BZWDD/Scala et al. - 2016 - Interval-based relaxation for general numeric planning.pdf}
}

@article{seleznovaGuidedExplorationUser2020,
  title = {Guided Exploration of User Groups},
  author = {Seleznova, Mariia and Omidvar-Tehrani, Behrooz and Amer-Yahia, Sihem and Simon, Eric},
  date = {2020-05},
  journaltitle = {Proceedings of the VLDB Endowment},
  shortjournal = {Proc. VLDB Endow.},
  volume = {13},
  number = {9},
  pages = {1469--1482},
  issn = {2150-8097},
  doi = {10.14778/3397230.3397242},
  url = {https://dl.acm.org/doi/10.14778/3397230.3397242},
  urldate = {2024-12-08},
  abstract = {Finding a set of users of interest serves several applications in behavioral analytics. Often times, identifying users requires to explore the data and gradually choose potential targets. This is a special case of Exploratory Data Analysis (EDA), an iterative and tedious process. In this paper, we formalize and solve the problem of guided exploration of user groups whose purpose is to find target users. We model exploration as an iterative decision-making process, where an agent is shown a set of groups, chooses users from those groups, and selects the best action to move to the next step. To solve our problem, we apply reinforcement learning to discover an efficient exploration strategy from a simulated agent experience, and propose to use the learned strategy to recommend an exploration policy that can be applied to the same task for any dataset. Our framework accepts a wide class of exploration actions and does not need to gather exploration logs. Our experiments show that the agent naturally captures manual exploration by human analysts, and succeeds to learn an interpretable and transferable exploration policy.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/JAFZE724/Seleznova et al. - 2020 - Guided exploration of user groups.pdf}
}

@article{shawkatOptimizedFPgrowthAlgorithm2022,
  title = {An Optimized {{FP-growth}} Algorithm for Discovery of Association Rules},
  author = {Shawkat, Mai and Badawi, Mahmoud and El-ghamrawy, Sally and Arnous, Reham and El-desoky, Ali},
  date = {2022-03-01},
  journaltitle = {The Journal of Supercomputing},
  shortjournal = {J Supercomput},
  volume = {78},
  number = {4},
  pages = {5479--5506},
  issn = {1573-0484},
  doi = {10.1007/s11227-021-04066-y},
  url = {https://doi.org/10.1007/s11227-021-04066-y},
  urldate = {2025-01-07},
  abstract = {Association rule mining (ARM) is a data mining technique to discover interesting associations between datasets. The frequent pattern-growth (FP-growth) is an effective ARM algorithm for compressing information in the tree structure. However, it tends to suffer from the performance gap when processing large databases because of its mining procedure. This study presents a modified FP-growth (MFP-growth) algorithm to enhance the efficiency of the FP-growth by obviating the need for recurrent creation of conditional subtrees. The proposed algorithm uses a header table configuration to reduce the complexity of the whole frequent pattern tree. Four experimental series are conducted using different benchmark datasets to analyze the operating efficiency of the proposed MFP-growth algorithm compared with state-of-the-art machine learning algorithms in terms of runtime, memory consumption, and the effectiveness of generated rules. The experimental results confirm the superiority of the MFP-growth algorithm, which focuses on its potential implementations in various contexts.},
  langid = {english},
  keywords = {Association rule mining,FP-tree. FP-growth,Frequent itemset mining,Particle swarm optimization},
  file = {/Users/DAADAMS/Zotero/storage/QAQBC7WL/Shawkat et al. - 2022 - An optimized FP-growth algorithm for discovery of association rules.pdf}
}

@dataset{singhDBExplorerExploratorySearch2016,
  title = {{{DBExplorer}}: {{Exploratory Search}} in {{Databases}}},
  shorttitle = {{{DBExplorer}}},
  author = {Singh, Manish and Cafarella, Michael and Jagadish, Hosagrahar Visvesvar},
  date = {2016},
  publisher = {OpenProceedings.org},
  doi = {10.5441/002/EDBT.2016.11},
  url = {https://openproceedings.org/2016/conf/edbt/paper-204.pdf},
  urldate = {2025-02-05},
  abstract = {A traditional relational database can evaluate complex queries but requires users to precisely express their information need. But users often do not know what information is available in a database, and hence cannot correctly express their information need. Traditional databases do not provide convenient means for users to gain familiarity with the data.},
  langid = {english},
  keywords = {Database Technology},
  file = {/Users/DAADAMS/Zotero/storage/X3BZQHEH/Singh et al. - 2016 - DBExplorer Exploratory Search in Databases.pdf}
}

@inproceedings{singhDBExplorerExploratorySearch2016a,
  title = {{{DBExplorer}}: {{Exploratory Search}} in {{Databases}}.},
  shorttitle = {{{DBExplorer}}},
  booktitle = {{{EDBT}}},
  author = {Singh, Manish and Cafarella, Michael J. and Jagadish, H. V.},
  date = {2016},
  pages = {89--100},
  url = {https://www.academia.edu/download/85384249/edbt.2016.pdf},
  urldate = {2025-02-05},
  file = {/Users/DAADAMS/Zotero/storage/RPCQTX2Q/Singh et al. - 2016 - DBExplorer Exploratory Search in Databases..pdf}
}

@inproceedings{singhDBExplorerExploratorySearch2016b,
  title = {{{DBExplorer}}: {{Exploratory Search}} in {{Databases}}.},
  shorttitle = {{{DBExplorer}}},
  booktitle = {{{EDBT}}},
  author = {Singh, Manish and Cafarella, Michael J. and Jagadish, H. V.},
  date = {2016},
  pages = {89--100},
  url = {https://www.academia.edu/download/85384249/edbt.2016.pdf},
  urldate = {2025-02-13},
  file = {/Users/DAADAMS/Zotero/storage/FX9HZFX6/Singh et al. - 2016 - DBExplorer Exploratory Search in Databases..pdf}
}

@inproceedings{solankiSurveyAssociationRule2015,
  title = {A {{Survey}} on {{Association Rule Mining}}},
  booktitle = {2015 {{Fifth International Conference}} on {{Advanced Computing}} \& {{Communication Technologies}}},
  author = {Solanki, Surbhi K. and Patel, Jalpa T.},
  date = {2015-02},
  pages = {212--216},
  issn = {2327-0659},
  doi = {10.1109/ACCT.2015.69},
  url = {https://ieeexplore.ieee.org/document/7079081/?arnumber=7079081},
  urldate = {2024-12-23},
  abstract = {Task of extracting useful and interesting knowledge from large data is called data mining. It has many aspects like clustering, classification, association mining, outlier detection, regression etc. Among them association rule mining is one of the important aspect for data mining. Best example of association rule mining is market-basket analysis. Applications of association rule mining are stock analysis, web log mining, medical diagnosis, customer market analysis bioinformatics etc. In past, many algorithms were developed by researchers for Boolean and Fuzzy association rule mining such as Apriori, FP-tree, Fuzzy FP-tree etc. We are discussing them in detail in later section of this paper.},
  eventtitle = {2015 {{Fifth International Conference}} on {{Advanced Computing}} \& {{Communication Technologies}}},
  keywords = {Algorithm design and analysis,Apriori,Association Rule Mining,Association rules,Data Mining,FP-tree,Fuzzy FP-tree,Itemsets,Partitioning algorithms,Pragmatics},
  file = {/Users/DAADAMS/Zotero/storage/EKREMI7R/Solanki and Patel - 2015 - A Survey on Association Rule Mining.pdf;/Users/DAADAMS/Zotero/storage/XMXSQS9X/7079081.html}
}

@inproceedings{solankiSurveyAssociationRule2015a,
  title = {A {{Survey}} on {{Association Rule Mining}}},
  booktitle = {2015 {{Fifth International Conference}} on {{Advanced Computing}} \& {{Communication Technologies}}},
  author = {Solanki, Surbhi K. and Patel, Jalpa T.},
  date = {2015-02},
  pages = {212--216},
  issn = {2327-0659},
  doi = {10.1109/ACCT.2015.69},
  url = {https://ieeexplore.ieee.org/document/7079081},
  urldate = {2025-02-14},
  abstract = {Task of extracting useful and interesting knowledge from large data is called data mining. It has many aspects like clustering, classification, association mining, outlier detection, regression etc. Among them association rule mining is one of the important aspect for data mining. Best example of association rule mining is market-basket analysis. Applications of association rule mining are stock analysis, web log mining, medical diagnosis, customer market analysis bioinformatics etc. In past, many algorithms were developed by researchers for Boolean and Fuzzy association rule mining such as Apriori, FP-tree, Fuzzy FP-tree etc. We are discussing them in detail in later section of this paper.},
  eventtitle = {2015 {{Fifth International Conference}} on {{Advanced Computing}} \& {{Communication Technologies}}},
  keywords = {Algorithm design and analysis,Apriori,Association Rule Mining,Association rules,Data Mining,FP-tree,Fuzzy FP-tree,Itemsets,Partitioning algorithms,Pragmatics},
  file = {/Users/DAADAMS/Zotero/storage/6955GTP6/Solanki and Patel - 2015 - A Survey on Association Rule Mining.pdf}
}

@dataset{somechPredictingWhatInteresting2019,
  title = {Predicting "{{What}} Is {{Interesting}}" by {{Mining Interactive-Data-Analysis Session Logs}}},
  author = {Somech, Amit and Milo, Tova and Ozeri, Chai},
  date = {2019},
  publisher = {OpenProceedings.org},
  doi = {10.5441/002/EDBT.2019.42},
  url = {https://openproceedings.org/2019/conf/edbt/EDBT19_paper_272.pdf},
  urldate = {2024-12-02},
  abstract = {Assessing the interestingness of data analysis actions has been the subject of extensive previous work, and a multitude of interestingness measures have been devised, each capturing a different facet of the broad concept. While such measures are a core component in many analysis platforms (e.g., for ranking association rules, recommending visualizations, and query formulation), choosing the most adequate measure for a specific analysis task or an application domain is known to be a difficult task.},
  langid = {english},
  version = {1},
  keywords = {Database Technology},
  file = {/Users/DAADAMS/Zotero/storage/44A2R567/Somech et al. - 2019 - Predicting What is Interesting by Mining Interactive-Data-Analysis Session Logs.pdf}
}

@inproceedings{songDiversitydrivenExtensibleHierarchical2019,
  title = {Diversity-Driven Extensible Hierarchical Reinforcement Learning},
  booktitle = {Proceedings of the {{AAAI}} Conference on Artificial Intelligence},
  author = {Song, Yuhang and Wang, Jianyi and Lukasiewicz, Thomas and Xu, Zhenghua and Xu, Mai},
  date = {2019},
  volume = {33},
  number = {01},
  pages = {4992--4999},
  url = {https://aaai.org/ojs/index.php/AAAI/article/view/4430},
  urldate = {2024-09-03},
  file = {/Users/DAADAMS/Zotero/storage/8WQI2KNR/Song et al. - 2019 - Diversity-driven extensible hierarchical reinforcement learning.pdf}
}

@inproceedings{srikantMiningQuantitativeAssociation1996,
  title = {Mining Quantitative Association Rules in Large Relational Tables},
  booktitle = {Proceedings of the 1996 {{ACM SIGMOD}} International Conference on {{Management}} of Data  - {{SIGMOD}} '96},
  author = {Srikant, Ramakrishnan and Agrawal, Rakesh},
  date = {1996},
  pages = {1--12},
  publisher = {ACM Press},
  location = {Montreal, Quebec, Canada},
  doi = {10.1145/233269.233311},
  url = {http://portal.acm.org/citation.cfm?doid=233269.233311},
  urldate = {2025-02-16},
  eventtitle = {The 1996 {{ACM SIGMOD}} International Conference},
  isbn = {978-0-89791-794-0},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/QPSFJZDY/Srikant and Agrawal - 1996 - Mining quantitative association rules in large relational tables.pdf}
}

@inproceedings{svoreEnhancingSingledocumentSummarization2007,
  title = {Enhancing Single-Document Summarization by Combining {{RankNet}} and Third-Party Sources},
  booktitle = {Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning ({{EMNLP-CoNLL}})},
  author = {Svore, Krysta and Vanderwende, Lucy and Burges, Christopher},
  date = {2007},
  pages = {448--457},
  url = {https://aclanthology.org/D07-1047.pdf},
  urldate = {2025-02-16},
  file = {/Users/DAADAMS/Zotero/storage/AA7P7KV2/Svore et al. - 2007 - Enhancing single-document summarization by combining RankNet and third-party sources.pdf}
}

@article{takenouchiPATSQLEfficientSynthesis2021,
  title = {{{PATSQL}}: {{Efficient Synthesis}} of {{SQL Queries}} from {{Example Tables}} with {{Quick Inference}} of {{Projected Columns}}},
  shorttitle = {{{PATSQL}}},
  author = {Takenouchi, Keita and Ishio, Takashi and Okada, Joji and Sakata, Yuji},
  date = {2021-07},
  journaltitle = {Proceedings of the VLDB Endowment},
  shortjournal = {Proc. VLDB Endow.},
  volume = {14},
  number = {11},
  eprint = {2010.05807},
  eprinttype = {arXiv},
  eprintclass = {cs},
  pages = {1937--1949},
  issn = {2150-8097},
  doi = {10.14778/3476249.3476253},
  url = {http://arxiv.org/abs/2010.05807},
  urldate = {2025-08-28},
  abstract = {SQL is one of the most popular tools for data analysis, and it is now used by an increasing number of users without having expertise in databases. Several studies have proposed programming-by-example approaches to help such non-experts to write correct SQL queries. While existing methods support a variety of SQL features such as aggregation and nested query, they suffer a significant increase in computational cost as the scale of example tables increases. In this paper, we propose an efficient algorithm utilizing properties known in relational algebra to synthesize SQL queries from input and output tables. Our key insight is that a projection operator in a program sketch can be lifted above other operators by applying transformation rules in relational algebra, while preserving the semantics of the program. This enables a quick inference of appropriate columns in the projection operator, which is an essential component in synthesis but causes combinatorial explosions in prior work. We also introduce a novel form of constraints and its top-down propagation mechanism for efficient sketch completion. We implemented this algorithm in our tool PATSQL and evaluated it on 226 queries from prior benchmarks and Kaggle’s tutorials. As a result, PATSQL solved 68\% of the benchmarks and found 89\% of the solutions within a second. Our tool is available at https://naist-se.github.io/patsql/.},
  langid = {english},
  keywords = {Computer Science - Databases,Computer Science - Programming Languages,Computer Science - Software Engineering},
  file = {/Users/DAADAMS/Zotero/storage/DCG8VFHA/Takenouchi et al. - 2021 - PATSQL Efficient Synthesis of SQL Queries from Example Tables with Quick Inference of Projected Col.pdf}
}

@inproceedings{takMonteCarloTree2014,
  title = {Monte {{Carlo Tree Search}} Variants for Simultaneous Move Games},
  booktitle = {2014 {{IEEE Conference}} on {{Computational Intelligence}} and {{Games}}},
  author = {Tak, Mandy J. W. and Lanctot, Marc and Winands, Mark H. M.},
  date = {2014-08},
  pages = {1--8},
  publisher = {IEEE},
  location = {Dortmund, Germany},
  doi = {10.1109/CIG.2014.6932889},
  url = {http://ieeexplore.ieee.org/document/6932889/},
  urldate = {2024-03-15},
  abstract = {Monte Carlo Tree Search (MCTS) is a widely-used technique for game-tree search in sequential turn-based games. The extension to simultaneous move games, where all players choose moves simultaneously each turn, is non-trivial due to the complexity of this class of games. In this paper, we describe simultaneous move MCTS and analyze its application in a set of nine disparate simultaneous move games. We use several possible variants, Decoupled UCT, Sequential UCT, Exp3, and Regret Matching. These variants include both deterministic and stochastic selection strategies and we characterize the game-play performance of each one. The results indicate that the relative performance of each variant depends strongly on the game and the opponent, and that parameter tuning can also not be as straightforward as the purely sequential case. Overall, Decoupled UCT performs best despite its theoretical shortcomings.},
  eventtitle = {2014 {{IEEE Conference}} on {{Computational Intelligence}} and {{Games}} ({{CIG}})},
  isbn = {978-1-4799-3547-5},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/G7QZR7PW/Tak et al. - 2014 - Monte Carlo Tree Search variants for simultaneous .pdf}
}

@article{tanReverseEngineeringAggregation2017,
  title = {Reverse Engineering Aggregation Queries},
  author = {Tan, Wei Chit and Zhang, Meihui and Elmeleegy, Hazem and Srivastava, Divesh},
  date = {2017-08},
  journaltitle = {Proceedings of the VLDB Endowment},
  shortjournal = {Proc. VLDB Endow.},
  volume = {10},
  number = {11},
  pages = {1394--1405},
  issn = {2150-8097},
  doi = {10.14778/3137628.3137648},
  url = {https://dl.acm.org/doi/10.14778/3137628.3137648},
  urldate = {2025-08-28},
  abstract = {Query reverse engineering seeks to re-generate the SQL query that produced a given query output table from a given database. In this paper, we solve this problem for OLAP queries with group-by and aggregation. We develop a novel three-phase algorithm named REGAL 1 for this problem. First, based on a lattice graph structure, we identify a set of group-by candidates for the desired query. Second, we apply a set of aggregation constraints that are derived from the properties of aggregate operators at both the table-level and the group-level to discover candidate combinations of group-by columns and aggregations that are consistent with the given query output table. Finally, we find a multi-dimensional filter, i.e., a conjunction of selection predicates over the base table attributes, that is needed to generate the exact query output table. We conduct an extensive experimental study over the TPC-H dataset to demonstrate the effectiveness and efficiency of our proposal.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/G9JYP7C4/Tan et al. - 2017 - Reverse engineering aggregation queries.pdf}
}

@article{telikaniSurveyEvolutionaryComputation2020,
  title = {A Survey of Evolutionary Computation for Association Rule Mining},
  author = {Telikani, Akbar and Gandomi, Amir H. and Shahbahrami, Asadollah},
  date = {2020},
  journaltitle = {Information Sciences},
  volume = {524},
  pages = {318--352},
  publisher = {Elsevier},
  url = {https://www.sciencedirect.com/science/article/pii/S002002552030164X},
  urldate = {2024-12-23},
  file = {/Users/DAADAMS/Zotero/storage/5I4UCHHQ/Telikani et al. - 2020 - A survey of evolutionary computation for association rule mining.pdf;/Users/DAADAMS/Zotero/storage/BPCRJH6P/scholar.html}
}

@inproceedings{thilinaIntruderDetectionUsing2016,
  title = {Intruder {{Detection Using Deep Learning}} and {{Association Rule Mining}}},
  booktitle = {2016 {{IEEE International Conference}} on {{Computer}} and {{Information Technology}} ({{CIT}})},
  author = {Thilina, Asantha and Attanayake, Shakthi and Samarakoon, Sacith and Nawodya, Dahami and Rupasinghe, Lakmal and Pathirage, Nadith and Edirisinghe, Tharindu and Krishnadeva, Kesavan},
  date = {2016-12},
  pages = {615--620},
  doi = {10.1109/CIT.2016.69},
  url = {https://ieeexplore.ieee.org/document/7876395/?arnumber=7876395},
  urldate = {2024-12-23},
  abstract = {With the upsurge of internet popularity, nowadays there are millions of online transactions that are being processed per minute thus increasing the possibilities of intruder attacks over the recent times. There have been various intruder detection techniques such as using traditional machine learning based algorithms. These algorithms were widely used to identify and prevent intruder activities in the recent past. Furthermore, multilayer neural networks[5] were also used in this regard to perform the detection. Hence multi-layer neural networks inherit fundamental drawbacks due to its inability to perform training due the problems such as overfitting, etc. In contrast, deep learning algorithms were introduced to overcome these issues effectively. We propose a novel framework to perform intruder detection and analysis using deep learning nets and association rule mining. We utilize a recurrent network to predict intruder activities and FP-Growth to perform the analysis. Our results show the effectiveness of our framework in detail.},
  eventtitle = {2016 {{IEEE International Conference}} on {{Computer}} and {{Information Technology}} ({{CIT}})},
  keywords = {Algorithm design and analysis,Association rule mining,Data mining,Deeplearning,FPGrowth,Intruder detection,Machine learning,Machine learning algorithms,Pattern Recognition,Recurrent neural networks,Recurrent Neural Networks,Training},
  file = {/Users/DAADAMS/Zotero/storage/9GUUCCFE/Thilina et al. - 2016 - Intruder Detection Using Deep Learning and Association Rule Mining.pdf;/Users/DAADAMS/Zotero/storage/URYG62KH/7876395.html}
}

@article{tuUnicornUnifiedMultitasking2023,
  title = {Unicorn: {{A Unified Multi-tasking Model}} for {{Supporting Matching Tasks}} in {{Data Integration}}},
  shorttitle = {Unicorn},
  author = {Tu, Jianhong and Fan, Ju and Tang, Nan and Wang, Peng and Li, Guoliang and Du, Xiaoyong and Jia, Xiaofeng and Gao, Song},
  date = {2023-05-26},
  journaltitle = {Proceedings of the ACM on Management of Data},
  shortjournal = {Proc. ACM Manag. Data},
  volume = {1},
  number = {1},
  pages = {1--26},
  issn = {2836-6573},
  doi = {10.1145/3588938},
  url = {https://dl.acm.org/doi/10.1145/3588938},
  urldate = {2025-08-01},
  abstract = {Data matching, which decides whether two data elements (e.g., string, tuple, column, or knowledge graph entity) are the “same” (a.k.a. a match), is a key concept in data integration. The widely used practice is to build task-specific or even dataset-specific solutions, which are hard to generalize and disable the opportunities of knowledge sharing that can be learned from di↵erent datasets and multiple tasks. In this paper, we propose Unicorn, a unified model for generally supporting common data matching tasks. Building such a unified model is challenging due to heterogeneous formats of input data elements and various matching semantics of multiple tasks. To address the challenges, Unicorn employs one generic Encoder that converts any pair of data elements (a, b) into a learned representation, and uses a Matcher, which is a binary classifier, to decide whether a matches b. To align matching semantics of multiple tasks, Unicorn adopts a mixture-of-experts model that enhances the learned representation into a better representation. We conduct extensive experiments using 20 datasets on 7 well-studied data matching tasks, and find that our unified model can achieve better performance on most tasks and on average, compared with the state-of-the-art specific models trained for ad-hoc tasks and datasets separately. Moreover, Unicorn can also well serve new matching tasks with zero-shot learning.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/48VYB329/Tu et al. - 2023 - Unicorn A Unified Multi-tasking Model for Supporting Matching Tasks in Data Integration.pdf}
}

@online{urbanEfficientLearnedQuery2024,
  title = {Efficient {{Learned Query Execution}} over {{Text}} and {{Tables}} [{{Technical Report}}]},
  author = {Urban, Matthias and Binnig, Carsten},
  date = {2024-10-29},
  eprint = {2410.22522},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2410.22522},
  url = {http://arxiv.org/abs/2410.22522},
  urldate = {2025-09-08},
  abstract = {In this paper, we present ELEET, a novel execution engine that allows one to seamlessly query and process text as a first-class citizen along with tables. To enable such a seamless integration of text and tables, ELEET leverages learned multi-modal operators (MMOps) such as joins and unions that seamlessly combine structured with unstructured textual data. While large language models (LLM) such as GPT-4 are interesting candidates to enable such learned multimodal operations, we deliberately do not follow this trend to enable MMOps, since it would result in high overhead at query runtime. Instead, to enable MMOps, ELEET comes with a more efficient small language model (SLM) that is targeted to extract structured data from text. Thanks to our novel architecture and pre-training procedure, the ELEET-model enables high-accuracy extraction with low overheads. In our evaluation, we compare query execution based on ELEET to baselines leveraging LLMs such as GPT-4 and show that ELEET can speed up multi-modal queries over tables and text by up to 575× without sacrificing accuracy.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Databases},
  file = {/Users/DAADAMS/Zotero/storage/U63NAKI5/Urban and Binnig - 2024 - Efficient Learned Query Execution over Text and Tables [Technical Report].pdf}
}

@inproceedings{vartakSeedbEfficientDatadriven2015,
  title = {Seedb: {{Efficient}} Data-Driven Visualization Recommendations to Support Visual Analytics},
  shorttitle = {Seedb},
  booktitle = {Proceedings of the {{VLDB Endowment International Conference}} on {{Very Large Data Bases}}},
  author = {Vartak, Manasi and Rahman, Sajjadur and Madden, Samuel and Parameswaran, Aditya and Polyzotis, Neoklis},
  date = {2015},
  volume = {8},
  number = {13},
  pages = {2182},
  publisher = {NIH Public Access},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4714568/},
  urldate = {2025-02-13},
  file = {/Users/DAADAMS/Zotero/storage/XS7ZYQIB/PMC4714568.html}
}

@online{veredHeuristicOnlineGoal2017,
  title = {Heuristic {{Online Goal Recognition}} in {{Continuous Domains}}},
  author = {Vered, Mor and Kaminka, Gal A.},
  date = {2017-09-28},
  eprint = {1709.09839},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.1709.09839},
  url = {http://arxiv.org/abs/1709.09839},
  urldate = {2025-09-04},
  abstract = {Goal recognition is the problem of inferring the goal of an agent, based on its observed actions. An inspiring approach—plan recognition by planning (PRP)—uses off-the-shelf planners to dynamically generate plans for given goals, eliminating the need for the traditional plan library. However, existing PRP formulation is inherently inefficient in online recognition, and cannot be used with motion planners for continuous spaces. In this paper, we utilize a different PRP formulation which allows for online goal recognition, and for application in continuous spaces. We present an online recognition algorithm, where two heuristic decision points may be used to improve run-time significantly over existing work. We specify heuristics for continuous domains, prove guarantees on their use, and empirically evaluate the algorithm over n hundreds of experiments in both a 3D navigational environment and a cooperative robotic team task.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence},
  file = {/Users/DAADAMS/Zotero/storage/4UKIZCKB/Vered and Kaminka - 2017 - Heuristic Online Goal Recognition in Continuous Domains.pdf;/Users/DAADAMS/Zotero/storage/HAQGGCMP/Vered and Kaminka - 2017 - Heuristic Online Goal Recognition in Continuous Domains.pdf;/Users/DAADAMS/Zotero/storage/VKPMRZ4N/1709.html}
}

@article{vivekanandanNovelWayCompute2024,
  title = {A Novel Way to Compute Association Rules},
  author = {Vivekanandan, S. J. and Gunasekaran, G.},
  date = {2024-01-01},
  journaltitle = {International Journal of System Assurance Engineering and Management},
  shortjournal = {Int J  Syst  Assur  Eng  Manag},
  volume = {15},
  number = {1},
  pages = {98--109},
  issn = {0976-4348},
  doi = {10.1007/s13198-022-01676-4},
  url = {https://doi.org/10.1007/s13198-022-01676-4},
  urldate = {2025-01-07},
  abstract = {Association Rule mining is the prime booming field among researchers. Apriori algorithm is a prime algorithm to compute association rules. Apriori algorithm considers only frequent itemsets and it neglects the non-frequent itemsets. In real-time scenarios, Non-frequent itemsets also have the chance to give more utility. Utility mining is a newish form of data mining study topic that focuses solely on high utility itemsets computed from utility values. To overcome this problem, we proposed an approach that incorporates both frequent and utility values called the Novel Utility Frequent Apriori algorithm. This approach considered both frequent itemsets together with non-frequent itemsets. Utility computed for both frequent itemsets and rare itemsets. Finally, it categorized the itemsets based on utility value and frequent value like High-Profit High Frequency, High-Profit Rare Frequency, Low-Profit High Frequency, and Low-Profit Rare Frequency itemsets. Repeated transactions were handled efficiently by our proposed method. We experimented with different datasets by using python, The Novel Utility Frequent Apriori method surpasses the classic Apriori algorithm in terms of time i.e. average rate of time reduction was 63\% with first experiment and 82\% with second experiment. We found that our approach is effective in categories of itemsets and also this approach will be useful in E-Commerce to make more profit, Medical field to discover new diseases and Banking sector to discover fraud activities.},
  langid = {english},
  keywords = {Apriori,Frequent itemsets,High utility itemsets (HUI),Minimum support (min_sup),Minimum utility (min_util),Utility mining},
  file = {/Users/DAADAMS/Zotero/storage/QXRUW9QX/Vivekanandan and Gunasekaran - 2024 - A novel way to compute association rules.pdf}
}

@inproceedings{wangDeepGraphMutual2022,
  title = {Deep {{Graph Mutual Learning}} for~{{Cross-domain Recommendation}}},
  booktitle = {Database {{Systems}} for {{Advanced Applications}}},
  author = {Wang, Yifan and Li, Yongkang and Li, Shuai and Song, Weiping and Fan, Jiangke and Gao, Shan and Ma, Ling and Cheng, Bing and Cai, Xunliang and Wang, Sheng and Zhang, Ming},
  editor = {Bhattacharya, Arnab and Lee Mong Li, Janice and Agrawal, Divyakant and Reddy, P. Krishna and Mohania, Mukesh and Mondal, Anirban and Goyal, Vikram and Uday Kiran, Rage},
  date = {2022},
  pages = {298--305},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-031-00126-0_22},
  abstract = {Cross-domain recommender systems have been increasingly important for helping users find satisfying items from different domains. However, existing approaches mostly share/map user features among different domains to transfer the knowledge. In fact, user-item interactions can be formulated as a bipartite graph and knowledge transferring through the graph is a more explicit way. Meanwhile, these approaches mostly focus on capturing users’ common interests, overlooking domain-specific preferences. In this paper, we propose a novel Deep Graph Mutual Learning framework (DGML) for cross-domain recommendation. In particular, we first separately construct domain-shared and domain-specific interaction graphs, and develop a parallel graph neural network to extract user preference in corresponding graph. Then the mutual learning procedure uses extracted preferences to form a more comprehensive user preference. Our extensive experiments on two real-world datasets demonstrate significant improvements over state-of-the-art approaches.},
  isbn = {978-3-031-00126-0},
  langid = {english},
  keywords = {Collaborative filtering,Cross-domain recommendation,Graph neural networks,Mutual learning},
  file = {/Users/DAADAMS/Zotero/storage/KT3W97HU/Wang et al. - 2022 - Deep Graph Mutual Learning for Cross-domain Recommendation.pdf}
}

@inproceedings{wangDeepGraphMutual2022a,
  title = {Deep {{Graph Mutual Learning}} for~{{Cross-domain Recommendation}}},
  booktitle = {Database {{Systems}} for {{Advanced Applications}}},
  author = {Wang, Yifan and Li, Yongkang and Li, Shuai and Song, Weiping and Fan, Jiangke and Gao, Shan and Ma, Ling and Cheng, Bing and Cai, Xunliang and Wang, Sheng and Zhang, Ming},
  editor = {Bhattacharya, Arnab and Lee Mong Li, Janice and Agrawal, Divyakant and Reddy, P. Krishna and Mohania, Mukesh and Mondal, Anirban and Goyal, Vikram and Uday Kiran, Rage},
  date = {2022},
  pages = {298--305},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-031-00126-0_22},
  abstract = {Cross-domain recommender systems have been increasingly important for helping users find satisfying items from different domains. However, existing approaches mostly share/map user features among different domains to transfer the knowledge. In fact, user-item interactions can be formulated as a bipartite graph and knowledge transferring through the graph is a more explicit way. Meanwhile, these approaches mostly focus on capturing users’ common interests, overlooking domain-specific preferences. In this paper, we propose a novel Deep Graph Mutual Learning framework (DGML) for cross-domain recommendation. In particular, we first separately construct domain-shared and domain-specific interaction graphs, and develop a parallel graph neural network to extract user preference in corresponding graph. Then the mutual learning procedure uses extracted preferences to form a more comprehensive user preference. Our extensive experiments on two real-world datasets demonstrate significant improvements over state-of-the-art approaches.},
  isbn = {978-3-031-00126-0},
  langid = {english},
  keywords = {Collaborative filtering,Cross-domain recommendation,Graph neural networks,Mutual learning},
  file = {/Users/DAADAMS/Zotero/storage/USPIZF4W/Wang et al. - 2022 - Deep Graph Mutual Learning for Cross-domain Recommendation.pdf}
}

@article{wangLeveragingDynamicHeterogeneous2024,
  title = {Leveraging {{Dynamic}} and {{Heterogeneous Workload Knowledge}} to {{Boost}} the {{Performance}} of {{Index Advisors}}},
  author = {Wang, Zijia and Liu, Haoran and Lin, Chen and Bao, Zhifeng and Li, Guoliang and Wang, Tianqing},
  date = {2024-03},
  journaltitle = {Proceedings of the VLDB Endowment},
  shortjournal = {Proc. VLDB Endow.},
  volume = {17},
  number = {7},
  pages = {1642--1654},
  issn = {2150-8097},
  doi = {10.14778/3654621.3654631},
  url = {https://dl.acm.org/doi/10.14778/3654621.3654631},
  urldate = {2025-02-24},
  abstract = {Current index advisors often struggle to balance efficiency and effectiveness when dealing with workload shifts. This arises from ignorance of the continual similarity and distant variety in workloads. This paper proposes a novel learning-based index advisor called BALANCE, which boosts indexing performance by leveraging knowledge obtained from dynamic and heterogeneous workloads. Our approach consists of three components. First, we build separate Lightweight Index Advisors (LIAs) on sequential chunks of similar workloads, where each LIA is trained with a small batch of workloads drawn from the chunk, and it provides direct index recommendations for all workloads in the same chunk. Second, we perform a policy transfer mechanism by adapting the LIA’s index selection strategy from historical knowledge, substantially reducing the training overhead. Third, we employ a self-supervised contrastive learning method to provide an off-the-shelf workload representation, enabling the LIA to generate more accurate index recommendations. Extensive experiments across various benchmarks demonstrate that BALANCE improves the state-of-the-art learning-based index advisor, SWIRL, by 10.03\% while reducing training overhead by 35.70\% on average.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/MQAH32QJ/Wang et al. - 2024 - Leveraging Dynamic and Heterogeneous Workload Knowledge to Boost the Performance of Index Advisors.pdf}
}

@online{wangLGEQRELearningGuided2023,
  title = {{{LGEQRE}}: {{Learning Guided Enumerative Synthesis}} for {{Query Reverse Engineering}}},
  shorttitle = {{{LGEQRE}}},
  author = {Wang, Huixian and Dou, Quansheng and Tang, Huanling and Pan, Hao and Zhang, Shun},
  date = {2023-09-08},
  eprinttype = {In Review},
  doi = {10.21203/rs.3.rs-3320857/v1},
  url = {https://www.researchsquare.com/article/rs-3320857/v1},
  urldate = {2025-08-28},
  abstract = {To address the problem of users’ lack of SQL query writing skills, Query Reverse Engineering (QRE) was proposed, where the goal of QRE is to generate a SQL statement based on a given database and query output table. SQUARES is one of the state-of-the-art models in the field, which enumerates constraint-compliant programs using a solver-based enumerator, and since the Solver randomly enumerates candidate programs, SQUARES synthesis is not very efficient. In this paper, we propose LGEQRE based on SQUARES, a learning-based approach to guide the enumeration of candidate programs. LGEQRE predicts the operators be required by neural network, sorts and deletes operators based on the prediction, and uses an Optimizer-based enumerator to enumerate programs according to the predicted probability of the operators. Under the same experimental conditions, the experimental results showed that LGEQRE increased the synthesis rate from 80\% to 89.1\% and reduced the average synthesis time from 251s to 117s compared to SQUARES.},
  langid = {english},
  pubstate = {prepublished},
  file = {/Users/DAADAMS/Zotero/storage/HH4IZA8V/Wang et al. - 2023 - LGEQRE Learning Guided Enumerative Synthesis for Query Reverse Engineering.pdf}
}

@inproceedings{wangSatnetBridgingDeep2019,
  title = {Satnet: {{Bridging}} Deep Learning and Logical Reasoning Using a Differentiable Satisfiability Solver},
  shorttitle = {Satnet},
  booktitle = {International {{Conference}} on {{Machine Learning}}},
  author = {Wang, Po-Wei and Donti, Priya and Wilder, Bryan and Kolter, Zico},
  date = {2019},
  pages = {6545--6554},
  publisher = {PMLR},
  url = {http://proceedings.mlr.press/v97/wang19e.html},
  urldate = {2024-03-19},
  file = {/Users/DAADAMS/Zotero/storage/QWE3AHH4/Wang et al. - 2019 - Satnet Bridging deep learning and logical reasoni.pdf}
}

@incollection{webbGeneralityPredictivePrediction2006,
  title = {Generality {{Is Predictive}} of {{Prediction Accuracy}}},
  booktitle = {Data {{Mining}}},
  author = {Webb, Geoffrey I. and Brain, Damien},
  editor = {Williams, Graham J. and Simoff, Simeon J.},
  editora = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Dough and Vardi, Moshe Y. and Weikum, Gerhard},
  editoratype = {redactor},
  date = {2006},
  volume = {3755},
  pages = {1--13},
  publisher = {Springer Berlin Heidelberg},
  location = {Berlin, Heidelberg},
  doi = {10.1007/11677437_1},
  url = {http://link.springer.com/10.1007/11677437_1},
  urldate = {2025-02-03},
  isbn = {978-3-540-32547-5 978-3-540-32548-2}
}

@article{yagerNewApproachSummarization1982,
  title = {A New Approach to the Summarization of Data},
  author = {Yager, Ronald R.},
  date = {1982},
  journaltitle = {Information Sciences},
  volume = {28},
  number = {1},
  pages = {69--86},
  publisher = {Elsevier},
  url = {https://www.sciencedirect.com/science/article/pii/0020025582900330},
  urldate = {2025-02-16}
}

@article{yangMemoryPoolVariational2024,
  title = {A Memory Pool Variational Autoencoder Framework for Cross-Domain Recommendation},
  author = {Yang, Jie and Zhu, Jianxiang and Ding, Xiaofeng and Peng, Yaxin and Zhang, Yangchun},
  date = {2024-05-01},
  journaltitle = {Expert Systems with Applications},
  shortjournal = {Expert Systems with Applications},
  volume = {241},
  pages = {122771},
  issn = {0957-4174},
  doi = {10.1016/j.eswa.2023.122771},
  url = {https://www.sciencedirect.com/science/article/pii/S0957417423032736},
  urldate = {2025-09-08},
  abstract = {Cross-domain recommendation (CDR) leverages knowledge from the source domain to make recommendations for the cold-start users in the target domain. On account of fully utilizing information, various relationships among users and items are taken into account, i.e., the interaction relationship between users and their corresponding items; the relationship among users or items; and the indirect relationship between the user and items related to other users. In order to process these relationships, we propose a novel framework named Memory Pool Variational AutoEncoder (MPVAE). The main advantages of the MPVAE model lie in three aspects: (1) it generates the embedding representations that incorporate more information by a memory pool mechanism in the source and target domains; (2) it involves the relationship among users or items efficiently by the similarity measurement, further, the indirect relationship can be explicitly described, which makes full use of information in the source domain; and (3) it leverages the superiority of the probability model from the perspective of the VAE structure, which ensures generation and robustness. Comprehensive experiments on three real datasets show that the proposed model achieves remarkable superiority over several competitive CDR models.},
  keywords = {Attention mechanism,Cold-start,Cross-domain recommendation,Variational autoencoder},
  file = {/Users/DAADAMS/Zotero/storage/U7WFGKPM/Yang et al. - 2024 - A memory pool variational autoencoder framework for cross-domain recommendation.pdf;/Users/DAADAMS/Zotero/storage/XGLVLT6E/S0957417423032736.html}
}

@inproceedings{yangRecommendingJoinQueries2009,
  title = {Recommending Join Queries via Query Log Analysis},
  booktitle = {2009 {{IEEE}} 25th {{International Conference}} on {{Data Engineering}}},
  author = {Yang, Xiaoyan and Procopiuc, Cecilia M. and Srivastava, Divesh},
  date = {2009},
  pages = {964--975},
  publisher = {IEEE},
  url = {https://ieeexplore.ieee.org/abstract/document/4812469/},
  urldate = {2025-02-16}
}

@online{youngmannGuidedExplorationData2022,
  title = {Guided {{Exploration}} of {{Data Summaries}}},
  author = {Youngmann, Brit and Amer-Yahia, Sihem and Personnaz, Aurélien},
  date = {2022-05-27},
  eprint = {2205.13956},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2205.13956},
  url = {http://arxiv.org/abs/2205.13956},
  urldate = {2024-12-08},
  abstract = {Data summarization is the process of producing interpretable and representative subsets of an input dataset. It is usually performed following a one-shot process with the purpose of finding the best summary. A useful summary contains 𝑘 individually uniform sets that are collectively diverse to be representative. Uniformity addresses interpretability and diversity addresses representativity. Finding such as summary is a difficult task when data is highly diverse and large. We examine the applicability of Exploratory Data Analysis (EDA) to data summarization and formalize Eda4Sum, the problem of guided exploration of data summaries that seeks to sequentially produce connected summaries with the goal of maximizing their cumulative utility. Eda4Sum generalizes one-shot summarization. We propose to solve it with one of two approaches: (i) Top1Sum that chooses the most useful summary at each step; (ii) RLSum that trains a policy with Deep Reinforcement Learning that rewards an agent for finding a diverse and new collection of uniform sets at each step. We compare these approaches with one-shot summarization and top-performing EDA solutions. We run extensive experiments on three large datasets. Our results demonstrate the superiority of our approaches for summarizing very large data, and the need to provide guidance to domain experts.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Databases,Computer Science - Machine Learning},
  file = {/Users/DAADAMS/Zotero/storage/D355XYIU/Youngmann et al. - 2022 - Guided Exploration of Data Summaries.pdf}
}

@online{youngmannGuidedExplorationData2022a,
  title = {Guided {{Exploration}} of {{Data Summaries}}},
  author = {Youngmann, Brit and Amer-Yahia, Sihem and Personnaz, Aurélien},
  date = {2022-05-27},
  eprint = {2205.13956},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2205.13956},
  url = {http://arxiv.org/abs/2205.13956},
  urldate = {2025-02-07},
  abstract = {Data summarization is the process of producing interpretable and representative subsets of an input dataset. It is usually performed following a one-shot process with the purpose of finding the best summary. A useful summary contains 𝑘 individually uniform sets that are collectively diverse to be representative. Uniformity addresses interpretability and diversity addresses representativity. Finding such as summary is a difficult task when data is highly diverse and large. We examine the applicability of Exploratory Data Analysis (EDA) to data summarization and formalize Eda4Sum, the problem of guided exploration of data summaries that seeks to sequentially produce connected summaries with the goal of maximizing their cumulative utility. Eda4Sum generalizes one-shot summarization. We propose to solve it with one of two approaches: (i) Top1Sum that chooses the most useful summary at each step; (ii) RLSum that trains a policy with Deep Reinforcement Learning that rewards an agent for finding a diverse and new collection of uniform sets at each step. We compare these approaches with one-shot summarization and top-performing EDA solutions. We run extensive experiments on three large datasets. Our results demonstrate the superiority of our approaches for summarizing very large data, and the need to provide guidance to domain experts.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Databases,Computer Science - Machine Learning},
  file = {/Users/DAADAMS/Zotero/storage/4DC29KR9/Youngmann et al. - 2022 - Guided Exploration of Data Summaries.pdf}
}

@inproceedings{yuanDARecDeepDomain2019,
  title = {{{DARec}}: {{Deep Domain Adaptation}} for {{Cross-Domain Recommendation}} via {{Transferring Rating Patterns}}},
  shorttitle = {{{DARec}}},
  booktitle = {Proceedings of the {{Twenty-Eighth International Joint Conference}} on {{Artificial Intelligence}}},
  author = {Yuan, Feng and Yao, Lina and Benatallah, Boualem},
  date = {2019-08},
  pages = {4227--4233},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  location = {Macao, China},
  doi = {10.24963/ijcai.2019/587},
  url = {https://www.ijcai.org/proceedings/2019/587},
  urldate = {2025-09-08},
  abstract = {Cross-domain recommendation has long been one of the major topics in recommender systems.Recently, various deep models have been proposed to transfer the learned knowledge across domains, but most of them focus on extracting abstract transferable features from auxiliary contents, e.g., images and review texts, and the patterns in the rating matrix itself is rarely touched. In this work, inspired by the concept of domain adaptation, we proposed a deep domain adaptation model (DARec) that is capable of extracting and transferring patterns from rating matrices only without relying on any auxillary information. We empirically demonstrate on public datasets that our method achieves the best performance among several state-of-the-art alternative cross-domain recommendation models.},
  eventtitle = {Twenty-{{Eighth International Joint Conference}} on {{Artificial Intelligence}} \{\vphantom\}{{IJCAI-19}}\vphantom\{\}},
  isbn = {978-0-9992411-4-1},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/6FGHZ7CV/Yuan et al. - 2019 - DARec Deep Domain Adaptation for Cross-Domain Recommendation via Transferring Rating Patterns.pdf}
}

@inproceedings{yuItTakesVariety2009,
  title = {It Takes Variety to Make a World: Diversification in Recommender Systems},
  shorttitle = {It Takes Variety to Make a World},
  booktitle = {Proceedings of the 12th {{International Conference}} on {{Extending Database Technology}}: {{Advances}} in {{Database Technology}}},
  author = {Yu, Cong and Lakshmanan, Laks and Amer-Yahia, Sihem},
  date = {2009-03-24},
  pages = {368--378},
  publisher = {ACM},
  location = {Saint Petersburg Russia},
  doi = {10.1145/1516360.1516404},
  url = {https://dl.acm.org/doi/10.1145/1516360.1516404},
  urldate = {2025-02-07},
  eventtitle = {{{EDBT}}/{{ICDT}} '09: {{EDBT}}/{{ICDT}} '09 Joint Conference},
  isbn = {978-1-60558-422-5},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/VFBWJZ2W/Yu et al. - 2009 - It takes variety to make a world diversification in recommender systems.pdf}
}

@software{yuYuFangxuDARec2025,
  title = {Yu-{{Fangxu}}/{{DARec}}},
  author = {Yu, Fangxu},
  date = {2025-07-23T07:02:35Z},
  origdate = {2021-06-14T05:30:54Z},
  url = {https://github.com/Yu-Fangxu/DARec},
  urldate = {2025-09-08},
  abstract = {Pytorch implementation of DARec: Deep Domain Adaptation for Cross-Domain Recommendation via Transferring Rating Patterns}
}

@online{zangSurveyCrossdomainRecommendation2022,
  title = {A {{Survey}} on {{Cross-domain Recommendation}}: {{Taxonomies}}, {{Methods}}, and {{Future Directions}}},
  shorttitle = {A {{Survey}} on {{Cross-domain Recommendation}}},
  author = {Zang, Tianzi and Zhu, Yanmin and Liu, Haobing and Zhang, Ruohan and Yu, Jiadi},
  date = {2022-07-24},
  eprint = {2108.03357},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2108.03357},
  url = {http://arxiv.org/abs/2108.03357},
  urldate = {2025-09-08},
  abstract = {Traditional recommendation systems are faced with two long-standing obstacles, namely, data sparsity and cold-start problems, which promote the emergence and development of Cross-Domain Recommendation (CDR). The core idea of CDR is to leverage information collected from other domains to alleviate the two problems in one domain. Over the last decade, many efforts have been engaged for cross-domain recommendation. Recently, with the development of deep learning and neural networks, a large number of methods have emerged. However, there is a limited number of systematic surveys on CDR, especially regarding the latest proposed methods as well as the recommendation scenarios and recommendation tasks they address. In this survey paper, we first proposed a two-level taxonomy of cross-domain recommendation which classifies different recommendation scenarios and recommendation tasks. We then introduce and summarize existing cross-domain recommendation approaches under different recommendation scenarios in a structured manner. We also organize datasets commonly used. We conclude this survey by providing several potential research directions about this field.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Information Retrieval,Computer Science - Machine Learning},
  file = {/Users/DAADAMS/Zotero/storage/ZR5WFDHW/Zang et al. - 2022 - A Survey on Cross-domain Recommendation Taxonomies, Methods, and Future Directions.pdf}
}

@online{zhangAutoMLGPTAutomaticMachine2023,
  title = {{{AutoML-GPT}}: {{Automatic Machine Learning}} with {{GPT}}},
  shorttitle = {{{AutoML-GPT}}},
  author = {Zhang, Shujian and Gong, Chengyue and Wu, Lemeng and Liu, Xingchao and Zhou, Mingyuan},
  date = {2023-05-03},
  eprint = {2305.02499},
  eprinttype = {arXiv},
  eprintclass = {cs, stat},
  url = {http://arxiv.org/abs/2305.02499},
  urldate = {2024-03-15},
  abstract = {AI tasks encompass a wide range of domains and fields. While numerous AI models have been designed for specific tasks and applications, they often require considerable human efforts in finding the right model architecture, optimization algorithm, and hyperparameters. Recent advances in large language models (LLMs) like ChatGPT show remarkable capabilities in various aspects of reasoning, comprehension, and interaction. Consequently, we propose developing task-oriented prompts and automatically utilizing LLMs to automate the training pipeline. To implement this concept, we present the AutoML-GPT, which employs GPT as the bridge to diverse AI models and dynamically trains models with optimized hyperparameters. AutoML-GPT dynamically takes user requests from the model and data cards and composes the corresponding prompt paragraph. Ultimately, with this prompt paragraph, AutoML-GPT will automatically conduct the experiments from data processing to model architecture, hyperparameter tuning, and predicted training log. By leveraging AutoML-GPT’s robust language capabilities and the available AI models, AutoML-GPT can tackle numerous intricate AI tasks across various tasks and datasets. This approach achieves remarkable results in computer vision, natural language processing, and other challenging areas. Extensive experiments and ablation studies demonstrate that our method can be general, effective, and beneficial for many AI tasks.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/DAADAMS/Zotero/storage/SIDFN4DA/Zhang et al. - 2023 - AutoML-GPT Automatic Machine Learning with GPT.pdf}
}

@article{zhangBIRCHEfficientData1996,
  title = {{{BIRCH}}: An Efficient Data Clustering Method for Very Large Databases},
  shorttitle = {{{BIRCH}}},
  author = {Zhang, Tian and Ramakrishnan, Raghu and Livny, Miron},
  date = {1996-06},
  journaltitle = {ACM SIGMOD Record},
  shortjournal = {SIGMOD Rec.},
  volume = {25},
  number = {2},
  pages = {103--114},
  issn = {0163-5808},
  doi = {10.1145/235968.233324},
  url = {https://dl.acm.org/doi/10.1145/235968.233324},
  urldate = {2025-02-16},
  abstract = {Finding useful patterns in large datasets has attracted considerable interest recently, and one of the most widely studied problems in this area is the identification of               clusters,               or densely populated regions, in a multi-dimensional dataset. Prior work does not adequately address the problem of large datasets and minimization of I/O costs.This paper presents a data clustering method named               BIRCH               (Balanced Iterative Reducing and Clustering using Hierarchies), and demonstrates that it is especially suitable for very large databases.               BIRCH               incrementally and dynamically clusters incoming multi-dimensional metric data points to try to produce the best quality clustering with the available resources (i.e., available memory and time constraints).               BIRCH               can typically find a good clustering with a single scan of the data, and improve the quality further with a few additional scans.               BIRCH               is also the first clustering algorithm proposed in the database area to handle "noise" (data points that are not part of the underlying pattern) effectively.We evaluate               BIRCH               's time/space efficiency, data input order sensitivity, and clustering quality through several experiments. We also present a performance comparisons of               BIRCH               versus               CLARANS,               a clustering method proposed recently for large datasets, and show that               BIRCH               is consistently superior.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/KIIV39AK/Zhang et al. - 1996 - BIRCH an efficient data clustering method for very large databases.pdf}
}

@online{zhangDistributionMatchingCollaborative2025,
  title = {Towards {{Distribution Matching}} between {{Collaborative}} and {{Language Spaces}} for {{Generative Recommendation}}},
  author = {Zhang, Yi and Zhang, Yiwen and Wang, Yu and Chen, Tong and Yin, Hongzhi},
  date = {2025-04-23},
  eprint = {2504.07363},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2504.07363},
  url = {http://arxiv.org/abs/2504.07363},
  urldate = {2025-09-08},
  abstract = {Generative recommendation aims to learn the underlying generative process over the entire item set to produce recommendations for users. Although it leverages non-linear probabilistic models to surpass the limited modeling capacity of linear factor models, it is often constrained by a trade-off between representation ability and tractability. With the rise of a new generation of generative methods based on pre-trained language models (LMs), incorporating LMs into general recommendation with implicit feedback has gained considerable attention. However, adapting them to generative recommendation remains challenging. The core reason lies in the mismatch between the input-output formats and semantics of generative models and LMs, making it challenging to achieve optimal alignment in the feature space. This work addresses this issue by proposing a model-agnostic generative recommendation framework called DMRec, which introduces a probabilistic meta-network to bridge the outputs of LMs with user interactions, thereby enabling an equivalent probabilistic modeling process. Subsequently, we design three cross-space distribution matching processes aimed at maximizing shared information while preserving the unique semantics of each space and filtering out irrelevant information. We apply DMRec to three different types of generative recommendation methods and conduct extensive experiments on three public datasets. The experimental results demonstrate that DMRec can effectively enhance the recommendation performance of these generative models, and it shows significant advantages over mainstream LM-enhanced recommendation methods.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Information Retrieval},
  file = {/Users/DAADAMS/Zotero/storage/63RLCYS2/Zhang et al. - 2025 - Towards Distribution Matching between Collaborative and Language Spaces for Generative Recommendatio.pdf}
}

@inproceedings{zhangExploringPolicyDiversity2022,
  title = {Exploring {{Policy Diversity}} in {{Parallel Actor-Critic Learning}}},
  booktitle = {2022 {{IEEE}} 34th {{International Conference}} on {{Tools}} with {{Artificial Intelligence}} ({{ICTAI}})},
  author = {Zhang, Yanqiang and Zhai, Yuanzhao and Zhou, Gongqian and Ding, Bo and Feng, Dawei and Liu, Songwang},
  date = {2022},
  pages = {1196--1203},
  publisher = {IEEE},
  url = {https://ieeexplore.ieee.org/abstract/document/10098030/?casa_token=jiCoZZZputcAAAAA:t5lZI-cbH0cqhKexHwz6lYsQ6_byPC3jlTXvCmmhzCEOfVq7eT873SZZNXYOGOU454QLu5pAYm_V},
  urldate = {2024-09-03},
  keywords = {actor-critic,Deep learning,diversity promotion,exploration efficiency,Learning (artificial intelligence),Probability distribution,Reinforcement learning,Task analysis}
}

@article{zhangLeveragingInteractiveUser,
  title = {Leveraging {{Interactive User Feedback}} for {{Personalized Data Visualization Recommendation}}},
  author = {Zhang, Xiaozhong},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/QL9E8ZAX/Zhang - Leveraging Interactive User Feedback for Personalized Data Visualization Recommendation.pdf}
}

@article{zhangTaskagnosticExplorationReinforcement2020,
  title = {Task-Agnostic Exploration in Reinforcement Learning},
  author = {Zhang, Xuezhou and Ma, Yuzhe and Singla, Adish},
  date = {2020},
  journaltitle = {Advances in Neural Information Processing Systems},
  volume = {33},
  pages = {11734--11743},
  url = {https://proceedings.neurips.cc/paper/2020/hash/8763d72bba4a7ade23f9ae1f09f4efc7-Abstract.html},
  urldate = {2024-09-03},
  file = {/Users/DAADAMS/Zotero/storage/RLFNWA29/Zhang et al. - 2020 - Task-agnostic exploration in reinforcement learnin.pdf}
}

@article{zhangVAEBasedUserPreference2023,
  title = {A {{VAE-Based User Preference Learning}} and {{Transfer Framework}} for {{Cross-Domain Recommendation}}},
  author = {Zhang, Tong and Chen, Chen and Wang, Dan and Guo, Jie and Song, Bin},
  date = {2023-10},
  journaltitle = {IEEE Transactions on Knowledge and Data Engineering},
  volume = {35},
  number = {10},
  pages = {10383--10396},
  issn = {1558-2191},
  doi = {10.1109/TKDE.2023.3253168},
  url = {https://ieeexplore.ieee.org/document/10061287/},
  urldate = {2025-09-04},
  abstract = {The core idea of cross-domain recommendation is to alleviate the problem of data scarcity. Previous methods have made brilliant successes. However, many of them mainly focus on learning an ideal mapping function across-domains, ignoring the user preferences within a specific domain, which leads to suboptimal results. In this paper, we propose a Cross-Domain Recommendation Variational AutoEncoder framework (CDRVAE), a novel extension of a variational autoencoder on cross-domain recommendations for user behaviour distribution modeling. It applies a new hybrid architecture of VAE as the backbone and simultaneously constructs two information flows, within-domain and cross-domain modeling. For the former, an asymmetric codec structure is designed to reconstruct preference distribution from domain-specific latent factors. To relieve the posterior collapse dilemma, a combined prior is employed to increase the distribution complexity. The equivalent transition by a transformation matrix and the unobserved interaction generation by cross-domain reconstruction contribute to the latter. We combine all the above components for the more accurate and reliable user features. Extensive experiments are conducted on three public benchmark datasets to validate the effectiveness of the proposed CDRVAE. Experimental results demonstrate that CDRVAE is consistently superior to other state-of-the-art alternative baseline models.},
  keywords = {Bayes methods,Collaboration,Cross-domain recommendation,Data models,Decoding,deep learning,Knowledge transfer,recommendation system,Sparse matrices,Training,variational autoencoder},
  file = {/Users/DAADAMS/Zotero/storage/NSUC3APZ/Zhang et al. - 2023 - A VAE-Based User Preference Learning and Transfer Framework for Cross-Domain Recommendation.pdf}
}

@article{zhangVAEBasedUserPreference2023a,
  title = {A {{VAE-Based User Preference Learning}} and {{Transfer Framework}} for {{Cross-Domain Recommendation}}},
  author = {Zhang, Tong and Chen, Chen and Wang, Dan and Guo, Jie and Song, Bin},
  date = {2023-10},
  journaltitle = {IEEE Transactions on Knowledge and Data Engineering},
  volume = {35},
  number = {10},
  pages = {10383--10396},
  issn = {1558-2191},
  doi = {10.1109/TKDE.2023.3253168},
  url = {https://ieeexplore.ieee.org/document/10061287/},
  urldate = {2025-09-08},
  abstract = {The core idea of cross-domain recommendation is to alleviate the problem of data scarcity. Previous methods have made brilliant successes. However, many of them mainly focus on learning an ideal mapping function across-domains, ignoring the user preferences within a specific domain, which leads to suboptimal results. In this paper, we propose a Cross-Domain Recommendation Variational AutoEncoder framework (CDRVAE), a novel extension of a variational autoencoder on cross-domain recommendations for user behaviour distribution modeling. It applies a new hybrid architecture of VAE as the backbone and simultaneously constructs two information flows, within-domain and cross-domain modeling. For the former, an asymmetric codec structure is designed to reconstruct preference distribution from domain-specific latent factors. To relieve the posterior collapse dilemma, a combined prior is employed to increase the distribution complexity. The equivalent transition by a transformation matrix and the unobserved interaction generation by cross-domain reconstruction contribute to the latter. We combine all the above components for the more accurate and reliable user features. Extensive experiments are conducted on three public benchmark datasets to validate the effectiveness of the proposed CDRVAE. Experimental results demonstrate that CDRVAE is consistently superior to other state-of-the-art alternative baseline models.},
  keywords = {Bayes methods,Collaboration,Cross-domain recommendation,Data models,Decoding,deep learning,Knowledge transfer,recommendation system,Sparse matrices,Training,variational autoencoder},
  file = {/Users/DAADAMS/Zotero/storage/GZXCPW6W/Zhang et al. - 2023 - A VAE-Based User Preference Learning and Transfer Framework for Cross-Domain Recommendation.pdf}
}

@online{zhaoCrossdomainRecommendationUser2023,
  title = {Cross-Domain Recommendation via User Interest Alignment},
  author = {Zhao, Chuang and Zhao, Hongke and He, Ming and Zhang, Jian and Fan, Jianping},
  date = {2023-01-26},
  eprint = {2301.11467},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2301.11467},
  url = {http://arxiv.org/abs/2301.11467},
  urldate = {2025-09-08},
  abstract = {Cross-domain recommendation aims to leverage knowledge from multiple domains to alleviate the data sparsity and cold-start problems in traditional recommender systems. One popular paradigm is to employ overlapping user representations to establish domain connections, thereby improving recommendation performance in all scenarios. Nevertheless, the general practice of this approach is to train user embeddings in each domain separately and then aggregate them in a plain manner, often ignoring potential cross-domain similarities between users and items. Furthermore, considering that their training objective is recommendation task-oriented without specific regularizations, the optimized embeddings disregard the interest alignment among user’s views, and even violate the user’s original interest distribution. To address these challenges, we propose a novel cross-domain recommendation framework, namely COAST, to improve recommendation performance on dual domains by perceiving the cross-domain similarity between entities and aligning user interests. Specifically, we first construct a unified cross-domain heterogeneous graph and redefine the message passing mechanism of graph convolutional networks to capture high-order similarity of users and items across domains. Targeted at user interest alignment, we develop deep insights from two more fine-grained perspectives of user-user and user-item interest invariance across domains by virtue of affluent unsupervised and semantic signals. We conduct intensive experiments on multiple tasks, constructed from two large recommendation data sets. Extensive results show COAST consistently and significantly outperforms state-of-the-art cross-domain recommendation algorithms as well as classic single-domain recommendation methods.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Information Retrieval},
  file = {/Users/DAADAMS/Zotero/storage/L4GDV9QU/Zhao et al. - 2023 - Cross-domain recommendation via user interest alignment.pdf}
}

@inproceedings{zhouDataBubblesNonvector2003,
  title = {Data Bubbles for Non-Vector Data: {{Speeding-up}} Hierarchical Clustering in Arbitrary Metric Spaces},
  shorttitle = {Data Bubbles for Non-Vector Data},
  booktitle = {Proceedings 2003 {{VLDB Conference}}},
  author = {Zhou, Jianjun and Sander, Jörg},
  date = {2003},
  pages = {452--463},
  publisher = {Elsevier},
  url = {https://www.sciencedirect.com/science/article/pii/B9780127224428500471},
  urldate = {2025-02-16},
  file = {/Users/DAADAMS/Zotero/storage/NSGZQT6K/Zhou and Sander - 2003 - Data bubbles for non-vector data Speeding-up hierarchical clustering in arbitrary metric spaces.pdf}
}

@online{zhuCrossDomainRecommendationChallenges2021,
  title = {Cross-{{Domain Recommendation}}: {{Challenges}}, {{Progress}}, and {{Prospects}}},
  shorttitle = {Cross-{{Domain Recommendation}}},
  author = {Zhu, Feng and Wang, Yan and Chen, Chaochao and Zhou, Jun and Li, Longfei and Liu, Guanfeng},
  date = {2021-03-02},
  eprint = {2103.01696},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2103.01696},
  url = {http://arxiv.org/abs/2103.01696},
  urldate = {2025-09-04},
  abstract = {To address the long-standing data sparsity problem in recommender systems (RSs), cross-domain recommendation (CDR) has been proposed to leverage the relatively richer information from a richer domain to improve the recommendation performance in a sparser domain. Although CDR has been extensively studied in recent years, there is a lack of a systematic review of the existing CDR approaches. To fill this gap, in this paper, we provide a comprehensive review of existing CDR approaches, including challenges, research progress, and prospects. Specifically, we first summarize existing CDR approaches into four types, including single-target CDR, multi-domain recommendation, dual-target CDR, and multi-target CDR. We then present the definitions and challenges of these CDR approaches. Next, we propose a full-view categorization and new taxonomies on these approaches and report their research progress in detail. In the end, we share several promising prospects in CDR.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Information Retrieval,Computer Science - Machine Learning},
  file = {/Users/DAADAMS/Zotero/storage/3PEX6F94/Zhu et al. - 2021 - Cross-Domain Recommendation Challenges, Progress, and Prospects.pdf}
}

@online{zhuCrossDomainRecommendationChallenges2021a,
  title = {Cross-{{Domain Recommendation}}: {{Challenges}}, {{Progress}}, and {{Prospects}}},
  shorttitle = {Cross-{{Domain Recommendation}}},
  author = {Zhu, Feng and Wang, Yan and Chen, Chaochao and Zhou, Jun and Li, Longfei and Liu, Guanfeng},
  date = {2021-03-02},
  eprint = {2103.01696},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2103.01696},
  url = {http://arxiv.org/abs/2103.01696},
  urldate = {2025-09-08},
  abstract = {To address the long-standing data sparsity problem in recommender systems (RSs), cross-domain recommendation (CDR) has been proposed to leverage the relatively richer information from a richer domain to improve the recommendation performance in a sparser domain. Although CDR has been extensively studied in recent years, there is a lack of a systematic review of the existing CDR approaches. To fill this gap, in this paper, we provide a comprehensive review of existing CDR approaches, including challenges, research progress, and prospects. Specifically, we first summarize existing CDR approaches into four types, including single-target CDR, multi-domain recommendation, dual-target CDR, and multi-target CDR. We then present the definitions and challenges of these CDR approaches. Next, we propose a full-view categorization and new taxonomies on these approaches and report their research progress in detail. In the end, we share several promising prospects in CDR.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Information Retrieval,Computer Science - Machine Learning},
  file = {/Users/DAADAMS/Zotero/storage/YXAGKZQ6/Zhu et al. - 2021 - Cross-Domain Recommendation Challenges, Progress, and Prospects.pdf}
}

@article{zhuoLearningHierarchicalTask2014,
  title = {Learning Hierarchical Task Network Domains from Partially Observed Plan Traces},
  author = {Zhuo, Hankz Hankui and Muñoz-Avila, Héctor and Yang, Qiang},
  date = {2014-07-01},
  journaltitle = {Artificial Intelligence},
  shortjournal = {Artificial Intelligence},
  volume = {212},
  pages = {134--157},
  issn = {0004-3702},
  doi = {10.1016/j.artint.2014.04.003},
  url = {https://www.sciencedirect.com/science/article/pii/S0004370214000447},
  urldate = {2024-03-18},
  abstract = {Hierarchical Task Network (HTN) planning is an effective yet knowledge intensive problem-solving technique. It requires humans to encode knowledge in the form of methods and action models. Methods describe how to decompose tasks into subtasks and the preconditions under which those methods are applicable whereas action models describe how actions change the world. Encoding such knowledge is a difficult and time-consuming process, even for domain experts. In this paper, we propose a new learning algorithm, called HTNLearn, to help acquire HTN methods and action models. HTNLearn receives as input a collection of plan traces with partially annotated intermediate state information, and a set of annotated tasks that specify the conditions before and after the tasks' completion. In addition, plan traces are annotated with potentially empty partial decomposition trees that record the processes of decomposing tasks to subtasks. HTNLearn outputs are a collection of methods and action models. HTNLearn first encodes constraints about the methods and action models as a constraint satisfaction problem, and then solves the problem using a weighted MAX-SAT solver. HTNLearn can learn methods and action models simultaneously from partially observed plan traces (i.e., plan traces where the intermediate states are partially observable). We test HTNLearn in several HTN domains. The experimental results show that our algorithm HTNLearn is both effective and efficient.},
  keywords = {Action model learning,HTN planning,Learning HTNs,Weighted MAX-SAT},
  file = {/Users/DAADAMS/Zotero/storage/TB6FAN9Y/Zhuo et al. - 2014 - Learning hierarchical task network domains from pa.pdf;/Users/DAADAMS/Zotero/storage/34IYLLZ8/S0004370214000447.html}
}

@online{zirakSeLePLearningBased2023,
  title = {{{SeLeP}}: {{Learning Based Semantic Prefetching}} for {{Exploratory Database Workloads}}},
  shorttitle = {{{SeLeP}}},
  author = {Zirak, Farzaneh and Choudhury, Farhana and Borovica-Gajic, Renata},
  date = {2023-10-23},
  eprint = {2310.14666},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2310.14666},
  url = {http://arxiv.org/abs/2310.14666},
  urldate = {2024-03-15},
  abstract = {Prefetching is a crucial technique employed in traditional databases to enhance interactivity, particularly in the context of data exploitation. Data exploration is a query processing paradigm in which users search for insights buried in the data, often not knowing what exactly they are looking for. Data exploratory tools deal with multiple challenges such as the need for interactivity with no a priori knowledge being present to help with the system tuning. The state-of-the-art prefetchers are specifically designed for navigational workloads only, where the number of possible actions is limited. The prefetchers that work with SQL-based workloads, on the other hand, mainly rely on data logical addresses rather than the data semantics. They fail to predict complex access patterns in cases where the database size is substantial, resulting in an extensive address space, or when there is frequent co-accessing of data. In this paper, we propose SeLeP, a semantic prefetcher that makes prefetching decisions for both types of workloads, based on the encoding of the data values contained inside the accessed blocks. Following the popular path of using machine learning approaches to automatically learn the hidden patterns, we formulate the prefetching task as a time-series forecasting problem and use an encoder-decoder LSTM architecture to learn the data access pattern. Our extensive experiments, across real-life exploratory workloads, demonstrate that SeLeP improves the hit ratio up to 40\% and reduces I/O time up to 45\% compared to the state-of-the-art, attaining impressive 95\% hit ratio and 80\% I/O reduction on average.},
  pubstate = {prepublished},
  keywords = {Computer Science - Databases},
  file = {/Users/DAADAMS/Zotero/storage/MJ7NMZ6W/Zirak et al. - 2023 - SeLeP Learning Based Semantic Prefetching for Exp.pdf;/Users/DAADAMS/Zotero/storage/7YGXGPX2/2310.html}
}