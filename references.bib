
% Journals

% First the Full Name is given, then the abbreviation used in the AMS Math
% Reviews, with an indication if it could not be found there.
% Note the 2nd overwrites the 1st, so swap them if you want the full name.

 %{AMS}
 @String{AMSTrans = "American Mathematical Society Translations" }
 @String{AMSTrans = "Amer. Math. Soc. Transl." }
 @String{BullAMS = "Bulletin of the American Mathematical Society" }
 @String{BullAMS = "Bull. Amer. Math. Soc." }
 @String{ProcAMS = "Proceedings of the American Mathematical Society" }
 @String{ProcAMS = "Proc. Amer. Math. Soc." }
 @String{TransAMS = "Transactions of the American Mathematical Society" }
 @String{TransAMS = "Trans. Amer. Math. Soc." }

 %ACM
 @String{CACM = "Communications of the {ACM}" }
 @String{CACM = "Commun. {ACM}" }
 @String{CompServ = "Comput. Surveys" }
 @String{JACM = "J. ACM" }
 @String{ACMMathSoft = "{ACM} Transactions on Mathematical Software" }
 @String{ACMMathSoft = "{ACM} Trans. Math. Software" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newsletter" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newslett." }

 @String{AmerSocio = "American Journal of Sociology" }
 @String{AmerStatAssoc = "Journal of the American Statistical Association" }
 @String{AmerStatAssoc = "J. Amer. Statist. Assoc." }
 @String{ApplMathComp = "Applied Mathematics and Computation" }
 @String{ApplMathComp = "Appl. Math. Comput." }
 @String{AmerMathMonthly = "American Mathematical Monthly" }
 @String{AmerMathMonthly = "Amer. Math. Monthly" }
 @String{BIT = "{BIT}" }
 @String{BritStatPsych = "British Journal of Mathematical and Statistical
          Psychology" }
 @String{BritStatPsych = "Brit. J. Math. Statist. Psych." }
 @String{CanMathBull = "Canadian Mathematical Bulletin" }
 @String{CanMathBull = "Canad. Math. Bull." }
 @String{CompApplMath = "Journal of Computational and Applied Mathematics" }
 @String{CompApplMath = "J. Comput. Appl. Math." }
 @String{CompPhys = "Journal of Computational Physics" }
 @String{CompPhys = "J. Comput. Phys." }
 @String{CompStruct = "Computers and Structures" }
 @String{CompStruct = "Comput. \& Structures" }
 @String{CompJour = "The Computer Journal" }
 @String{CompJour = "Comput. J." }
 @String{CompSysSci = "Journal of Computer and System Sciences" }
 @String{CompSysSci = "J. Comput. System Sci." }
 @String{Computing = "Computing" }
 @String{ContempMath = "Contemporary Mathematics" }
 @String{ContempMath = "Contemp. Math." }
 @String{Crelle = "Crelle's Journal" }
 @String{GiornaleMath = "Giornale di Mathematiche" }
 @String{GiornaleMath = "Giorn. Mat." } % didn't find in AMS MR., ibid.

 %IEEE
 @String{Computer = "{IEEE} Computer" }
 @String{IEEETransComp = "{IEEE} Transactions on Computers" }
 @String{IEEETransComp = "{IEEE} Trans. Comput." }
 @String{IEEETransAC = "{IEEE} Transactions on Automatic Control" }
 @String{IEEETransAC = "{IEEE} Trans. Automat. Control" }
 @String{IEEESpec = "{IEEE} Spectrum" } % didn't find in AMS MR
 @String{ProcIEEE = "Proceedings of the {IEEE}" }
 @String{ProcIEEE = "Proc. {IEEE}" } % didn't find in AMS MR
 @String{IEEETransAeroElec = "{IEEE} Transactions on Aerospace and Electronic
     Systems" }
 @String{IEEETransAeroElec = "{IEEE} Trans. Aerospace Electron. Systems" }

 @String{IMANumerAna = "{IMA} Journal of Numerical Analysis" }
 @String{IMANumerAna = "{IMA} J. Numer. Anal." }
 @String{InfProcLet = "Information Processing Letters" }
 @String{InfProcLet = "Inform. Process. Lett." }
 @String{InstMathApp = "Journal of the Institute of Mathematics and
     its Applications" }
 @String{InstMathApp = "J. Inst. Math. Appl." }
 @String{IntControl = "International Journal of Control" }
 @String{IntControl = "Internat. J. Control" }
 @String{IntNumerEng = "International Journal for Numerical Methods in
     Engineering" }
 @String{IntNumerEng = "Internat. J. Numer. Methods Engrg." }
 @String{IntSuper = "International Journal of Supercomputing Applications" }
 @String{IntSuper = "Internat. J. Supercomputing Applic." } % didn't find
%% in AMS MR
 @String{Kibernetika = "Kibernetika" }
 @String{JResNatBurStand = "Journal of Research of the National Bureau
     of Standards" }
 @String{JResNatBurStand = "J. Res. Nat. Bur. Standards" }
 @String{LinAlgApp = "Linear Algebra and its Applications" }
 @String{LinAlgApp = "Linear Algebra Appl." }
 @String{MathAnaAppl = "Journal of Mathematical Analysis and Applications" }
 @String{MathAnaAppl = "J. Math. Anal. Appl." }
 @String{MathAnnalen = "Mathematische Annalen" }
 @String{MathAnnalen = "Math. Ann." }
 @String{MathPhys = "Journal of Mathematical Physics" }
 @String{MathPhys = "J. Math. Phys." }
 @String{MathComp = "Mathematics of Computation" }
 @String{MathComp = "Math. Comp." }
 @String{MathScand = "Mathematica Scandinavica" }
 @String{MathScand = "Math. Scand." }
 @String{TablesAidsComp = "Mathematical Tables and Other Aids to Computation" }
 @String{TablesAidsComp = "Math. Tables Aids Comput." }
 @String{NumerMath = "Numerische Mathematik" }
 @String{NumerMath = "Numer. Math." }
 @String{PacificMath = "Pacific Journal of Mathematics" }
 @String{PacificMath = "Pacific J. Math." }
 @String{ParDistComp = "Journal of Parallel and Distributed Computing" }
 @String{ParDistComp = "J. Parallel and Distrib. Comput." } % didn't find
%% in AMS MR
 @String{ParComputing = "Parallel Computing" }
 @String{ParComputing = "Parallel Comput." }
 @String{PhilMag = "Philosophical Magazine" }
 @String{PhilMag = "Philos. Mag." }
 @String{ProcNAS = "Proceedings of the National Academy of Sciences
                    of the USA" }
 @String{ProcNAS = "Proc. Nat. Acad. Sci. U. S. A." }
 @String{Psychometrika = "Psychometrika" }
 @String{QuartMath = "Quarterly Journal of Mathematics, Oxford, Series (2)" }
 @String{QuartMath = "Quart. J. Math. Oxford Ser. (2)" }
 @String{QuartApplMath = "Quarterly of Applied Mathematics" }
 @String{QuartApplMath = "Quart. Appl. Math." }
 @String{RevueInstStat = "Review of the International Statisical Institute" }
 @String{RevueInstStat = "Rev. Inst. Internat. Statist." }

 %SIAM
 @String{JSIAM = "Journal of the Society for Industrial and Applied
     Mathematics" }
 @String{JSIAM = "J. Soc. Indust. Appl. Math." }
 @String{JSIAMB = "Journal of the Society for Industrial and Applied
     Mathematics, Series B, Numerical Analysis" }
 @String{JSIAMB = "J. Soc. Indust. Appl. Math. Ser. B Numer. Anal." }
 @String{SIAMAlgMeth = "{SIAM} Journal on Algebraic and Discrete Methods" }
 @String{SIAMAlgMeth = "{SIAM} J. Algebraic Discrete Methods" }
 @String{SIAMAppMath = "{SIAM} Journal on Applied Mathematics" }
 @String{SIAMAppMath = "{SIAM} J. Appl. Math." }
 @String{SIAMComp = "{SIAM} Journal on Computing" }
 @String{SIAMComp = "{SIAM} J. Comput." }
 @String{SIAMMatrix = "{SIAM} Journal on Matrix Analysis and Applications" }
 @String{SIAMMatrix = "{SIAM} J. Matrix Anal. Appl." }
 @String{SIAMNumAnal = "{SIAM} Journal on Numerical Analysis" }
 @String{SIAMNumAnal = "{SIAM} J. Numer. Anal." }
 @String{SIAMReview = "{SIAM} Review" }
 @String{SIAMReview = "{SIAM} Rev." }
 @String{SIAMSciStat = "{SIAM} Journal on Scientific and Statistical
     Computing" }
 @String{SIAMSciStat = "{SIAM} J. Sci. Statist. Comput." }

 @String{SoftPracExp = "Software Practice and Experience" }
 @String{SoftPracExp = "Software Prac. Experience" } % didn't find in AMS MR
 @String{StatScience = "Statistical Science" }
 @String{StatScience = "Statist. Sci." }
 @String{Techno = "Technometrics" }
 @String{USSRCompMathPhys = "{USSR} Computational Mathematics and Mathematical
     Physics" }
 @String{USSRCompMathPhys = "{U. S. S. R.} Comput. Math. and Math. Phys." }
 @String{VLSICompSys = "Journal of {VLSI} and Computer Systems" }
 @String{VLSICompSys = "J. {VLSI} Comput. Syst." }
 @String{ZAngewMathMech = "Zeitschrift fur Angewandte Mathematik und
     Mechanik" }
 @String{ZAngewMathMech = "Z. Angew. Math. Mech." }
 @String{ZAngewMathPhys = "Zeitschrift fur Angewandte Mathematik und Physik" }
 @String{ZAngewMathPhys = "Z. Angew. Math. Phys." }

% Publishers % ================================================= |

 @String{Academic = "Academic Press" }
 @String{ACMPress = "{ACM} Press" }
 @String{AdamHilger = "Adam Hilger" }
 @String{AddisonWesley = "Addison-Wesley" }
 @String{AllynBacon = "Allyn and Bacon" }
 @String{AMS = "American Mathematical Society" }
 @String{Birkhauser = "Birkha{\"u}ser" }
 @String{CambridgePress = "Cambridge University Press" }
 @String{Chelsea = "Chelsea" }
 @String{ClaredonPress = "Claredon Press" }
 @String{DoverPub = "Dover Publications" }
 @String{Eyolles = "Eyolles" }
 @String{HoltRinehartWinston = "Holt, Rinehart and Winston" }
 @String{Interscience = "Interscience" }
 @String{JohnsHopkinsPress = "The Johns Hopkins University Press" }
 @String{JohnWileySons = "John Wiley and Sons" }
 @String{Macmillan = "Macmillan" }
 @String{MathWorks = "The Math Works Inc." }
 @String{McGrawHill = "McGraw-Hill" }
 @String{NatBurStd = "National Bureau of Standards" }
 @String{NorthHolland = "North-Holland" }
 @String{OxfordPress = "Oxford University Press" }  %address Oxford or London?
 @String{PergamonPress = "Pergamon Press" }
 @String{PlenumPress = "Plenum Press" }
 @String{PrenticeHall = "Prentice-Hall" }
 @String{SIAMPub = "{SIAM} Publications" }
 @String{Springer = "Springer-Verlag" }
 @String{TexasPress = "University of Texas Press" }
 @String{VanNostrand = "Van Nostrand" }
 @String{WHFreeman = "W. H. Freeman and Co." }


@article{abadiBeckmanReportDatabase2014,
  title = {The {{Beckman Report}} on {{Database Research}}},
  author = {Abadi, Daniel and Agrawal, Rakesh and Ailamaki, Anastasia and Balazinska, Magdalena and Bernstein, Philip A and Carey, Michael J and Chaudhuri, Surajit and Dean, Jeffrey and Doan, AnHai and Franklin, Michael J and Gehrke, Johannes and Haas, Laura M and Halevy, Alon Y and Hellerstein, Joseph M and Ioannidis, Yannis E and Jagadish, H V and Kossmann, Donald and Madden, Samuel and Mehrotra, Sharad and Milo, Tova and Naughton, Jeffrey F and Ramakrishnan, Raghu and Markl, Volker and Olston, Christopher and Ooi, Beng Chin and Re, Christopher and Suciu, Dan and Stonebraker, Michael and Walter, Todd and Widom, Jennifer},
  year = {2014},
  journal = {SIGMOD Record},
  volume = {43},
  number = {3},
  abstract = {Every few years a group of database researchers meets to discuss the state of database research, its impact on practice, and important new directions. This report summarizes the discussion and conclusions of the eighth such meeting, held October 1415, 2013 in Irvine, California. It observes that Big Data has now become a defining challenge of our time, and that the database research community is uniquely positioned to address it, with enormous opportunities to make transformative impact. To do so, the report recommends significantly more attention to five research areas: scalable big/fast data infrastructures; coping with diversity in the data management landscape; end-to-end processing and understanding of data; cloud services; and managing the diverse roles of people in the data life cycle.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/RJY34YSA/Abadi et al. - 2014 - The Beckman Report on Database Research.pdf}
}

@article{abadiBeckmanReportDatabase2014,
  title = {The {{Beckman Report}} on {{Database Research}}},
  author = {Abadi, Daniel and Agrawal, Rakesh and Ailamaki, Anastasia and Balazinska, Magdalena and Bernstein, Philip A and Carey, Michael J and Chaudhuri, Surajit and Dean, Jeffrey and Doan, AnHai and Franklin, Michael J and Gehrke, Johannes and Haas, Laura M and Halevy, Alon Y and Hellerstein, Joseph M and Ioannidis, Yannis E and Jagadish, H V and Kossmann, Donald and Madden, Samuel and Mehrotra, Sharad and Milo, Tova and Naughton, Jeffrey F and Ramakrishnan, Raghu and Markl, Volker and Olston, Christopher and Ooi, Beng Chin and Re, Christopher and Suciu, Dan and Stonebraker, Michael and Walter, Todd and Widom, Jennifer},
  year = {2014},
  journal = {SIGMOD Record},
  volume = {43},
  number = {3},
  abstract = {Every few years a group of database researchers meets to discuss the state of database research, its impact on practice, and important new directions. This report summarizes the discussion and conclusions of the eighth such meeting, held October 1415, 2013 in Irvine, California. It observes that Big Data has now become a defining challenge of our time, and that the database research community is uniquely positioned to address it, with enormous opportunities to make transformative impact. To do so, the report recommends significantly more attention to five research areas: scalable big/fast data infrastructures; coping with diversity in the data management landscape; end-to-end processing and understanding of data; cloud services; and managing the diverse roles of people in the data life cycle.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/AUAQ2Z9U/Abadi et al. - 2014 - The Beckman Report on Database Research.pdf}
}

@misc{abbasiDiffusionAugmentedCoresetExpansion2024,
  title = {Diffusion-{{Augmented Coreset Expansion}} for {{Scalable Dataset Distillation}}},
  author = {Abbasi, Ali and Imani, Shima and An, Chenyang and Mahalingam, Gayathri and Shrivastava, Harsh and Diesendruck, Maurice and Pirsiavash, Hamed and Sharma, Pramod and Kolouri, Soheil},
  year = {2024},
  month = dec,
  number = {arXiv:2412.04668},
  eprint = {2412.04668},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2412.04668},
  urldate = {2025-04-17},
  abstract = {With the rapid scaling of neural networks, data storage and communication demands have intensified. Dataset distillation has emerged as a promising solution, condensing information from extensive datasets into a compact set of synthetic samples by solving a bilevel optimization problem. However, current methods face challenges in computational efficiency, particularly with high-resolution data and complex architectures. Recently, knowledge-distillation-based dataset condensation approaches have made this process more computationally feasible. Yet, with the recent developments of generative foundation models, there is now an opportunity to achieve even greater compression, enhance the quality of distilled data, and introduce valuable diversity into the data representation. In this work, we propose a two-stage solution. First, we compress the dataset by selecting only the most informative patches to form a coreset. Next, we leverage a generative foundation model to dynamically expand this compressed set in real-time---enhancing the resolution of these patches and introducing controlled variability to the coreset. Our extensive experiments demonstrate the robustness and efficiency of our approach across a range of dataset distillation benchmarks. We demonstrate a significant improvement of over 10\% compared to the state-of-the-art on several large-scale dataset distillation benchmarks. The code will be released soon.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/DAADAMS/Zotero/storage/EGTQUUV6/Abbasi et al. - 2024 - Diffusion-Augmented Coreset Expansion for Scalable Dataset Distillation.pdf}
}

@misc{abbasiDiffusionAugmentedCoresetExpansion2024,
  title = {Diffusion-{{Augmented Coreset Expansion}} for {{Scalable Dataset Distillation}}},
  author = {Abbasi, Ali and Imani, Shima and An, Chenyang and Mahalingam, Gayathri and Shrivastava, Harsh and Diesendruck, Maurice and Pirsiavash, Hamed and Sharma, Pramod and Kolouri, Soheil},
  year = {2024},
  month = dec,
  number = {arXiv:2412.04668},
  eprint = {2412.04668},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2412.04668},
  urldate = {2025-04-17},
  abstract = {With the rapid scaling of neural networks, data storage and communication demands have intensified. Dataset distillation has emerged as a promising solution, condensing information from extensive datasets into a compact set of synthetic samples by solving a bilevel optimization problem. However, current methods face challenges in computational efficiency, particularly with high-resolution data and complex architectures. Recently, knowledge-distillation-based dataset condensation approaches have made this process more computationally feasible. Yet, with the recent developments of generative foundation models, there is now an opportunity to achieve even greater compression, enhance the quality of distilled data, and introduce valuable diversity into the data representation. In this work, we propose a two-stage solution. First, we compress the dataset by selecting only the most informative patches to form a coreset. Next, we leverage a generative foundation model to dynamically expand this compressed set in real-time---enhancing the resolution of these patches and introducing controlled variability to the coreset. Our extensive experiments demonstrate the robustness and efficiency of our approach across a range of dataset distillation benchmarks. We demonstrate a significant improvement of over 10\% compared to the state-of-the-art on several large-scale dataset distillation benchmarks. The code will be released soon.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition},
  file = {/Users/DAADAMS/Zotero/storage/3I68AS8D/Abbasi et al. - 2024 - Diffusion-Augmented Coreset Expansion for Scalable Dataset Distillation.pdf}
}

@inproceedings{acharyaJoinSynopsesApproximate1999,
  title = {Join Synopses for Approximate Query Answering},
  booktitle = {Proceedings of the 1999 {{ACM SIGMOD}} International Conference on {{Management}} of Data},
  author = {Acharya, Swarup and Gibbons, Phillip B. and Poosala, Viswanath and Ramaswamy, Sridhar},
  year = {1999},
  month = jun,
  pages = {275--286},
  publisher = {ACM},
  address = {Philadelphia Pennsylvania USA},
  doi = {10.1145/304182.304207},
  urldate = {2024-08-13},
  isbn = {978-1-58113-084-3},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/E77W4RWU/Acharya et al. - 1999 - Join synopses for approximate query answering.pdf}
}

@inproceedings{acharyaJoinSynopsesApproximate1999,
  title = {Join Synopses for Approximate Query Answering},
  booktitle = {Proceedings of the 1999 {{ACM SIGMOD}} International Conference on {{Management}} of Data},
  author = {Acharya, Swarup and Gibbons, Phillip B. and Poosala, Viswanath and Ramaswamy, Sridhar},
  year = {1999},
  month = jun,
  pages = {275--286},
  publisher = {ACM},
  address = {Philadelphia Pennsylvania USA},
  doi = {10.1145/304182.304207},
  urldate = {2024-08-13},
  isbn = {978-1-58113-084-3},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/DSNKHRRU/Acharya et al. - 1999 - Join synopses for approximate query answering.pdf}
}

@article{aggarwalNewApproachOnline2001,
  title = {A New Approach to Online Generation of Association Rules},
  author = {Aggarwal, C.C. and Yu, P.S.},
  year = {2001},
  month = jul,
  journal = {IEEE Transactions on Knowledge and Data Engineering},
  volume = {13},
  number = {4},
  pages = {527--540},
  issn = {1558-2191},
  doi = {10.1109/69.940730},
  urldate = {2025-01-15},
  abstract = {We discuss the problem of online mining of association rules in a large database of sales transactions. The online mining is performed by preprocessing the data effectively in order to make it suitable for repeated online queries. We store the preprocessed data in such a way that online processing may be done by applying a graph theoretic search algorithm whose complexity is proportional to the size of the output. The result is an online algorithm which is independent of the size of the transactional data and the size of the preprocessed data. The algorithm is almost instantaneous in the size of the output. The algorithm also supports techniques for quickly discovering association rules from large itemsets. The algorithm is capable of finding rules with specific items in the antecedent or consequent. These association rules are presented in a compact form, eliminating redundancy. The use of nonredundant association rules helps significantly in the reduction of irrelevant noise in the data mining process.},
  keywords = {Association rules,Data mining,Itemsets,Marketing and sales,Noise reduction,Promotion - marketing,Transaction databases},
  file = {/Users/DAADAMS/Zotero/storage/I4I7585U/Aggarwal and Yu - 2001 - A new approach to online generation of association rules.pdf;/Users/DAADAMS/Zotero/storage/SADH8LMA/940730.html}
}

@article{aggarwalNewApproachOnline2001,
  title = {A New Approach to Online Generation of Association Rules},
  author = {Aggarwal, C.C. and Yu, P.S.},
  year = {2001},
  month = jul,
  journal = {IEEE Transactions on Knowledge and Data Engineering},
  volume = {13},
  number = {4},
  pages = {527--540},
  issn = {1558-2191},
  doi = {10.1109/69.940730},
  urldate = {2025-01-15},
  abstract = {We discuss the problem of online mining of association rules in a large database of sales transactions. The online mining is performed by preprocessing the data effectively in order to make it suitable for repeated online queries. We store the preprocessed data in such a way that online processing may be done by applying a graph theoretic search algorithm whose complexity is proportional to the size of the output. The result is an online algorithm which is independent of the size of the transactional data and the size of the preprocessed data. The algorithm is almost instantaneous in the size of the output. The algorithm also supports techniques for quickly discovering association rules from large itemsets. The algorithm is capable of finding rules with specific items in the antecedent or consequent. These association rules are presented in a compact form, eliminating redundancy. The use of nonredundant association rules helps significantly in the reduction of irrelevant noise in the data mining process.},
  keywords = {Association rules,Data mining,Itemsets,Marketing and sales,Noise reduction,Promotion - marketing,Transaction databases},
  file = {/Users/DAADAMS/Zotero/storage/238BMZHL/Aggarwal and Yu - 2001 - A new approach to online generation of association rules.pdf;/Users/DAADAMS/Zotero/storage/658AL8GP/940730.html}
}

@article{ahmedDataSummarizationSurvey2019,
  title = {Data Summarization: A Survey},
  shorttitle = {Data Summarization},
  author = {Ahmed, Mohiuddin},
  year = {2019},
  month = feb,
  journal = {Knowledge and Information Systems},
  volume = {58},
  number = {2},
  pages = {249--273},
  issn = {0219-3116},
  doi = {10.1007/s10115-018-1183-0},
  urldate = {2025-02-03},
  abstract = {Summarization has been proven to be a useful and effective technique supporting data analysis of large amounts of data. Knowledge discovery from data (KDD) is time consuming, and summarization is an important step to expedite KDD tasks by intelligently reducing the size of processed data. In this paper, different summarization techniques for structured and unstructured data are discussed. The key finding of this survey is that not all summarization techniques create a summary suitable for further analysis. It is highlighted that sampling techniques are a viable way of creating a summary for further knowledge discovery such as anomaly detection from summary. Also different summary evaluation metrics are discussed.},
  langid = {english},
  keywords = {Cyber security,Machine learning,Natural language processing,Semantics,Statistics,Structured data,Summarization,Unstructured data},
  file = {/Users/DAADAMS/Zotero/storage/9AZY32LD/Ahmed - 2019 - Data summarization a survey.pdf}
}

@article{ahmedDataSummarizationSurvey2019,
  title = {Data Summarization: A Survey},
  shorttitle = {Data Summarization},
  author = {Ahmed, Mohiuddin},
  year = {2019},
  month = feb,
  journal = {Knowledge and Information Systems},
  volume = {58},
  number = {2},
  pages = {249--273},
  issn = {0219-3116},
  doi = {10.1007/s10115-018-1183-0},
  urldate = {2025-02-03},
  abstract = {Summarization has been proven to be a useful and effective technique supporting data analysis of large amounts of data. Knowledge discovery from data (KDD) is time consuming, and summarization is an important step to expedite KDD tasks by intelligently reducing the size of processed data. In this paper, different summarization techniques for structured and unstructured data are discussed. The key finding of this survey is that not all summarization techniques create a summary suitable for further analysis. It is highlighted that sampling techniques are a viable way of creating a summary for further knowledge discovery such as anomaly detection from summary. Also different summary evaluation metrics are discussed.},
  langid = {english},
  keywords = {Cyber security,Machine learning,Natural language processing,Semantics,Statistics,Structured data,Summarization,Unstructured data},
  file = {/Users/DAADAMS/Zotero/storage/U9AYDN6I/Ahmed - 2019 - Data summarization a survey.pdf}
}

@article{ahmedSemanticProbabilisticLayers,
  title = {Semantic {{Probabilistic Layers}} for {{Neuro-Symbolic Learning}}},
  author = {Ahmed, Kareem and Teso, Stefano and Chang, Kai-Wei},
  abstract = {We design a predictive layer for structured-output prediction (SOP) that can be plugged into any neural network guaranteeing its predictions are consistent with a set of predefined symbolic constraints. Our Semantic Probabilistic Layer (SPL) can model intricate correlations, and hard constraints, over a structured output space all while being amenable to end-to-end learning via maximum likelihood. SPLs combine exact probabilistic inference with logical reasoning in a clean and modular way, learning complex distributions and restricting their support to solutions of the constraint. As such, they can faithfully, and efficiently, model complex SOP tasks beyond the reach of alternative neuro-symbolic approaches. We empirically demonstrate that SPLs outperform these competitors in terms of accuracy on challenging SOP tasks including hierarchical multi-label classification, pathfinding and preference learning, while retaining perfect constraint satisfaction. Our code is made publicly available on Github at github.com/KareemYousrii/SPL.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/LYKPUXYI/Ahmed et al. - Semantic Probabilistic Layers for Neuro-Symbolic L.pdf}
}

@article{ahmedSemanticProbabilisticLayers,
  title = {Semantic {{Probabilistic Layers}} for {{Neuro-Symbolic Learning}}},
  author = {Ahmed, Kareem and Teso, Stefano and Chang, Kai-Wei},
  abstract = {We design a predictive layer for structured-output prediction (SOP) that can be plugged into any neural network guaranteeing its predictions are consistent with a set of predefined symbolic constraints. Our Semantic Probabilistic Layer (SPL) can model intricate correlations, and hard constraints, over a structured output space all while being amenable to end-to-end learning via maximum likelihood. SPLs combine exact probabilistic inference with logical reasoning in a clean and modular way, learning complex distributions and restricting their support to solutions of the constraint. As such, they can faithfully, and efficiently, model complex SOP tasks beyond the reach of alternative neuro-symbolic approaches. We empirically demonstrate that SPLs outperform these competitors in terms of accuracy on challenging SOP tasks including hierarchical multi-label classification, pathfinding and preference learning, while retaining perfect constraint satisfaction. Our code is made publicly available on Github at github.com/KareemYousrii/SPL.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/Y8EH8T7U/Ahmed et al. - Semantic Probabilistic Layers for Neuro-Symbolic L.pdf}
}

@article{ahmedSurveyAnomalyDetection2016,
  title = {A Survey of Anomaly Detection Techniques in Financial Domain},
  author = {Ahmed, Mohiuddin and Mahmood, Abdun Naser and Islam, Md Rafiqul},
  year = {2016},
  journal = {Future Generation Computer Systems},
  volume = {55},
  pages = {278--288},
  publisher = {Elsevier},
  urldate = {2025-02-16},
  file = {/Users/DAADAMS/Zotero/storage/PYNBIQ6A/Ahmed et al. - 2016 - A survey of anomaly detection techniques in financial domain.pdf}
}

@article{ahmedSurveyAnomalyDetection2016,
  title = {A Survey of Anomaly Detection Techniques in Financial Domain},
  author = {Ahmed, Mohiuddin and Mahmood, Abdun Naser and Islam, Md Rafiqul},
  year = {2016},
  journal = {Future Generation Computer Systems},
  volume = {55},
  pages = {278--288},
  publisher = {Elsevier},
  urldate = {2025-02-16}
}

@inproceedings{ainetoModelRecognitionPlanning2019,
  title = {Model Recognition as Planning},
  booktitle = {Proceedings of the {{International Conference}} on {{Automated Planning}} and {{Scheduling}}},
  author = {Aineto, Diego and Jim{\'e}nez, Sergio and Onaindia, Eva and Ram{\'i}rez, Miquel},
  year = {2019},
  volume = {29},
  pages = {13--21},
  urldate = {2024-08-12},
  file = {/Users/DAADAMS/Zotero/storage/ZSLA6DTG/Aineto et al. - 2019 - Model recognition as planning.pdf}
}

@inproceedings{al-hegamiNoveltyFrameworkKnowledge2004,
  title = {Novelty {{Framework}} for {{Knowledge Discovery}} in {{Databases}}},
  booktitle = {Data {{Warehousing}} and {{Knowledge Discovery}}},
  author = {{Al-Hegami}, Ahmed Sultan and Bhatnagar, Vasudha and Kumar, Naveen},
  editor = {Kambayashi, Yahiko and Mohania, Mukesh and W{\"o}{\ss}, Wolfram},
  year = {2004},
  pages = {48--57},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-540-30076-2_5},
  abstract = {Knowledge Discovery in Databases (KDD) is an iterative process that aims at extracting interesting, previously unknown and hidden patterns from huge databases. Use of objective measures of interestingness in popular data mining algorithms often leads to another data mining problem, although of reduced complexity. The reduction in the volume of the discovered rules is desirable in order to improve the efficiency of the overall KDD process. Subjective measures of interestingness are required to achieve this. In this paper we study novelty of the discovered rules as a subjective measure of interestingness. We propose a framework to quantify novelty of the discovered rules in terms of their deviations from the known rules. The computations are carried out using the importance that the user gives to different deviations. The computed degree of novelty is then compared with the user given threshold to report novel rules to the user. We implement the proposed framework and experiment with some public datasets. The experimental results are quite promising.},
  isbn = {978-3-540-30076-2},
  langid = {english},
  keywords = {Association Rule,Data Mining,Domain Knowledge,Knowledge Discovery,Mining Algorithm},
  file = {/Users/DAADAMS/Zotero/storage/W7CWNTW7/Al-Hegami et al. - 2004 - Novelty Framework for Knowledge Discovery in Datab.pdf}
}

@article{alanf.blackwellGoalRecognitionGoal2001,
  title = {Goal Recognition through Goal Graph Analysis},
  author = {{Alan F. Blackwell} and Blackwell, Alan F.},
  year = {2001},
  month = mar,
  journal = {Artificial Intelligence Review},
  volume = {15},
  number = {1},
  pages = {1--30},
  doi = {10.1023/a:1006673610113},
  abstract = {We present a novel approach to goal recognition based on a two-stage paradigm of graph construction and analysis. First, a graph structure called a Goal Graph is constructed to represent the observed actions, the state of the world, and the achieved goals as well as various connections between these nodes at consecutive time steps. Then, the Goal Graph is analysed at each time step to recognise those partially or fully achieved goals that are consistent with the actions observed so far. The Goal Graph analysis also reveals valid plans for the recognised goals or part of these goals. Our approach to goal recognition does not need a plan library. It does not suffer from the problems in the acquisition and hand-coding of large plan libraries, neither does it have the problems in searching the plan space of exponential size. We describe two algorithms for Goal Graph construction and analysis in this paradigm. These algorithms are both provably sound, polynomial-time, and polynomial-space. The number of goals recognised by our algorithms is usually very small after a sequence of observed actions has been processed. Thus the sequence of observed actions is well explained by the recognised goals with little ambiguity. We have evaluated these algorithms in the UNIX domain, in which excellent performance has been achieved in terms of accuracy, efficiency, and scalability.},
  annotation = {MAG ID: 1512990509}
}

@article{aligonCollaborativeFilteringApproach2015,
  title = {A Collaborative Filtering Approach for Recommending {{OLAP}} Sessions},
  author = {Aligon, Julien and Gallinucci, Enrico and Golfarelli, Matteo and Marcel, Patrick and Rizzi, Stefano},
  year = {2015},
  journal = {Decision Support Systems},
  volume = {69},
  pages = {20--30},
  publisher = {Elsevier},
  urldate = {2025-02-16},
  file = {/Users/DAADAMS/Zotero/storage/2EZVU385/Aligon et al. - 2015 - A collaborative filtering approach for recommending OLAP sessions.pdf}
}

@inproceedings{amadoRobustNeurosymbolicGoal2023,
  title = {Robust Neuro-Symbolic Goal and Plan Recognition},
  booktitle = {Proceedings of the {{AAAI Conference}} on {{Artificial Intelligence}}},
  author = {Amado, Leonardo and Pereira, Ramon Fraga and Meneguzzi, Felipe},
  year = {2023},
  volume = {37},
  pages = {11937--11944},
  urldate = {2025-06-16},
  file = {/Users/DAADAMS/Zotero/storage/L5VHE8DH/Amado et al. - 2023 - Robust neuro-symbolic goal and plan recognition.pdf}
}

@misc{amer-yahiaReliableConversationalData2025,
  title = {Towards {{Reliable Conversational Data Analytics}}},
  author = {{Amer-Yahia}, Sihem and Bogojeska, Jasmina and Facchinetti, Roberta and Franceschi, Valeria and Gionis, Aristides and Hose, Katja and Koutrika, Georgia and Kouyos, Roger and Lissandrini, Matteo and Maniu, Silviu and Mirylenka, Katsiaryna and Mottin, Davide and Palpanas, Themis and Rigotti, Mattia and Velegrakis, Yannis},
  year = {2025},
  publisher = {OpenProceedings.org},
  doi = {10.48786/EDBT.2025.78},
  urldate = {2025-09-08},
  abstract = {Conversational AI systems for data analytics aim to enable the extraction of analytical insights by means of conversational interfaces. Such interfaces are powered by a mix of query modalities and machine learning methods for analytics, and are relying on Large Language Models (LLMs) for natural language generation. However, critical challenges hinder their adoption. The question we discuss is how to devise reliable Conversational Data Analytics (CDA) systems producing timely, consistent, and verifiable answers. To reach this goal, we identify five properties that impose a paradigm shift in the way systems are built and in the way they interact with users. To illustrate that shift, we describe a prototypical CDA system. Realizing these properties involves either extending existing components, or redesigning components from scratch; both solutions require overcoming data management challenges and conducting a tight integration with advanced data management and machine learning techniques.},
  langid = {english},
  keywords = {Database Technology},
  file = {/Users/DAADAMS/Zotero/storage/IZ5UIMI3/Amer-Yahia et al. - 2025 - Towards Reliable Conversational Data Analytics.pdf}
}

@article{amirHIGHLIGHTSSummarizingAgent,
  title = {{{HIGHLIGHTS}}: {{Summarizing Agent Behavior}} to {{People}}},
  author = {Amir, Dan and Amir, Ofra},
  abstract = {People increasingly interact with autonomous agents. This paper introduces and formalizes the problem of automatically generating a summary of an agent's behavior with the goal of increasing people's familiarity with the agent's capabilities and limitations. In contrast with prior approaches which developed methods for explaining a single decision made by an agent, our approach aims to provide users with a summary that describes the agent's behavior in different situations. We hypothesize that reviewing such summaries could help people in tasks such as choosing between agents or determining the level of autonomy to grant to an agent. We develop ``HIGHLIGHTS'', an algorithm that produces a summary of an agent's behavior by extracting important trajectories from simulations of the agent. We conducted a human-subject experiment to evaluate whether HIGHLIGHTS summaries help people assess the capabilities of agents. Our results show that participants were more successful at evaluating the capabilities of agents when presented with HIGHLIGHTS summaries compared to baseline summaries, and rated them as more helpful. We also explore a variant of the HIGHLIGHTS algorithm which aims to increase the diversity of states included in the summary, and show that this modification further improves people's ability to assess agents' capabilities.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/Y56DN3CH/Amir and Amir - HIGHLIGHTS Summarizing Agent Behavior to People.pdf}
}

@article{amsterdamerCrowdMinerMiningAssociation2013,
  title = {{{CrowdMiner}}: Mining Association Rules from the Crowd},
  shorttitle = {{{CrowdMiner}}},
  author = {Amsterdamer, Yael and Grossman, Yael and Milo, Tova and Senellart, Pierre},
  year = {2013},
  month = aug,
  journal = {Proceedings of the VLDB Endowment},
  volume = {6},
  number = {12},
  pages = {1250--1253},
  issn = {2150-8097},
  doi = {10.14778/2536274.2536288},
  urldate = {2024-12-08},
  abstract = {This demo presents CrowdMiner , a system enabling the mining of interesting data patterns from the crowd. While traditional data mining techniques have been used extensively for finding patterns in classic databases, they are not always suitable for the crowd, mainly because humans tend to remember only simple trends and summaries rather than exact details. To address this, CrowdMiner employs a novel crowd-mining algorithm, designed specifically for this context. The algorithm iteratively chooses appropriate questions to ask the crowd, while aiming to maximize the knowledge gain at each step. We demonstrate CrowdMiner through a WellBeing portal, constructed interactively by mining the crowd, and in particular the conference participants, for common health related practices and trends.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/FLX3WKLN/Amsterdamer et al. - 2013 - CrowdMiner mining association rules from the crowd.pdf}
}

@article{aoneTrainableSummarizerKnowledge1999,
  title = {A Trainable Summarizer with Knowledge Acquired from Robust {{NLP}} Techniques},
  author = {Aone, Chinatsu},
  year = {1999},
  journal = {Advances in automatic text summarization},
  pages = {71--80},
  publisher = {The Mit Press},
  urldate = {2025-02-16}
}

@inproceedings{argentaMultiAgentPlanRecognition2016,
  title = {Multi-{{Agent Plan Recognition}} as {{Planning}} ({{MAPRAP}}).},
  booktitle = {{{ICAART}} (2)},
  author = {Argenta, Chris and Doyle, Jon},
  year = {2016},
  pages = {141--148},
  urldate = {2024-08-12},
  file = {/Users/DAADAMS/Zotero/storage/8GPE7W3V/Argenta and Doyle - 2016 - Multi-Agent Plan Recognition as Planning (MAPRAP)..pdf}
}

@inproceedings{asaiClassicalPlanningDeep2018,
  title = {Classical Planning in Deep Latent Space: {{Bridging}} the Subsymbolic-Symbolic Boundary},
  shorttitle = {Classical Planning in Deep Latent Space},
  booktitle = {Proceedings of the Aaai Conference on Artificial Intelligence},
  author = {Asai, Masataro and Fukunaga, Alex},
  year = {2018},
  volume = {32},
  urldate = {2024-03-19},
  file = {/Users/DAADAMS/Zotero/storage/5XFSRZKD/Asai and Fukunaga - 2018 - Classical planning in deep latent space Bridging .pdf}
}

@article{atkinsonMeasurementInequality1970,
  title = {On the Measurement of Inequality},
  author = {Atkinson, Anthony B.},
  year = {1970},
  journal = {Journal of economic theory},
  volume = {2},
  number = {3},
  pages = {244--263},
  urldate = {2024-08-12},
  file = {/Users/DAADAMS/Zotero/storage/D44ABMJU/Atkinson - 1970 - On the measurement of inequality.pdf}
}

@article{ayemowaSystematicReviewLiterature2024,
  title = {A Systematic Review of the Literature on Deep Learning Approaches for Cross-Domain Recommender Systems},
  author = {Ayemowa, Matthew O. and Ibrahim, Roliana and Bena, Yunusa Adamu},
  year = {2024},
  month = dec,
  journal = {Decision Analytics Journal},
  volume = {13},
  pages = {100518},
  issn = {2772-6622},
  doi = {10.1016/j.dajour.2024.100518},
  urldate = {2025-09-08},
  abstract = {The increase in online information and the expanding diversity of user preferences require developing improved recommender systems. Cross-domain recommender systems (CDRS) have emerged as a favorable solution to solve issues related to cold start, data sparsity, and diversity by leveraging knowledge from the source domains. This systematic literature review delves into the latest deep learning approaches utilized for CDRS, comprehensively analyzing state-of-the-art techniques, methodologies, metrics, datasets, and applications. We systematically review selected primary studies from popular databases covering sixty-eight publications from 2019 to March 2024. The review process involved selecting relevant studies based on the predefined inclusion and exclusion criteria to ensure the inclusion of high-quality research. Key deep learning (DL) models explored include neural collaborative filtering, convolutional neural networks, recurrent neural networks, variational autoencoder, and generative adversarial networks. We also examine the hybrid models that integrate DL with traditional machine learning techniques to enhance recommendation performance. Our findings reveal that DL approaches significantly improve accuracy, cold start, and data sparsity. This review also identifies current trends and future research directions, emphasizing the potential of Artificial Intelligence (AI), transfer learning, and reinforcement learning in advancing CDRS. In our analysis, we discovered that the domains mainly utilized are movies, books, and music, respectively, and the most widely used evaluation metrics are root mean square error (RMSE) and normalized discounted cumulative gain (NDCG). Research challenges and future scope are also highlighted to assist the researchers and practitioners seeking to develop robust cross-domain recommender systems using DL techniques.},
  keywords = {Cross-domain,Decision making,Deep learning,Predictive analytics,Recommender systems,Users behavior analysis},
  file = {/Users/DAADAMS/Zotero/storage/ZG3YR67A/Ayemowa et al. - 2024 - A systematic review of the literature on deep learning approaches for cross-domain recommender syste.pdf;/Users/DAADAMS/Zotero/storage/SELIG6F5/S277266222400122X.html}
}

@article{babuSPARTANModelbasedSemantic2001,
  title = {{{SPARTAN}}: A Model-Based Semantic Compression System for Massive Data Tables},
  shorttitle = {{{SPARTAN}}},
  author = {Babu, Shivnath and Garofalakis, Minos and Rastogi, Rajeev},
  year = {2001},
  month = jun,
  journal = {ACM SIGMOD Record},
  volume = {30},
  number = {2},
  pages = {283--294},
  issn = {0163-5808},
  doi = {10.1145/376284.375693},
  urldate = {2025-02-16},
  abstract = {While a variety of lossy compression schemes have been developed for certain forms of digital data (e.g., images, audio, video), the area of lossy compression techniques for arbitrary data tables has been left relatively unexplored. Nevertheless, such techniques are clearly motivated by the ever-increasing data collection rates of modern enterprises and the need for effective, guaranteed-quality approximate answers to queries over massive relational data sets. In this paper, we propose               SPARTAN               , a system that takes advantage of attribute semantics and data-mining models to perform lossy compression of massive data tables.               SPARTAN               is based on the novel idea of exploiting predictive data correlations and prescribed error tolerances for individual attributes to construct concise and accurate               Classification and Regression Tree (CaRT)               models for entire columns of a table. More precisely,               SPARTAN               selects a certain subset of attributes for which no values are explicitly stored in the compressed table; instead, concise CaRTs that predict these values (within the prescribed error bounds) are maintained. To restrict the huge search space and construction cost of possible CaRT predictors,               SPARTAN               employs sophisticated learning techniques and novel combinatorial optimization algorithms. Our experimentation with several real-life data sets offers convincing evidence of the effectiveness of               SPARTAN               's model-based approach ---               SPARTAN               is able to consistently yield substantially better compression ratios than existing semantic or syntactic compression tools (e.g., gzip) while utilizing only small data samples for model inference.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/9PASXCBI/Babu et al. - 2001 - SPARTAN a model-based semantic compression system for massive data tables.pdf}
}

@misc{baekResearchAgentIterativeResearch2024,
  title = {{{ResearchAgent}}: {{Iterative Research Idea Generation}} over {{Scientific Literature}} with {{Large Language Models}}},
  shorttitle = {{{ResearchAgent}}},
  author = {Baek, Jinheon and Jauhar, Sujay Kumar and Cucerzan, Silviu and Hwang, Sung Ju},
  year = {2024},
  month = apr,
  number = {arXiv:2404.07738},
  eprint = {2404.07738},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2024-04-29},
  abstract = {Scientific Research, vital for improving human life, is hindered by its inherent complexity, slow pace, and the need for specialized experts. To enhance its productivity, we propose a ResearchAgent, a large language modelpowered research idea writing agent, which automatically generates problems, methods, and experiment designs while iteratively refining them based on scientific literature. Specifically, starting with a core paper as the primary focus to generate ideas, our ResearchAgent is augmented not only with relevant publications through connecting information over an academic graph but also entities retrieved from an entity-centric knowledge store based on their underlying concepts, mined and shared across numerous papers. In addition, mirroring the human approach to iteratively improving ideas with peer discussions, we leverage multiple ReviewingAgents that provide reviews and feedback iteratively. Further, they are instantiated with human preference-aligned large language models whose criteria for evaluation are derived from actual human judgments. We experimentally validate our ResearchAgent on scientific publications across multiple disciplines, showcasing its effectiveness in generating novel, clear, and valid research ideas based on human and model-based evaluation results.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/DAADAMS/Zotero/storage/ZGYXE8BY/Baek et al. - 2024 - ResearchAgent Iterative Research Idea Generation .pdf}
}

@inproceedings{barelATENAAutonomousSystem2019,
  title = {{{ATENA}}: {{An Autonomous System}} for {{Data Exploration Based}} on {{Deep Reinforcement Learning}}},
  shorttitle = {{{ATENA}}},
  booktitle = {Proceedings of the 28th {{ACM International Conference}} on {{Information}} and {{Knowledge Management}}},
  author = {Bar El, Ori and Milo, Tova and Somech, Amit},
  year = {2019},
  month = nov,
  pages = {2873--2876},
  publisher = {ACM},
  address = {Beijing China},
  doi = {10.1145/3357384.3357845},
  urldate = {2024-12-08},
  abstract = {Exploratory Data Analysis (EDA), is an important yet challenging task, that requires profound analytical skills and familiarity with the data domain. While Deep Reinforcement Learning (DRL) is nowadays used to solve AI challenges previously considered to be intractable, to our knowledge such solutions have not yet been applied to EDA.},
  isbn = {978-1-4503-6976-3},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/T7Q6SZC4/Bar El et al. - 2019 - ATENA An Autonomous System for Data Exploration Based on Deep Reinforcement Learning.pdf}
}

@inproceedings{barelAutomaticallyGeneratingData2020,
  title = {Automatically {{Generating Data Exploration Sessions Using Deep Reinforcement Learning}}},
  booktitle = {Proceedings of the 2020 {{ACM SIGMOD International Conference}} on {{Management}} of {{Data}}},
  author = {Bar El, Ori and Milo, Tova and Somech, Amit},
  year = {2020},
  month = jun,
  pages = {1527--1537},
  publisher = {ACM},
  address = {Portland OR USA},
  doi = {10.1145/3318464.3389779},
  urldate = {2024-12-08},
  abstract = {Exploratory Data Analysis (EDA) is an essential yet highly demanding task. To get a head start before exploring a new dataset, data scientists often prefer to view existing EDA notebooks -- illustrative, curated exploratory sessions, on the same dataset, that were created by fellow data scientists who shared them online. Unfortunately, such notebooks are not always available (e.g., if the dataset is new or confidential). To address this, we present ATENA, a system that takes an input dataset and auto-generates a compelling exploratory session, presented in an EDA notebook. We shape EDA into a control problem, and devise a novel Deep Reinforcement Learning (DRL) architecture to effectively optimize the notebook generation. Though ATENA uses a limited set of EDA operations, our experiments show that it generates useful EDA notebooks, allowing users to gain actual insights.},
  isbn = {978-1-4503-6735-6},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/3Y3TFVJL/Bar El et al. - 2020 - Automatically Generating Data Exploration Sessions Using Deep Reinforcement Learning.pdf}
}

@inproceedings{barzilayInformationFusionContext1999,
  title = {Information Fusion in the Context of Multi-Document Summarization},
  booktitle = {Proceedings of the 37th Annual Meeting of the {{Association}} for {{Computational Linguistics}}},
  author = {Barzilay, Regina and McKeown, Kathleen and Elhadad, Michael},
  year = {1999},
  pages = {550--557},
  urldate = {2025-02-16},
  file = {/Users/DAADAMS/Zotero/storage/FISZMFSX/Barzilay et al. - 1999 - Information fusion in the context of multi-document summarization.pdf}
}

@article{barzilayUsingLexicalChains1997,
  title = {Using Lexical Chains for Text Summarization},
  author = {Barzilay, Regina and Elhadad, Michael},
  year = {1997},
  file = {/Users/DAADAMS/Zotero/storage/4LGMZDBN/Barzilay and Elhadad - 1997 - Using lexical chains for text summarization.pdf}
}

@article{bastianoetomoNoteBoundingRegret2019,
  title = {A {{Note}} on {{Bounding Regret}} of the {{C}}\${\textasciicircum}2\${{UCB Contextual Combinatorial Bandit}}},
  author = {{Bastian Oetomo} and Oetomo, Bastian and {Malinga Perera} and Perera, R. Malinga and {Malinga Perera} and Perera, Malinga and {Renata Borovica-Gaji{\'c}} and {Borovica-Gajic}, Renata and {Benjamin I. P. Rubinstein} and Rubinstein, Benjamin I. P.},
  year = {2019},
  month = feb,
  journal = {arXiv: Learning},
  abstract = {We revisit the proof by Qin et al. (2014) of bounded regret of the C\${\textasciicircum}2\$UCB contextual combinatorial bandit. We demonstrate an error in the proof of volumetric expansion of the moment matrix, used in upper bounding a function of context vector norms. We prove a relaxed inequality that yields the originally-stated regret bound.},
  annotation = {MAG ID: 2915194867}
}

@article{battleCharacterizingExploratoryVisual2019,
  title = {Characterizing {{Exploratory Visual Analysis}}: {{A Literature Review}} and {{Evaluation}} of {{Analytic Provenance}} in {{Tableau}}},
  shorttitle = {Characterizing {{Exploratory Visual Analysis}}},
  author = {Battle, Leilani and Heer, Jeffrey},
  year = {2019},
  month = jun,
  journal = {Computer Graphics Forum},
  volume = {38},
  number = {3},
  pages = {145--159},
  issn = {0167-7055, 1467-8659},
  doi = {10.1111/cgf.13678},
  urldate = {2025-09-11},
  abstract = {Supporting exploratory visual analysis (EVA) is a central goal of visualization research, and yet our understanding of the process is arguably vague and piecemeal. We contribute a consistent definition of EVA through review of the relevant literature, and an empirical evaluation of existing assumptions regarding how analysts perform EVA using Tableau, a popular visual analysis tool. We present the results of a study where 27 Tableau users answered various analysis questions across 3 datasets. We measure task performance, identify recurring patterns across participants' analyses, and assess variance from task specificity and dataset. We find striking differences between existing assumptions and the collected data. Participants successfully completed a variety of tasks, with over 80\% accuracy across focused tasks with measurably correct answers. The observed cadence of analyses is surprisingly slow compared to popular assumptions from the database community. We find significant overlap in analyses across participants, showing that EVA behaviors can be predictable. Furthermore, we find few structural differences between behavior graphs for open-ended and more focused exploration tasks.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/JL4ZC56W/Battle and Heer - 2019 - Characterizing Exploratory Visual Analysis A Literature Review and Evaluation of Analytic Provenanc.pdf}
}

@article{baxendaleMachinemadeIndexTechnical1958,
  title = {Machine-Made Index for Technical Literature---an Experiment},
  author = {Baxendale, Phyllis B.},
  year = {1958},
  journal = {IBM Journal of research and development},
  volume = {2},
  number = {4},
  pages = {354--361},
  publisher = {IBM},
  urldate = {2025-02-16}
}

@article{bergerDiversityPlanktonicForaminifera1970,
  title = {Diversity of {{Planktonic Foraminifera}} in {{Deep-Sea Sediments}}},
  author = {Berger, Wolfgang H. and Parker, Frances L.},
  year = {1970},
  month = jun,
  journal = {Science},
  volume = {168},
  number = {3937},
  pages = {1345--1347},
  issn = {0036-8075, 1095-9203},
  doi = {10.1126/science.168.3937.1345},
  urldate = {2024-08-12},
  abstract = {The diversity of a planktonic foraminiferal assemblage on the ocean floor depends on the state of preservation of that assemblage. As dissolution progresses, species diversity (number of species in the assemblage) decreases, but compound diversity (based on relative species abundance) first increases and then decreases; species dominance first decreases and then increases. The reason for these changes is that the species most susceptible to solution deliver more sediment to the ocean floor than do species with solution-resistant shells, possibly because the more soluble tests are produced in surface waters, where growth and production are greatest.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/ASI2QKFS/sfxlcl41.html}
}

@misc{bertelootAssociationRulesMining2023,
  title = {Association {{Rules Mining}} with {{Auto-Encoders}}},
  author = {Berteloot, Th{\'e}ophile and Khoury, Richard and Durand, Audrey},
  year = {2023},
  month = apr,
  number = {arXiv:2304.13717},
  eprint = {2304.13717},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2304.13717},
  urldate = {2024-12-23},
  abstract = {Association rule mining is one of the most studied research fields of data mining, with applications ranging from grocery basket problems to explainable classification systems. Classical association rule mining algorithms have several limitations, especially with regards to their high execution times and number of rules produced. Over the past decade, neural network solutions have been used to solve various optimization problems, such as classification, regression or clustering. However there are still no efficient way association rules using neural networks. In this paper, we present an auto-encoder solution to mine association rule called ARM-AE. We compare our algorithm to FP-Growth and NSGAII on three categorical datasets, and show that our algorithm discovers high support and confidence rule set and has a better execution time than classical methods while preserving the quality of the rule set produced.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Databases,Computer Science - Machine Learning},
  file = {/Users/DAADAMS/Zotero/storage/ANCRXF34/Berteloot et al. - 2023 - Association Rules Mining with Auto-Encoders.pdf}
}

@article{bettiniSystemNeuralDiversity2023,
  title = {System Neural Diversity: Measuring Behavioral Heterogeneity in Multi-Agent Learning},
  shorttitle = {System Neural Diversity},
  author = {Bettini, Matteo and Shankar, Ajay and Prorok, Amanda},
  year = {2023},
  journal = {arXiv preprint arXiv:2305.02128},
  eprint = {2305.02128},
  urldate = {2024-09-11},
  archiveprefix = {arXiv},
  file = {/Users/DAADAMS/Zotero/storage/D8R6782W/Bettini et al. - 2023 - System neural diversity measuring behavioral heterogeneity in multi-agent learning.pdf}
}

@misc{blueghostyiBlueGhostYiDMRec2025,
  title = {{{BlueGhostYi}}/{{DMRec}}},
  author = {BlueGhostYi},
  year = {2025},
  month = aug,
  urldate = {2025-09-08},
  abstract = {[SIGIR2025] Towards Distribution Matching between Collaborative and Language Spaces for Generative Recommendation}
}

@inproceedings{boultUnifyingFrameworkFormal2021,
  title = {Towards a Unifying Framework for Formal Theories of Novelty},
  booktitle = {Proceedings of the {{AAAI}} Conference on Artificial Intelligence},
  author = {Boult, Terrance and Grabowicz, Przemyslaw and Prijatelj, Derek and Stern, Roni and Holder, Lawrence and Alspector, Joshua and Jafarzadeh, Mohsen M. and Ahmad, Toqueer and Dhamija, Akshay and Li, Chunchun},
  year = {2021},
  volume = {35},
  pages = {15047--15052},
  urldate = {2024-05-07},
  file = {/Users/DAADAMS/Zotero/storage/MJPEIW5C/Boult et al. - 2021 - Towards a unifying framework for formal theories o.pdf}
}

@inproceedings{brancasReliableSQLSynthesis2024,
  title = {Towards Reliable {{SQL}} Synthesis: {{Fuzzing-based}} Evaluation and Disambiguation},
  shorttitle = {Towards Reliable {{SQL}} Synthesis},
  booktitle = {International {{Conference}} on {{Fundamental Approaches}} to {{Software Engineering}}},
  author = {Brancas, Ricardo and {Terra-Neves}, Miguel and Ventura, Miguel and Manquinho, Vasco and Martins, Ruben},
  year = {2024},
  pages = {232--254},
  publisher = {Springer Nature Switzerland Cham},
  urldate = {2025-08-28},
  file = {/Users/DAADAMS/Zotero/storage/4JF5EMXF/Brancas et al. - 2024 - Towards reliable SQL synthesis Fuzzing-based evaluation and disambiguation.pdf}
}

@article{brayOrdinationUplandForest1957,
  title = {An Ordination of the Upland Forest Communities of Southern {{Wisconsin}}},
  author = {Bray, J. Roger and Curtis, John T.},
  year = {1957},
  journal = {Ecological monographs},
  volume = {27},
  number = {4},
  eprint = {1942268},
  eprinttype = {jstor},
  pages = {326--349},
  publisher = {JSTOR},
  urldate = {2024-08-12}
}

@inproceedings{breunigDataBubblesQuality2001,
  title = {Data Bubbles: Quality Preserving Performance Boosting for Hierarchical Clustering},
  shorttitle = {Data Bubbles},
  booktitle = {Proceedings of the 2001 {{ACM SIGMOD}} International Conference on {{Management}} of Data},
  author = {Breunig, Markus M. and Kriegel, Hans-Peter and Kr{\"o}ger, Peer and Sander, J{\"o}rg},
  year = {2001},
  month = may,
  pages = {79--90},
  publisher = {ACM},
  address = {Santa Barbara California USA},
  doi = {10.1145/375663.375672},
  urldate = {2025-02-16},
  isbn = {978-1-58113-332-5},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/W3VU7WS6/Breunig et al. - 2001 - Data bubbles quality preserving performance boosting for hierarchical clustering.pdf}
}

@incollection{breunigFastHierarchicalClustering2000,
  title = {Fast {{Hierarchical Clustering Based}} on {{Compressed Data}} and {{OPTICS}}},
  booktitle = {Principles of {{Data Mining}} and {{Knowledge Discovery}}},
  author = {Breunig, Markus M. and Kriegel, Hans-Peter and Sander, J{\"o}rg},
  editor = {Goos, G. and Hartmanis, J. and Van Leeuwen, J. and Zighed, Djamel A. and Komorowski, Jan and {\.Z}ytkow, Jan},
  year = {2000},
  volume = {1910},
  pages = {232--242},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/3-540-45372-5_23},
  urldate = {2025-02-16},
  isbn = {978-3-540-41066-9 978-3-540-45372-7},
  file = {/Users/DAADAMS/Zotero/storage/FQJA673E/Breunig et al. - 2000 - Fast Hierarchical Clustering Based on Compressed Data and OPTICS.pdf}
}

@article{browneSurveyMonteCarlo2012,
  title = {A {{Survey}} of {{Monte Carlo Tree Search Methods}}},
  author = {Browne, Cameron B. and Powley, Edward and Whitehouse, Daniel and Lucas, Simon M. and Cowling, Peter I. and Rohlfshagen, Philipp and Tavener, Stephen and Perez, Diego and Samothrakis, Spyridon and Colton, Simon},
  year = {2012},
  month = mar,
  journal = {IEEE Transactions on Computational Intelligence and AI in Games},
  volume = {4},
  number = {1},
  pages = {1--43},
  issn = {1943-068X, 1943-0698},
  doi = {10.1109/TCIAIG.2012.2186810},
  urldate = {2024-03-15},
  abstract = {Monte Carlo Tree Search (MCTS) is a recently proposed search method that combines the precision of tree search with the generality of random sampling. It has received considerable interest due to its spectacular success in the difficult problem of computer Go, but has also proved beneficial in a range of other domains. This paper is a survey of the literature to date, intended to provide a snapshot of the state of the art after the first five years of MCTS research. We outline the core algorithm's derivation, impart some structure on the many variations and enhancements that have been proposed, and summarise the results from the key game and non-game domains to which MCTS methods have been applied. A number of open research questions indicate that the field is ripe for future work.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/EXHRBXNA/Browne et al. - 2012 - A Survey of Monte Carlo Tree Search Methods.pdf}
}

@inproceedings{brownLibratusSuperhumanAI2017,
  title = {Libratus: {{The Superhuman AI}} for {{No-Limit Poker}}},
  shorttitle = {Libratus},
  booktitle = {Proceedings of the {{Twenty-Sixth International Joint Conference}} on {{Artificial Intelligence}}},
  author = {Brown, Noam and Sandholm, Tuomas},
  year = {2017},
  month = aug,
  pages = {5226--5228},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  address = {Melbourne, Australia},
  doi = {10.24963/ijcai.2017/772},
  urldate = {2024-03-15},
  abstract = {No-limit Texas Hold'em is the most popular variant of poker in the world. Heads-up no-limit Texas Hold'em is the main benchmark challenge for AI in imperfect-information games. We present Libratus, the first---and so far only---AI to defeat top human professionals in that game. Libratus's architecture features three main modules, each of which has new algorithms: pre-computing a solution to an abstraction of the game which provides a high-level blueprint for the strategy of the AI, a new nested subgame-solving algorithm which repeatedly calculates a more detailed strategy as play progresses, and a self-improving module which augments the pre-computed blueprint over time.},
  isbn = {978-0-9992411-0-3},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/B424932V/Brown and Sandholm - 2017 - Libratus The Superhuman AI for No-Limit Poker.pdf}
}

@inproceedings{brownRegretBasedPruningExtensiveForm2015,
  title = {Regret-{{Based Pruning}} in {{Extensive-Form Games}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Brown, Noam and Sandholm, Tuomas},
  year = {2015},
  volume = {28},
  publisher = {Curran Associates, Inc.},
  urldate = {2024-03-15},
  abstract = {Counterfactual Regret Minimization (CFR) is a leading algorithm for finding a Nash equilibrium in large zero-sum imperfect-information games. CFR is an iterative algorithm that repeatedly traverses the game tree, updating regrets at each information set.We introduce an improvement to CFR that prunes any path of play in the tree, and its descendants, that has negative regret. It revisits that sequence at the earliest subsequent CFR iteration where the regret could have become positive, had that path been explored on every iteration. The new algorithm maintains CFR's convergence guarantees while making iterations significantly faster---even if previously known pruning techniques are used in the comparison. This improvement carries over to CFR+, a recent variant of CFR. Experiments show an order of magnitude speed improvement, and the relative speed improvement increases with the size of the game.},
  file = {/Users/DAADAMS/Zotero/storage/A9HK978S/Brown and Sandholm - 2015 - Regret-Based Pruning in Extensive-Form Games.pdf}
}

@article{c.l.carterEfficientAttributeorientedGeneralization1998,
  title = {Efficient Attribute-Oriented Generalization for Knowledge Discovery from Large Databases},
  author = {{C.L. Carter} and Carter, Colin L. and {Howard J. Hamilton} and Hamilton, Howard J.},
  year = {1998},
  month = mar,
  journal = {IEEE Transactions on Knowledge and Data Engineering},
  volume = {10},
  number = {2},
  pages = {193--208},
  doi = {10.1109/69.683752},
  abstract = {We present GDBR (Generalize DataBase Relation) and FIGR (Fast, Incremental Generalization and Regeneralization), two enhancements of Attribute Oriented Generalization, a well known knowledge discovery from databases technique. GDBR and FIGR are both O(n) and, as such, are optimal. GDBR is an online algorithm and requires only a small, constant amount of space. FIGR also requires a constant amount of space that is generally reasonable, although under certain circumstances, may grow large. FIGR is incremental, allowing changes to the database to be reflected in the generalization results without rereading input data. FIGR also allows fast regeneralization to both higher and lower levels of generality without rereading input. We compare GDBR and FIGR to two previous algorithms, LCHR and AOI, which are O(n log n) and O(np), respectively, where n is the number of input tuples and p the number of tuples in the generalized relation. Both require O(n) space that, for large input, causes memory problems. We implemented all four algorithms and ran empirical tests, and we found that GDBR and FIGR are faster. In addition, their runtimes increase only linearly as input size increases, while the runtimes of LCHR and AOI increase greatly when input size exceeds memory limitations.},
  annotation = {MAG ID: 2166582235}
}

@article{caiAttributeorientedInductionRelational1989,
  title = {Attribute-Oriented Induction in Relational Databases},
  author = {Cai, Yandong},
  year = {1989},
  publisher = {Simon Fraser University},
  urldate = {2025-02-16},
  file = {/Users/DAADAMS/Zotero/storage/WYZQQYIT/Cai - 1989 - Attribute-oriented induction in relational databases.pdf}
}

@inproceedings{carbonellUseMMRDiversitybased1998,
  title = {The Use of {{MMR}}, Diversity-Based Reranking for Reordering Documents and Producing Summaries},
  booktitle = {Proceedings of the 21st Annual International {{ACM SIGIR}} Conference on {{Research}} and Development in Information Retrieval},
  author = {Carbonell, Jaime and Goldstein, Jade},
  year = {1998},
  month = aug,
  pages = {335--336},
  publisher = {ACM},
  address = {Melbourne Australia},
  doi = {10.1145/290941.291025},
  urldate = {2025-02-16},
  isbn = {978-1-58113-015-7},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/Z6YPASFR/Carbonell and Goldstein - 1998 - The use of MMR, diversity-based reranking for reordering documents and producing summaries.pdf}
}

@article{chandolaSummarizationCompressingData2007,
  title = {Summarization -- Compressing Data into an Informative Representation},
  author = {Chandola, Varun and Kumar, Vipin},
  year = {2007},
  month = aug,
  journal = {Knowledge and Information Systems},
  volume = {12},
  number = {3},
  pages = {355--378},
  issn = {0219-1377, 0219-3116},
  doi = {10.1007/s10115-006-0039-1},
  urldate = {2025-02-03},
  abstract = {In this paper, we formulate the problem of summarization of a data set of transactions with categorical attributes as an optimization problem involving two objective functions -- compaction gain and information loss. We propose metrics to characterize the output of any summarization algorithm. We investigate two approaches to address this problem. The first approach is an adaptation of clustering and the second approach makes use of frequent itemsets from the association analysis domain. We illustrate one application of summarization in the field of network data where we show how our technique can be effectively used to summarize network traffic into a compact but meaningful representation. Specifically, we evaluate our proposed algorithms on the 1998 DARPA Off-Line Intrusion Detection Evaluation data and network data generated by SKAION Corp for the ARDA information assurance program.},
  copyright = {http://www.springer.com/tdm},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/RL556HEB/Chandola and Kumar - 2007 - Summarization – compressing data into an informative representation.pdf}
}

@article{chandolaSummarizationCompressingData2007a,
  title = {Summarization--Compressing Data into an Informative Representation},
  author = {Chandola, Varun and Kumar, Vipin},
  year = {2007},
  journal = {Knowledge and Information Systems},
  volume = {12},
  pages = {355--378},
  publisher = {Springer},
  urldate = {2025-02-03},
  file = {/Users/DAADAMS/Zotero/storage/5ZR4ZUKW/Chandola and Kumar - 2007 - Summarization–compressing data into an informative representation.pdf}
}

@inproceedings{chanMaintainingInteractivityExploring2008,
  title = {Maintaining Interactivity While Exploring Massive Time Series},
  booktitle = {2008 {{IEEE Symposium}} on {{Visual Analytics Science}} and {{Technology}}},
  author = {Chan, Sye-Min and Xiao, Ling and Gerth, John and Hanrahan, Pat},
  year = {2008},
  pages = {59--66},
  publisher = {IEEE},
  urldate = {2024-08-12}
}

@misc{chansonAutomaticGenerationComparison2022,
  title = {Automatic Generation of Comparison Notebooks for Interactive Data Exploration},
  author = {Chanson, Alexandre and Labroche, Nicolas and Marcel, Patrick and Rizzi, Stefano and T'Kindt, Vincent},
  year = {2022},
  publisher = {OpenProceedings.org},
  doi = {10.48786/EDBT.2022.15},
  urldate = {2025-09-10},
  abstract = {We consider the problem of generating SQL notebooks of comparison queries for Exploratory Data Analysis (EDA). A comparison query allows to find insights in a dataset by specifying the comparison of subsets of data. In this paper, we study the problem of generating sequences of comparison queries that are insightful and coherent. We propose exact and approximate resolution approaches, and study their efficiency and effectiveness on artificial and real datasets, as well as with a user study.},
  langid = {english},
  keywords = {Database Technology},
  file = {/Users/DAADAMS/Zotero/storage/S6WV5R2J/Chanson et al. - 2022 - Automatic generation of comparison notebooks for interactive data exploration.pdf}
}

@inproceedings{chansonInterestingnessMeasuresExploratory2025a,
  title = {Interestingness {{Measures}} for~{{Exploratory Data Analysis}}: A~{{Survey}}},
  shorttitle = {Interestingness {{Measures}} for~{{Exploratory Data Analysis}}},
  booktitle = {New {{Trends}} in {{Database}} and {{Information Systems}}},
  author = {Chanson, Alexandre and Labroche, Nicolas and Marcel, Patrick and Perlata, Ver{\'o}nika and Vassiliadis, Panos},
  editor = {Tekli, Joe and Gamper, Johann and Chbeir, Richard and Manolopoulos, Yannis and Sassi, Salma and Ivanovic, Mirjana and {Vargas-Solar}, Genoveva and Zumpano, Ester},
  year = {2025},
  pages = {14--24},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-70421-5_2},
  abstract = {Exploratory Data Analysis (EDA) is the tedious activity of interactively analyzing a dataset to extract insights. Many approaches aiming at supporting EDA were recently proposed. They all rely on interestingness measures to score the importance of insights. This paper surveys and categorizes the different interestingness measures proposed in the literature for approaches aiming at automating EDA. The lessons learned from this survey allow to point out promising research directions.},
  isbn = {978-3-031-70421-5},
  langid = {english},
  keywords = {EDA,Insights,Interestingness measures},
  file = {/Users/DAADAMS/Zotero/storage/VU2EJ8QB/Chanson et al. - 2025 - Interestingness Measures for Exploratory Data Analysis a Survey.pdf}
}

@article{chaudhuriAutomatedQuestionGeneration2018,
  title = {Automated {{Question Generation}} on {{Tabular Data}} for {{Conversational Data Exploration}}},
  author = {Chaudhuri, Ritwik},
  year = {2018},
  abstract = {Exploratory data analysis (EDA) is an essential step for analyzing a dataset to derive insights. Several EDA techniques have been explored in the literature. Many of them leverage visualizations through various plots. But it is not easy to interpret them for a non-technical user, and producing appropriate visualizations is also tough when there are a large number of columns. Few other works provide a view of some interesting slices of data but it is still difficult for the user to draw relevant insights from them. Of late, conversational data exploration is gaining a lot of traction among non-technical users. It helps the user to explore the dataset without having deep technical knowledge about the data. Towards this, we propose a system that recommends interesting questions in natural language based on relevant slices of a dataset in a conversational setting. Specifically, given a dataset, we pick a select set of interesting columns and identify interesting slices of such columns and column combinations based on few interestingness measures. We use our own fine-tuned variation of a pre-trained language model(T5) to generate natural language questions in a specific manner. We then slot-fill values in the generated questions and rank them for recommendations. We show the utility of our proposed system in a coversational setting with a collection of real datasets.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/PAXR5XDD/Chaudhuri - 2018 - Automated Question Generation on Tabular Data for Conversational Data Exploration.pdf}
}

@article{chaudhuriAutomatedRankingDatabase,
  title = {Automated {{Ranking}} of {{Database Query Results}}},
  author = {Chaudhuri, Surajit and Agrawal, Sanjay and Das, Gautam},
  abstract = {Ranking and returning the most relevant results of a query is a popular paradigm in Information Retrieval. We discuss challenges and investigate several approaches to enable ranking in databases, including adaptations of known techniques from information retrieval. We present results of preliminary experiments.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/PUS772X6/Chaudhuri et al. - Computer Science Dept Stanford University.pdf}
}

@article{chaudhuriProbabilisticInformationRetrieval2006,
  title = {Probabilistic Information Retrieval Approach for Ranking of Database Query Results},
  author = {Chaudhuri, Surajit and Das, Gautam and Hristidis, Vagelis and Weikum, Gerhard},
  year = {2006},
  month = sep,
  journal = {ACM Transactions on Database Systems},
  volume = {31},
  number = {3},
  pages = {1134--1168},
  issn = {0362-5915, 1557-4644},
  doi = {10.1145/1166074.1166085},
  urldate = {2025-04-22},
  abstract = {We investigate the problem of ranking the answers to a database query when many tuples are returned. In particular, we present methodologies to tackle the problem for conjunctive and range queries, by adapting and applying principles of probabilistic models from information retrieval for structured data. Our solution is domain independent and leverages data and workload statistics and correlations. We evaluate the quality of our approach with a user survey on a real database. Furthermore, we present and experimentally evaluate algorithms to efficiently retrieve the top ranked results, which demonstrate the feasibility of our ranking system.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/JIIJUFE8/Chaudhuri et al. - 2006 - Probabilistic information retrieval approach for ranking of database query results.pdf}
}

@article{chaudhuriRandomSamplingJoins1999,
  title = {On Random Sampling over Joins},
  author = {Chaudhuri, Surajit and Motwani, Rajeev and Narasayya, Vivek},
  year = {1999},
  month = jun,
  journal = {ACM SIGMOD Record},
  volume = {28},
  number = {2},
  pages = {263--274},
  issn = {0163-5808},
  doi = {10.1145/304181.304206},
  urldate = {2024-08-13},
  abstract = {A major bottleneck in implementing sampling as a primitive relational operation is the inefficiency of sampling the output of a query. It is not even known whether it is possible to generate a sample of a join tree without first evaluating the join tree completely. We undertake a detailed study of this problem and attempt to analyze it in a variety of settings. We present theoretical results explaining the difficulty of this problem and setting limits on the efficiency that can be achieved. Based on new insights into the interaction between join and sampling, we develop join sampling techniques for the settings where our negative results do not apply. Our new sampling algorithms are significantly more efficient than those known earlier. We present experimental evaluation of our techniques on Microsoft's SQL Server 7.0.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/9Y7MAFDQ/Chaudhuri et al. - 1999 - On random sampling over joins.pdf}
}

@misc{chenEquivalentTransformationUser2022,
  title = {Towards {{Equivalent Transformation}} of {{User Preferences}} in {{Cross Domain Recommendation}}},
  author = {Chen, Xu and Zhang, Ya and Tsang, Ivor and Pan, Yuangang and Su, Jingchao},
  year = {2022},
  month = mar,
  number = {arXiv:2009.06884},
  eprint = {2009.06884},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2009.06884},
  urldate = {2025-09-10},
  abstract = {Cross domain recommendation (CDR) is one popular research topic in recommender systems. This paper focuses on a popular scenario for CDR where different domains share the same set of users but no overlapping items. The majority of recent methods have explored the shared-user representation to transfer knowledge across domains. However, the idea of shared-user representation resorts to learn the overlapped features of user preferences and suppresses the domain-specific features. Other works try to capture the domain-specific features by an MLP mapping but require heuristic human knowledge of choosing samples to train the mapping. In this paper, we attempt to learn both features of user preferences in a more principled way. We assume that each user's preferences in one domain can be expressed by the other one, and these preferences can be mutually converted to each other with the so-called equivalent transformation. Based on this assumption, we propose an equivalent transformation learner (ETL) which models the joint distribution of user behaviors across domains. The equivalent transformation in ETL relaxes the idea of shared-user representation and allows the learned preferences in different domains to preserve the domain-specific features as well as the overlapped features. Extensive experiments on three public benchmarks demonstrate the effectiveness of ETL compared with recent state-of-the-art methods. Codes and data are available online:{\textasciitilde}{\textbackslash}url\{https://github.com/xuChenSJTU/ETL-master\}},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Information Retrieval},
  file = {/Users/DAADAMS/Zotero/storage/PDYYWTDT/Chen et al. - 2022 - Towards Equivalent Transformation of User Preferences in Cross Domain Recommendation.pdf}
}

@article{chenGraphOptimalTransport,
  title = {Graph {{Optimal Transport}} for {{Cross-Domain Alignment}}},
  author = {Chen, Liqun and Gan, Zhe and Cheng, Yu and Li, Linjie and Carin, Lawrence and Liu, Jingjing},
  abstract = {Cross-domain alignment between two sets of entities (e.g., objects in an image, words in a sentence) is fundamental to both computer vision and natural language processing. Existing methods mainly focus on designing advanced attention mechanisms to simulate soft alignment, with no training signals to explicitly encourage alignment. The learned attention matrices are also dense and lacks interpretability. We propose Graph Optimal Transport (GOT), a principled framework that germinates from recent advances in Optimal Transport (OT). In GOT, cross-domain alignment is formulated as a graph matching problem, by representing entities into a dynamically-constructed graph. Two types of OT distances are considered: (i) Wasserstein distance (WD) for node (entity) matching; and (ii) Gromov-Wasserstein distance (GWD) for edge (structure) matching. Both WD and GWD can be incorporated into existing neural network models, effectively acting as a dropin regularizer. The inferred transport plan also yields sparse and self-normalized alignment, enhancing the interpretability of the learned model. Experiments show consistent outperformance of GOT over baselines across a wide range of tasks, including image-text retrieval, visual question answering, image captioning, machine translation, and text summarization.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/YXHKAPQN/Chen et al. - Graph Optimal Transport for Cross-Domain Alignment.pdf}
}

@article{chenHiggsBosonDiscovery,
  title = {Higgs {{Boson Discovery}} with {{Boosted Trees}}},
  author = {Chen, Tianqi and He, Tong},
  abstract = {The discovery of the Higgs boson is remarkable for its importance in modern Physics research. The next step for physicists is to discover more about the Higgs boson from the data of the Large Hadron Collider (LHC). A fundamental and challenging task is to extract the signal of Higgs boson from background noises. The machine learning technique is one important component in solving this problem.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/NN5WWCTI/Chen and He - Higgs Boson Discovery with Boosted Trees.pdf}
}

@misc{chenLiqunChen0606GraphOptimalTransport2025,
  title = {{{LiqunChen0606}}/{{Graph-Optimal-Transport}}},
  author = {Chen, Liqun},
  year = {2025},
  month = jul,
  urldate = {2025-09-08},
  abstract = {Code for ICML 2020 "Graph Optimal Transport for Cross-Domain Alignment"},
  copyright = {MIT}
}

@article{chenNovelCrossDomainRecommendation2024,
  title = {A {{Novel Cross-Domain Recommendation}} with {{Evolution Learning}}},
  author = {Chen, Yi-Cheng and Lee, Wang-Chien},
  year = {2024},
  month = feb,
  journal = {ACM Transactions on Internet Technology},
  volume = {24},
  number = {1},
  pages = {1--23},
  issn = {1533-5399, 1557-6051},
  doi = {10.1145/3639567},
  urldate = {2025-09-08},
  abstract = {In this ``info-plosion'' era, recommendation systems (or recommenders) play a significant role in finding interesting items in the surge of online digital activities and e-commerce. Several techniques have been widely applied for recommendation systems, but the cold-start and sparsity problems remain a major challenge. The cold-start~problem occurs when generating recommendations for new users and items without sufficient information. Sparsity refers to the problem of having a large amount of users and items but with few transactions or interactions. In this article, a novel cross-domain recommendation model, Cross-Domain Evolution Learning Recommendation (abbreviated as CD-ELR), is developed to communicate the information from different domains in order to tackle the cold-start and sparsity issues by integrating matrix factorization and recurrent neural network. We introduce an evolutionary concept to describe the preference variation of users over time. Furthermore, several optimization methods are developed for combining the domain features for precision recommendation. Experimental results show that CD-ELR outperforms existing state-of-the-art recommendation baselines. Finally, we conduct experiments on several real-world datasets to demonstrate the practicability of the proposed CD-ELR.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/6WH4SA5A/Chen and Lee - 2024 - A Novel Cross-Domain Recommendation with Evolution Learning.pdf}
}

@article{chenSymphonyNaturalLanguage2023,
  title = {Symphony: {{Towards Natural Language Query Answering}} over {{Multi-modal Data Lakes}}},
  author = {Chen, Zui and Gu, Zihui and Cao, Lei and Fan, Ju and Madden, Sam and Tang, Nan},
  year = {2023},
  abstract = {Wouldn't it be great if we could query large, diverse data lakes of tables, text, and databases as easily as using Siri or Alexa? The problem is hard from two perspectives: integrating data lakes requires data normalization/transformation, schema matching, and entity resolution and is notoriously hard, with high human cost. Even if successful, such integration efforts typically do not support arbitrary SQL queries over the integrated data set. In this paper, we propose Symphony, a novel system that enables users to easily query complex, multi-modal data lakes without performing upfront integration. For ease of use, Symphony adopts a natural language (NL) interface. To avoid integration, it employs a unified representation for multi-modal datasets, called cross-modality representation learning. When a user poses an NL query, Symphony discovers which tables or textual data should be retrieved based on the learned cross-modal representations, decomposes a complicated NL query into NL sub-queries on-demand, evaluates each sub-query on one data source and combines the results from these sub-queries. A preliminary evaluation shows that the resulting system is able to effectively answer questions over tables and text extracted from Wikipedia.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/85JPUKBL/Chen et al. - 2023 - Symphony Towards Natural Language Query Answering.pdf}
}

@inproceedings{choiReviewBasedDomainDisentanglement2022,
  title = {Review-{{Based Domain Disentanglement}} without {{Duplicate Users}} or {{Contexts}} for {{Cross-Domain Recommendation}}},
  booktitle = {Proceedings of the 31st {{ACM International Conference}} on {{Information}} \& {{Knowledge Management}}},
  author = {Choi, Yoonhyuk and Choi, Jiho and Ko, Taewook and Byun, Hyungho and Kim, Chong-Kwon},
  year = {2022},
  month = oct,
  eprint = {2110.12648},
  primaryclass = {cs},
  pages = {293--303},
  doi = {10.1145/3511808.3557434},
  urldate = {2025-09-08},
  abstract = {A cross-domain recommendation has shown promising results in solving data-sparsity and cold-start problems. Despite such progress, existing methods focus on domain-shareable information (overlapped users or same contexts) for a knowledge transfer, and they fail to generalize well without such requirements. To deal with these problems, we suggest utilizing review texts that are general to most e-commerce systems. Our model (named SER) uses three text analysis modules, guided by a single domain discriminator for disentangled representation learning. Here, we suggest a novel optimization strategy that can enhance the quality of domain disentanglement, and also debilitates detrimental information of a source domain. Also, we extend the encoding network from a single to multiple domains, which has proven to be powerful for review-based recommender systems. Extensive experiments and ablation studies demonstrate that our method is efficient, robust, and scalable compared to the state-of-the-art single and cross-domain recommendation methods.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Information Retrieval},
  file = {/Users/DAADAMS/Zotero/storage/TKR4CH2I/Choi et al. - 2022 - Review-Based Domain Disentanglement without Duplicate Users or Contexts for Cross-Domain Recommendat.pdf}
}

@article{chrisbakerActionUnderstandingInverse2009,
  title = {Action Understanding as Inverse Planning.},
  author = {{Chris Baker} and Baker, Chris L. and {Rebecca Saxe} and Saxe, Rebecca and {Joshua B. Tenenbaum} and Tenenbaum, Joshua B.},
  year = {2009},
  month = dec,
  journal = {Cognition},
  volume = {113},
  number = {3},
  pages = {329--349},
  doi = {10.1016/j.cognition.2009.07.005},
  abstract = {Humans are adept at inferring the mental states underlying other agents' actions, such as goals, beliefs, desires, emotions and other thoughts. We propose a computational framework based on Bayesian inverse planning for modeling human action understanding. The framework represents an intuitive theory of intentional agents' behavior based on the principle of rationality: the expectation that agents will plan approximately rationally to achieve their goals, given their beliefs about the world. The mental states that caused an agent's behavior are inferred by inverting this model of rational planning using Bayesian inference, integrating the likelihood of the observed actions with the prior over mental states. This approach formalizes in precise probabilistic terms the essence of previous qualitative approaches to action understanding based on an ``intentional stance'' [Dennett, D. C. (1987). The intentional stance. Cambridge, MA: MIT Press] or a ``teleological stance'' [Gergely, G., Nadasdy, Z., Csibra, G., \& Biro, S. (1995). Taking the intentional stance at 12 months of age. Cognition, 56, 165--193]. In three psychophysical experiments using animated stimuli of agents moving in simple mazes, we assess how well different inverse planning models based on different goal priors can predict human goal inferences. The results provide quantitative evidence for an approximately rational inference mechanism in human goal inference within our simplified stimulus paradigm, and for the flexible nature of goal representations that human observers can adopt. We discuss the implications of our experimental results for human action understanding in real-world contexts, and suggest how our framework might be extended to capture other kinds of mental state inferences, such as inferences about beliefs, or inferring whether an entity is an intentional agent.},
  pmid = {19729154},
  annotation = {MAG ID: 2151516755},
  file = {/Users/DAADAMS/Zotero/storage/72BVH5IH/Baker et al. - 2009 - Action understanding as inverse planning.pdf}
}

@article{christopherw.geibProbabilisticPlanRecognition2009,
  title = {A Probabilistic Plan Recognition Algorithm Based on Plan Tree Grammars},
  author = {{Christopher W. Geib} and Geib, Christopher W. and {Robert P. Goldman} and Goldman, Robert P.},
  year = {2009},
  month = jul,
  journal = {Artificial Intelligence},
  volume = {173},
  number = {11},
  pages = {1101--1132},
  doi = {10.1016/j.artint.2009.01.003},
  annotation = {MAG ID: 1981637451}
}

@misc{chuangDataDesignerCOAST2025,
  title = {Data-{{Designer}}/{{COAST}}},
  author = {Chuang, Zhao},
  year = {2025},
  month = jul,
  urldate = {2025-09-08}
}

@article{cideronQdrlEfficientMixing2020,
  title = {Qd-Rl: {{Efficient}} Mixing of Quality and Diversity in Reinforcement Learning},
  shorttitle = {Qd-Rl},
  author = {Cideron, Geoffrey and Pierrot, Thomas and Perrin, Nicolas and Beguir, Karim and Sigaud, Olivier},
  year = {2020},
  journal = {arXiv preprint arXiv:2006.08505},
  eprint = {2006.08505},
  pages = {28--73},
  urldate = {2024-09-11},
  archiveprefix = {arXiv},
  file = {/Users/DAADAMS/Zotero/storage/IDBZ4FIN/Cideron et al. - 2020 - Qd-rl Efficient mixing of quality and diversity in reinforcement learning.pdf}
}

@article{coddFurtherNormalizationData1972,
  title = {Further Normalization of the Data Base Relational Model},
  author = {Codd, Edgar F.},
  year = {1972},
  journal = {Data base systems},
  volume = {6},
  pages = {33--64},
  publisher = {Prentice-Hall Englewood Cliffs, NJ},
  urldate = {2024-08-12},
  file = {/Users/DAADAMS/Zotero/storage/K5VYA5BB/Codd - 1972 - Further normalization of the data base relational .pdf}
}

@misc{cohenMaximumEntropyDiverse2019,
  title = {Maximum {{Entropy Diverse Exploration}}: {{Disentangling Maximum Entropy Reinforcement Learning}}},
  shorttitle = {Maximum {{Entropy Diverse Exploration}}},
  author = {Cohen, Andrew and Yu, Lei and Qiao, Xingye and Tong, Xiangrong},
  year = {2019},
  month = nov,
  number = {arXiv:1911.00828},
  eprint = {1911.00828},
  primaryclass = {cs, stat},
  publisher = {arXiv},
  urldate = {2024-09-03},
  abstract = {Two hitherto disconnected threads of research, diverse exploration (DE) and maximum entropy RL have addressed a wide range of problems facing reinforcement learning algorithms via ostensibly distinct mechanisms. In this work, we identify a connection between these two approaches. First, a discriminator-based diversity objective is put forward and connected to commonly used divergence measures. We then extend this objective to the maximum entropy framework and propose an algorithm Maximum Entropy Diverse Exploration (MEDE) which provides a principled method to learn diverse behaviors. A theoretical investigation shows that the set of policies learned by MEDE capture the same modalities as the optimal maximum entropy policy. In effect, the proposed algorithm disentangles the maximum entropy policy into its diverse, constituent policies. Experiments show that MEDE is superior to the state of the art in learning high performing and diverse policies.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/DAADAMS/Zotero/storage/PWPCXYB2/Cohen et al. - 2019 - Maximum Entropy Diverse Exploration Disentangling.pdf;/Users/DAADAMS/Zotero/storage/B8FF5RPY/1911.html}
}

@inproceedings{conroyTextSummarizationHidden2001,
  title = {Text Summarization via Hidden {{Markov}} Models},
  booktitle = {Proceedings of the 24th Annual International {{ACM SIGIR}} Conference on {{Research}} and Development in Information Retrieval},
  author = {Conroy, John M. and O'leary, Dianne P.},
  year = {2001},
  month = sep,
  pages = {406--407},
  publisher = {ACM},
  address = {New Orleans Louisiana USA},
  doi = {10.1145/383952.384042},
  urldate = {2025-02-16},
  isbn = {978-1-58113-331-8},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/BPVIUP7K/Conroy and O'leary - 2001 - Text summarization via hidden Markov models.pdf}
}

@article{copulDemonstratingTabEETabular2024,
  title = {Demonstrating {{TabEE}}: {{Tabular Embedding Explanations}}},
  shorttitle = {Demonstrating {{TabEE}}},
  author = {Copul, Roni and Frost, Nave and Milo, Tova and Razmadze, Kathy},
  year = {2024},
  month = aug,
  journal = {Proceedings of the VLDB Endowment},
  volume = {17},
  number = {12},
  pages = {4285--4288},
  issn = {2150-8097},
  doi = {10.14778/3685800.3685856},
  urldate = {2024-12-08},
  abstract = {We present TabEE, Tabular Embedding Explanations, a framework designed to generate explanations for interpreting tabular embedding models. Our framework aims to furnish both local and global explanations for the original data, facilitating the detection of potential flaws in embedding models. TabEE is versatile and compatible with any tabular embedding algorithm, as it adheres to the black box perspective of embedding models. The generated explanations also enable comparisons between multiple embedding models. This demonstration illustrates the effectiveness of TabEE in providing interpretable insights into tabular embedding models, contributing to improved model understanding and credibility assessment.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/A2W3AP2R/Copul et al. - 2024 - Demonstrating TabEE Tabular Embedding Explanations.pdf}
}

@misc{correaClassicalPlanningLLMGenerated2025,
  title = {Classical {{Planning}} with {{LLM-Generated Heuristics}}: {{Challenging}} the {{State}} of the {{Art}} with {{Python Code}}},
  shorttitle = {Classical {{Planning}} with {{LLM-Generated Heuristics}}},
  author = {Corr{\^e}a, Augusto B. and Pereira, Andr{\'e} G. and Seipp, Jendrik},
  year = {2025},
  month = mar,
  number = {arXiv:2503.18809},
  eprint = {2503.18809},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2503.18809},
  urldate = {2025-06-16},
  abstract = {In recent years, large language models (LLMs) have shown remarkable capabilities in various artificial intelligence problems. However, they fail to plan reliably, even when prompted with a detailed definition of the planning task. Attempts to improve their planning capabilities, such as chain-of-thought prompting, fine-tuning, and explicit ``reasoning'' still yield incorrect plans and usually fail to generalize to larger tasks. In this paper, we show how to use LLMs to generate correct plans, even for out-of-distribution tasks of increasing size. For a given planning domain, we ask an LLM to generate several domain-dependent heuristic functions in the form of Python code, evaluate them on a set of training tasks within a greedy best-first search, and choose the strongest one. The resulting LLM-generated heuristics solve many more unseen test tasks than state-of-the-art domain-independent heuristics for classical planning. They are even competitive with the strongest learning algorithm for domain-dependent planning. These findings are especially remarkable given that our proof-of-concept implementation is based on an unoptimized Python planner and the baselines all build upon highly optimized C++ code. In some domains, the LLM-generated heuristics expand fewer states than the baselines, revealing that they are not only efficiently computable, but sometimes even more informative than the state-of-the-art heuristics. Overall, our results show that sampling a set of planning heuristic function programs can significantly improve the planning capabilities of LLMs.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {/Users/DAADAMS/Zotero/storage/E4LKDGDJ/Corrêa et al. - 2025 - Classical Planning with LLM-Generated Heuristics Challenging the State of the Art with Python Code.pdf}
}

@book{coverElementsInformationTheory1999,
  title = {Elements of Information Theory},
  author = {Cover, Thomas M.},
  year = {1999},
  publisher = {John Wiley \& Sons},
  file = {/Users/DAADAMS/Zotero/storage/3JIC9MEW/Cover - 1999 - Elements of information theory.pdf}
}

@article{cowlingEnsembleDeterminizationMonte2012,
  title = {Ensemble {{Determinization}} in {{Monte Carlo Tree Search}} for the {{Imperfect Information Card Game Magic}}: {{The Gathering}}},
  shorttitle = {Ensemble {{Determinization}} in {{Monte Carlo Tree Search}} for the {{Imperfect Information Card Game Magic}}},
  author = {Cowling, Peter I. and Ward, Colin D. and Powley, Edward J.},
  year = {2012},
  month = dec,
  journal = {IEEE Transactions on Computational Intelligence and AI in Games},
  volume = {4},
  number = {4},
  pages = {241--257},
  issn = {1943-068X, 1943-0698},
  doi = {10.1109/TCIAIG.2012.2204883},
  urldate = {2024-03-15},
  abstract = {In this paper, we examine the use of Monte Carlo Tree Search (MCTS) for a variant of one of the most popular and profitable games in the world: the card game Magic: The Gathering (M:TG). The game tree for M:TG has a range of distinctive features, which we discuss here, and has incomplete information through the opponent's hidden cards, and randomness through card drawing from a shuffled deck. We investigate a wide range of approaches that use determinization, where all hidden and random information is assumed known to all players, alongside Monte Carlo Tree Search. We consider a number of variations to the rollout strategy using a range of levels of sophistication and expert knowledge, and decaying reward to encourage play urgency. We examine the effect of utilising various pruning strategies in order to increase the information gained from each determinization, alongside methods that increase the relevance of random choices. Additionally we deconstruct the move generation procedure into a binary yes/no decision tree and apply MCTS to this finer grained decision process. We compare our modifications to a basic MCTS approach for Magic: The Gathering using fixed decks, and show that significant improvements in playing strength can be obtained.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/URS62NBJ/Cowling et al. - 2012 - Ensemble Determinization in Monte Carlo Tree Searc.pdf}
}

@inproceedings{dalkilicInformationDependencies2000,
  title = {Information Dependencies},
  booktitle = {Proceedings of the Nineteenth {{ACM SIGMOD-SIGACT-SIGART}} Symposium on {{Principles}} of Database Systems  - {{PODS}} '00},
  author = {Dalkilic, Mehmet M. and Roberston, Edward L.},
  year = {2000},
  pages = {245--253},
  publisher = {ACM Press},
  address = {Dallas, Texas, United States},
  doi = {10.1145/335168.336059},
  urldate = {2024-07-30},
  abstract = {This paper uses the tools of information theory to examine and reason about the information content of the attributes within a relation instance. For tw o sets of attributes X and Y , an information dependency measure  InD measure  characterizes the uncertain ty remaining about the values for the set Y when the values for the set X are kno wn. A variety of arithmetic inequalities  InD inequalities  are shown to hold among InD measures; InD inequalities hold in any relation instance. Numeric constraints  InD constraints  on InD measures, consistent with the InD inequalities, can be applied to relation instances. Remarkably, functional and multivalued dependencies correspond to setting certain constrain ts to zero, with Armstrong's axioms shown to be consequences of the arithmetic inequalities applied to constraints. As an analog of completeness, for any set of constrain ts consisten t with the inequalities, we may construct a relation instance that appro ximates these constraints within any positiv e . InD measures suggest many valuable applications in areas such as data mining.},
  isbn = {978-1-58113-214-4},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/9HEQSTKE/Dalkilic and Roberston - 2000 - Information dependencies.pdf}
}

@book{davenportCompetingAnalyticsUpdated2017,
  title = {Competing on {{Analytics}}: {{Updated}}, with a {{New Introduction}}: {{The New Science}} of {{Winning}}},
  shorttitle = {Competing on {{Analytics}}},
  author = {Davenport, Thomas and Harris, Jeanne},
  year = {2017},
  month = aug,
  publisher = {Harvard Business Press},
  abstract = {The New Edition of a Business ClassicThis landmark work, the first to introduce business leaders to analytics, reveals how analytics are rewriting the rules of competition.Updated with fresh content, Competing on Analytics provides the road map for becoming an analytical competitor, showing readers how to create new strategies for their organizations based on sophisticated analytics. Introducing a five-stage model of analytical competition, Davenport and Harris describe the typical behaviors, capabilities, and challenges of each stage. They explain how to assess your company's capabilities and guide it toward the highest level of competition. With equal emphasis on two key resources, human and technological, this book reveals how even the most highly analytical companies can up their game.With an emphasis on predictive, prescriptive, and autonomous analytics for marketing, supply chain, finance, M\&A, operations, R\&D, and HR, the book contains numerous new examples from different industries and business functions, such as Disney's vacation experience, Google's HR, UPS's logistics, the Chicago Cubs' training methods, and Firewire Surfboards' customization. Additional new topics and research include:Data scientists and what they doBig data and the changes it has wroughtHadoop and other open-source software for managing and analyzing dataData products---new products and services based on data and analyticsMachine learning and other AI technologiesThe Internet of Things and its implicationsNew computing architectures, including cloud computingEmbedding analytics within operational systemsVisual analyticsThe business classic that turned a generation of leaders into analytical competitors, Competing on Analytics is the definitive guide for transforming your company's fortunes in the age of analytics and big data.},
  googlebooks = {LW9GDgAAQBAJ},
  isbn = {978-1-63369-373-9},
  langid = {english},
  keywords = {Business & Economics / Decision-Making & Problem Solving,Business & Economics / Information Management,Business & Economics / Knowledge Capital,Business & Economics / Management}
}

@inproceedings{davidsonASQPRLDemoLearning2024,
  title = {{{ASQP-RL Demo}}: {{Learning Approximation Sets}} for {{Exploratory Queries}}},
  shorttitle = {{{ASQP-RL Demo}}},
  booktitle = {Companion of the 2024 {{International Conference}} on {{Management}} of {{Data}}},
  author = {Davidson, Susan B. and Milo, Tova and Razmadze, Kathy and Zeevi, Gal},
  year = {2024},
  month = jun,
  pages = {452--455},
  publisher = {ACM},
  address = {Santiago AA Chile},
  doi = {10.1145/3626246.3654741},
  urldate = {2024-12-08},
  abstract = {We demonstrate the Approximate Selection Query Processing (ASQPRL) system, which uses Reinforcement Learning to select a subset of a large external dataset to process locally in a notebook during data exploration. Given a query workload over an external database and notebook memory size, the system translates the workload to select-project-join (non-aggregate) queries and finds a subset of each relation such that the data subset -- called the approximation set -- fits into the notebook memory and maximizes query result quality. The data subset can then be loaded into the notebook, and rapidly queried by the analyst. Our demonstration shows how ASQP-RL can be used during data exploration and achieve comparable results to external queries over the large dataset at significantly reduced query times. It also shows how ASQP-RL can be used for aggregation queries, achieving surprisingly good results compared to state-of-the-art techniques.},
  isbn = {979-8-4007-0422-2},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/D56FL4KS/Davidson et al. - 2024 - ASQP-RL Demo Learning Approximation Sets for Exploratory Queries.pdf}
}

@misc{degiacomoPlanningTemporallyExtended2022,
  title = {Planning for {{Temporally Extended Goals}} in {{Pure-Past Linear Temporal Logic}}: {{A Polynomial Reduction}} to {{Standard Planning}}},
  shorttitle = {Planning for {{Temporally Extended Goals}} in {{Pure-Past Linear Temporal Logic}}},
  author = {De Giacomo, Giuseppe and Favorito, Marco and Fuggitti, Francesco},
  year = {2022},
  month = may,
  number = {arXiv:2204.09960},
  eprint = {2204.09960},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2024-05-07},
  abstract = {We study temporally extended goals expressed in Pure-Past ltl (ppltl). ppltl is particularly interesting for expressing goals since it allows to express sophisticated tasks as in the Formal Methods literature, while the worst-case computational complexity of Planning in both deterministic and nondeterministic domains (FOND) remains the same as for classical reachability goals. However, while the theory of planning for ppltl goals is well understood, practical tools have not been specifically investigated. In this paper, we make a significant leap forward in the construction of actual tools to handle ppltl goals. We devise a technique to polynomially translate planning for ppltl goals into standard planning. We show the formal correctness of the translation, its complexity, and its practical effectiveness through some comparative experiments. As a result, our translation enables state-of-the-art tools, such as FD or MyND, to handle ppltl goals seamlessly, maintaining the impressive performances they have for classical reachability goals.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence},
  file = {/Users/DAADAMS/Zotero/storage/EJDY9ZBB/De Giacomo et al. - 2022 - Planning for Temporally Extended Goals in Pure-Pas.pdf}
}

@article{deutchExplainEDExplanationsEDA2020,
  title = {{{ExplainED}}: Explanations for {{EDA}} Notebooks},
  shorttitle = {{{ExplainED}}},
  author = {Deutch, Daniel and Gilad, Amir and Milo, Tova and Somech, Amit},
  year = {2020},
  month = aug,
  journal = {Proceedings of the VLDB Endowment},
  volume = {13},
  number = {12},
  pages = {2917--2920},
  issn = {2150-8097},
  doi = {10.14778/3415478.3415508},
  urldate = {2024-12-08},
  abstract = {Exploratory Data Analysis (EDA) is an essential yet highly demanding task. To get a head start before exploring a new dataset, data scientists often prefer to view existing EDA notebooks -- illustrative exploratory sessions that were created by fellow data scientists who examined the same dataset and shared their notebooks via online platforms. Unfortunately, creating an illustrative, well-documented notebook is cumbersome and time-consuming, therefore users sometimes share their notebook without explaining their exploratory steps and their results. Such notebooks are difficult to follow and to understand.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/7VLVT28C/Deutch et al. - 2020 - ExplainED explanations for EDA notebooks.pdf}
}

@misc{deutchFEDEXExplainabilityFramework2022,
  title = {{{FEDEX}}: {{An Explainability Framework}} for {{Data Exploration Steps}}},
  shorttitle = {{{FEDEX}}},
  author = {Deutch, Daniel and Gilad, Amir and Milo, Tova and Mualem, Amit and Somech, Amit},
  year = {2022},
  month = sep,
  number = {arXiv:2209.06260},
  eprint = {2209.06260},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2209.06260},
  urldate = {2024-12-08},
  abstract = {When exploring a new dataset, Data Scientists often apply analysis queries, look for insights in the resulting dataframe, and repeat to apply further queries. We propose in this paper a novel solution that assists data scientists in this laborious process. In a nutshell, our solution pinpoints the most interesting (sets of) rows in each obtained dataframe. Uniquely, our definition of interest is based on the contribution of each row to the interestingness of different columns of the entire dataframe, which, in turn, is defined using standard measures such as diversity and exceptionality. Intuitively, interesting rows are ones that explain why (some column of) the analysis query result is interesting as a whole. Rows are correlated in their contribution and so the interesting score for a set of rows may not be directly computed based on that of individual rows. We address the resulting computational challenge by restricting attention to semantically-related sets, based on multiple notions of semantic relatedness; these sets serve as more informative explanations. Our experimental study across multiple real-world datasets shows the usefulness of our system in various scenarios.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Databases},
  file = {/Users/DAADAMS/Zotero/storage/DZABRIZA/Deutch et al. - 2022 - FEDEX An Explainability Framework for Data Exploration Steps.pdf}
}

@inproceedings{deutchQPlainQueryExplanation2016,
  title = {{{QPlain}}: {{Query}} by Explanation},
  shorttitle = {{{QPlain}}},
  booktitle = {2016 {{IEEE}} 32nd {{International Conference}} on {{Data Engineering}} ({{ICDE}})},
  author = {Deutch, Daniel and Gilad, Amir},
  year = {2016},
  pages = {1358--1361},
  publisher = {IEEE},
  urldate = {2025-02-16},
  file = {/Users/DAADAMS/Zotero/storage/LY96BQW4/Deutch and Gilad - 2016 - QPlain Query by explanation.pdf}
}

@article{dibiaData2visAutomaticGeneration2019,
  title = {Data2vis: {{Automatic}} Generation of Data Visualizations Using Sequence-to-Sequence Recurrent Neural Networks},
  shorttitle = {Data2vis},
  author = {Dibia, Victor and Demiralp, {\c C}a{\u g}atay},
  year = {2019},
  journal = {IEEE computer graphics and applications},
  volume = {39},
  number = {5},
  pages = {33--46},
  publisher = {IEEE},
  urldate = {2025-02-16},
  file = {/Users/DAADAMS/Zotero/storage/EFLQRS6K/Dibia and Demiralp - 2019 - Data2vis Automatic generation of data visualizations using sequence-to-sequence recurrent neural ne.pdf}
}

@article{dibowski28SeptemberOktober2021,
  title = {28. {{September}} - 2. {{Oktober}} 2020},
  author = {Dibowski, Henrik and Schmid, Stefan},
  year = {2021},
  publisher = {[object Object]},
  issn = {1617-5468},
  doi = {10.18420/INF2020_02},
  urldate = {2024-03-19},
  abstract = {Knowledge graphs as fundamental pillar of artificial intelligence are experiencing a strong demand. In contrast to machine learning and deep learning, knowledge graphs do not require large amounts of (training) data and offer a bigger potential for a multitude of domains and problems. This article shows the application of knowledge graphs for the semantic description and management of data in a data lake, which improves the findability and reusability of data, and enables the automatic processing by algorithms. Since knowledge graphs contain both the data as well as its semantically described schema (ontology), they enable novel ontology-driven software architectures, in which the domain knowledge and business logic can completely reside on the knowledge graph level. This article further introduces such a use case{$\jmath$} an ontology-driven frontend implementation, which is able to fully adapt itself based on the underlying knowledge graph schema and dynamically render information in the desired manner.},
  isbn = {9783885797012},
  langid = {english},
  keywords = {Artificial Intelligence,Data Catalog,Knowledge Graph,Knowledge Representation,Ontology,Ontology-Driven UIs,Semantic Data Lake,Semantic Layer,Semantic Search},
  file = {/Users/DAADAMS/Zotero/storage/AKECNVBW/Dibowski and Schmid - 2021 - 28. September - 2. Oktober 2020.pdf}
}

@article{difallahOLTPBenchExtensibleTestbed2013,
  title = {{{OLTP-Bench}}: An Extensible Testbed for Benchmarking Relational Databases},
  shorttitle = {{{OLTP-Bench}}},
  author = {Difallah, Djellel Eddine and Pavlo, Andrew and Curino, Carlo and {Cudre-Mauroux}, Philippe},
  year = {2013},
  month = dec,
  journal = {Proceedings of the VLDB Endowment},
  volume = {7},
  number = {4},
  pages = {277--288},
  issn = {2150-8097},
  doi = {10.14778/2732240.2732246},
  urldate = {2025-02-24},
  abstract = {Benchmarking is an essential aspect of any database management system (DBMS) effort. Despite several recent advancements, such as pre-configured cloud database images and database-as-a-service (DBaaS) offerings, the deployment of a comprehensive testing platform with a diverse set of datasets and workloads is still far from being trivial. In many cases, researchers and developers are limited to a small number of workloads to evaluate the performance characteristics of their work. This is due to the lack of a universal benchmarking infrastructure, and to the difficulty of gaining access to real data and workloads. This results in lots of unnecessary engineering efforts and makes the performance evaluation results difficult to compare. To remedy these problems, we present OLTP-Bench, an extensible ``batteries included'' DBMS benchmarking testbed. The key contributions of OLTP-Bench are its ease of use and extensibility, support for tight control of transaction mixtures, request rates, and access distributions over time, as well as the ability to support all major DBMSs and DBaaS platforms. Moreover, it is bundled with fifteen workloads that all differ in complexity and system demands, including four synthetic workloads, eight workloads from popular benchmarks, and three workloads that are derived from real-world applications. We demonstrate through a comprehensive set of experiments conducted on popular DBMS and DBaaS offerings the different features provided by OLTP-Bench and the effectiveness of our testbed in characterizing the performance of database services.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/EVY8BYTW/Difallah et al. - 2013 - OLTP-Bench an extensible testbed for benchmarking relational databases.pdf}
}

@article{dimitriadouAIDEActiveLearningBased2016,
  title = {{{AIDE}}: {{An Active Learning-Based Approach}} for {{Interactive Data Exploration}}},
  shorttitle = {{{AIDE}}},
  author = {Dimitriadou, Kyriaki and Papaemmanouil, Olga and Diao, Yanlei},
  year = {2016},
  month = nov,
  journal = {IEEE Transactions on Knowledge and Data Engineering},
  volume = {28},
  number = {11},
  pages = {2842--2856},
  publisher = {IEEE},
  issn = {1041-4347},
  doi = {10.1109/TKDE.2016.2599168},
  urldate = {2025-01-28},
  abstract = {In this paper, we argue that database systems be augmented with an automated data exploration service that methodically steers users through the data in a meaningful way. Such an automated system is crucial for deriving insights from complex datasets found in many big data applications such as scientific and healthcare applications as well as for reducing the human effort of data exploration. Towards this end, we present AIDE, an Automatic Interactive Data Exploration framework that assists users in discovering new interesting data patterns and eliminate expensive ad-hoc exploratory queries. AIDE relies on a seamless integration of classification algorithms and data management optimization techniques that collectively strive to accurately learn the user interests based on his relevance feedback on strategically collected samples. We present a number of exploration techniques as well as optimizations that minimize the number of samples presented to the user while offering interactive performance. AIDE can deliver highly accurate query predictions for very common conjunctive queries with small user effort while, given a reasonable number of samples, it can predict with high accuracy complex disjunctive queries. It provides interactive performance as it limits the user wait time per iteration of exploration to less than a few seconds.},
  copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/MNPN7J47/Dimitriadou et al. - 2016 - AIDE An Active Learning-Based Approach for Interactive Data Exploration.pdf}
}

@inproceedings{dimitriadouExplorebyexampleAutomaticQuery2014,
  title = {Explore-by-Example: An Automatic Query Steering Framework for Interactive Data Exploration},
  shorttitle = {Explore-by-Example},
  booktitle = {Proceedings of the 2014 {{ACM SIGMOD International Conference}} on {{Management}} of {{Data}}},
  author = {Dimitriadou, Kyriaki and Papaemmanouil, Olga and Diao, Yanlei},
  year = {2014},
  month = jun,
  pages = {517--528},
  publisher = {ACM},
  address = {Snowbird Utah USA},
  doi = {10.1145/2588555.2610523},
  urldate = {2024-08-13},
  abstract = {Interactive Data Exploration (IDE) is a key ingredient of a diverse set of discovery-oriented applications, including ones from scientific computing and evidence-based medicine. In these applications, data discovery is a highly ad hoc interactive process where users execute numerous exploration queries using varying predicates aiming to balance the trade-off between collecting all relevant information and reducing the size of returned data. Therefore, there is a strong need to support these human-in-the-loop applications by assisting their navigation in the data to find interesting objects.},
  isbn = {978-1-4503-2376-5},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/VUBRJS3Z/Dimitriadou et al. - 2014 - Explore-by-example an automatic query steering framework for interactive data exploration.pdf;/Users/DAADAMS/Zotero/storage/XKDUN6GB/Dimitriadou et al. - 2014 - Explore-by-example an automatic query steering fr.pdf}
}

@inproceedings{dingQuickInsightsQuickAutomatic2019,
  title = {{{QuickInsights}}: {{Quick}} and {{Automatic Discovery}} of {{Insights}} from {{Multi-Dimensional Data}}},
  shorttitle = {{{QuickInsights}}},
  booktitle = {Proceedings of the 2019 {{International Conference}} on {{Management}} of {{Data}}},
  author = {Ding, Rui and Han, Shi and Xu, Yong and Zhang, Haidong and Zhang, Dongmei},
  year = {2019},
  month = jun,
  pages = {317--332},
  publisher = {ACM},
  address = {Amsterdam Netherlands},
  doi = {10.1145/3299869.3314037},
  urldate = {2025-02-03},
  abstract = {Discovering interesting data patterns is a common and important analytical need in data, with increasing user demand for automated discovery abilities. However, automatically discovering interesting patterns from multi-dimensional data remains challenging. Existing techniques focus on mining individual types of patterns. There is a lack of unified formulation for different pattern types, as well as general mining frameworks to derive them effectively and efficiently. We present a novel technique QuickInsights, which quickly and automatically discovers interesting patterns from multi-dimensional data. QuickInsights proposes a unified formulation of interesting patterns, called insights, and designs a systematic mining framework to discover high-quality insights efficiently. We demonstrate the effectiveness and efficiency of QuickInsights through our evaluation on 447 real datasets as well as user studies on both expert users and non-expert users. QuickInsights is released in Microsoft Power BI.},
  isbn = {978-1-4503-5643-5},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/B9JUE58Q/Ding et al. - 2019 - QuickInsights Quick and Automatic Discovery of Insights from Multi-Dimensional Data.pdf}
}

@inproceedings{djenouriGPUbasedBioinspiredModel2017,
  title = {{{GPU-based}} Bio-Inspired Model for Solving Association Rules Mining Problem},
  booktitle = {2017 25th {{Euromicro International Conference}} on {{Parallel}}, {{Distributed}} and {{Network-Based Processing}} ({{PDP}})},
  author = {Djenouri, Youcef and Bendjoudi, Ahcene and Djenouri, Djamel and Comuzzi, Marco},
  year = {2017},
  pages = {262--269},
  publisher = {IEEE},
  urldate = {2024-12-23},
  file = {/Users/DAADAMS/Zotero/storage/P2HBGGAW/Djenouri et al. - 2017 - GPU-based bio-inspired model for solving association rules mining problem.pdf;/Users/DAADAMS/Zotero/storage/62JRBM5K/scholar.html}
}

@article{DOI101017,
  title = {{{DOI}}: 10.1017/{{S000000000000000 Printed}} in the {{United Kingdom A Survey}} of {{Interestingness Measures}} for {{Knowledge Discovery}}},
  annotation = {S2ID: baf7f99e1b567868a6dc6238cc5906881242da01}
}

@incollection{dongInterestingnessDiscoveredAssociation1998,
  title = {Interestingness of Discovered Association Rules in Terms of Neighborhood-Based Unexpectedness},
  booktitle = {Research and {{Development}} in {{Knowledge Discovery}} and {{Data Mining}}},
  author = {Dong, Guozhu and Li, Jinyan},
  editor = {Wu, Xindong and Kotagiri, Ramamohanarao and Korb, Kevin B.},
  year = {1998},
  volume = {1394},
  pages = {72--86},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/3-540-64383-4_7},
  urldate = {2024-08-07},
  isbn = {978-3-540-64383-8 978-3-540-69768-8},
  file = {/Users/DAADAMS/Zotero/storage/PY8WM5HI/Dong and Li - 1998 - Interestingness of discovered association rules in.pdf}
}

@misc{dorazioAlternativeFunctionApproximation2020,
  title = {Alternative {{Function Approximation Parameterizations}} for {{Solving Games}}: {{An Analysis}} of \$f\$-{{Regression Counterfactual Regret Minimization}}},
  shorttitle = {Alternative {{Function Approximation Parameterizations}} for {{Solving Games}}},
  author = {D'Orazio, Ryan and Morrill, Dustin and Wright, James R. and Bowling, Michael},
  year = {2020},
  month = may,
  number = {arXiv:1912.02967},
  eprint = {1912.02967},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2024-03-15},
  abstract = {Function approximation is a powerful approach for structuring large decision problems that has facilitated great achievements in the areas of reinforcement learning and game playing. Regression counterfactual regret minimization (RCFR) is a simple algorithm for approximately solving imperfect information games with normalized rectified linear unit (ReLU) parameterized policies. In contrast, the more conventional softmax parameterization is standard in the field of reinforcement learning and yields a regret bound with a better dependence on the number of actions. We derive approximation error-aware regret bounds for ({$\Phi$}, f )-regret matching, which applies to a general class of link functions and regret objectives. These bounds recover a tighter bound for RCFR and provide a theoretical justification for RCFR implementations with alternative policy parameterizations (f -RCFR), including softmax. We provide exploitability bounds for f -RCFR with the polynomial and exponential link functions in zero-sum imperfect information games and examine empirically how the link function interacts with the severity of the approximation. We find that the previously studied ReLU parameterization performs better when the approximation error is small while the softmax parameterization can perform better when the approximation error is large.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Science and Game Theory,Computer Science - Machine Learning},
  file = {/Users/DAADAMS/Zotero/storage/3G49UCTP/D'Orazio et al. - 2020 - Alternative Function Approximation Parameterizatio.pdf}
}

@article{doritavrahami-zilberbrandFastCompleteSymbolic2005,
  title = {Fast and Complete Symbolic Plan Recognition},
  author = {{Dorit Avrahami-Zilberbrand} and {Avrahami-Zilberbrand}, Dorit and {Gal A. Kaminka} and Kaminka, Gal A.},
  year = {2005},
  month = jul,
  pages = {653--658},
  abstract = {Recent applications of plan recognition face several open challenges: (i) matching observations to the plan library is costly, especially with complex multi-featured observations; (ii) computing recognition hypotheses is expensive. We present techniques for addressing these challenges. First, we show a novel application of machine-learning decision-tree to efficiently map multi-featured observations to matching plan steps. Second, we provide efficient lazy-commitment recognition algorithms that avoid enumerating hypotheses with every observation, instead only carrying out bookkeeping incrementally. The algorithms answer queries as to the current state of the agent, as well as its history of selected states. We provide empirical results demonstrating their efficiency and capabilities.},
  annotation = {MAG ID: 98519143}
}

@inproceedings{draganLegibilityPredictabilityRobot2013,
  title = {Legibility and Predictability of Robot Motion},
  booktitle = {2013 8th {{ACM}}/{{IEEE International Conference}} on {{Human-Robot Interaction}} ({{HRI}})},
  author = {Dragan, Anca D. and Lee, Kenton CT and Srinivasa, Siddhartha S.},
  year = {2013},
  pages = {301--308},
  publisher = {IEEE},
  urldate = {2024-08-12}
}

@inproceedings{dragomirCentroidbasedSummarizationMultiple2000,
  title = {Centroid-Based Summarization of Multiple Documents: Sentence Extraction, Utility-Based Evaluation, and User Studies},
  shorttitle = {Centroid-Based Summarization of Multiple Documents},
  booktitle = {{{ANLP}}/{{NAACL Workshop}} on {{Summarization}}},
  author = {Dragomir, Radev and Hongyan, Jing and Malgorzata, Budzikowska},
  year = {2000},
  volume = {10}
}

@inproceedings{drosouReDRIVEResultdrivenDatabase2011,
  title = {{{ReDRIVE}}: Result-Driven Database Exploration through Recommendations},
  shorttitle = {{{ReDRIVE}}},
  booktitle = {Proceedings of the 20th {{ACM}} International Conference on {{Information}} and Knowledge Management},
  author = {Drosou, Marina and Pitoura, Evaggelia},
  year = {2011},
  month = oct,
  pages = {1547--1552},
  publisher = {ACM},
  address = {Glasgow Scotland, UK},
  doi = {10.1145/2063576.2063798},
  urldate = {2025-03-31},
  abstract = {Typically, users interact with database systems by formulating queries. However, many times users do not have a clear understanding of their information needs or the exact content of the database, thus, their queries are of an exploratory nature. In this paper, we propose assisting users in database exploration by recommending to them additional items that are highly related with the items in the result of their original query. Such items are computed based on the most interesting sets of attribute values (or faSets) that appear in the result of the original user query. The interestingness of a faSet is defined based on its frequency both in the query result and in the database instance. Database frequency estimations rely on a novel approach that employs an {\k o}-tolerance closed rare faSets representation. We report evaluation results of the efficiency and effectiveness of our approach on both real and synthetic datasets.},
  isbn = {978-1-4503-0717-8},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/UFXUZXG5/Drosou and Pitoura - 2011 - ReDRIVE result-driven database exploration through recommendations.pdf}
}

@article{drosouYmaldbExploringRelational2013,
  title = {Ymaldb: Exploring Relational Databases via Result-Driven Recommendations},
  shorttitle = {Ymaldb},
  author = {Drosou, Marina and Pitoura, Evaggelia},
  year = {2013},
  journal = {The VLDB Journal},
  volume = {22},
  number = {6},
  pages = {849--874},
  publisher = {Springer},
  urldate = {2025-02-13},
  file = {/Users/DAADAMS/Zotero/storage/RLW58QMR/s00778-013-0311-4.html}
}

@article{dushkinQueryDrivenData,
  title = {Query {{Driven Data Labeling}} with {{Experts}}: {{Why Pay Twice}}?},
  author = {Dushkin, Eyal and Gershtein, Shay and Milo, Tova and Novgorodov, Slava},
  abstract = {Data has become a major priority for customer facing businesses of all sizes. Companies put a lot of effort and money into storing, cleaning, organizing, enriching and processing data to better meet user needs. Usually in large scale systems such as big ecommerce sites these tasks involve machine learning methods, relying on training data annotated by domain experts. Since domain experts are an expensive resource in terms of monetary costs and latency, it is desired to design algorithms that minimize the interaction with them.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/3WMBE6L2/Dushkin et al. - Query Driven Data Labeling with Experts Why Pay Twice.pdf}
}

@article{edmundsonNewMethodsAutomatic1969,
  title = {New {{Methods}} in {{Automatic Extracting}}},
  author = {Edmundson, H. P.},
  year = {1969},
  month = apr,
  journal = {Journal of the ACM},
  volume = {16},
  number = {2},
  pages = {264--285},
  issn = {0004-5411, 1557-735X},
  doi = {10.1145/321510.321519},
  urldate = {2025-02-16},
  abstract = {This paper describes new methods of automatically extracting documents for screening purposes, i.e. the computer selection of sentences having the greatest potential for conveying to the reader the substance of the document. While previous work has focused on one component of sentence significance, namely, the presence of high-frequency content words (key words), the methods described here also treat three additional components: pragmatic words (cue words); title and heading words; and structural indicators (sentence location).             The research has resulted in an operating system and a research methodology. The extracting system is parameterized to control and vary the influence of the above four components. The research methodology includes procedures for the compilation of the required dictionaries, the setting of the control parameters, and the comparative evaluation of the automatic extracts with manually produced extracts. The results indicate that the three newly proposed components dominate the frequency component in the production of better extracts.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/SU28P87J/Edmundson - 1969 - New Methods in Automatic Extracting.pdf}
}

@article{edwardsimpsonMeasurementDiversity1949,
  title = {Measurement of Diversity},
  author = {{Edward Simpson} and Simpson, E. H.},
  year = {1949},
  month = jan,
  journal = {Nature},
  volume = {163},
  number = {4148},
  pages = {688--688},
  doi = {10.1038/163688a0},
  abstract = {THE 'characteristic' defined by Yule1 and the 'index of diversity' defined by Fisher2 are two measures of the degree of concentration or diversity achieved when the individuals of a population are classified into groups. Both are defined as statistics to be calculated from sample data and not in terms of population constants. The index of diversity has so far been used chiefly with the logarithmic distribution. It cannot be used everywhere, as it does not always give values which are independent of sample size ; it cannot do so, for example, when applied to an infinite population of individuals classified into a finite number of groups. Williams3 has pointed out a relationship between the characteristic and the index of diversity when both are applied to a logarithmic distribution. The present purpose is to define and examine a measure of concentration in terms of population constants.},
  annotation = {MAG ID: 2087189381},
  file = {/Users/DAADAMS/Zotero/storage/L6BBQTQG/sfxlcl41.html}
}

@inproceedings{eichmannIDEBenchBenchmarkInteractive2020,
  title = {{{IDEBench}}: {{A Benchmark}} for {{Interactive Data Exploration}}},
  shorttitle = {{{IDEBench}}},
  booktitle = {Proceedings of the 2020 {{ACM SIGMOD International Conference}} on {{Management}} of {{Data}}},
  author = {Eichmann, Philipp and Zgraggen, Emanuel and Binnig, Carsten and Kraska, Tim},
  year = {2020},
  month = jun,
  pages = {1555--1569},
  publisher = {ACM},
  address = {Portland OR USA},
  doi = {10.1145/3318464.3380574},
  urldate = {2025-02-05},
  abstract = {In recent years, many query processing techniques have been developed to better support interactive data exploration (IDE) of large structured datasets. To evaluate and compare database engines in terms of how well they support such workloads, experimenters have mostly used self-designed evaluation procedures rather than established benchmarks. In this paper we argue that this is due to the fact that the workloads and metrics of popular analytical benchmarks such as TPC-H or TPC-DS were designed for traditional performance reporting scenarios, and do not capture distinctive IDE characteristics. Guided by the findings of several user studies we present a new benchmark called IDEBench, designed to evaluate database engines based on common IDE workflows and metrics that matter to the end-user. We demonstrate the applicability of IDEBench through a number of experiments with five different database engines, and present and discuss our findings.},
  isbn = {978-1-4503-6735-6},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/SGI2JY3U/Eichmann et al. - 2020 - IDEBench A Benchmark for Interactive Data Exploration.pdf}
}

@inproceedings{einyCostEffectiveLLMUtilization2024,
  title = {Cost-{{Effective LLM Utilization}} for {{Machine Learning Tasks}} over {{Tabular Data}}},
  booktitle = {Proceedings of the {{Conference}} on {{Governance}}, {{Understanding}} and {{Integration}} of {{Data}} for {{Effective}} and {{Responsible AI}}},
  author = {Einy, Yael and Milo, Tova and Novgorodov, Slava},
  year = {2024},
  month = jun,
  pages = {45--49},
  publisher = {ACM},
  address = {Santiago AA Chile},
  doi = {10.1145/3665601.3669848},
  urldate = {2024-12-08},
  abstract = {Classic machine learning (ML) models excel in modeling tabular datasets but lack broader world knowledge due to the absence of pre-training, an area where Large Language Models (LLMs) stand out. This paper presents an effective method that bridges the gap, leveraging LLMs to enrich tabular data to enhance the performance of classical ML models. Despite the previously limited success of direct LLM application to tabular tasks due to their high computational demands, our approach selectively enriches datasets with essential world knowledge, balancing performance improvement with costeffectiveness. This work advances the capabilities of traditional ML models and opens new avenues for research at the convergence of classical ML and LLMs, marking the onset of a new era in cost-effective data enrichment.},
  isbn = {979-8-4007-0694-3},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/VU4URLAM/Einy et al. - 2024 - Cost-Effective LLM Utilization for Machine Learning Tasks over Tabular Data.pdf}
}

@article{eirinakiQuerieCollaborativeDatabase2013,
  title = {Querie: {{Collaborative}} Database Exploration},
  shorttitle = {Querie},
  author = {Eirinaki, Magdalini and Abraham, Suju and Polyzotis, Neoklis and Shaikh, Naushin},
  year = {2013},
  journal = {IEEE Transactions on knowledge and data engineering},
  volume = {26},
  number = {7},
  pages = {1778--1790},
  publisher = {IEEE},
  urldate = {2025-02-16},
  file = {/Users/DAADAMS/Zotero/storage/5C93UHP5/Eirinaki et al. - 2013 - Querie Collaborative database exploration.pdf}
}

@techreport{englishFlexibleSearchNavigation2002,
  title = {Flexible Search and Navigation Using Faceted Metadata},
  author = {English, Jennifer and Hearst, Marti and Sinha, Rashmi and Swearingen, Kirsten and Lee, K. P.},
  year = {2002},
  institution = {Technical report, University of Berkeley, School of Information Management {\dots}},
  urldate = {2024-08-13},
  file = {/Users/DAADAMS/Zotero/storage/K76Q3T6V/English et al. - 2002 - Flexible search and navigation using faceted metad.pdf}
}

@article{evansSimilaritybasedMultilingualMultidocument2005,
  title = {Similarity-Based Multilingual Multi-Document Summarization},
  author = {Evans, David Kirk and McKeown, Kathleen and Klavans, Judith L.},
  year = {2005},
  file = {/Users/DAADAMS/Zotero/storage/QJNP2ZB5/Evans et al. - 2005 - Similarity-based multilingual multi-document summarization.pdf}
}

@article{fisterjrNarmVizNovelMethod2024,
  title = {{{NarmViz}}: {{A}} Novel Method for Visualization of Time Series Numerical Association Rules for Smart Agriculture},
  shorttitle = {{{NarmViz}}},
  author = {Fister Jr, Iztok and Fister, Iztok and Podgorelec, Vili and {Salcedo-Sanz}, Sancho and Holzinger, Andreas},
  year = {2024},
  journal = {Expert Systems},
  volume = {41},
  number = {3},
  pages = {e13503},
  issn = {1468-0394},
  doi = {10.1111/exsy.13503},
  urldate = {2025-01-07},
  abstract = {Numerical association rule mining (NARM) is a popular method under the umbrella of data mining, focused on finding relationships between attributes in transaction databases. Numerical association rules for time series are a new paradigm that extends the applicability of NARM to the domain of time series. Association rule mining algorithms result in numerous rules, the interpretation of which is sometimes not easy for human experts. Therefore, various visualization methods have been developed to improve the explanation results of the rule mining process. This article is a novel contribution to the development of a new visualization method capable of presenting the association rules for time series developed according to the principles of explainable artificial intelligence. The experiments are conducted in the context of smart agriculture (i.e., agricultural time series data), and show the great potential of the proposed visualization method for the future.},
  langid = {english},
  keywords = {association rule mining,explainable artificial intelligence,smart agriculture,time series,visualization},
  file = {/Users/DAADAMS/Zotero/storage/G5ZET3G7/Fister Jr et al. - 2024 - NarmViz A novel method for visualization of time series numerical association rules for smart agric.pdf;/Users/DAADAMS/Zotero/storage/8QK33WMI/exsy.html}
}

@misc{flageatBenchmarkingQualityDiversityAlgorithms2022,
  title = {Benchmarking {{Quality-Diversity Algorithms}} on {{Neuroevolution}} for {{Reinforcement Learning}}},
  author = {Flageat, Manon and Lim, Bryan and Grillotti, Luca and Allard, Maxime and Smith, Sim{\'o}n C. and Cully, Antoine},
  year = {2022},
  month = nov,
  number = {arXiv:2211.02193},
  eprint = {2211.02193},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2024-09-03},
  abstract = {We present a Quality-Diversity benchmark suite for Deep Neuroevolution in Reinforcement Learning domains for robot control. The suite includes the definition of tasks, environments, behavioral descriptors, and fitness. We specify different benchmarks based on the complexity of both the task and the agent controlled by a deep neural network. The benchmark uses standard Quality-Diversity metrics, including coverage, QD-score, maximum fitness, and an archive profile metric to quantify the relation between coverage and fitness. We also present how to quantify the robustness of the solutions with respect to environmental stochasticity by introducing corrected versions of the same metrics. We believe that our benchmark is a valuable tool for the community to compare and improve their findings. The source code is available online: https://github.com/adaptive-intelligent-robotics/QDax},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Computer Science - Robotics},
  file = {/Users/DAADAMS/Zotero/storage/DDM365E2/Flageat et al. - 2022 - Benchmarking Quality-Diversity Algorithms on Neuroevolution for Reinforcement Learning.pdf;/Users/DAADAMS/Zotero/storage/4CX5MYSX/2211.html}
}

@article{francescoborrelliPredictiveControlLinear2017,
  title = {Predictive {{Control}} for {{Linear}} and {{Hybrid Systems}}},
  author = {{Francesco Borrelli} and Borrelli, Francesco and {Alberto Bemporad} and Bemporad, Alberto and {Manfred Morari} and Morari, Manfred},
  year = {2017},
  month = jul,
  abstract = {Model Predictive Control (MPC), the dominant advanced control approach in industry over the past twenty-five years, is presented comprehensively in this unique book. With a simple, unified approach, and with attention to real-time implementation, it covers predictive control theory including the stability, feasibility, and robustness of MPC controllers. The theory of explicit MPC, where the nonlinear optimal feedback controller can be calculated efficiently, is presented in the context of linear systems with linear constraints, switched linear systems, and, more generally, linear hybrid systems. Drawing upon years of practical experience and using numerous examples and illustrative applications, the authors discuss the techniques required to design predictive control laws, including algorithms for polyhedral manipulations, mathematical and multiparametric programming and how to validate the theoretical properties and to implement predictive control policies. The most important algorithms feature in an accompanying free online MATLAB toolbox, which allows easy access to sample solutions. Predictive Control for Linear and Hybrid Systems is an ideal reference for graduate, postgraduate and advanced control practitioners interested in theory and/or implementation aspects of predictive control.},
  annotation = {MAG ID: 2749680651}
}

@misc{gadreDataCompSearchNext2023,
  title = {{{DataComp}}: {{In}} Search of the next Generation of Multimodal Datasets},
  shorttitle = {{{DataComp}}},
  author = {Gadre, Samir Yitzhak and Ilharco, Gabriel and Fang, Alex and Hayase, Jonathan and Smyrnis, Georgios and Nguyen, Thao and Marten, Ryan and Wortsman, Mitchell and Ghosh, Dhruba and Zhang, Jieyu and Orgad, Eyal and Entezari, Rahim and Daras, Giannis and Pratt, Sarah and Ramanujan, Vivek and Bitton, Yonatan and Marathe, Kalyani and Mussmann, Stephen and Vencu, Richard and Cherti, Mehdi and Krishna, Ranjay and Koh, Pang Wei and Saukh, Olga and Ratner, Alexander and Song, Shuran and Hajishirzi, Hannaneh and Farhadi, Ali and Beaumont, Romain and Oh, Sewoong and Dimakis, Alex and Jitsev, Jenia and Carmon, Yair and Shankar, Vaishaal and Schmidt, Ludwig},
  year = {2023},
  month = apr,
  journal = {arXiv.org},
  urldate = {2024-03-19},
  abstract = {Multimodal datasets are a critical component in recent breakthroughs such as Stable Diffusion and GPT-4, yet their design does not receive the same research attention as model architectures or training algorithms. To address this shortcoming in the ML ecosystem, we introduce DataComp, a testbed for dataset experiments centered around a new candidate pool of 12.8 billion image-text pairs from Common Crawl. Participants in our benchmark design new filtering techniques or curate new data sources and then evaluate their new dataset by running our standardized CLIP training code and testing the resulting model on 38 downstream test sets. Our benchmark consists of multiple compute scales spanning four orders of magnitude, which enables the study of scaling trends and makes the benchmark accessible to researchers with varying resources. Our baseline experiments show that the DataComp workflow leads to better training sets. In particular, our best baseline, DataComp-1B, enables training a CLIP ViT-L/14 from scratch to 79.2\% zero-shot accuracy on ImageNet, outperforming OpenAI's CLIP ViT-L/14 by 3.7 percentage points while using the same training procedure and compute. We release DataComp and all accompanying code at www.datacomp.ai.},
  howpublished = {https://arxiv.org/abs/2304.14108v5},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/EJR4J4JP/Gadre et al. - 2023 - DataComp In search of the next generation of mult.pdf}
}

@inproceedings{gaoDBAugurAdversarialbasedTrend2023,
  title = {{{DBAugur}}: {{An Adversarial-based Trend Forecasting System}} for {{Diversified Workloads}}},
  shorttitle = {{{DBAugur}}},
  booktitle = {2023 {{IEEE}} 39th {{International Conference}} on {{Data Engineering}} ({{ICDE}})},
  author = {Gao, Yuanning and Huang, Xiuqi and Zhou, Xuanhe and Gao, Xiaofeng and Li, Guoliang and Chen, Guihai},
  year = {2023},
  month = apr,
  pages = {27--39},
  publisher = {IEEE},
  address = {Anaheim, CA, USA},
  doi = {10.1109/ICDE55515.2023.00385},
  urldate = {2025-02-24},
  abstract = {Trend forecasting is vital to optimize the workload performance. It becomes even more urgent with an increasing number of applications and database configurations. However, DBAs mainly target at historical workloads and may give suboptimal configuration advice when the workload trends have changed. Although there are some studies on trend forecasting, they have several limitations. First, they mainly predict the changes of query numbers, which do not combine other critical factors (e.g., disk utilization) and cannot fully reflect the future workload trends. Besides, there are numerous queries in the workloads and exact clustering algorithms like K-means cannot effectively merge similar queries which contain noises like time shifts. Second, basic machine learning models like RNN may have relatively low prediction accuracy on complex workloads (e.g., no cycles but random bursts). Third, real-world workloads may have diverse patterns, while previous models cannot efficiently and reliably predict for all the different workload patterns.},
  copyright = {https://doi.org/10.15223/policy-029},
  isbn = {979-8-3503-2227-9},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/M4ZNJXE8/Gao et al. - 2023 - DBAugur An Adversarial-based Trend Forecasting System for Diversified Workloads.pdf}
}

@article{gengInterestingnessMeasuresData2006,
  title = {Interestingness Measures for Data Mining: {{A}} Survey},
  shorttitle = {Interestingness Measures for Data Mining},
  author = {Geng, Liqiang and Hamilton, Howard J.},
  year = {2006},
  month = sep,
  journal = {ACM Computing Surveys},
  volume = {38},
  number = {3},
  pages = {9},
  issn = {0360-0300, 1557-7341},
  doi = {10.1145/1132960.1132963},
  urldate = {2024-06-28},
  abstract = {Interestingness measures play an important role in data mining, regardless of the kind of patterns being mined. These measures are intended for selecting and ranking patterns according to their potential interest to the user. Good measures also allow the time and space costs of the mining process to be reduced. This survey reviews the interestingness measures for rules and summaries, classifies them from several perspectives, compares their properties, identifies their roles in the data mining process, gives strategies for selecting appropriate measures for applications, and identifies opportunities for future research in this area.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/IKBIFY6Q/Geng and Hamilton - 2006 - Interestingness measures for data mining A survey.pdf;/Users/DAADAMS/Zotero/storage/ZYUP6L83/Geng and Hamilton - 2006 - Interestingness measures for data mining A survey.pdf}
}

@article{ghazanfariSequentialAssociationRule2020,
  title = {Sequential {{Association Rule Mining}} for {{Autonomously Extracting Hierarchical Task Structures}} in {{Reinforcement Learning}}},
  author = {Ghazanfari, Behzad and Afghah, Fatemeh and Taylor, Matthew E.},
  year = {2020},
  journal = {IEEE Access},
  volume = {8},
  pages = {11782--11799},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2020.2965930},
  urldate = {2025-01-13},
  abstract = {Reinforcement learning (RL) techniques, while often powerful, can suffer from slow learning speeds, particularly in high dimensional spaces or in environments with sparse rewards. The decomposition of tasks into a hierarchical structure holds the potential to significantly speed up learning, generalization, and transfer learning. However, the current task decomposition techniques often cannot extract hierarchical task structures without relying on high-level knowledge provided by an expert (e.g., using dynamic Bayesian networks (DBNs) in factored Markov decision processes), which is not necessarily available in autonomous systems. In this paper, we propose a novel method based on Sequential Association Rule Mining that can extract Hierarchical Structure of Tasks in Reinforcement Learning (SARM-HSTRL) in an autonomous manner for both Markov decision processes (MDPs) and factored MDPs. The proposed method leverages association rule mining to discover the causal and temporal relationships among states in different trajectories and extracts a task hierarchy that captures these relationships among sub-goals as termination conditions of different sub-tasks. We prove that the extracted hierarchical policy offers a hierarchically optimal policy in MDPs and factored MDPs. It should be noted that SARM-HSTRL extracts this hierarchical optimal policy without having dynamic Bayesian networks in scenarios with a single task trajectory and also with multiple tasks' trajectories. Furthermore, we show theoretically and empirically that the extracted hierarchical task structure is consistent with trajectories and provides the most efficient, reliable, and compact structure under appropriate assumptions. The numerical results compare the performance of the proposed SARM-HSTRL method with conventional HRL algorithms in terms of the accuracy in detecting the sub-goals, the validity of the extracted hierarchies, and the speed of learning in several testbeds. The key capabilities of SARM-HSTRL including handling multiple tasks and autonomous hierarchical task extraction can lead to the application of this HRL method in reusing, transferring, and generalization of knowledge in different domains.},
  keywords = {Association rule mining,Autonomous systems,Bayes methods,extracting task structure,hierarchical reinforcement learning,Markov processes,Reinforcement learning,Reliability,Task analysis,Trajectory},
  annotation = {Read\_Status: Read\\
Read\_Status\_Date: 2025-01-13T05:34:24.006Z},
  file = {/Users/DAADAMS/Zotero/storage/CREYEIEC/Ghazanfari et al. - 2020 - Sequential Association Rule Mining for Autonomously Extracting Hierarchical Task Structures in Reinf.pdf;/Users/DAADAMS/Zotero/storage/XVEIRYJX/8957114.html}
}

@incollection{giacomettiRecommendingMultidimensionalQueries2009,
  title = {Recommending {{Multidimensional Queries}}},
  booktitle = {Data {{Warehousing}} and {{Knowledge Discovery}}},
  author = {Giacometti, Arnaud and Marcel, Patrick and Negre, Elsa},
  editor = {Pedersen, Torben Bach and Mohania, Mukesh K. and Tjoa, A Min},
  year = {2009},
  volume = {5691},
  pages = {453--466},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-03730-6_36},
  urldate = {2025-02-16},
  isbn = {978-3-642-03729-0 978-3-642-03730-6},
  file = {/Users/DAADAMS/Zotero/storage/6RSUR8AM/Giacometti et al. - 2009 - Recommending Multidimensional Queries.pdf}
}

@article{goodmanRuleInductionUsing1991,
  title = {Rule Induction Using Information Theory},
  author = {Goodman, Rodney M. and Smyth, P.},
  year = {1991},
  journal = {G. Piatetsky},
  publisher = {Citeseer},
  urldate = {2024-08-07},
  file = {/Users/DAADAMS/Zotero/storage/LN7E4N3H/Goodman and Smyth - 1991 - Rule induction using information theory.pdf}
}

@article{goyalgarimaStudyInterestingnessMeasures2015,
  title = {A {{Study}} of {{Interestingness Measures}} for {{Knowledge Discovery}} in {{Databases}}---{{A Genetic Approach}}},
  author = {{Goyal Garima} and Garima, Goyal and {Jyoti Vashishtha} and Vashishtha, Jyoti},
  year = {2015},
  month = jan,
  pages = {69--79},
  doi = {10.1007/978-81-322-2208-8_8},
  abstract = {One of the vital areas of attention in the field of knowledge discovery is to analyze the interestingness measures in rule discovery and to select the best one according to the situation. There is a wide variety of interestingness measures available in data mining literature and it is difficult for user to select appropriate measure in a particular application domain. The main contribution of the paper is to compare these interestingness measures on diverse datasets by using genetic algorithm and select the best one according to the situation.},
  annotation = {MAG ID: 3403051}
}

@article{gregorypiateskiKnowledgeDiscoveryDatabases1991,
  title = {Knowledge {{Discovery}} in {{Databases}}},
  author = {{Gregory Piateski} and Piateski, Gregory and {William Frawley} and {William Frawley} and Frawley, William and {William Frawley}},
  year = {1991},
  month = dec,
  abstract = {From the Publisher: Knowledge Discovery in Databases brings together current research on the exciting problem of discovering useful and interesting knowledge in databases. It spans many different approaches to discovery, including inductive learning, bayesian statistics, semantic query optimization, knowledge acquisition for expert systems, information theory, and fuzzy 1 sets. The rapid growth in the number and size of databases creates a need for tools and techniques for intelligent data understanding. Relationships and patterns in data may enable a manufacturer to discover the cause of a persistent disk failure or the reason for consumer complaints. But today's databases hide their secrets beneath a cover of overwhelming detail. The task of uncovering these secrets is called "discovery in databases." This loosely defined subfield of machine learning is concerned with discovery from large amounts of possible uncertain data. Its techniques range from statistics to the use of domain knowledge to control search. Following an overview of knowledge discovery in databases, thirty technical chapters are grouped in seven parts which cover discovery of quantitative laws, discovery of qualitative laws, using knowledge in discovery, data summarization, domain specific discovery methods, integrated and multi-paradigm systems, and methodology and application issues. An important thread running through the collection is reliance on domain knowledge, starting with general methods and progressing to specialized methods where domain knowledge is built in. Gregory Piatetski-Shapiro is Senior Member of Technical Staff and Principal Investigator of the Knowledge Discovery Project at GTELaboratories. William Frawley is Principal Member of Technical Staff at GTE and Principal Investigator of the Learning in Expert Domains Project.},
  annotation = {MAG ID: 1601529450}
}

@article{guoDADANDualAdversarial2024,
  title = {{{DA-DAN}}: {{A Dual Adversarial Domain Adaption Network}} for {{Unsupervised Non-overlapping Cross-domain Recommendation}}},
  shorttitle = {{{DA-DAN}}},
  author = {Guo, Lei and Liu, Hao and Zhu, Lei and Guan, Weili and Cheng, Zhiyong},
  year = {2024},
  month = mar,
  journal = {ACM Transactions on Information Systems},
  volume = {42},
  number = {2},
  pages = {1--27},
  issn = {1046-8188, 1558-2868},
  doi = {10.1145/3617825},
  urldate = {2025-09-08},
  abstract = {Unsupervised Non-overlapping Cross-domain Recommendation (UNCR) is the task that recommends source domain items to the target domain users, which is more challenging as the users are non-overlapped, and its learning process is unsupervised. Unsupervised Non-overlapping Cross-domain Recommendation UNCR is still unsolved due to the following: (1) Previous studies need extra auxiliary information to learn transferable features when aligning two domains, which is unrealistic and hard to obtain due to privacy concerns. (2) Since the adoption of the shared network, existing works cannot well eliminate the domain-specific features in the common feature space, which may incorporate domain noise and harm the cross-domain recommendation. In this work, we propose a domain adaption-based method, namely DA-DAN, to address the above challenges. Specifically, to let DA-DAN be free of auxiliary information, we learn users' preferences by only exploring their sequential patterns, and propose an improved self-attention layer to model them. To well eliminate the domain-specific features from the common feature space, we resort to a dual generative adversarial network with a multi-target adversarial loss, where two generators and discriminators are leveraged to model each domain separately. Experimental results on three real-world datasets demonstrate the advantage of DA-DAN compared with the state-of-the-art recommendation baselines. Moreover, our source codes have been publicly released.                                1},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/MLMM4539/Guo et al. - 2024 - DA-DAN A Dual Adversarial Domain Adaption Network for Unsupervised Non-overlapping Cross-domain Rec.pdf}
}

@misc{guoUraniaVisualizingData2023,
  title = {Urania: {{Visualizing Data Analysis Pipelines}} for {{Natural Language-Based Data Exploration}}},
  shorttitle = {Urania},
  author = {Guo, Yi and Cao, Nan and Qi, Xiaoyu and Li, Haoyang and Shi, Danqing and Zhang, Jing and Chen, Qing and Weiskopf, Daniel},
  year = {2023},
  month = jun,
  number = {arXiv:2306.07760},
  eprint = {2306.07760},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2306.07760},
  urldate = {2024-12-08},
  abstract = {Exploratory Data Analysis (EDA) is an essential yet tedious process for examining a new dataset. To facilitate it, natural language interfaces (NLIs) can help people intuitively explore the dataset via data-oriented questions. However, existing NLIs primarily focus on providing accurate answers to questions, with few offering explanations or presentations of the data analysis pipeline used to uncover the answer. Such presentations are crucial for EDA as they enhance the interpretability and reliability of the answer, while also helping users understand the analysis process and derive insights. To fill this gap, we introduce Urania, a natural language interactive system that is able to visualize the data analysis pipelines used to resolve input questions. It integrates a natural language interface that allows users to explore data via questions, and a novel dataaware question decomposition algorithm that resolves each input question into a data analysis pipeline. This pipeline is visualized in the form of a datamation, with animated presentations of analysis operations and their corresponding data changes. Through two quantitative experiments and expert interviews, we demonstrated that our data-aware question decomposition algorithm outperforms the state-of-the-art technique in terms of execution accuracy, and that Urania can help people explore datasets better. In the end, we discuss the observations from the studies and the potential future works.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Human-Computer Interaction},
  file = {/Users/DAADAMS/Zotero/storage/PFSD9LRQ/Guo et al. - 2023 - Urania Visualizing Data Analysis Pipelines for Natural Language-Based Data Exploration.pdf}
}

@inproceedings{ha-thucQualitythresholdDataSummarization2008,
  title = {A Quality-Threshold Data Summarization Algorithm},
  booktitle = {2008 {{IEEE International Conference}} on {{Research}}, {{Innovation}} and {{Vision}} for the {{Future}} in {{Computing}} and {{Communication Technologies}}},
  author = {{Ha-Thuc}, Viet and Nguyen, Duc-Cuong and Srinivasan, Padmini},
  year = {2008},
  pages = {240--246},
  publisher = {IEEE},
  urldate = {2025-02-16}
}

@article{han16ExplorationPower,
  title = {16 {{Exploration}} of the {{Power}} of {{Attribute-Oriented Induction}} in {{Data Mining}}},
  author = {Han, Jiawei and Fu, Yongjian},
  journal = {Ad{\dots} ces in Know Ledge Discover and Data M ining. Cambridge: AAAI/'\&I1T Press, 1g96},
  pages = {399--42l},
  publisher = {Citeseer},
  urldate = {2025-02-16},
  file = {/Users/DAADAMS/Zotero/storage/JN8YBXST/Han and Fu - 16 Exploration of the Power of Attribute-Oriented Induction in Data Mining.pdf}
}

@inproceedings{hanDBLearnSystemPrototype1994,
  title = {{{DBLearn}}: A System Prototype for Knowledge Discovery in Relational Databases},
  shorttitle = {{{DBLearn}}},
  booktitle = {Proceedings of the 1994 {{ACM SIGMOD}} International Conference on {{Management}} of Data},
  author = {Han, Jiawei and Fu, Yongjian and Huang, Yue and Cai, Yandong and Cercone, Nick},
  year = {1994},
  month = may,
  pages = {516},
  publisher = {ACM},
  address = {Minneapolis Minnesota USA},
  doi = {10.1145/191839.191979},
  urldate = {2025-02-16},
  isbn = {978-0-89791-639-4},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/UPRGTBC3/Han et al. - 1994 - DBLearn a system prototype for knowledge discovery in relational databases.pdf}
}

@inproceedings{hanDBMinerSystemMining1996,
  title = {{{DBMiner}}: {{A System}} for {{Mining Knowledge}} in {{Large Relational Databases}}.},
  shorttitle = {{{DBMiner}}},
  booktitle = {{{KDD}}},
  author = {Han, Jiawei and Fu, Yongjian and Wang, Wei and Chiang, Jenny and Gong, Wan and Koperski, Krzysztof and Li, Deyi and Lu, Yijun and Rajan, Amynmohamed and Stefanovic, Nebojsa},
  year = {1996},
  volume = {96},
  pages = {250--255},
  urldate = {2025-02-16},
  file = {/Users/DAADAMS/Zotero/storage/PTJHDTEK/Han et al. - 1996 - DBMiner A System for Mining Knowledge in Large Relational Databases..pdf}
}

@inproceedings{hanKnowledgeDiscoveryDatabases1992,
  title = {Knowledge Discovery in Databases: {{An}} Attribute-Oriented Approach},
  shorttitle = {Knowledge Discovery in Databases},
  booktitle = {{{VLDB}}},
  author = {Han, Jiawei and Cai, Yandong and Cercone, Nick},
  year = {1992},
  volume = {18},
  pages = {574--559},
  urldate = {2025-02-16},
  file = {/Users/DAADAMS/Zotero/storage/DHVZYUG6/Han et al. - 1992 - Knowledge discovery in databases An attribute-oriented approach.pdf}
}

@article{hectorgeffnerConciseIntroductionModels2013,
  title = {A {{Concise Introduction}} to {{Models}} and {{Methods}} for {{Automated Planning}}},
  author = {{H{\'e}ctor Geffner} and Geffner, Hector and {Blai Bonet} and Bonet, Blai},
  year = {2013},
  month = jul,
  volume = {7},
  number = {2},
  pages = {1--141},
  abstract = {Planning is the model-based approach to autonomous behavior where the agent behavior is derived automatically from a model of the actions, sensors, and goals. The main challenges in planning are computational as all models, whether featuring uncertainty and feedback or not, are intractable in the worst case when represented in compact form. In this book, we look at a variety of models used in AI planning, and at the methods that have been developed for solving them. The goal is to provide a modern and coherent view of planning that is precise, concise, and mostly self-contained, without being shallow. For this, we make no attempt at covering the whole variety of planning approaches, ideas, and applications, and focus on the essentials. The target audience of the book are students and researchers interested in autonomous behavior and planning from an AI, engineering, or cognitive science perspective. Table of Contents: Preface / Planning and Autonomous Behavior / Classical Planning: Full Information and Deterministic Actions / Classical Planning: Variations and Extensions / Beyond Classical Planning: Transformations / Planning with Sensing: Logical Models / MDP Planning: Stochastic Actions and Full Feedback / POMDP Planning: Stochastic Actions and Partial Feedback / Discussion / Bibliography / Author's Biography},
  annotation = {MAG ID: 1987411046}
}

@misc{hendrickxMachineLearningReject2024,
  title = {Machine {{Learning}} with a {{Reject Option}}: {{A}} Survey},
  shorttitle = {Machine {{Learning}} with a {{Reject Option}}},
  author = {Hendrickx, Kilian and Perini, Lorenzo and {Van der Plas}, Dries and Meert, Wannes and Davis, Jesse},
  year = {2024},
  month = feb,
  number = {arXiv:2107.11277},
  eprint = {2107.11277},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2107.11277},
  urldate = {2024-09-23},
  abstract = {Machine learning models always make a prediction, even when it is likely to be inaccurate. This behavior should be avoided in many decision support applications, where mistakes can have severe consequences. Albeit already studied in 1970, machine learning with rejection recently gained interest. This machine learning subfield enables machine learning models to abstain from making a prediction when likely to make a mistake. This survey aims to provide an overview on machine learning with rejection. We introduce the conditions leading to two types of rejection, ambiguity and novelty rejection, which we carefully formalize. Moreover, we review and categorize strategies to evaluate a model's predictive and rejective quality. Additionally, we define the existing architectures for models with rejection and describe the standard techniques for learning such models. Finally, we provide examples of relevant application domains and show how machine learning with rejection relates to other machine learning research areas.},
  archiveprefix = {arXiv},
  keywords = {68T02,Computer Science - Artificial Intelligence,Computer Science - Machine Learning,I.2.6},
  annotation = {Read\_Status: To Read\\
Read\_Status\_Date: 2024-12-09T00:54:31.212Z},
  file = {/Users/DAADAMS/Zotero/storage/E7KIBSZ8/Hendrickx et al. - 2024 - Machine Learning with a Reject Option A survey.pdf;/Users/DAADAMS/Zotero/storage/W2BPJU2B/2107.html}
}

@article{heraguemiMultiswarmBatAlgorithm2016,
  title = {Multi-Swarm Bat Algorithm for Association Rule Mining Using Multiple Cooperative Strategies},
  author = {Heraguemi, Kamel Eddine and Kamel, Nadjet and Drias, Habiba},
  year = {2016},
  month = dec,
  journal = {Applied Intelligence},
  volume = {45},
  number = {4},
  pages = {1021--1033},
  issn = {0924-669X, 1573-7497},
  doi = {10.1007/s10489-016-0806-y},
  urldate = {2024-12-23},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/SN3QGG87/Heraguemi et al. - 2016 - Multi-swarm bat algorithm for association rule mining using multiple cooperative strategies.pdf}
}

@article{hildermanEvfaolruRataionnkinofgIDntiescreosvteirnegdneKsnsOMweleadsgueres,
  title = {{{EvfaolruRataionnkinofg IDntiescreosvteirnegdneKsns oMweleadsgueres}}},
  author = {Hilderman, Robert J and Hamilton, Howard J},
  abstract = {When mining a large database, the number of patterns discovered can easily exceed the capabilities of a human user to identify interesting results. To address this problem, various techniques have been suggested to reduce and/or order the patterns prior to presenting them to the user. In this paper, our focus is on ranking summaries generated from a single dataset, where attributes can be generalized in many different ways and to many levels of granularity according to taxonomic hierarchies. We theoretically and empirically evaluate thirteen diversity measures used as heuristic measures of interestingness for ranking summaries generated from databases. The thirteen diversity measures have previously been utilized in various disciplines, such as information theory, statistics, ecology, and economics. We describe ve principles that any measure must satisfy to be considered useful for ranking summaries. Theoretical results show that only four of the thirteen diversity measures satisfy all of the principles. We then analyze the distribution of the index values generated by each of the thirteen diversity measures. Empirical results, obtained using synthetic data, show that the distribution of index values generated tend to be highly skewed about the mean, median, and middle index values. The objective of this work is to gain some insight into the behaviour that can be expected from each of the measures in practice.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/2DTXN8AF/Hilderman and Hamilton - EvfaolruRataionnkinofg IDntiescreosvteirnegdneKsns.pdf}
}

@misc{HKUDSRLMRec2025,
  title = {{{HKUDS}}/{{RLMRec}}},
  year = {2025},
  month = sep,
  urldate = {2025-09-08},
  abstract = {[WWW'2024] "RLMRec: Representation Learning with Large Language Models for Recommendation"},
  copyright = {Apache-2.0},
  howpublished = {✨Data Intelligence Lab@HKU✨},
  keywords = {collaborative-filtering,graph-neural-networks,large-language-models,recommendation,recommender-systems}
}

@article{hoffmannOrderedLandmarksPlanning2004,
  title = {Ordered Landmarks in Planning},
  author = {Hoffmann, J{\"o}rg and Porteous, Julie and Sebastia, Laura},
  year = {2004},
  month = jul,
  journal = {Journal of Artificial Intelligence Research},
  volume = {22},
  number = {1},
  pages = {215--278},
  doi = {10.1613/jair.1492},
  abstract = {Many known planning tasks have inherent constraints concerning the best order in which to achieve the goals. A number of research efiorts have been made to detect such constraints and to use them for guiding search, in the hope of speeding up the planning process. We go beyond the previous approaches by considering ordering constraints not only over the (top-level) goals, but also over the sub-goals that will necessarily arise during planning. Landmarks are facts that must be true at some point in every valid solution plan. We extend Koehler and Hoffmann's definition of reasonable orders between top level goals to the more general case of landmarks. We show how landmarks can be found, how their reasonable orders can be approximated, and how this information can be used to decompose a given planning task into several smaller sub-tasks. Our methodology is completely domain- and planner-independent. The implementation demonstrates that the approach can yield significant runtime performance improvements when used as a control loop around state-of-the-art sub-optimal planning systems, as exemplified by FF and LPG.},
  annotation = {MAG ID: 1561643832}
}

@article{hograferSteeringbyexampleProgressiveVisual2022,
  title = {Steering-by-Example for {{Progressive Visual Analytics}}},
  author = {Hogr{\"a}fer, Marius and Angelini, Marco and Santucci, Giuseppe and Schulz, Hans-J{\"o}rg},
  year = {2022},
  month = dec,
  journal = {ACM Transactions on Intelligent Systems and Technology},
  volume = {13},
  number = {6},
  pages = {1--26},
  issn = {2157-6904, 2157-6912},
  doi = {10.1145/3531229},
  urldate = {2025-09-11},
  abstract = {Progressive visual analytics allows users to interact with early, partial results of long-running computations on large datasets. In this context, computational steering is often brought up as a means to prioritize the progressive computation. This is meant to focus computational resources on data subspaces of interest so as to ensure their computation is completed before all others. Yet, current approaches to select a region of the view space and then to prioritize its corresponding data subspace either require a one-to-one mapping between view and data space, or they need to establish and maintain computationally costly index structures to trace complex mappings between view and data space. We present steering-by-example, a novel interactive steering approach for progressive visual analytics, which allows prioritizing data subspaces for the progression by generating a relaxed query from a set of selected data items. Our approach works independently of the particular visualization technique and without additional index structures. First benchmark results show that steering-by-example considerably improves Precision and Recall for prioritizing unprocessed data for a selected view region, clearly outperforming random uniform sampling.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/LBK7EGD3/Hogräfer et al. - 2022 - Steering-by-example for Progressive Visual Analytics.pdf}
}

@article{hollensteinHowOfflineMeasures2020,
  title = {How Do {{Offline Measures}} for {{Exploration}} in {{Reinforcement Learning}} Behave?},
  author = {Hollenstein, Jakob J. and Auddy, Sayantan and Saveriano, Matteo and Renaudo, Erwan and Piater, Justus},
  year = {2020},
  journal = {arXiv preprint arXiv:2010.15533},
  eprint = {2010.15533},
  urldate = {2024-09-11},
  archiveprefix = {arXiv},
  file = {/Users/DAADAMS/Zotero/storage/HYKT47PR/Hollenstein et al. - 2020 - How do Offline Measures for Exploration in Reinforcement Learning behave.pdf}
}

@inproceedings{hollerPlanGoalRecognition2018,
  title = {Plan and {{Goal Recognition}} as {{HTN Planning}}},
  booktitle = {2018 {{IEEE}} 30th {{International Conference}} on {{Tools}} with {{Artificial Intelligence}} ({{ICTAI}})},
  author = {Holler, Daniel and Behnke, Gregor and Bercher, Pascal and Biundo, Susanne},
  year = {2018},
  month = nov,
  pages = {466--473},
  publisher = {IEEE},
  address = {Volos, Greece},
  doi = {10.1109/ICTAI.2018.00078},
  urldate = {2025-06-16},
  abstract = {Plan- and Goal Recognition (PGR) is the task of inferring the goals and plans of an agent based on its actions. A few years ago, an approach has been introduced that successfully exploits the performance of planning systems to solve it. That way, no specialized solvers are needed and PGR benefits from present and future research in planning. The approach uses classical planning systems and needs to plan (at least) once for every possible goal. However, models in PGR are often structured in a hierarchical way, similar to Hierarchical Task Networks (HTNs). These models are strictly more expressive than those in classical planning and can describe partially ordered sets of tasks or multiple goals with interleaving plans. We present the approach PGR as HTN Planning that enables the recognition of complex agent behavior by using unmodified, off-the-shelf HTN planners. Planning is thereby needed only once, regardless of how many possible goals there are. Our evaluation shows that current planning systems are able to handle large models with thousands of possible goals and that the approach results in high recognition rates.},
  isbn = {978-1-5386-7449-9},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/7KJRT2VS/Holler et al. - 2018 - Plan and Goal Recognition as HTN Planning.pdf}
}

@article{hoplarosDataSummarizationNetwork2014,
  title = {Data Summarization for Network Traffic Monitoring},
  author = {Hoplaros, Demetris and Tari, Zahir and Khalil, Ibrahim},
  year = {2014},
  journal = {Journal of network and computer applications},
  volume = {37},
  pages = {194--205},
  publisher = {Elsevier},
  urldate = {2025-02-07},
  file = {/Users/DAADAMS/Zotero/storage/UJ8KD58S/Hoplaros et al. - 2014 - Data summarization for network traffic monitoring.pdf}
}

@misc{HttpsRepositoryEssex,
  title = {{{https://repository.essex.ac.uk/4117/1/MCTS-Survey.pdf}}},
  urldate = {2024-03-15},
  howpublished = {https://repository.essex.ac.uk/4117/1/MCTS-Survey.pdf}
}

@misc{HttpsWwwSteveblackburn,
  title = {{{https://www.steveblackburn.org/pubs/papers/lbo-ispass-2022.pdf}}},
  urldate = {2024-07-22},
  howpublished = {https://www.steveblackburn.org/pubs/papers/lbo-ispass-2022.pdf}
}

@article{huangOptimizationActiveLearningbased2018,
  title = {Optimization for Active Learning-Based Interactive Database Exploration},
  author = {Huang, Enhui and Peng, Liping and Palma, Luciano Di and Abdelkafi, Ahmed and Liu, Anna and Diao, Yanlei},
  year = {2018},
  month = sep,
  journal = {Proceedings of the VLDB Endowment},
  volume = {12},
  number = {1},
  pages = {71--84},
  issn = {2150-8097},
  doi = {10.14778/3275536.3275542},
  urldate = {2025-01-28},
  abstract = {There is an increasing gap between the fast growth of data and the limited human ability to comprehend data. Consequently, there has been a growing demand of data management tools that can bridge this gap and help the user retrieve high-value content from data more effectively. In this work, we aim to build interactive data exploration as a new database service, using an approach called ``explore-by-example''. In particular, we cast the explore-by-example problem in a principled ``active learning'' framework, and bring the properties of important classes of database queries to bear on the design of new algorithms and optimizations for active learningbased database exploration. These new techniques allow the database system to overcome fundamental limitations of traditional active learning, in particular, the slow convergence problem. Evaluation results using real-world datasets and user interest patterns show that our new system significantly outperforms state-of-the-art active learning techniques and data exploration systems in accuracy while achieving desired efficiency for interactive performance.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/HWJJ9Y99/Huang et al. - 2018 - Optimization for active learning-based interactive database exploration.pdf}
}

@phdthesis{huangOptimizationActiveLearningbased2018a,
  title = {Optimization for Active Learning-Based Interactive Database Exploration},
  author = {Huang, Enhui and Peng, Liping and Di Palma, Luciano and Abdelkafi, Ahmed and Liu, Anna and Diao, Yanlei},
  year = {2018},
  urldate = {2025-02-16},
  school = {Ecole Polytechnique; University of Massachusetts Amherst},
  file = {/Users/DAADAMS/Zotero/storage/8PXEVD4Q/Huang et al. - 2018 - Optimization for active learning-based interactive database exploration.pdf}
}

@article{huangSibylForecastingTimeEvolving2024,
  title = {Sibyl: {{Forecasting Time-Evolving Query Workloads}}},
  shorttitle = {Sibyl},
  author = {Huang, Hanxian and Siddiqui, Tarique and Alotaibi, Rana and Curino, Carlo and Leeka, Jyoti and Jindal, Alekh and Zhao, Jishen and {Camacho-Rodr{\'i}guez}, Jes{\'u}s and Tian, Yuanyuan},
  year = {2024},
  month = mar,
  journal = {Proceedings of the ACM on Management of Data},
  volume = {2},
  number = {1},
  pages = {1--27},
  issn = {2836-6573},
  doi = {10.1145/3639308},
  urldate = {2025-02-24},
  abstract = {HANXIAN HUANG, University of California San Diego, USA TARIQUE SIDDIQUI, Microsoft Research, USA RANA ALOTAIBI, Microsoft Gray Systems Lab, USA CARLO CURINO, Microsoft Gray Systems Lab, USA JYOTI LEEKA, Microsoft, USA ALEKH JINDAL, SmartApps, USA JISHEN ZHAO, University of California San Diego, USA JES{\'U}S CAMACHO-RODR{\'I}GUEZ, Microsoft Gray Systems Lab, USA YUANYUAN TIAN, Microsoft Gray Systems Lab, USA Database systems often rely on historical query traces to perform workload-based performance tuning. However, real production workloads are time-evolving, making historical queries ineffective for optimizing future workloads. To address this challenge, we propose Sibyl, an end-to-end machine learning-based framework that accurately forecasts a sequence of future queries, with the entire query statements, in various prediction windows. Drawing insights from real-workloads, we propose template-based featurization techniques and develop a stacked-LSTM with an encoder-decoder architecture for accurate forecasting of query workloads. We also develop techniques to improve forecasting accuracy over large prediction windows and achieve high scalability over large workloads with high variability in arrival rates of queries. Finally, we propose techniques to handle workload drifts. Our evaluation on four real workloads demonstrates that Sibyl can forecast workloads with an 87.3\% median F1 score, and can result in 1.7{\texttimes} and 1.3{\texttimes} performance improvement when applied to materialized view selection and index selection applications, respectively. CCS Concepts: {$\bullet$} Information systems {$\rightarrow$} Data management systems.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/KGY9FKMY/Huang et al. - 2024 - Sibyl Forecasting Time-Evolving Query Workloads.pdf}
}

@misc{huLoRALowRankAdaptation2021,
  title = {{{LoRA}}: {{Low-Rank Adaptation}} of {{Large Language Models}}},
  shorttitle = {{{LoRA}}},
  author = {Hu, Edward J. and Shen, Yelong and Wallis, Phillip and {Allen-Zhu}, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  year = {2021},
  month = oct,
  number = {arXiv:2106.09685},
  eprint = {2106.09685},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2106.09685},
  urldate = {2024-03-15},
  abstract = {An important paradigm of natural language processing consists of large-scale pre-training on general domain data and adaptation to particular tasks or domains. As we pre-train larger models, full fine-tuning, which retrains all model parameters, becomes less feasible. Using GPT-3 175B as an example -- deploying independent instances of fine-tuned models, each with 175B parameters, is prohibitively expensive. We propose Low-Rank Adaptation, or LoRA, which freezes the pre-trained model weights and injects trainable rank decomposition matrices into each layer of the Transformer architecture, greatly reducing the number of trainable parameters for downstream tasks. Compared to GPT-3 175B fine-tuned with Adam, LoRA can reduce the number of trainable parameters by 10,000 times and the GPU memory requirement by 3 times. LoRA performs on-par or better than fine-tuning in model quality on RoBERTa, DeBERTa, GPT-2, and GPT-3, despite having fewer trainable parameters, a higher training throughput, and, unlike adapters, no additional inference latency. We also provide an empirical investigation into rank-deficiency in language model adaptation, which sheds light on the efficacy of LoRA. We release a package that facilitates the integration of LoRA with PyTorch models and provide our implementations and model checkpoints for RoBERTa, DeBERTa, and GPT-2 at https://github.com/microsoft/LoRA.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {/Users/DAADAMS/Zotero/storage/NSAHNR8L/Hu et al. - 2021 - LoRA Low-Rank Adaptation of Large Language Models.pdf;/Users/DAADAMS/Zotero/storage/KEGUCZRS/2106.html}
}

@inproceedings{idreosOverviewDataExploration2015,
  title = {Overview of {{Data Exploration Techniques}}},
  booktitle = {Proceedings of the 2015 {{ACM SIGMOD International Conference}} on {{Management}} of {{Data}}},
  author = {Idreos, Stratos and Papaemmanouil, Olga and Chaudhuri, Surajit},
  year = {2015},
  month = may,
  pages = {277--281},
  publisher = {ACM},
  address = {Melbourne Victoria Australia},
  doi = {10.1145/2723372.2731084},
  urldate = {2024-08-07},
  abstract = {Data exploration is about efficiently extracting knowledge from data even if we do not know exactly what we are looking for. In this tutorial, we survey recent developments in the emerging area of database systems tailored for data exploration. We discuss new ideas on how to store and access data as well as new ideas on how to interact with a data system to enable users and applications to quickly figure out which data parts are of interest. In addition, we discuss how to exploit lessons-learned from past research, the new challenges data exploration crafts, emerging applications and future research directions.},
  isbn = {978-1-4503-2758-9},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/2YBVSI8S/Idreos et al. - 2015 - Overview of Data Exploration Techniques.pdf}
}

@inproceedings{jagadishItcompressIterativeSemantic2004,
  title = {Itcompress: {{An}} Iterative Semantic Compression Algorithm},
  shorttitle = {Itcompress},
  booktitle = {Proceedings. 20th {{International Conference}} on {{Data Engineering}}},
  author = {Jagadish, H. V. and Ng, Raymond T. and Ooi, Beng Chin and Tung, Anthony KH},
  year = {2004},
  pages = {646--657},
  publisher = {IEEE},
  urldate = {2025-02-16},
  file = {/Users/DAADAMS/Zotero/storage/7R3D3UFX/Jagadish et al. - 2004 - Itcompress An iterative semantic compression algorithm.pdf}
}

@inproceedings{jagadishSemanticCompressionPattern1999,
  title = {Semantic Compression and Pattern Extraction with Fascicles},
  booktitle = {{{VLDB}}},
  author = {Jagadish, H. V. and Madar, Jason and Ng, Raymond T.},
  year = {1999},
  volume = {99},
  pages = {186--97},
  urldate = {2025-02-16},
  file = {/Users/DAADAMS/Zotero/storage/XX7ZYTWS/Jagadish et al. - 1999 - Semantic compression and pattern extraction with fascicles.pdf}
}

@misc{jannachSurveyIntentawareRecommender2024,
  title = {A {{Survey}} on {{Intent-aware Recommender Systems}}},
  author = {Jannach, Dietmar and Zanker, Markus},
  year = {2024},
  month = jun,
  number = {arXiv:2406.16350},
  eprint = {2406.16350},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2024-08-07},
  abstract = {Many modern online services feature personalized recommendations. A central challenge when providing such recommendations is that the reason why an individual user accesses the service may change from visit to visit or even during an ongoing usage session. To be effective, a recommender system should therefore aim to take the users' probable intent of using the service at a certain point in time into account. In recent years, researchers have thus started to address this challenge by incorporating intent-awareness into recommender systems. Correspondingly, a number of technical approaches were put forward, including diversification techniques, intent prediction models or latent intent modeling approaches. In this paper, we survey and categorize existing approaches to building the next generation of Intent-Aware Recommender Systems (IARS). Based on an analysis of current evaluation practices, we outline open gaps and possible future directions in this area, which in particular include the consideration of additional interaction signals and contextual information to further improve the effectiveness of such systems.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Information Retrieval},
  file = {/Users/DAADAMS/Zotero/storage/V7FJ9ZNI/Jannach and Zanker - 2024 - A Survey on Intent-aware Recommender Systems.pdf}
}

@article{jinInverseOptimalControl2021,
  title = {Inverse {{Optimal Control}} from {{Incomplete Trajectory Observations}}},
  author = {Jin, Wanxin and Kuli{\'c}, Dana and Mou, Shaoshuai and Hirche, Sandra},
  year = {2021},
  month = jun,
  journal = {The International Journal of Robotics Research},
  volume = {40},
  number = {6-7},
  eprint = {1803.07696},
  primaryclass = {cs},
  pages = {848--865},
  issn = {0278-3649, 1741-3176},
  doi = {10.1177/0278364921996384},
  urldate = {2025-09-08},
  abstract = {This article develops a methodology that enables learning an objective function of an optimal control system from incomplete trajectory observations. The objective function is assumed to be a weighted sum of features (or basis functions) with unknown weights, and the observed data is a segment of a trajectory of system states and inputs. The proposed technique introduces the concept of the recovery matrix to establish the relationship between any available segment of the trajectory and the weights of given candidate features. The rank of the recovery matrix indicates whether a subset of relevant features can be found among the candidate features and the corresponding weights can be learned from the segment data. The recovery matrix can be obtained iteratively and its rank non-decreasing property shows that additional observations may contribute to the objective learning. Based on the recovery matrix, a method for using incomplete trajectory observations to learn the weights of selected features is established, and an incremental inverse optimal control algorithm is developed by automatically finding the minimal required observation. The effectiveness of the proposed method is demonstrated on a linear quadratic regulator system and a simulated robot manipulator.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Robotics,Computer Science - Systems and Control},
  file = {/Users/DAADAMS/Zotero/storage/HHE7VKIV/Jin et al. - 2021 - Inverse Optimal Control from Incomplete Trajectory Observations.pdf}
}

@article{joglekarInteractiveDataExploration2017,
  title = {Interactive Data Exploration with Smart Drill-Down},
  author = {Joglekar, Manas and {Garcia-Molina}, Hector and Parameswaran, Aditya},
  year = {2017},
  journal = {IEEE Transactions on Knowledge and Data Engineering},
  volume = {31},
  number = {1},
  pages = {46--60},
  publisher = {IEEE},
  urldate = {2025-02-13},
  file = {/Users/DAADAMS/Zotero/storage/7DA6DZ5L/PMC5308207.html}
}

@inproceedings{kalininInteractiveDataExploration2014,
  title = {Interactive Data Exploration Using Semantic Windows},
  booktitle = {Proceedings of the 2014 {{ACM SIGMOD International Conference}} on {{Management}} of {{Data}}},
  author = {Kalinin, Alexander and Cetintemel, Ugur and Zdonik, Stan},
  year = {2014},
  month = jun,
  series = {{{SIGMOD}} '14},
  pages = {505--516},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/2588555.2593666},
  urldate = {2024-08-11},
  abstract = {We present a new interactive data exploration approach, called Semantic Windows (SW), in which users query for multidimensional "windows" of interest via standard DBMS-style queries enhanced with exploration constructs. Users can specify SWs using (i) shape-based properties, e.g., "identify all 3-by-3 windows", as well as (ii) content-based properties, e.g., "identify all windows in which the average brightness of stars exceeds 0.8". This SW approach enables the interactive processing of a host of useful exploratory queries that are difficult to express and optimize using standard DBMS techniques. SW uses a sampling-guided, data-driven search strategy to explore the underlying data set and quickly identify windows of interest. To facilitate human-in-the-loop style interactive processing, SW is optimized to produce online results during query execution. To control the tension between online performance and query completion time, it uses a tunable, adaptive prefetching technique. To enable exploration of big data, the framework supports distributed computation.We describe the semantics and implementation of SW as a distributed layer on top of PostgreSQL. The experimental results with real astronomical and artificial data reveal that SW can offer online results quickly and continuously with little or no degradation in query completion times.},
  isbn = {978-1-4503-2376-5},
  file = {/Users/DAADAMS/Zotero/storage/JUWVFJWR/Kalinin et al. - 2014 - Interactive data exploration using semantic window.pdf}
}

@misc{kambhampatiLLMsCantPlan2024,
  title = {{{LLMs Can}}'t {{Plan}}, {{But Can Help Planning}} in {{LLM-Modulo Frameworks}}},
  author = {Kambhampati, Subbarao and Valmeekam, Karthik and Guan, Lin and Verma, Mudit and Stechly, Kaya and Bhambri, Siddhant and Saldyt, Lucas and Murthy, Anil},
  year = {2024},
  month = jun,
  number = {arXiv:2402.01817},
  eprint = {2402.01817},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2402.01817},
  urldate = {2024-09-23},
  abstract = {There is considerable confusion about the role of Large Language Models (LLMs) in planning and reasoning tasks. On one side are over-optimistic claims that LLMs can indeed do these tasks with just the right prompting or self-verification strategies. On the other side are perhaps over-pessimistic claims that all that LLMs are good for in planning/reasoning tasks are as mere translators of the problem specification from one syntactic format to another, and ship the problem off to external symbolic solvers. In this position paper, we take the view that both these extremes are misguided. We argue that auto-regressive LLMs cannot, by themselves, do planning or self-verification (which is after all a form of reasoning), and shed some light on the reasons for misunderstandings in the literature. We will also argue that LLMs should be viewed as universal approximate knowledge sources that have much more meaningful roles to play in planning/reasoning tasks beyond simple front-end/back-end format translators. We present a vision of \{{\textbackslash}bf LLM-Modulo Frameworks\} that combine the strengths of LLMs with external model-based verifiers in a tighter bi-directional interaction regime. We will show how the models driving the external verifiers themselves can be acquired with the help of LLMs. We will also argue that rather than simply pipelining LLMs and symbolic components, this LLM-Modulo Framework provides a better neuro-symbolic approach that offers tighter integration between LLMs and symbolic components, and allows extending the scope of model-based planning/reasoning regimes towards more flexible knowledge, problem and preference specifications.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  annotation = {Read\_Status: To Read\\
Read\_Status\_Date: 2024-12-09T00:54:05.783Z},
  file = {/Users/DAADAMS/Zotero/storage/K9495QA3/Kambhampati et al. - 2024 - LLMs Can't Plan, But Can Help Planning in LLM-Modulo Frameworks.pdf;/Users/DAADAMS/Zotero/storage/BY8UHZGG/2402.html}
}

@inproceedings{kaminkaPlanRecognitionContinuous2018,
  title = {Plan Recognition in Continuous Domains},
  booktitle = {Proceedings of the {{AAAI Conference}} on {{Artificial Intelligence}}},
  author = {Kaminka, Gal and Vered, Mor and Agmon, Noa},
  year = {2018},
  volume = {32},
  urldate = {2024-08-07},
  file = {/Users/DAADAMS/Zotero/storage/J9TDM8PK/Kaminka et al. - 2018 - Plan recognition in continuous domains.pdf}
}

@article{karkusQMDPNetDeepLearning,
  title = {{{QMDP-Net}}: {{Deep Learning}} for {{Planning}} under {{Partial Observability}}},
  author = {Karkus, Peter and Hsu, David and Lee, Wee Sun},
  abstract = {This paper introduces the QMDP-net, a neural network architecture for planning under partial observability. The QMDP-net combines the strengths of model-free learning and model-based planning. It is a recurrent policy network, but it represents a policy for a parameterized set of tasks by connecting a model with a planning algorithm that solves the model, thus embedding the solution structure of planning in a network learning architecture. The QMDP-net is fully differentiable and allows for end-to-end training. We train a QMDPnet on different tasks so that it can generalize to new ones in the parameterized task set and ``transfer'' to other similar tasks beyond the set. In preliminary experiments, QMDP-net showed strong performance on several robotic tasks in simulation. Interestingly, while QMDP-net encodes the QMDP algorithm, it sometimes outperforms the QMDP algorithm in the experiments, as a result of end-to-end learning.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/6JB3QX49/Karkus et al. - QMDP-Net Deep Learning for Planning under Partial.pdf}
}

@inproceedings{kashyapFACeTORCostdrivenExploration2010,
  title = {{{FACeTOR}}: Cost-Driven Exploration of Faceted Query Results},
  shorttitle = {{{FACeTOR}}},
  booktitle = {Proceedings of the 19th {{ACM}} International Conference on {{Information}} and Knowledge Management},
  author = {Kashyap, Abhijith and Hristidis, Vagelis and Petropoulos, Michalis},
  year = {2010},
  month = oct,
  pages = {719--728},
  publisher = {ACM},
  address = {Toronto ON Canada},
  doi = {10.1145/1871437.1871530},
  urldate = {2025-04-22},
  abstract = {Faceted navigation is being increasingly employed as an effective technique for exploring large query results on structured databases. This technique of mitigating information-overload leverages metadata of the query results to provide users with facet conditions that can be used to progressively refine the user's query and filter the query results. However, the number of facet conditions can be quite large, thereby increasing the burden on the user. We present the FACeTOR system that proposes a cost-based approach to faceted navigation. At each step of the navigation, the user is presented with a subset of all possible facet conditions that are selected such that the overall expected navigation cost is minimized and every result is guaranteed to be reachable by a facet condition. We prove that the problem of selecting the optimal facet conditions at each navigation step is NP-Hard, and subsequently present two intuitive heuristics employed by FACeTOR. Our user study at Amazon Mechanical Turk shows that FACeTOR reduces the user navigation time compared to the cutting edge commercial and academic faceted search algorithms. The user study also confirms the validity of our cost model. We also present the results of an extensive experimental evaluation on the performance of the proposed approach using two real datasets. FACeTOR is available at http://db.cse.buffalo.edu/facetor/.},
  isbn = {978-1-4503-0099-5},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/5WV6EVPK/Kashyap et al. - 2010 - FACeTOR cost-driven exploration of faceted query results.pdf}
}

@misc{kaushikNumericalAssociationRule2023,
  title = {Numerical {{Association Rule Mining}}: {{A Systematic Literature Review}}},
  shorttitle = {Numerical {{Association Rule Mining}}},
  author = {Kaushik, Minakshi and Sharma, Rahul and Jr, Iztok Fister and Draheim, Dirk},
  year = {2023},
  month = jul,
  number = {arXiv:2307.00662},
  eprint = {2307.00662},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2307.00662},
  urldate = {2025-01-21},
  abstract = {Numerical association rule mining (NARM) is a widely used variant of the association rule mining (ARM) technique, and it has been extensively used in discovering patterns in numerical data. Initially, researchers and scientists incorporated numerical attributes in ARM using various discretization approaches; however, over time, a plethora of alternative methods have emerged in this field. Unfortunately, the increase of alternative methods has resulted into a significant knowledge gap in understanding diverse techniques employed in NARM -- this paper attempts to bridge this knowledge gap by conducting a comprehensive systematic literature review (SLR). We provide an in-depth study of diverse methods, algorithms, metrics, and datasets derived from 1,140 scholarly articles published from the inception of NARM in the year 1996 to 2022. Out of them, 68 articles are extensively reviewed in accordance with inclusion, exclusion, and quality criteria. To the best of our knowledge, this SLR is the first of its kind to provide an exhaustive analysis of the current literature and previous surveys on NARM. The paper discusses important research issues, the current status, and the future possibilities of NARM. On the basis of this SLR, the article also presents a novel discretization measure that contributes by providing a partitioning of numerical data that meets well human perception of partitions. CCS Concepts: {$\bullet$} Information systems {$\rightarrow$} Association rules; Data mining; {$\bullet$} Computing methodologies {$\rightarrow$} Bio-inspired approaches; Machine learning; {$\bullet$} General and reference {$\rightarrow$} Surveys and overviews.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Databases,Computer Science - Machine Learning},
  file = {/Users/DAADAMS/Zotero/storage/G83686Q7/Kaushik et al. - 2023 - Numerical Association Rule Mining A Systematic Literature Review.pdf}
}

@article{kaushikSystematicAssessmentNumerical2021,
  title = {A {{Systematic Assessment}} of {{Numerical Association Rule Mining Methods}}},
  author = {Kaushik, Minakshi and Sharma, Rahul and Peious, Sijo Arakkal and Shahin, Mahtab and Yahia, Sadok Ben and Draheim, Dirk},
  year = {2021},
  month = jun,
  journal = {SN Computer Science},
  volume = {2},
  number = {5},
  pages = {348},
  issn = {2661-8907},
  doi = {10.1007/s42979-021-00725-2},
  urldate = {2025-01-07},
  abstract = {In data mining, the classical association rule mining techniques deal with binary attributes; however, real-world data have a variety of attributes (numerical, categorical, Boolean). To deal with the variety of data attributes, the classical association rule mining technique was extended to numerical association rule mining. Initially, the concept of numerical association rule mining started with the discretization method, and later, many other methods, e.g., optimization, distribution are proposed in state-of-the-art. Different authors have presented various algorithms for each numerical association rule mining method; therefore, it is hard to select a suitable algorithm for a numerical association rule mining task. In this article, we present a systematic assessment of various numerical association rule mining methods and we provide a meta-study of thirty numerical association rule mining algorithms. We investigate how far the discretization techniques have been used in the numerical association rule mining methods.},
  langid = {english},
  keywords = {Association rule mining,Data mining,Knowledge discovery in databases,Numerical association rule mining,Quantitative association rule mining},
  file = {/Users/DAADAMS/Zotero/storage/Y3A26JER/Kaushik et al. - 2021 - A Systematic Assessment of Numerical Association Rule Mining Methods.pdf}
}

@article{kayaFuzzyOLAPAssociation2005,
  title = {Fuzzy {{OLAP}} Association Rules Mining-Based Modular Reinforcement Learning Approach for Multiagent Systems},
  author = {Kaya, M. and Alhajj, R.},
  year = {2005},
  month = apr,
  journal = {IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)},
  volume = {35},
  number = {2},
  pages = {326--338},
  issn = {1941-0492},
  doi = {10.1109/TSMCB.2004.843278},
  urldate = {2025-01-13},
  abstract = {Multiagent systems and data mining have recently attracted considerable attention in the field of computing. Reinforcement learning is the most commonly used learning process for multiagent systems. However, it still has some drawbacks, including modeling other learning agents present in the domain as part of the state of the environment, and some states are experienced much less than others, or some state-action pairs are never visited during the learning phase. Further, before completing the learning process, an agent cannot exhibit a certain behavior in some states that may be experienced sufficiently. In this study, we propose a novel multiagent learning approach to handle these problems. Our approach is based on utilizing the mining process for modular cooperative learning systems. It incorporates fuzziness and online analytical processing (OLAP) based mining to effectively process the information reported by agents. First, we describe a fuzzy data cube OLAP architecture which facilitates effective storage and processing of the state information reported by agents. This way, the action of the other agent, not even in the visual environment of the agent under consideration, can simply be predicted by extracting online association rules, a well-known data mining technique, from the constructed data cube. Second, we present a new action selection model, which is also based on association rules mining. Finally, we generalize not sufficiently experienced states, by mining multilevel association rules from the proposed fuzzy data cube. Experimental results obtained on two different versions of a well-known pursuit domain show the robustness and effectiveness of the proposed fuzzy OLAP mining based modular learning approach. Finally, we tested the scalability of the approach presented in this paper and compared it with our previous work on modular-fuzzy Q-learning and ordinary Q-learning.},
  keywords = {Association rules,Control systems,data cube,data mining,Data mining,fuzziness,Fuzzy systems,Information analysis,Learning systems,modularity,multiagent systems,Multiagent systems,OLAP,reinforcement learning,Robustness,Scalability,Testing},
  annotation = {Read\_Status: Read\\
Read\_Status\_Date: 2025-01-13T03:59:50.869Z},
  file = {/Users/DAADAMS/Zotero/storage/JAB79F4V/Kaya and Alhajj - 2005 - Fuzzy OLAP association rules mining-based modular reinforcement learning approach for multiagent sys.pdf;/Users/DAADAMS/Zotero/storage/UEYNPFKK/1408061.html}
}

@incollection{keimVisualAnalyticsDefinition2008,
  title = {Visual {{Analytics}}: {{Definition}}, {{Process}}, and {{Challenges}}},
  shorttitle = {Visual {{Analytics}}},
  booktitle = {Information {{Visualization}}},
  author = {Keim, Daniel and Andrienko, Gennady and Fekete, Jean-Daniel and G{\"o}rg, Carsten and Kohlhammer, J{\"o}rn and Melan{\c c}on, Guy},
  editor = {Kerren, Andreas and Stasko, John T. and Fekete, Jean-Daniel and North, Chris},
  year = {2008},
  volume = {4950},
  pages = {154--175},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  issn = {0302-9743, 1611-3349},
  doi = {10.1007/978-3-540-70956-5_7},
  urldate = {2024-08-07},
  isbn = {978-3-540-70955-8 978-3-540-70956-5},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/TME4WZM7/Keim et al. - 2008 - Visual Analytics Definition, Process, and Challen.pdf}
}

@inproceedings{kerenGoalRecognitionDesign2014,
  title = {Goal Recognition Design},
  booktitle = {Proceedings of the {{International Conference}} on {{Automated Planning}} and {{Scheduling}}},
  author = {Keren, Sarah and Gal, Avigdor and Karpas, Erez},
  year = {2014},
  volume = {24},
  pages = {154--162},
  urldate = {2024-08-12},
  file = {/Users/DAADAMS/Zotero/storage/MYGAXIDK/Keren et al. - 2014 - Goal recognition design.pdf}
}

@inproceedings{kerenGoalRecognitionDesign2016,
  title = {Goal Recognition Design with Non-Observable Actions},
  booktitle = {Proceedings of the {{AAAI Conference}} on {{Artificial Intelligence}}},
  author = {Keren, Sarah and Gal, Avigdor and Karpas, Erez},
  year = {2016},
  volume = {30},
  urldate = {2024-03-19},
  file = {/Users/DAADAMS/Zotero/storage/E7JE4TD9/Keren et al. - 2016 - Goal recognition design with non-observable action.pdf}
}

@inproceedings{keryStoryNotebookExploratory2018,
  title = {The {{Story}} in the {{Notebook}}: {{Exploratory Data Science}} Using a {{Literate Programming Tool}}},
  shorttitle = {The {{Story}} in the {{Notebook}}},
  booktitle = {Proceedings of the 2018 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Kery, Mary Beth and Radensky, Marissa and Arya, Mahima and John, Bonnie E. and Myers, Brad A.},
  year = {2018},
  month = apr,
  pages = {1--11},
  publisher = {ACM},
  address = {Montreal QC Canada},
  doi = {10.1145/3173574.3173748},
  urldate = {2025-02-16},
  isbn = {978-1-4503-5620-6},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/MAKS94TQ/Kery et al. - 2018 - The Story in the Notebook Exploratory Data Science using a Literate Programming Tool.pdf}
}

@article{keyderSoundCompleteLandmarks,
  title = {Sound and {{Complete Landmarks}} for {{And}}/{{Or Graphs}}},
  author = {Keyder, Emil and Richter, Silvia and Helmert, Malte},
  abstract = {Landmarks for a planning problem are subgoals that are necessarily made true at some point in the execution of any plan. Since verifying that a fact is a landmark is PSPACE-complete, earlier approaches have focused on finding landmarks for the delete relaxation {$\Pi$}+. Furthermore, some of these approaches have approximated this set of landmarks, although it has been shown that the complete set of causal delete-relaxation landmarks can be identified in polynomial time by a simple procedure over the relaxed planning graph. Here, we give a declarative characterisation of this set of landmarks and show that the procedure computes the landmarks described by our characterisation. Building on this, we observe that the procedure can be applied to any delete-relaxation problem and take advantage of a recent compilation of the m-relaxation of a problem into a problem with no delete effects to extract landmarks that take into account delete effects in the original problem. We demonstrate that this approach finds strictly more causal landmarks than previous approaches and discuss the relationship between increased computational effort and experimental performance, using these landmarks in a recently proposed admissible landmark-counting heuristic.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/MRGSCS6V/Keyder et al. - Sound and Complete Landmarks for AndOr Graphs.pdf}
}

@inproceedings{keyVizDeckSelforganizingDashboards2012,
  title = {{{VizDeck}}: Self-Organizing Dashboards for Visual Analytics},
  shorttitle = {{{VizDeck}}},
  booktitle = {Proceedings of the 2012 {{ACM SIGMOD International Conference}} on {{Management}} of {{Data}}},
  author = {Key, Alicia and Howe, Bill and Perry, Daniel and Aragon, Cecilia},
  year = {2012},
  month = may,
  pages = {681--684},
  publisher = {ACM},
  address = {Scottsdale Arizona USA},
  doi = {10.1145/2213836.2213931},
  urldate = {2024-08-13},
  isbn = {978-1-4503-1247-9},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/RBXQQ5GT/Key et al. - 2012 - VizDeck self-organizing dashboards for visual ana.pdf}
}

@incollection{kishorAssociationRuleMining2019,
  title = {Association {{Rule Mining Using}} an {{Unsupervised Neural Network}} with an {{Optimized Genetic Algorithm}}},
  booktitle = {{{ICCCE}} 2018},
  author = {Kishor, Peddi and Sammulal, Porika},
  editor = {Kumar, Amit and Mozar, Stefan},
  year = {2019},
  volume = {500},
  pages = {657--669},
  publisher = {Springer Singapore},
  address = {Singapore},
  doi = {10.1007/978-981-13-0212-1_67},
  urldate = {2024-12-23},
  abstract = {The best known and most widely utilized pattern finding algorithm in data mining applications is association rule mining (ARM). Extraction of frequent patterns is an indispensable step in ARM. Most studies in the literature have been implemented on the concept of support and confidence framework utilization. Here, we investigated an efficient and robust ARM scheme based on a self-organizing map (SOM) and an optimized genetic algorithm (OGA). A SOM is an unsupervised neural network that efficaciously produces spatially coordinated internal feature representations and detected abstractions in the input space and is the most efficient clustering technique that reveals conventional similarities in the input space by performing a topology maintaining mapping. Hence, a SOM is utilized to generate accurate clustered frequency patterns and an OGA is used to generate positive and negative association rules with multiple consequences by studying all possible patterns. Experimental analysis on various datasets has shown the robustness of our proposed ARM in comparison to traditional rule mining approaches by proving that a greater number of positive and negative association rules is generated by the proposed methodology resulting in a better performance when compared to conventional rule mining schemes.},
  isbn = {978-981-13-0211-4 978-981-13-0212-1},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/PEMHW8J6/Kishor and Sammulal - 2019 - Association Rule Mining Using an Unsupervised Neural Network with an Optimized Genetic Algorithm.pdf}
}

@incollection{kocsisBanditBasedMonteCarlo2006,
  title = {Bandit {{Based Monte-Carlo Planning}}},
  booktitle = {Machine {{Learning}}: {{ECML}} 2006},
  author = {Kocsis, Levente and Szepesv{\'a}ri, Csaba},
  editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Dough and Vardi, Moshe Y. and Weikum, Gerhard and F{\"u}rnkranz, Johannes and Scheffer, Tobias and Spiliopoulou, Myra},
  year = {2006},
  volume = {4212},
  pages = {282--293},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/11871842_29},
  urldate = {2024-03-15},
  abstract = {For large state-space Markovian Decision Problems MonteCarlo planning is one of the few viable approaches to find near-optimal solutions. In this paper we introduce a new algorithm, UCT, that applies bandit ideas to guide Monte-Carlo planning. In finite-horizon or discounted MDPs the algorithm is shown to be consistent and finite sample bounds are derived on the estimation error due to sampling. Experimental results show that in several domains, UCT is significantly more efficient than its alternatives.},
  isbn = {978-3-540-45375-8 978-3-540-46056-5},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/ZL5XW8CA/Kocsis and Szepesvári - 2006 - Bandit Based Monte-Carlo Planning.pdf}
}

@article{kocsisImprovedMonteCarloSearch,
  title = {Improved {{Monte-Carlo Search}}},
  author = {Kocsis, Levente and Szepesvari, Csaba and Willemson, Jan},
  abstract = {Monte-Carlo search has been successful in many non-deterministic games, and recently in deterministic games with high branching factor. One of the drawbacks of the current approaches is that even if the iterative process would last for a very long time, the selected move does not necessarily converge to a game-theoretic optimal one. In this paper we introduce a new algorithm, UCT, which extends a bandit algorithm for Monte-Carlo search. It is proven that the probability that the algorithm selects the correct move converges to 1. Moreover it is shown empirically that the algorithm converges rather fast even in comparison with alpha-beta search. Experiments in Amazons and Clobber indicate that the UCT algorithm outperforms considerably a plain Monte-Carlo version, and it is competitive against alpha-beta based game programs.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/UA35FBSJ/Kocsis et al. - Improved Monte-Carlo Search.pdf}
}

@inbook{komorowskiExploratoryDataAnalysis2016,
  title = {Exploratory {{Data Analysis}}},
  booktitle = {Secondary {{Analysis}} of {{Electronic Health Records}}},
  author = {Komorowski, Matthieu and Marshall, Dominic C. and Salciccioli, Justin D. and Crutain, Yves},
  year = {2016},
  pages = {185--203},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-43742-2_15},
  urldate = {2025-02-13},
  collaborator = {{Mit Critical Data}},
  copyright = {http://creativecommons.org/licenses/by-nc/4.0},
  isbn = {978-3-319-43740-8 978-3-319-43742-2},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/JP4MZXF3/Komorowski et al. - 2016 - Exploratory Data Analysis.pdf}
}

@article{kraskaNorthstarInteractiveData2021,
  title = {Northstar: {{An}} Interactive Data Science System},
  shorttitle = {Northstar},
  author = {Kraska, Tim},
  year = {2021},
  publisher = {VLDB Endowment},
  urldate = {2025-02-13},
  file = {/Users/DAADAMS/Zotero/storage/ZYFKDNIY/Kraska - 2021 - Northstar An interactive data science system.pdf}
}

@article{kraskaSageDBLearnedDatabase,
  title = {{{SageDB}}: {{A Learned Database System}}},
  author = {Kraska, Tim and Alizadeh, Mohammad and Beutel, Alex and Chi, Ed H and Ding, Jialin and Kristo, Ani and Leclerc, Guillaume and Madden, Samuel and Mao, Hongzi and Nathan, Vikram},
  abstract = {Modern data processing systems are designed to be general purpose, in that they can handle a wide variety of different schemas, data types, and data distributions, and aim to provide efficient access to that data via the use of optimizers and cost models. This general purpose nature results in systems that do not take advantage of the characteristics of the particular application and data of the user. With SageDB we present a vision towards a new type of a data processing system, one which highly specializes to an application through code synthesis and machine learning. By modeling the data distribution, workload, and hardware, SageDB learns the structure of the data and optimal access methods and query plans. These learned models are deeply embedded, through code synthesis, in essentially every component of the database. As such, SageDB presents radical departure from the way database systems are currently developed, raising a host of new problems in databases, machine learning and programming systems.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/KJTIR64T/Kraska et al. - SageDB A Learned Database System.pdf}
}

@inproceedings{kulkarniUnifiedFrameworkPlanning2019,
  title = {A Unified Framework for Planning in Adversarial and Cooperative Environments},
  booktitle = {Proceedings of the {{AAAI Conference}} on {{Artificial Intelligence}}},
  author = {Kulkarni, Anagha and Srivastava, Siddharth and Kambhampati, Subbarao},
  year = {2019},
  volume = {33},
  pages = {2479--2487},
  urldate = {2024-08-12},
  file = {/Users/DAADAMS/Zotero/storage/MQF3Q9EG/Kulkarni et al. - 2019 - A unified framework for planning in adversarial an.pdf}
}

@article{kullbackInformationSufficiency1951,
  title = {On Information and Sufficiency},
  author = {Kullback, Solomon and Leibler, Richard A.},
  year = {1951},
  journal = {The annals of mathematical statistics},
  volume = {22},
  number = {1},
  eprint = {2236703},
  eprinttype = {jstor},
  pages = {79--86},
  publisher = {JSTOR},
  urldate = {2024-08-12},
  file = {/Users/DAADAMS/Zotero/storage/6FJHXQDA/sfxlcl41.html}
}

@inproceedings{kupiecTrainableDocumentSummarizer1995,
  title = {A Trainable Document Summarizer},
  booktitle = {Proceedings of the 18th Annual International {{ACM SIGIR}} Conference on {{Research}} and Development in Information Retrieval  - {{SIGIR}} '95},
  author = {Kupiec, Julian and Pedersen, Jan and Chen, Francine},
  year = {1995},
  pages = {68--73},
  publisher = {ACM Press},
  address = {Seattle, Washington, United States},
  doi = {10.1145/215206.215333},
  urldate = {2025-02-16},
  isbn = {978-0-89791-714-8},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/RRZWUAYZ/Kupiec et al. - 1995 - A trainable document summarizer.pdf}
}

@article{lanctotMonteCarloSampling,
  title = {Monte {{Carlo Sampling}} for {{Regret Minimization}} in {{Extensive Games}}},
  author = {Lanctot, Marc and Waugh, Kevin and Zinkevich, Martin and Bowling, Michael},
  abstract = {Sequential decision-making with multiple agents and imperfect information is commonly modeled as an extensive game. One efficient method for computing Nash equilibria in large, zero-sum, imperfect information games is counterfactual regret minimization (CFR). In the domain of poker, CFR has proven effective, particularly when using a domain-specific augmentation involving chance outcome sampling. In this paper, we describe a general family of domain-independent CFR sample-based algorithms called Monte Carlo counterfactual regret minimization (MCCFR) of which the original and poker-specific versions are special cases. We start by showing that MCCFR performs the same regret updates as CFR on expectation. Then, we introduce two sampling schemes: outcome sampling and external sampling, showing that both have bounded overall regret with high probability. Thus, they can compute an approximate equilibrium using self-play. Finally, we prove a new tighter bound on the regret for the original CFR algorithm and relate this new bound to MCCFR's bounds. We show empirically that, although the sample-based algorithms require more iterations, their lower cost per iteration can lead to dramatically faster convergence in various games.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/2IFE93UJ/Lanctot et al. - Monte Carlo Sampling for Regret Minimization in Ex.pdf}
}

@book{lanctotMonteCarloSampling2013,
  title = {Monte {{Carlo}} Sampling and Regret Minimization for Equilibrium Computation and Decision-Making in Large Extensive Form Games},
  author = {Lanctot, Marc},
  year = {2013},
  publisher = {University of Alberta (Canada)},
  urldate = {2024-03-15},
  file = {/Users/DAADAMS/Zotero/storage/NN7TG4TM/Lanctot - 2013 - Monte Carlo sampling and regret minimization for e.pdf}
}

@misc{lanctotPopulationbasedEvaluationRepeated2023,
  title = {Population-Based {{Evaluation}} in {{Repeated Rock-Paper-Scissors}} as a {{Benchmark}} for {{Multiagent Reinforcement Learning}}},
  author = {Lanctot, Marc and Schultz, John and Burch, Neil and Smith, Max Olan and Hennes, Daniel and Anthony, Thomas and Perolat, Julien},
  year = {2023},
  month = oct,
  number = {arXiv:2303.03196},
  eprint = {2303.03196},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2024-07-30},
  abstract = {Progress in fields of machine learning and adversarial planning has benefited significantly from benchmark domains, from checkers and the classic UCI data sets to Go and Diplomacy. In sequential decision-making, agent evaluation has largely been restricted to few interactions against experts, with the aim to reach some desired level of performance (e.g. beating a human professional player). We propose a benchmark for multiagent learning based on repeated play of the simple game Rock, Paper, Scissors along with a population of forty-three tournament entries, some of which are intentionally sub-optimal. We describe metrics to measure the quality of agents based both on average returns and exploitability. We then show that several RL, online learning, and language model approaches can learn good counter-strategies and generalize well, but ultimately lose to the top-performing bots, creating an opportunity for research in multiagent learning.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Science and Game Theory,Computer Science - Machine Learning,Computer Science - Multiagent Systems},
  file = {/Users/DAADAMS/Zotero/storage/38DSRU7K/Lanctot et al. - 2023 - Population-based Evaluation in Repeated Rock-Paper.pdf}
}

@article{lanFullyOndiskUpdatable,
  title = {A {{Fully On-disk Updatable Learned Index}}},
  author = {Lan, Hai and Culpepper, J Shane and {Borovica-Gajic}, Renata and Dong, Yu},
  abstract = {While in-memory learned indexes have shown promising performance as compared to B+-tree, most widely used databases in real applications still rely on disk-based operations. From our experiments, we observe that directly applying the existing in-memory learned indexes into on-disk setting suffers from several drawbacks and cannot outperform a standard B+-tree in most cases. Therefore, we make the first attempt to show how the idea of learned index can benefit the on-disk index by proposing AULID, a fully on-disk updatable learned index that can achieve state-of-the-art performance across multiple workload types. The AULID approach combines the benefits from both traditional indexing techniques and the learned indexes to reduce the I/O cost -- the main overhead under disk setting. Specifically, three aspects are taken into consideration in reducing I/O costs: (1) reduce the overhead in updating the index structure; (2) induce shorter paths from root to leaf node; (3) achieve better locality to minimize the number of block reads required to complete a scan. Five principles are proposed to guide the design of AULID which shows remarkable performance gains and meanwhile is easy to implement. Our evaluation shows that AULID has comparable storage costs to a B+-tree and is much smaller than other learned indexes, and AULID is up to 2.11x, 8.63x, 1.72x, 5.51x, and 8.02x more efficient than FITing-tree, PGM, B+-tree, ALEX, and LIPP.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/BGKU5XR3/Lan et al. - A Fully On-disk Updatable Learned Index.pdf}
}

@incollection{leeMultidocumentTextSummarization2013,
  title = {Multi-Document {{Text Summarization Using Topic Model}} and {{Fuzzy Logic}}},
  booktitle = {Machine {{Learning}} and {{Data Mining}} in {{Pattern Recognition}}},
  author = {Lee, Sanghoon and Belkasim, Saeid and Zhang, Yanqing},
  editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Perner, Petra},
  year = {2013},
  volume = {7988},
  pages = {159--168},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-39712-7_12},
  urldate = {2025-02-16},
  isbn = {978-3-642-39711-0 978-3-642-39712-7}
}

@article{leilanibattleDynamicPrefetchingData2016,
  title = {Dynamic {{Prefetching}} of {{Data Tiles}} for {{Interactive Visualization}}},
  author = {{Leilani Battle} and Battle, Leilani and {Remco Chang} and Chang, Remco and {Michael Stonebraker} and Stonebraker, Michael},
  year = {2016},
  month = jun,
  journal = {SIGMOD Conference},
  pages = {1363--1375},
  doi = {10.1145/2882903.2882919},
  abstract = {In this paper, we present ForeCache, a general-purpose tool for exploratory browsing of large datasets. ForeCache utilizes a client-server architecture, where the user interacts with a lightweight client-side interface to browse datasets, and the data to be browsed is retrieved from a DBMS running on a back-end server. We assume a detail-on-demand browsing paradigm, and optimize the back-end support for this paradigm by inserting a separate middleware layer in front of the DBMS. To improve response times, the middleware layer fetches data ahead of the user as she explores a dataset.   We consider two different mechanisms for prefetching: (a) learning what to fetch from the user's recent movements, and (b) using data characteristics (e.g., histograms) to find data similar to what the user has viewed in the past. We incorporate these mechanisms into a single prediction engine that adjusts its prediction strategies over time, based on changes in the user's behavior. We evaluated our prediction engine with a user study, and found that our dynamic prefetching strategy provides: (1) significant improvements in overall latency when compared with non-prefetching systems (430\% improvement); and (2) substantial improvements in both prediction accuracy (25\% improvement) and latency (88\% improvement) relative to existing prefetching techniques.},
  annotation = {MAG ID: 2287207825\\
S2ID: f53e9e29f978bd09fe3d273c4812a0927d49fe98}
}

@article{leisHowGoodAre2015,
  title = {How Good Are Query Optimizers, Really?},
  author = {Leis, Viktor and Gubichev, Andrey and Mirchev, Atanas and Boncz, Peter and Kemper, Alfons and Neumann, Thomas},
  year = {2015},
  month = nov,
  journal = {Proceedings of the VLDB Endowment},
  volume = {9},
  number = {3},
  pages = {204--215},
  issn = {2150-8097},
  doi = {10.14778/2850583.2850594},
  urldate = {2025-02-24},
  abstract = {Finding a good join order is crucial for query performance. In this paper, we introduce the Join Order Benchmark (JOB) and experimentally revisit the main components in the classic query optimizer architecture using a complex, real-world data set and realistic multi-join queries. We investigate the quality of industrial-strength cardinality estimators and find that all estimators routinely produce large errors. We further show that while estimates are essential for finding a good join order, query performance is unsatisfactory if the query engine relies too heavily on these estimates. Using another set of experiments that measure the impact of the cost model, we find that it has much less influence on query performance than the cardinality estimates. Finally, we investigate plan enumeration techniques comparing exhaustive dynamic programming with heuristic algorithms and find that exhaustive enumeration improves performance despite the sub-optimal cardinality estimates.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/VF75LB9S/Leis et al. - 2015 - How good are query optimizers, really.pdf}
}

@article{leonardoamadoGoalRecognitionLatent2018,
  title = {Goal {{Recognition}} in {{Latent Space}}},
  author = {{Leonardo Amado} and Amado, Leonardo and {Ramon Fraga Pereira} and Pereira, Ramon Fraga and {Jo{\~a}o Paulo Aires} and Aires, Jo{\~a}o Paulo and {Maur{\'i}cio Cec{\'i}lio Magnaguagno} and Magnaguagno, Mauricio Cecilio and {Roger Granada} and Granada, Roger and {Felipe Meneguzzi} and {Felipe Meneguzzi} and Meneguzzi, Felipe},
  year = {2018},
  month = jul,
  pages = {1--8},
  doi = {10.1109/ijcnn.2018.8489653},
  abstract = {Recent approaches to goal recognition have progressively relaxed the requirements about the amount of domain knowledge and available observations, yielding accurate and efficient algorithms. These approaches, however, assume that there is a domain expert capable of building complete and correct domain knowledge to successfully recognize an agent's goal. This is too strong for most real-world applications. We overcome these limitations by combining goal recognition techniques from automated planning, and deep autoencoders to carry out unsupervised learning to generate domain theories from data streams and use the resulting domain theories to deal with incomplete and noisy observations. We show the effectiveness of the technique in a number of domains and compare the recognition effectiveness of the autoencoded against hand-coded versions of these domains.},
  annotation = {MAG ID: 2895996109}
}

@inproceedings{leshSoundFastGoal1995,
  title = {A Sound and Fast Goal Recognizer},
  booktitle = {{{IJCAI}}},
  author = {Lesh, Neal and Etzioni, Oren},
  year = {1995},
  volume = {95},
  pages = {1704--1710},
  publisher = {Citeseer},
  urldate = {2024-08-08},
  file = {/Users/DAADAMS/Zotero/storage/JCWL23R4/Lesh and Etzioni - 1995 - A sound and fast goal recognizer.pdf}
}

@article{liCDCDRConditionalDiffusionbased2025,
  title = {{{CD-CDR}}: {{Conditional Diffusion-based Item Generationfor Cross-Domain Recommendation}}},
  author = {Li, Hanyu},
  year = {2025},
  abstract = {Cross-domain recommendation (CDR) has emerged as a promising direction for expanding the applicability of recommendation systems. Recent advances in CDR have demonstrated the effectiveness of the unified distribution paradigm, which leverages shared distributions to transfer knowledge across domains and employs domain-specific adapters for targeted recommendations. While this well-designed paradigm shows promising performance, existing methods require extra supervision signals (e.g. contrastive learning on domain-masked embeddings) to maintain unified distributions across domains, leading to an inherent trade-off between unified objectives and domain-specific preference modeling.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/LX75FGS2/Li - 2025 - CD-CDR Conditional Diffusion-based Item Generationfor Cross-Domain Recommendation.pdf}
}

@incollection{liEfficientQueryReverse2020,
  title = {Efficient {{Query Reverse Engineering Using Table Fragments}}},
  booktitle = {Database {{Systems}} for {{Advanced Applications}}},
  author = {Li, Meiying and Chan, Chee-Yong},
  editor = {Nah, Yunmook and Cui, Bin and Lee, Sang-Won and Yu, Jeffrey Xu and Moon, Yang-Sae and Whang, Steven Euijong},
  year = {2020},
  volume = {12114},
  pages = {406--422},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-59419-0_25},
  urldate = {2025-08-28},
  abstract = {Given an output table T that is the result of some unknown query on a database D, Query Reverse Engineering (QRE) computes one or more target query Q such that the result of Q on D is T. A fundamental challenge in QRE is how to efficiently compute target queries given its large search space. In this paper, we focus on the QRE problem for PJ+ queries, which is a more expressive class of queries than projectjoin queries by supporting antijoins as well as inner joins. To enhance efficiency, we propose a novel query-centric approach consisting of table partitioning, precomputation, and indexing techniques. Our experimental study demonstrates that our approach significantly outperforms the state-of-the-art solution by an average improvement factor of 120.},
  isbn = {978-3-030-59418-3 978-3-030-59419-0},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/69ETW5VT/Li and Chan - 2020 - Efficient Query Reverse Engineering Using Table Fragments.pdf}
}

@misc{linAccurateEfficientDocument2024,
  title = {Towards {{Accurate}} and {{Efficient Document Analytics}} with {{Large Language Models}}},
  author = {Lin, Yiming and Hulsebos, Madelon and Ma, Ruiying and Shankar, Shreya and Zeigham, Sepanta and Parameswaran, Aditya G. and Wu, Eugene},
  year = {2024},
  month = may,
  number = {arXiv:2405.04674},
  eprint = {2405.04674},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2405.04674},
  urldate = {2025-09-08},
  abstract = {Unstructured data formats account for over 80\% of the data currently stored, and extracting value from such formats remains a considerable challenge. In particular, current approaches for managing unstructured documents do not support ad-hoc analytical queries on document collections. Moreover, Large Language Models (LLMs) directly applied to the documents themselves, or on portions of documents through a process of Retrieval-Augmented Generation (RAG), fail to provide high-accuracy query results, and in the LLM-only case, additionally incur high costs. Since many unstructured documents in a collection often follow similar templates that impart a common semantic structure, we introduce ZenDB, a document analytics system that leverages this semantic structure, coupled with LLMs, to answer ad-hoc SQL queries on document collections. ZenDB efficiently extracts semantic hierarchical structures from such templatized documents and introduces a novel query engine that leverages these structures for accurate and cost-effective query execution. Users can impose a schema on their documents, and query it, all via SQL. Extensive experiments on three real-world document collections demonstrate ZenDB 's benefits, achieving up to 30{\texttimes} cost savings compared to LLM-based baselines, while maintaining or improving accuracy, and surpassing RAG-based baselines by up to 61\% in precision and 80\% in recall, at a marginally higher cost.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Databases},
  file = {/Users/DAADAMS/Zotero/storage/QKJUXS4M/Lin et al. - 2024 - Towards Accurate and Efficient Document Analytics with Large Language Models.pdf}
}

@inproceedings{linIdentifyingTopicsPosition1997,
  title = {Identifying Topics by Position},
  booktitle = {Fifth Conference on Applied Natural Language Processing},
  author = {Lin, Chin-Yew and Hovy, Eduard},
  year = {1997},
  pages = {283--290},
  urldate = {2025-02-16},
  file = {/Users/DAADAMS/Zotero/storage/6EWRDLG9/Lin and Hovy - 1997 - Identifying topics by position.pdf}
}

@misc{LinmagitQueryBot5000Querybased,
  title = {Linmagit/{{QueryBot5000}}: {{Query-based Workload Forecasting}} for {{Self-Driving DBMS}}},
  urldate = {2025-02-24},
  howpublished = {https://github.com/linmagit/QueryBot5000?tab=readme-ov-file},
  file = {/Users/DAADAMS/Zotero/storage/FMU8VRXN/QueryBot5000.html}
}

@inproceedings{linRougePackageAutomatic2004,
  title = {Rouge: {{A}} Package for Automatic Evaluation of Summaries},
  shorttitle = {Rouge},
  booktitle = {Text Summarization Branches Out},
  author = {Lin, Chin-Yew},
  year = {2004},
  pages = {74--81},
  urldate = {2025-02-16},
  file = {/Users/DAADAMS/Zotero/storage/3A4ZTZBW/Lin - 2004 - Rouge A package for automatic evaluation of summaries.pdf}
}

@inproceedings{linTrainingSelectionFunction1999,
  title = {Training a Selection Function for Extraction},
  booktitle = {Proceedings of the Eighth International Conference on {{Information}} and Knowledge Management},
  author = {Lin, Chin-Yew},
  year = {1999},
  month = nov,
  pages = {55--62},
  publisher = {ACM},
  address = {Kansas City Missouri USA},
  doi = {10.1145/319950.319957},
  urldate = {2025-02-16},
  isbn = {978-1-58113-146-8},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/ME7CK92A/Lin - 1999 - Training a selection function for extraction.pdf}
}

@inproceedings{lipmanATENAPROGeneratingPersonalized2023,
  title = {{{ATENA-PRO}}: {{Generating Personalized Exploration Notebooks}} with {{Constrained Reinforcement Learning}}},
  shorttitle = {{{ATENA-PRO}}},
  booktitle = {Companion of the 2023 {{International Conference}} on {{Management}} of {{Data}}},
  author = {Lipman, Tavor and Milo, Tova and Somech, Amit},
  year = {2023},
  month = jun,
  pages = {167--170},
  publisher = {ACM},
  address = {Seattle WA USA},
  doi = {10.1145/3555041.3589727},
  urldate = {2024-12-08},
  abstract = {We present ATENA-PRO, a framework for generating personalized data exploration notebooks, given an input dataset and user preferences. Via a dedicated wizard interface, users first specify their information needs from the desired exploration notebook. These specifications, alongside the input dataset, are fed to a constrained Deep Reinforcement Learning (CDRL) framework. Our CDRL framework is based on ATENA, a general-purpose DRL architecture for data exploration, augmenting it with a new compliance reward scheme, and a specification-aware neural network architecture, both crucial for the generation of personalized notebooks.},
  isbn = {978-1-4503-9507-6},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/C2CI2RNP/Lipman et al. - 2023 - ATENA-PRO Generating Personalized Exploration Notebooks with Constrained Reinforcement Learning.pdf}
}

@misc{lipmanLINXLanguageDriven2024,
  title = {{{LINX}}: {{A Language Driven Generative System}} for {{Goal-Oriented Automated Data Exploration}}},
  shorttitle = {{{LINX}}},
  author = {Lipman, Tavor and Milo, Tova and Somech, Amit and Wolfson, Tomer and Zafar, Oz},
  year = {2024},
  month = jun,
  number = {arXiv:2406.05107},
  eprint = {2406.05107},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2406.05107},
  urldate = {2024-11-26},
  abstract = {Data exploration is a challenging and time-consuming process in which users examine a dataset by iteratively employing a series of queries. While in some cases the user explores a new dataset to become familiar with it, more often, the exploration process is conducted with a specific analysis goal or question in mind. To assist users in exploring a new dataset, Automated Data Exploration (ADE) systems have been devised in previous work. These systems aim to auto-generate a full exploration session, containing a sequence of queries that showcase interesting elements of the data. However, existing ADE systems are often constrained by a predefined objective function, thus always generating the same session for a given dataset. Therefore, their effectiveness in goal-oriented exploration, in which users need to answer specific questions about the data, are extremely limited.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Databases},
  file = {/Users/DAADAMS/Zotero/storage/EE38SJDN/Lipman et al. - 2024 - LINX A Language Driven Generative System for Goal-Oriented Automated Data Exploration.pdf}
}

@article{luhnAutomaticCreationLiterature1958,
  title = {The Automatic Creation of Literature Abstracts},
  author = {Luhn, Hans Peter},
  year = {1958},
  journal = {IBM Journal of research and development},
  volume = {2},
  number = {2},
  pages = {159--165},
  publisher = {Ibm},
  urldate = {2025-02-16}
}

@article{luiseDifferentialPropertiesSinkhorn,
  title = {Differential {{Properties}} of {{Sinkhorn Approximation}} for {{Learning}} with {{Wasserstein Distance}}},
  author = {Luise, Giulia and Rudi, Alessandro and Pontil, Massimiliano and Ciliberto, Carlo},
  abstract = {Applications of optimal transport have recently gained remarkable attention as a result of the computational advantages of entropic regularization. However, in most situations the Sinkhorn approximation to the Wasserstein distance is replaced by a regularized version that is less accurate but easy to differentiate. In this work we characterize the differential properties of the original Sinkhorn approximation, proving that it enjoys the same smoothness of its regularized version and we explicitly provide an efficient algorithm to compute its gradient. We show that this result benefits both theory and applications: on one hand, high order smoothness confers statistical guarantees to learning with Wasserstein approximations. On the other hand, the gradient formula is used to efficiently solve learning and optimization problems in practice. Promising preliminary experiments complement our analysis.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/NJVF7WLA/Luise et al. - Differential Properties of Sinkhorn Approximation for Learning with Wasserstein Distance.pdf}
}

@inproceedings{luoDeepeyeAutomaticData2018,
  title = {Deepeye: {{Towards}} Automatic Data Visualization},
  shorttitle = {Deepeye},
  booktitle = {2018 {{IEEE}} 34th International Conference on Data Engineering ({{ICDE}})},
  author = {Luo, Yuyu and Qin, Xuedi and Tang, Nan and Li, Guoliang},
  year = {2018},
  pages = {101--112},
  publisher = {IEEE},
  urldate = {2025-02-16},
  file = {/Users/DAADAMS/Zotero/storage/PD9474IP/Luo et al. - 2018 - Deepeye Towards automatic data visualization.pdf}
}

@article{macarthurPATTERNSSPECIESDIVERSITY1965,
  title = {{{PATTERNS OF SPECIES DIVERSITY}}},
  author = {Macarthur, Robert H.},
  year = {1965},
  month = nov,
  journal = {Biological Reviews},
  volume = {40},
  number = {4},
  pages = {510--533},
  issn = {1464-7931, 1469-185X},
  doi = {10.1111/j.1469-185X.1965.tb00815.x},
  urldate = {2024-08-12},
  abstract = {Summary             1. Species diversity is most simply measured by counting species. More complicated measures, which take into account the relative abundance of the species, have been derived from information theory or from parameters of statistical distributions fitted to the census data. The information theory formulae can also be used to measure habitat diversity and differences between communities or habitats. In this way, changes in the pattern of species diversity can be compared with changes in the environment.             2. Small or remote islands and islands with uniform topography have fewer species than large or complex islands or islands nearer the source of colonization. For birds and some orders of insects it appears that the rate of colonization of new species is virtually balanced by the rate of extinction, so that the number of species has reached equilibrium. For other organisms, such as mammals, and for all organisms on the most remote islands, this equilibrium has probably not been reached and further increases in the fauna may be expected. The comparison of impoverished island faunas with the mainland faunas whence they were derived shows the effect of relaxed competition.             3. Local variations in the species diversity of small uniform habitats can usually be predicted in terms of the structure and productivity of the habitat. Habitats of similar structure on islands and mainland often have similar species diversities; the impoverishment of the island is reflected in the fact that different habitats on the island have nearly the same species, while different habitats on the mainland have more different species. This is interpreted as evidence that uniform habitats are nearly saturated with species and that new species usually colonize by occupying different habitats from present species.             4. The theory of competition and the facts of character displacement indicate that there is a limiting similarity to species which co-exist within a habitat. Species more similar than this limiting value must occupy different habitats. According to the theory, this limiting value should be less where productivity is high, where family size is low and where the seasons are relatively uniform. It should also be less for pursuing hunters than for species which search for stationary prey.             5. Total species diversities, from areas composed of many types of habitat, are usually, but not always, much greater in the tropics than in temperate regions. This is accomplished by a finer subdivision of habitats (habitat selection) more than by a marked increase in diversity within habitats. This total diversity may still be increasing and may have not reached saturation.},
  langid = {english}
}

@inproceedings{macnallyActionSelectionTransparent2018,
  title = {Action Selection for Transparent Planning},
  booktitle = {Proceedings of the 17th {{International Conference}} on {{Autonomous Agents}} and {{MultiAgent Systems}}},
  author = {MacNally, Aleck M. and Lipovetzky, Nir and Ramirez, Miquel and Pearce, Adrian R.},
  year = {2018},
  pages = {1327--1335},
  urldate = {2024-08-12},
  file = {/Users/DAADAMS/Zotero/storage/HXUSDK5B/MacNally et al. - 2018 - Action selection for transparent planning.pdf}
}

@inproceedings{macqueenMethodsClassificationAnalysis1967,
  title = {Some Methods for Classification and Analysis of Multivariate Observations},
  booktitle = {Proceedings of 5-Th {{Berkeley Symposium}} on {{Mathematical Statistics}} and {{Probability}}/{{University}} of {{California Press}}},
  author = {MacQueen, J.},
  year = {1967},
  urldate = {2025-02-16},
  file = {/Users/DAADAMS/Zotero/storage/6GDHYH2E/MacQueen - 1967 - Some methods for classification and analysis of multivariate observations.pdf}
}

@misc{manatkarILAEDAImitationLearning2024,
  title = {{{ILAEDA}}: {{An Imitation Learning Based Approach}} for {{Automatic Exploratory Data Analysis}}},
  shorttitle = {{{ILAEDA}}},
  author = {Manatkar, Abhijit and Patel, Devarsh and Patel, Hima and Manwani, Naresh},
  year = {2024},
  month = oct,
  number = {arXiv:2410.11276},
  eprint = {2410.11276},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2410.11276},
  urldate = {2024-12-08},
  abstract = {Automating end-to-end Exploratory Data Analysis (AutoEDA) is a challenging open problem, often tackled through Reinforcement Learning (RL) by learning to predict a sequence of analysis operations (FILTER, GROUP, etc). Defining rewards for each operation is a challenging task and existing methods rely on various interestingness measures to craft reward functions to capture the importance of each operation. In this work, we argue that not all of the essential features of what makes an operation important can be accurately captured mathematically using rewards. We propose an AutoEDA model trained through imitation learning from expert EDA sessions, bypassing the need for manually defined interestingness measures. Our method, based on generative adversarial imitation learning (GAIL), generalizes well across datasets, even with limited expert data. We also introduce a novel approach for generating synthetic EDA demonstrations for training. Our method outperforms the existing state-of-the-art end-to-end EDA approach on benchmarks by upto 3x, showing strong performance and generalization, while naturally capturing diverse interestingness measures in generated EDA sessions.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Databases,Computer Science - Machine Learning},
  file = {/Users/DAADAMS/Zotero/storage/UEIJG5ZH/Manatkar et al. - 2024 - ILAEDA An Imitation Learning Based Approach for Automatic Exploratory Data Analysis.pdf}
}

@article{manolescuExploringRDFGraphs,
  title = {Exploring {{RDF Graphs}} through {{Summarization}} and {{Analytic Query Discovery}}},
  author = {Manolescu, Ioana},
  abstract = {Graph data is central to many applications, ranging from social networks to scientific databases. Graph formats maximize the flexibility offered to data designers, as they are mostly schemaless and thus can be used to capture very heterogeneous-structure content. RDF, the W3C's format for sharing open (linked) data, adds the possibility to attach semantics to data, describing applicationdomain constraints by means of ontologies; in turn, this leads to implicit data that is also part of a graph even if it is not explicitly in it.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/TW5SQHGC/Manolescu - Exploring RDF Graphs through Summarization and Analytic Query Discovery.pdf}
}

@inproceedings{maQuerybasedWorkloadForecasting2018,
  title = {Query-Based {{Workload Forecasting}} for {{Self-Driving Database Management Systems}}},
  booktitle = {Proceedings of the 2018 {{International Conference}} on {{Management}} of {{Data}}},
  author = {Ma, Lin and Van Aken, Dana and Hefny, Ahmed and Mezerhane, Gustavo and Pavlo, Andrew and Gordon, Geoffrey J.},
  year = {2018},
  month = may,
  pages = {631--645},
  publisher = {ACM},
  address = {Houston TX USA},
  doi = {10.1145/3183713.3196908},
  urldate = {2025-02-24},
  abstract = {The first step towards an autonomous database management system (DBMS) is the ability to model the target application's workload. This is necessary to allow the system to anticipate future workload needs and select the proper optimizations in a timely manner. Previous forecasting techniques model the resource utilization of the queries. Such metrics, however, change whenever the physical design of the database and the hardware resources change, thereby rendering previous forecasting models useless.},
  isbn = {978-1-4503-4703-7},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/V8UW2VB2/Ma et al. - 2018 - Query-based Workload Forecasting for Self-Driving Database Management Systems.pdf}
}

@article{mariafoxModellingMixedDiscretecontinuous2006,
  title = {Modelling Mixed Discrete-Continuous Domains for Planning},
  author = {{Maria Fox} and Fox, Maria and {Derek Long} and Long, Derek},
  year = {2006},
  month = sep,
  journal = {Journal of Artificial Intelligence Research},
  volume = {27},
  number = {1},
  pages = {235--297},
  doi = {10.1613/jair.2044},
  abstract = {In this paper we present PDDL+, a planning domain description language for modelling mixed discrete-continuous planning domains. We describe the syntax and modelling style of PDDL+, showing that the language makes convenient the modelling of complex time-dependent effects. We provide a formal semantics for PDDL+ by mapping planning instances into constructs of hybrid automata. Using the syntax of HAs as our semantic model we construct a semantic mapping to labelled transition systems to complete the formal interpretation of PDDL+ planning instances. An advantage of building a mapping from PDDL+ to HA theory is that it forms a bridge between the Planning and Real Time Systems research communities. One consequence is that we can expect to make use of some of the theoretical properties of HAs. For example, for a restricted class of HAs the Reachability problem (which is equivalent to Plan Existence) is decidable. PDDL+ provides an alternative to the continuous durative action model of PDDL2.1, adding a more flexible and robust model of time-dependent behaviour.},
  annotation = {MAG ID: 2133517325},
  file = {/Users/DAADAMS/Zotero/storage/GW7DU95X/Fox and Long - 2006 - Modelling mixed discrete-continuous domains for pl.pdf}
}

@article{mariafoxPDDL2ExtensionPDDL2003,
  title = {{{PDDL2}}.1: An Extension to {{PDDL}} for Expressing Temporal Planning Domains},
  author = {{Maria Fox} and Fox, Maria and {Derek Long} and Long, Derek},
  year = {2003},
  month = dec,
  journal = {Journal of Artificial Intelligence Research},
  volume = {20},
  number = {1},
  pages = {61--124},
  doi = {10.1613/jair.1129},
  abstract = {In recent years research in the planning community has moved increasingly towards application of planners to realistic problems involving both time and many types of resources. For example, interest in planning demonstrated by the space research community has inspired work in observation scheduling, planetary rover exploration and spacecraft control domains. Other temporal and resource-intensive domains including logistics planning, plant control and manufacturing have also helped to focus the community on the modelling and reasoning issues that must be confronted to make planning technology meet the challenges of application. The International Planning Competitions have acted as an important motivating force behind the progress that has been made in planning since 1998. The third competition (held in 2002) set the planning community the challenge of handling time and numeric resources. This necessitated the development of a modelling language capable of expressing temporal and numeric properties of planning domains. In this paper we describe the language, PDDL2.1, that was used in the competition. We describe the syntax of the language, its formal semantics and the validation of concurrent plans. We observe that PDDL2.1 has considerable modelling power -- exceeding the capabilities of current planning technology -- and presents a number of important challenges to the research community.},
  annotation = {MAG ID: 2119709400},
  file = {/Users/DAADAMS/Zotero/storage/3S56RDNP/Fox and Long - 2003 - PDDL2. 1 An extension to PDDL for expressing temp.pdf}
}

@article{martinsReverseEngineeringDatabase2019,
  title = {Reverse Engineering Database Queries from Examples: {{State-of-the-art}}, Challenges, and Research Opportunities},
  shorttitle = {Reverse Engineering Database Queries from Examples},
  author = {Martins, Denis Mayr Lima},
  year = {2019},
  month = jul,
  journal = {Information Systems},
  volume = {83},
  pages = {89--100},
  issn = {0306-4379},
  doi = {10.1016/j.is.2019.03.002},
  urldate = {2025-08-28},
  abstract = {With the popularization of data access and usage, an increasing number of users without expert knowledge of databases is required to perform data interactions. Often, these users face the challenges of writing and reformulating database queries, which consume a considerable amount of time and frequently yield unsatisfactory results. To facilitate this human--database interaction, researchers have investigated the Query By Example (QBE) paradigm in which database queries are (semi) automatically discovered from data examples given by users. This paradigm allows non-database experts to formulate queries without relying on complex query languages. In this context, this work aims to present a systematic review of the recent developments, open challenges, and research opportunities of the QBE reported in the literature. This work also describes strategies employed to leverage efficient example acquisition and query reverse engineering. The obtained results show that recent research developments have focused on enhancing the expressiveness of produced queries, minimizing user interaction, and enabling efficient query learning in the context of data retrieval, exploration, integration, and analytics. Our findings indicate that future research should concentrate efforts to provide innovative solutions to the challenges of improving controllability and transparency, considering diverse user preferences in the processes of learning personalized queries, ensuring data quality, and improving the support of additional SQL features and operators.},
  keywords = {Databases,Query discovery,Query learning,Query synthesis,Reverse engineering database queries},
  file = {/Users/DAADAMS/Zotero/storage/S9JWLPKB/S0306437918300978.html}
}

@article{mastersCostbasedGoalRecognition2019,
  title = {Cost-Based Goal Recognition in Navigational Domains},
  author = {Masters, Peta and Sardina, Sebastian},
  year = {2019},
  journal = {Journal of Artificial Intelligence Research},
  volume = {64},
  pages = {197--242},
  urldate = {2024-08-08},
  file = {/Users/DAADAMS/Zotero/storage/T78A5IQD/Masters and Sardina - 2019 - Cost-based goal recognition in navigational domain.pdf}
}

@inproceedings{mastersGoalRecognitionRational2019,
  title = {Goal Recognition for Rational and Irrational Agents},
  booktitle = {Proceedings of the 18th International Conference on Autonomous Agents and Multiagent Systems},
  author = {Masters, Peta and Sardina, Sebastian},
  year = {2019},
  pages = {440--448},
  urldate = {2024-08-08},
  file = {/Users/DAADAMS/Zotero/storage/YZB8YFQC/Masters and Sardina - 2019 - Goal recognition for rational and irrational agent.pdf}
}

@article{mccullochLogicalCalculusIdeas1943,
  title = {A Logical Calculus of the Ideas Immanent in Nervous Activity},
  author = {McCulloch, Warren S. and Pitts, Walter},
  year = {1943},
  journal = {The bulletin of mathematical biophysics},
  volume = {5},
  pages = {115--133},
  publisher = {Springer},
  urldate = {2025-02-16},
  file = {/Users/DAADAMS/Zotero/storage/ZS6EGMKU/McCulloch and Pitts - 1943 - A logical calculus of the ideas immanent in nervous activity.pdf}
}

@article{mcintoshIndexDiversityRelation1967,
  title = {An {{Index}} of {{Diversity}} and the {{Relation}} of {{Certain Concepts}} to {{Diversity}}},
  author = {McIntosh, Robert P.},
  year = {1967},
  month = may,
  journal = {Ecology},
  volume = {48},
  number = {3},
  pages = {392--404},
  issn = {0012-9658, 1939-9170},
  doi = {10.2307/1932674},
  urldate = {2024-08-12},
  abstract = {The uses in ecology of the terms richness, diversity, homogeneity, and similarity are considered in the context of recent studies of plant and animal communities. Various uses of divesity are reviewed and an index of diversity derived from the distance measure of similarity is suggested. This index is               {$\Sigma$}               i               =               1               n               2               i               where S equals the number of species and n equals the number of individuals in each species. This index is compared with other indices of diversity. The principal problem of measuring diversity is the assessment of the homogeneity or similarity of the sample or samples being studied. An advantage of the proposed index is that it derives from a measure of similarity of which it is a special case, and it is a special case, and it is a more natural and familiar representation of points in a coordinate system.},
  copyright = {http://onlinelibrary.wiley.com/termsAndConditions\#vor},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/DALUPSDV/McIntosh - 1967 - An Index of Diversity and the Relation of Certain .pdf}
}

@inproceedings{meneguzziSurveyGoalRecognition2021,
  title = {A {{Survey}} on {{Goal Recognition}} as {{Planning}}},
  booktitle = {Proceedings of the {{Thirtieth International Joint Conference}} on {{Artificial Intelligence}}},
  author = {Meneguzzi, Felipe and Fraga Pereira, Ramon},
  year = {2021},
  month = aug,
  pages = {4524--4532},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  address = {Montreal, Canada},
  doi = {10.24963/ijcai.2021/616},
  urldate = {2024-03-15},
  abstract = {Goal Recognition is the task of inferring an agent's goal, from a set of hypotheses, given a model of the environment dynamic, and a sequence of observations of such agent's behavior. While research on this problem gathered momentum as an offshoot of plan recognition, recent research has established it as a major subject of research on its own, leading to numerous new approaches that both expand the expressivity of domains in which to perform goal recognition and substantial advances to the stateof-the-art on established domain types. In this survey, we focus on the advances to goal recognition achieved in the last decade, categorizing the resulting techniques and identifying a number of opportunities for further breakthrough research.},
  isbn = {978-0-9992411-9-6},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/IHCWNXK5/Meneguzzi and Fraga Pereira - 2021 - A Survey on Goal Recognition as Planning.pdf}
}

@article{miguelperezramirezGoalRecognitionPOMDPs2011,
  title = {Goal Recognition over {{POMDPs}}: Inferring the Intention of a {{POMDP}} Agent},
  author = {{Miguel P{\'e}rez Ram{\'i}rez} and Ram{\'i}rez, Miquel and {H{\'e}ctor Geffner} and Geffner, Hector},
  year = {2011},
  month = jul,
  pages = {2009--2014},
  doi = {10.5591/978-1-57735-516-8/ijcai11-335},
  abstract = {Plan recognition is the problem of inferring the goals and plans of an agent from partial observations of her behavior. Recently, it has been shown that the problem can be formulated and solved using planners, reducing plan recognition to plan generation. In this work, we extend this model-based approach to plan recognition to the POMDP setting, where actions are stochastic and states are partially observable. The task is to infer a probability distribution over the possible goals of an agent whose behavior results from a POMDP model. The POMDP model is shared between agent and observer except for the true goal of the agent that is hidden to the observer. The observations are action sequences O that may contain gaps as some or even most of the actions done by the agent may not be observed. We show that the posterior goal distribution P(G{\textbar}O) can be computed from the value function VG(b) over beliefs b generated by the POMDP planner for each possible goal G. Some extensions of the basic framework are discussed, and a number of experiments are reported.},
  annotation = {MAG ID: 1530655603}
}

@inproceedings{miloAutomatingExploratoryData2020,
  title = {Automating {{Exploratory Data Analysis}} via {{Machine Learning}}: {{An Overview}}},
  shorttitle = {Automating {{Exploratory Data Analysis}} via {{Machine Learning}}},
  booktitle = {Proceedings of the 2020 {{ACM SIGMOD International Conference}} on {{Management}} of {{Data}}},
  author = {Milo, Tova and Somech, Amit},
  year = {2020},
  month = jun,
  pages = {2617--2622},
  publisher = {ACM},
  address = {Portland OR USA},
  doi = {10.1145/3318464.3383126},
  urldate = {2024-12-08},
  abstract = {Exploratory Data Analysis (EDA) is an important initial step for any knowledge discovery process, in which data scientists interactively explore unfamiliar datasets by issuing a sequence of analysis operations (e.g. filter, aggregation, and visualization). Since EDA is long known as a difficult task, requiring profound analytical skills, experience, and domain knowledge, a plethora of systems have been devised over the last decade in order to facilitate EDA.},
  isbn = {978-1-4503-6735-6},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/98MCTQTV/Milo and Somech - 2020 - Automating Exploratory Data Analysis via Machine Learning An Overview.pdf}
}

@inproceedings{miloDeepReinforcementLearningFramework2018,
  title = {Deep {{Reinforcement-Learning Framework}} for {{Exploratory Data Analysis}}},
  booktitle = {Proceedings of the {{First International Workshop}} on {{Exploiting Artificial Intelligence Techniques}} for {{Data Management}}},
  author = {Milo, Tova and Somech, Amit},
  year = {2018},
  month = jun,
  pages = {1--4},
  publisher = {ACM},
  address = {Houston TX USA},
  doi = {10.1145/3211954.3211958},
  urldate = {2024-12-08},
  abstract = {Deep Reinforcement Learning (DRL) is unanimously considered as a breakthrough technology, used in solving a growing number of AI challenges previously considered to be intractable. In this work, we aim to set the ground for employing DRL techniques in the context of Exploratory Data Analysis (EDA), an important yet challenging, that is critical in many application domains. We suggest an end-to-end framework architecture, coupled with an initial implementation of each component. The goal of this short paper is to encourage the exploration of DRL models and techniques for facilitating a full-fledged, autonomous solution for EDA.},
  isbn = {978-1-4503-5851-4},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/57ISBU99/Milo and Somech - 2018 - Deep Reinforcement-Learning Framework for Exploratory Data Analysis.pdf}
}

@inproceedings{miloNextStepSuggestionsModern2018,
  title = {Next-{{Step Suggestions}} for {{Modern Interactive Data Analysis Platforms}}},
  booktitle = {Proceedings of the 24th {{ACM SIGKDD International Conference}} on {{Knowledge Discovery}} \& {{Data Mining}}},
  author = {Milo, Tova and Somech, Amit},
  year = {2018},
  month = jul,
  pages = {576--585},
  publisher = {ACM},
  address = {London United Kingdom},
  doi = {10.1145/3219819.3219848},
  urldate = {2024-12-17},
  isbn = {978-1-4503-5552-0},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/9FYVZ8ZN/Milo and Somech - 2018 - Next-Step Suggestions for Modern Interactive Data Analysis Platforms.pdf}
}

@inproceedings{miloREACTContextSensitiveRecommendations2016,
  title = {{{REACT}}: {{Context-Sensitive Recommendations}} for {{Data Analysis}}},
  shorttitle = {{{REACT}}},
  booktitle = {Proceedings of the 2016 {{International Conference}} on {{Management}} of {{Data}}},
  author = {Milo, Tova and Somech, Amit},
  year = {2016},
  month = jun,
  pages = {2137--2140},
  publisher = {ACM},
  address = {San Francisco California USA},
  doi = {10.1145/2882903.2899392},
  urldate = {2025-02-16},
  isbn = {978-1-4503-3531-7},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/NUVXYJHJ/Milo and Somech - 2016 - REACT Context-Sensitive Recommendations for Data Analysis.pdf}
}

@misc{MinimizingSimpleCumulative,
  title = {Minimizing~{{Simple}}~and~{{Cumulative~Regret}} in~{{Monte-Carlo~Tree~Search}} {\textbar} {{SpringerLink}}},
  urldate = {2024-03-15},
  howpublished = {https://link.springer.com/chapter/10.1007/978-3-319-14923-3\_1},
  file = {/Users/DAADAMS/Zotero/storage/DZZHPM5B/978-3-319-14923-3_1.html}
}

@article{mirskyGoalPlanRecognition2019,
  title = {Goal and {{Plan Recognition Design}} for {{Plan Libraries}}},
  author = {Mirsky, Reuth and Gal, Kobi and Stern, Roni and Kalech, Meir},
  year = {2019},
  month = mar,
  journal = {ACM Transactions on Intelligent Systems and Technology},
  volume = {10},
  number = {2},
  pages = {1--23},
  issn = {2157-6904, 2157-6912},
  doi = {10.1145/3234464},
  urldate = {2024-08-07},
  abstract = {This article provides new techniques for optimizing domain design for goal and plan recognition using plan libraries. We define two new problems: Goal Recognition Design for Plan Libraries (GRD-PL) and Plan Recognition Design (PRD). Solving the GRD-PL helps to infer               which               goal the agent is trying to achieve, while solving PRD can help to infer               how               the agent is going to achieve its goal. For each problem, we define a worst-case distinctiveness measure that is an upper bound on the number of observations that are necessary to unambiguously recognize the agent's goal or plan. This article studies the relationship between these measures, showing that the worst-case distinctiveness of GRD-PL is a lower bound of the worst-case plan distinctiveness of PRD and that they are equal under certain conditions. We provide two complete algorithms for minimizing the worst-case distinctiveness of plan libraries without reducing the agent's ability to complete its goals: One is a brute-force search over all possible plans and one is a constraint-based search that identifies plans that are most difficult to distinguish in the domain. These algorithms are evaluated in three hierarchical plan recognition settings from the literature. We were able to reduce the worst-case distinctiveness of the domains using our approach, in some cases reaching 100\% improvement within a predesignated time window. Our iterative algorithm outperforms the brute-force approach by an order of magnitude in terms of runtime.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/72JL7KPL/Mirsky et al. - 2019 - Goal and Plan Recognition Design for Plan Librarie.pdf}
}

@inproceedings{mirskySequentialPlanRecognition2016,
  title = {Sequential {{Plan Recognition}}: ({{Extended Abstract}})},
  shorttitle = {Sequential {{Plan Recognition}}},
  booktitle = {Proceedings of the 2016 {{International Conference}} on {{Autonomous Agents}} \& {{Multiagent Systems}}},
  author = {Mirsky, Reuth and Gal, Ya'akov (Kobi) and Stern, Roni and Kalech, Meir},
  year = {2016},
  month = may,
  series = {{{AAMAS}} '16},
  pages = {1347--1348},
  publisher = {{International Foundation for Autonomous Agents and Multiagent Systems}},
  address = {Richland, SC},
  urldate = {2024-08-07},
  abstract = {Plan recognition algorithms need to maintain all candidate hypotheses which are consistent with the observations, even though there is only a single hypothesis that is the correct one. Unfortunately, the number of possible hypotheses can be exponentially large in practice. This paper addresses the problem of how to disambiguate between many possible hypotheses that are all consistent with the actions of the observed agent. One way to reduce the number of hypotheses is to consult a domain expert or the acting agent directly about its intentions. This process can be performed sequentially, updating the set of hypotheses during the recognition process. The paper specifically addresses the problem of how to minimize the number of queries made that are required to find the correct hypothesis. It adapts a number of probing techniques for choosing which plan to query, such as maximal information gain and maximum likelihood. These approaches were evaluated on a domain from the literature using a well known plan recognition algorithm. The results showed that the information gain approach was able to find the correct plan using significantly fewer queries than the maximum likelihood approach as well as a baseline approach choosing random plans. Our technique can inform the design of future plan recognition systems that interleave the recognition process with intelligent interventions of their users.},
  isbn = {978-1-4503-4239-1}
}

@article{mokkademRecursiveAlgorithmMining2022,
  title = {A {{Recursive Algorithm}} for {{Mining Association Rules}}},
  author = {Mokkadem, Abdelkader and Pelletier, Mariane and Raimbault, Louis},
  year = {2022},
  month = jul,
  journal = {SN Computer Science},
  volume = {3},
  number = {5},
  pages = {384},
  issn = {2661-8907},
  doi = {10.1007/s42979-022-01266-y},
  urldate = {2025-01-07},
  abstract = {Mining frequent itemsets and association rules are an essential task within data mining and data analysis. In this paper, we introduce PrefRec, a recursive algorithm for finding frequent itemsets and association rules. Its main advantage is its recursiveness with respect to the items. It is particularly efficient for updating the mining process when new items are added to the database or when some are excluded. We present in a complete way the logic of the algorithm, and give some of its applications. After that, we carry out an experimental study on the effectiveness of PrefRec. We first compare the execution times with some very popular frequent itemset mining algorithms. Then, we do experiments to test the updating capabilities of our algorithm.},
  langid = {english},
  keywords = {Association rule,Data mining,Frequent itemset,Recursive algorithm},
  file = {/Users/DAADAMS/Zotero/storage/HA5968EB/Mokkadem et al. - 2022 - A Recursive Algorithm for Mining Association Rules.pdf}
}

@inproceedings{moreScalableClusteringDistributed2004,
  title = {Scalable Clustering: A Distributed Approach},
  shorttitle = {Scalable Clustering},
  booktitle = {2004 {{IEEE International Conference}} on {{Fuzzy Systems}} ({{IEEE Cat}}. {{No}}. {{04CH37542}})},
  author = {More, P. and Hall, Lawrence O.},
  year = {2004},
  volume = {1},
  pages = {143--148},
  publisher = {IEEE},
  urldate = {2025-02-16},
  file = {/Users/DAADAMS/Zotero/storage/WWSXBHIJ/More and Hall - 2004 - Scalable clustering a distributed approach.pdf}
}

@article{neubergCausalityModelsReasoning2003,
  title = {Causality: Models, Reasoning, and Inference, by Judea Pearl, Cambridge University Press, 2000},
  shorttitle = {Causality},
  author = {Neuberg, Leland Gerson},
  year = {2003},
  journal = {Econometric Theory},
  volume = {19},
  number = {4},
  pages = {675--685},
  publisher = {cambridge university press},
  urldate = {2025-02-16},
  file = {/Users/DAADAMS/Zotero/storage/H3EP33JE/212370297.html}
}

@article{nguyenCARIMEfficientAlgorithm2015,
  title = {{{CARIM}}: {{An Efficient Algorithm}} for {{Mining Class-Association Rules}} with {{Interestingness Measures}}.},
  shorttitle = {{{CARIM}}},
  author = {Nguyen, Loan and Vo, Bay and Hong, Tzung-Pei},
  year = {2015},
  journal = {International Arab Journal of Information Technology (IAJIT)},
  volume = {12},
  urldate = {2025-01-13},
  annotation = {Read\_Status: Read\\
Read\_Status\_Date: 2025-01-13T05:40:49.695Z},
  file = {/Users/DAADAMS/Zotero/storage/GNRH2GSR/Nguyen et al. - 2015 - CARIM An Efficient Algorithm for Mining Class-Association Rules with Interestingness Measures..pdf}
}

@inproceedings{nguyenInterestingnessMeasuresClassification2012,
  title = {Interestingness {{Measures}} for {{Classification Based}} on {{Association Rules}}},
  booktitle = {Computational {{Collective Intelligence}}. {{Technologies}} and {{Applications}}},
  author = {Nguyen, Loan T. T. and Vo, Bay and Hong, Tzung-Pei and Thanh, Hoang Chi},
  editor = {Nguyen, Ngoc-Thanh and Hoang, Kiem and J{\c e}drzejowicz, Piotr},
  year = {2012},
  pages = {383--392},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-34707-8_39},
  abstract = {This paper proposes a new algorithm for classification based on association rule with interestingness measures. The proposed algorithm uses a tree structure for maintenance of related information in each node, thus making the process of generating rules fast. Besides, the proposed algorithm can be easily extended to integrate some measures together for ranking rules. Experiments are also made to show the efficiency of the proposed approach for different settings. The mining time for different interestingness measures is varied only a little when ten measures are integrated.},
  isbn = {978-3-642-34707-8},
  langid = {english},
  keywords = {accuracy,class-association rulem,classification,integration,interestingness measure},
  file = {/Users/DAADAMS/Zotero/storage/Z4PCE8SG/Nguyen et al. - 2012 - Interestingness Measures for Classification Based on Association Rules.pdf}
}

@misc{OpenAllSynced,
  title = {Open All Synced Tabs? : R/Firefox},
  urldate = {2024-07-18},
  howpublished = {https://www.reddit.com/r/firefox/comments/8pfhjd/open\_all\_synced\_tabs/},
  file = {/Users/DAADAMS/Zotero/storage/CNFTGKLY/open_all_synced_tabs.html}
}

@article{orvalhoSQUARESSQLSynthesizer,
  title = {{{SQUARES}} : {{A SQL Synthesizer Using Query Reverse Engineering}}},
  author = {Orvalho, Pedro and {Terra-Neves}, Miguel and Ventura, Miguel and Martins, Ruben and Manquinho, Vasco},
  abstract = {Nowadays, many data analysts are domain experts, but they lack programming skills. As a result, many of them can provide examples of data transformations but are unable to produce the desired query. Hence, there is an increasing need for systems capable of solving the problem of Query Reverse Engineering (QRE). Given a database and output table, these systems have to find the query that generated this table. We present SQUARES, a program synthesis tool based on input-output examples that can help data analysts to extract and transform data by synthesizing SQL queries, and table manipulation programs using the R language.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/IIPN3GLR/Orvalho et al. - SQUARES  A SQL Synthesizer Using Query Reverse Engineering.pdf}
}

@misc{OSFSIMBABenchmark,
  title = {{{OSF}} {\textbar} {{SIMBA Benchmark}}},
  urldate = {2025-09-10},
  howpublished = {https://osf.io/vbm8z/files/osfstorage?view\_only=2e06892f0c104a9e911e8e7599deb2ab},
  file = {/Users/DAADAMS/Zotero/storage/AYCY24L3/osfstorage.html}
}

@inbook{paezExploratoryDataAnalysis2022,
  title = {Exploratory {{Data Analysis}}},
  booktitle = {Discrete {{Choice Analysis}} with {{R}}},
  author = {P{\'a}ez, Antonio and Boisjoly, Genevi{\`e}ve},
  year = {2022},
  pages = {25--64},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-031-20719-8_2},
  urldate = {2024-08-07},
  collaborator = {P{\'a}ez, Antonio and Boisjoly, Genevi{\`e}ve},
  isbn = {978-3-031-20718-1 978-3-031-20719-8},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/WDCWIJRY/Páez and Boisjoly - 2022 - Exploratory Data Analysis.pdf}
}

@misc{panevReverseEngineeringTopk2016,
  title = {Reverse {{Engineering Top-k Database Queries}} with {{PALEO}}},
  author = {Panev, Kiril and Michel, Sebastian},
  year = {2016},
  publisher = {OpenProceedings.org},
  doi = {10.5441/002/EDBT.2016.13},
  urldate = {2025-08-28},
  abstract = {Ranked lists are an essential methodology to succinctly summarize outstanding items, computed over database tables or crowdsourced in dedicated websites. In this work, we address the problem of reverse engineering top-k queries over a database, that is, given a relation R and a sample topk result list, our approach, named PALEO1, aims at determining an SQL query that returns the provided input result when executed over R. The core problem consists of finding predicates of the where clause that return the given items, determining the correct ranking criteria, and to evaluate the most promising candidate queries first. To capture cases where only a sample of R is available or when R is different to the relation that indeed generated the input, we put forward a probabilistic model that allows assessing the chance of a query to output tuples that are resembling or are somewhat close to the input data. We further propose an iterative candidate query execution to further eliminate unpromising queries before being executed. We report on the results of a comprehensive performance evaluation using data and queries of the TPC-H and SSB [14] benchmarks.},
  langid = {english},
  keywords = {Database Technology},
  file = {/Users/DAADAMS/Zotero/storage/NFCVHK92/Panev and Michel - 2016 - Reverse Engineering Top-k Database Queries with PALEO.pdf}
}

@inproceedings{papadopoulosHAIDESAdaptiveApproximation2025,
  title = {{{HAIDES}}: {{Adaptive Approximation}} of {{Inference Queries}} over {{Unstructured Data}}},
  shorttitle = {{{HAIDES}}},
  booktitle = {2025 {{IEEE}} 41st {{International Conference}} on {{Data Engineering}} ({{ICDE}})},
  author = {Papadopoulos, Christos C. and Simitsis, Alkis and Pedersen, Torben Bach},
  year = {2025},
  month = may,
  pages = {2394--2407},
  issn = {2375-026X},
  doi = {10.1109/ICDE65448.2025.00181},
  urldate = {2025-09-11},
  abstract = {Modern analytics rely on insights derived from the execution of inference queries over vast amounts of unstructured data such as text, images, and video. Oftentimes, these queries evaluate predicates based on an expensive ``oracle`` model in the likes of a deep neural network or human input that dominates the total query cost. Prior work has focused on training computationally cheap proxy models at query time that produce an approximate result. Alternatively, index-based methods apply the original oracle over a representative set of data points and generate the approximate result through an inference propagation process. Current state-of-the-art (SOTA) index-based methods require a memory -expensive index construction process which offsets their oracle cost-effectiveness and can make their usage prohibitive. In this work, we present HAIDES, an index-based, domain-agnostic framework for approximating inference on unstructured data. HAIDES consists of two main components: a coarse-to-fine framework that can be efficiently constructed using minimal memory, and a novel index adaptation component that makes use of oracle invocations during query execution in order to adaptively produce representative sets that yield high-quality approximate results. Our experimental results across three challenging domains-video, images, text-show that HAIDES (a) constructs indexes that produce performant representative sets with up to 2 orders of magnitude less memory than the SOTA baseline, while (b) requires up to 2x less oracle calls to produce the same result quality, and (c) achieves up to 10 percentage points better result quality when using the same oracle calls.},
  keywords = {Artificial neural networks,Computational modeling,Costs,Data engineering,index-based inference,Indexes,inference queries,Memory management,Training,un-structured data queries,Videos},
  file = {/Users/DAADAMS/Zotero/storage/NUWSPIUM/Papadopoulos et al. - 2025 - HAIDES Adaptive Approximation of Inference Queries over Unstructured Data.pdf}
}

@incollection{parhamExplainingBehaviorReinforcement2023,
  title = {Explaining the {{Behavior}} of {{Reinforcement Learning Agents Using Association Rules}}},
  booktitle = {Learning and {{Intelligent Optimization}}},
  author = {Parham, Zahra and De Lille, Vi Tching and Cappart, Quentin},
  editor = {Sellmann, Meinolf and Tierney, Kevin},
  year = {2023},
  volume = {14286},
  pages = {107--120},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-031-44505-7_8},
  urldate = {2025-01-09},
  isbn = {978-3-031-44504-0 978-3-031-44505-7},
  langid = {english},
  annotation = {Read\_Status: Read\\
Read\_Status\_Date: 2025-01-09T01:13:57.350Z},
  file = {/Users/DAADAMS/Zotero/storage/W6W7BUQN/Parham et al. - 2023 - Explaining the Behavior of Reinforcement Learning Agents Using Association Rules.pdf}
}

@article{parker-holderEffectiveDiversityPopulation2020,
  title = {Effective Diversity in Population Based Reinforcement Learning},
  author = {{Parker-Holder}, Jack and Pacchiano, Aldo and Choromanski, Krzysztof M. and Roberts, Stephen J.},
  year = {2020},
  journal = {Advances in Neural Information Processing Systems},
  volume = {33},
  pages = {18050--18062},
  urldate = {2024-09-11},
  file = {/Users/DAADAMS/Zotero/storage/R2S3XF5D/Parker-Holder et al. - 2020 - Effective diversity in population based reinforcement learning.pdf}
}

@incollection{patraToleranceRoughSet2011,
  title = {Tolerance {{Rough Set Theory Based Data Summarization}} for {{Clustering Large Datasets}}},
  booktitle = {Transactions on {{Rough Sets XIV}}},
  author = {Patra, Bidyut Kr. and Nandi, Sukumar},
  editor = {Peters, James F. and Skowron, Andrzej and Sakai, Hiroshi and Chakraborty, Mihir Kumar and Slezak, Dominik and Hassanien, Aboul Ella and Zhu, William},
  year = {2011},
  volume = {6600},
  pages = {139--158},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-21563-6_8},
  urldate = {2025-02-16},
  isbn = {978-3-642-21562-9 978-3-642-21563-6}
}

@misc{patrickmarcelPatrickmarcelSqlEDAqueryGenerator2025,
  title = {Patrickmarcel/{{sqlEDAqueryGenerator}}},
  author = {{patrickmarcel}},
  year = {2025},
  month = jan,
  urldate = {2025-09-10}
}

@incollection{pattisonDomainIndependentGoal2010,
  title = {Domain Independent Goal Recognition},
  booktitle = {{{STAIRS}} 2010},
  author = {Pattison, David and Long, Derek},
  year = {2010},
  pages = {238--250},
  publisher = {IOS Press},
  urldate = {2024-08-08},
  file = {/Users/DAADAMS/Zotero/storage/7M554EW7/Pattison and Long - 2010 - Domain independent goal recognition.pdf}
}

@inproceedings{PDFExtractingTopK,
  title = {{{Extracting Top-K Insights}} from {{Multi-dimensional Data}}},
  booktitle = {{{ResearchGate}}},
  doi = {10.1145/3035918.3035922},
  urldate = {2025-09-11},
  year = {2017},
  abstract = {PDF {\textbar} OLAP tools have been extensively used by enterprises to make better and faster decisions. Nevertheless, they require users to specify group-by... {\textbar} Find, read and cite all the research you need on ResearchGate},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/WKUPJG8E/316849173_Extracting_Top-K_Insights_from_Multi-dimensional_Data.html}
}

@misc{pearceImitatingHumanBehaviour2023,
  title = {Imitating {{Human Behaviour}} with {{Diffusion Models}}},
  author = {Pearce, Tim and Rashid, Tabish and Kanervisto, Anssi and Bignell, Dave and Sun, Mingfei and Georgescu, Raluca and Macua, Sergio Valcarcel and Tan, Shan Zheng and Momennejad, Ida and Hofmann, Katja and Devlin, Sam},
  year = {2023},
  month = mar,
  number = {arXiv:2301.10677},
  eprint = {2301.10677},
  primaryclass = {cs, stat},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2301.10677},
  urldate = {2024-09-23},
  abstract = {Diffusion models have emerged as powerful generative models in the text-to-image domain. This paper studies their application as observation-to-action models for imitating human behaviour in sequential environments. Human behaviour is stochastic and multimodal, with structured correlations between action dimensions. Meanwhile, standard modelling choices in behaviour cloning are limited in their expressiveness and may introduce bias into the cloned policy. We begin by pointing out the limitations of these choices. We then propose that diffusion models are an excellent fit for imitating human behaviour, since they learn an expressive distribution over the joint action space. We introduce several innovations to make diffusion models suitable for sequential environments; designing suitable architectures, investigating the role of guidance, and developing reliable sampling strategies. Experimentally, diffusion models closely match human demonstrations in a simulated robotic control task and a modern 3D gaming environment.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  annotation = {Read\_Status: To Read\\
Read\_Status\_Date: 2024-12-09T00:54:35.247Z},
  file = {/Users/DAADAMS/Zotero/storage/ENJZLY3H/Pearce et al. - 2023 - Imitating Human Behaviour with Diffusion Models.pdf;/Users/DAADAMS/Zotero/storage/CACS6UCU/2301.html}
}

@article{pereiraLandmarkbasedApproachesGoal2020,
  title = {Landmark-Based Approaches for Goal Recognition as Planning},
  author = {Pereira, Ramon Fraga and Oren, Nir and Meneguzzi, Felipe},
  year = {2020},
  journal = {Artificial Intelligence},
  volume = {279},
  pages = {103217},
  publisher = {Elsevier},
  urldate = {2024-08-08},
  file = {/Users/DAADAMS/Zotero/storage/5A9YJUHW/S0004370219300013.html}
}

@article{pereiraTemporallyExtendedGoal2024,
  title = {Temporally Extended Goal Recognition in Fully Observable Non-Deterministic Domain Models},
  author = {Pereira, Ramon Fraga and Fuggitti, Francesco and Meneguzzi, Felipe and De Giacomo, Giuseppe},
  year = {2024},
  month = jan,
  journal = {Applied Intelligence},
  volume = {54},
  number = {1},
  pages = {470--489},
  issn = {1573-7497},
  doi = {10.1007/s10489-023-05087-1},
  urldate = {2024-05-07},
  abstract = {Goal Recognition is the task of discerning the intended goal that an agent aims to achieve, given a set of goal hypotheses, a domain model, and a sequence of observations (i.e., a sample of the plan executed in the environment). Existing approaches assume that goal hypotheses comprise a single conjunctive formula over a single final state and that the environment dynamics are deterministic, preventing the recognition of temporally extended goals in more complex settings. In this paper, we expand goal recognition to temporally extended goals in Fully Observable Non-Deterministic (fond) planning domain models, focusing on goals on finite traces expressed in Linear Temporal Logic (ltl\$\$\_f\$\$) and Pure-Past Linear Temporal Logic (ppltl). We develop the first approach capable of recognizing goals in such settings and evaluate it using different ltl\$\$\_f\$\$and ppltl goals over six fond planning domain models. Empirical results show that our approach is accurate in recognizing temporally extended goals in different recognition settings.},
  langid = {english},
  keywords = {Automated planning,Goal recognition,Linear temporal logic.,Non-deterministic planning},
  file = {/Users/DAADAMS/Zotero/storage/6Z94SKEP/Pereira et al. - 2024 - Temporally extended goal recognition in fully obse.pdf;/Users/DAADAMS/Zotero/storage/KYR67DAR/s10489-023-05087-1.html}
}

@article{pereraHMABSelfdrivingHierarchy2022,
  title = {{{HMAB}}: Self-Driving Hierarchy of Bandits for Integrated Physical Database Design Tuning},
  shorttitle = {{{HMAB}}},
  author = {Perera, R. Malinga and Oetomo, Bastian and Rubinstein, Benjamin I. P. and {Borovica-Gajic}, Renata},
  year = {2022},
  month = oct,
  journal = {Proceedings of the VLDB Endowment},
  volume = {16},
  number = {2},
  pages = {216--229},
  issn = {2150-8097},
  doi = {10.14778/3565816.3565824},
  urldate = {2024-03-15},
  abstract = {Effective physical database design tuning requires selection of several physical design structures (PDS), such as indices and materialised views, whose combination influences overall system performance in a non-linear manner. While the simplicity of combining the results of iterative searches for individual PDSs may be appealing, such a greedy approach may yield vastly suboptimal results compared to an integrated search. We propose a new self-driving approach (HMAB) based on hierarchical multi-armed bandit learners, which can work in an integrated space of multiple PDS while avoiding the full cost of combinatorial search. HMAB eschews the optimiser cost misestimates by direct performance observations through a strategic exploration, while carefully leveraging its knowledge to prune the less useful exploration paths. As an added advantage, HMAB comes with a provable guarantee on its expected performance. To the best of our knowledge, this is the first learned system to tune both indices and materialised views in an integrated manner. We find that our solution enjoys superior empirical performance relative to state-of-the-art commercial physical database design tools that search over the integrated space of materialised views and indices. Specifically, HMAB achieves up to 96\% performance gain over a state-of-the-art commercial physical database design tool when running industrial benchmarks.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/SDVFDAFJ/Perera et al. - 2022 - HMAB self-driving hierarchy of bandits for integr.pdf}
}

@article{pereraNoDBANo2023,
  title = {No {{DBA}}? {{No Regret}}! {{Multi-Armed Bandits}} for {{Index Tuning}} of {{Analytical}} and {{HTAP Workloads With Provable Guarantees}}},
  shorttitle = {No {{DBA}}?},
  author = {Perera, R. Malinga and Oetomo, Bastian and Rubinstein, Benjamin I. P. and {Borovica-Gajic}, Renata},
  year = {2023},
  month = dec,
  journal = {IEEE Transactions on Knowledge and Data Engineering},
  volume = {35},
  number = {12},
  pages = {12855--12872},
  issn = {1041-4347, 1558-2191, 2326-3865},
  doi = {10.1109/TKDE.2023.3271664},
  urldate = {2024-03-15},
  abstract = {Automating physical database design has remained a long-term interest in database research due to substantial performance gains afforded by optimised structures. Despite significant progress, a majority of today's commercial solutions are highly manual, requiring offline invocation by database administrators (DBAs). This status quo is untenable: identifying representative static workloads is no longer realistic; and physical design tools remain susceptible to the query optimiser's cost misestimates. Furthermore, modern application environments like hybrid transactional and analytical processing (HTAP) systems render analytical modelling next to impossible. We propose a self-driving approach to online index selection that does not depend on the DBA and query optimiser, and instead learns the benefits of viable structures through strategic exploration and direct performance observation. We view the problem as one of sequential decision making under uncertainty, specifically within the bandit learning setting. Multi-armed bandits balance exploration and exploitation to provably guarantee average performance that converges to policies that are optimal with perfect hindsight. Our comprehensive empirical evaluation against a state-of-the-art commercial tuning tool demonstrates up to 75\% speed-up in analytical processing environments and 59\% speed-up in HTAP environments. Lastly, our bandit framework outperforms a Monte Carlo tree search (MCTS)-based database optimiser, providing up to 24\% speed-up.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/ZP46SLBW/Perera et al. - 2023 - No DBA No Regret! Multi-Armed Bandits for Index T.pdf}
}

@inproceedings{perickComparisonDifferentSelection2012,
  title = {Comparison of Different Selection Strategies in {{Monte-Carlo Tree Search}} for the Game of {{Tron}}},
  booktitle = {2012 {{IEEE Conference}} on {{Computational Intelligence}} and {{Games}} ({{CIG}})},
  author = {Perick, Pierre and {St-Pierre}, David L. and Maes, Francis and Ernst, Damien},
  year = {2012},
  month = sep,
  pages = {242--249},
  publisher = {IEEE},
  address = {Granada, Spain},
  doi = {10.1109/CIG.2012.6374162},
  urldate = {2024-03-15},
  abstract = {Monte-Carlo Tree Search (MCTS) techniques are essentially known for their performance on turn-based games, such as Go, for which players have considerable time for choosing their moves. In this paper, we apply MCTS to the game of Tron, a simultaneous real-time two-player game. The fact that players have to react fast and that moves occur simultaneously creates an unusual setting for MCTS, in which classical selection policies such as UCB1 may be suboptimal. In this paper, we perform an empirical comparison of a wide range of selection policies for MCTS applied to Tron, with both deterministic policies (UCB1, UCB1-Tuned, UCB-V, UCBMinimal, OMC-Deterministic, MOSS) and stochastic policies ({\k o}ngreedy, EXP3, Thompson Sampling, OMC-Stochastic, PBBM). From the experiments, we observe that UCB1-Tuned has the best behavior shortly followed by UCB1. Even if UCB-Minimal is ranked fourth, this is a remarkable result for this recently introduced selection policy found through automatic discovery of good policies on generic multi-armed bandit problems. We also show that deterministic policies perform better than stochastic ones for this problem.},
  isbn = {978-1-4673-1194-6 978-1-4673-1193-9 978-1-4673-1192-2},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/L5Z7RHDK/Perick et al. - 2012 - Comparison of different selection strategies in Mo.pdf}
}

@article{persianiProbabilisticPlanLegibility2021,
  title = {Probabilistic Plan Legibility with Off-the-Shelf Planners},
  author = {Persiani, Michele and Hellstr{\"o}m, Thomas},
  year = {2021},
  urldate = {2024-08-12}
}

@article{personnazDoraExplorerExploring2021,
  title = {Dora the Explorer: {{Exploring Very Large Data}} with {{Interactive Deep Reinforcement Learning Authors}}' {{Copy}}},
  author = {Personnaz, Aur{\'e}lien and {Amer-Yahia}, Sihem and {Berti-Equille}, Laure and Fabricius, Maximilian and Subramanian, Srividya},
  year = {2021},
  abstract = {We demonstrate dora the explorer, a system that guides users in finding items of interest in a very large data set. dora the explorer provides users with the full spectrum of exploration modes and is driven by Data Familiarity or Curiosity, as well as User Interventions. dora the explorer is able to handle data and search scenario complexity, i.e., the difficulty to find scattered/clustered individual records in the data set, and user ability to express what s/he needs. dora the explorer relies on Deep Reinforcement Learning that combines intrinsic (curiosity) and extrinsic (familiarity) rewards. dora's main goal is to support scientific discovery from data. We describe the system architecture and illustrate it with three demonstration scenarios on a 2.6 million galaxies SDSS, a large sky survey data set1. A video of dora the explorer is available at https://bit.ly/dora-demo, the code https://github.com/apersonnaz/rl-guided-galaxy-exploration, and the application at https://bit.ly/dora-application.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/G45MDSWB/Personnaz et al. - 2021 - Dora the explorer Exploring Very Large Data with Interactive Deep Reinforcement Learning Authors' C.pdf}
}

@article{petamastersCostBasedGoalRecognition2017,
  title = {Cost-{{Based Goal Recognition}} for {{Path-Planning}}},
  author = {{Peta Masters} and Masters, Peta and {Sebastian Sardi{\~n}a} and Sardina, Sebastian},
  year = {2017},
  month = may,
  volume = {2},
  pages = {750--758},
  abstract = {Recent developments in plan recognition have established a method of identifying an agent's most probable plan or goal by use of a classical planner and an appeal to the principle of rational action. We examine this technique in the strict context of path-planning. We show that a simpler formula provides an identical result in less than half the time under all but one set of conditions, which we identify. Further, we show that the probability distribution based on this technique is observation-independent and present a revised formula that achieves goal-recognition by reference to the agent's current location only.},
  annotation = {MAG ID: 2620640742}
}

@inproceedings{phamTimeSequenceSummarization2009,
  title = {Time Sequence Summarization to Scale up Chronology-Dependent Applications},
  booktitle = {Proceedings of the 18th {{ACM}} Conference on {{Information}} and Knowledge Management},
  author = {Pham, Quang-Khai and Raschia, Guillaume and Mouaddib, Noureddine and {Saint-Paul}, Regis and Benatallah, Boualem},
  year = {2009},
  month = nov,
  pages = {1137--1146},
  publisher = {ACM},
  address = {Hong Kong China},
  doi = {10.1145/1645953.1646098},
  urldate = {2025-02-16},
  isbn = {978-1-60558-512-3},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/7LTGJ5AQ/Pham et al. - 2009 - Time sequence summarization to scale up chronology-dependent applications.pdf}
}

@phdthesis{phamTimeSequenceSummarization2010,
  title = {Time Sequence Summarization: Theory and Applications},
  shorttitle = {Time Sequence Summarization},
  author = {Pham, Quang-Khai},
  year = {2010},
  urldate = {2025-02-16},
  school = {Universit{\'e} de Nantes},
  file = {/Users/DAADAMS/Zotero/storage/FQSLQ9F2/Pham - 2010 - Time sequence summarization theory and applications.pdf}
}

@article{philippelencaAssociationRuleInterestingness2007,
  title = {Association {{Rule Interestingness Measures}}: {{Experimental}} and {{Theoretical Studies}}},
  author = {{Philippe Lenca} and Lenca, Philippe and {Beno{\^i}t Vaillant} and Vaillant, Beno{\^i}t and {Patrick Meyer} and Meyer, Patrick and {Patrick Meyer} and {Patrick Meyer} and {Patrick Meyer} and {St{\'e}phane Lallich} and Lallich, St{\'e}phane},
  year = {2007},
  month = jan,
  pages = {51--76},
  doi = {10.1007/978-3-540-44918-8_3},
  annotation = {MAG ID: 1524938675}
}

@article{piatetsky-shapiroDiscoveryAnalysisPresentation1991,
  title = {Discovery, {{Analysis}}, and {{Presentation}} of {{Strong Rules}}},
  author = {{Piatetsky-Shapiro}, G.},
  year = {1991},
  journal = {Knowledge Discovery in Data-bases},
  pages = {229--248},
  publisher = {AAAI Press},
  urldate = {2024-08-07},
  file = {/Users/DAADAMS/Zotero/storage/7QPT8ZX9/1570009749294099584.html}
}

@article{pimentelReviewNoveltyDetection2014,
  title = {A Review of Novelty Detection},
  author = {Pimentel, Marco A.F. and Clifton, David A. and Clifton, Lei and Tarassenko, Lionel},
  year = {2014},
  month = jun,
  journal = {Signal Processing},
  volume = {99},
  pages = {215--249},
  issn = {01651684},
  doi = {10.1016/j.sigpro.2013.12.026},
  urldate = {2024-05-07},
  abstract = {Novelty detection is the task of classifying test data that differ in some respect from the data that are available during training. This may be seen as ``one-class classification'', in which a model is constructed to describe ``normal'' training data. The novelty detection approach is typically used when the quantity of available ``abnormal'' data is insufficient to construct explicit models for non-normal classes. Application includes inference in datasets from critical systems, where the quantity of available normal data is very large, such that ``normality'' may be accurately modelled. In this review we aim to provide an updated and structured investigation of novelty detection research papers that have appeared in the machine learning literature during the last decade.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/RJJQTWTN/Pimentel et al. - 2014 - A review of novelty detection.pdf}
}

@article{pocoReverseEngineeringVisualizationsRecovering2017,
  title = {Reverse-{{Engineering Visualizations}}: {{Recovering Visual Encodings}} from {{Chart Images}}},
  shorttitle = {Reverse-{{Engineering Visualizations}}},
  author = {Poco, Jorge and Heer, Jeffrey},
  year = {2017},
  month = jun,
  journal = {Computer Graphics Forum},
  volume = {36},
  number = {3},
  pages = {353--363},
  issn = {0167-7055, 1467-8659},
  doi = {10.1111/cgf.13193},
  urldate = {2025-02-16},
  abstract = {Abstract             We investigate how to automatically recover visual encodings from a chart image, primarily using inferred text elements. We contribute an end-to-end pipeline which takes a bitmap image as input and returns a visual encoding specification as output. We present a text analysis pipeline which detects text elements in a chart, classifies their role (e.g., chart title, x-axis label, y-axis title, etc.), and recovers the text content using optical character recognition. We also train a Convolutional Neural Network for mark type classification. Using the identified text elements and graphical mark type, we can then infer the encoding specification of an input chart image. We evaluate our techniques on three chart corpora: a set of automatically labeled charts generated using Vega, charts from the Quartz news website, and charts extracted from academic papers. We demonstrate accurate automatic inference of text elements, mark types, and chart specifications across a variety of input chart types.},
  langid = {english}
}

@inproceedings{ponIScoreMeasuringInterestingness2007,
  title = {{{iScore}}: {{Measuring}} the {{Interestingness}} of {{Articles}} in a {{Limited User Environment}}},
  shorttitle = {{{iScore}}},
  booktitle = {2007 {{IEEE Symposium}} on {{Computational Intelligence}} and {{Data Mining}}},
  author = {Pon, Raymond K. and Cardenas, Alfonso F. and Buttler, David J. and Critchlow, Terence J.},
  year = {2007},
  pages = {354--361},
  publisher = {IEEE},
  address = {Honolulu, HI, USA},
  doi = {10.1109/CIDM.2007.368896},
  urldate = {2024-07-23},
  abstract = {Search engines, such as Google, assign scores to news articles based on their relevancy to a query. However, not all relevant articles for the query may be interesting to a user. For example, if the article is old or yields little new information, the article would be uninteresting. Relevancy scores do not take into account what makes an article interesting, which would vary from user to user. Although methods such as collaborative filtering have been shown to be effective in recommendation systems, in a limited user environment there are not enough users that would make collaborative filtering effective. We present a general framework for defining and measuring the ``interestingness'' of articles, incorporating user-feedback. We show 21\% improvement over traditional IR methods.},
  isbn = {978-1-4244-0705-7},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/F7IBYDQC/Pon et al. - 2007 - iScore Measuring the Interestingness of Articles .pdf}
}

@misc{ponsenComputingApproximateNash2014,
  title = {Computing {{Approximate Nash Equilibria}} and {{Robust Best-Responses Using Sampling}}},
  author = {Ponsen, Marc and {de Jong}, Steven and Lanctot, Marc},
  year = {2014},
  month = jan,
  eprint = {1401.4591},
  primaryclass = {cs},
  doi = {10.1613/jair.3402},
  urldate = {2024-03-15},
  abstract = {This article discusses two contributions to decision-making in complex partially observable stochastic games. First, we apply two state-of-the-art search techniques that use Monte-Carlo sampling to the task of approximating a Nash-Equilibrium (NE) in such games, namely Monte-Carlo Tree Search (MCTS) and Monte-Carlo Counterfactual Regret Minimization (MCCFR). MCTS has been proven to approximate a NE in perfect-information games. We show that the algorithm quickly finds a reasonably strong strategy (but not a NE) in a complex imperfect information game, i.e. Poker. MCCFR on the other hand has theoretical NE convergence guarantees in such a game. We apply MCCFR for the first time in Poker. Based on our experiments, we may conclude that MCTS is a valid approach if one wants to learn reasonably strong strategies fast, whereas MCCFR is the better choice if the quality of the strategy is most important. Our second contribution relates to the observation that a NE is not a best response against players that are not playing a NE. We present Monte-Carlo Restricted Nash Response (MCRNR), a sample-based algorithm for the computation of restricted Nash strategies. These are robust best-response strategies that (1) exploit non-NE opponents more than playing a NE and (2) are not (overly) exploitable by other strategies. We combine the advantages of two state-of-the-art algorithms, i.e. MCCFR and Restricted Nash Response (RNR). MCRNR samples only relevant parts of the game tree. We show that MCRNR learns quicker than standard RNR in smaller games. Also we show in Poker that MCRNR learns robust best-response strategies fast, and that these strategies exploit opponents more than playing a NE does.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Science and Game Theory},
  file = {/Users/DAADAMS/Zotero/storage/HX8Y67MM/Ponsen et al. - 2014 - Computing Approximate Nash Equilibria and Robust B.pdf;/Users/DAADAMS/Zotero/storage/PNQMC8CL/1401.html}
}

@inbook{pouzolsSummarizationAnalysisNetwork2011,
  title = {Summarization and {{Analysis}} of {{Network Traffic Flow Records}}},
  booktitle = {Mining and {{Control}} of {{Network Traffic}} by {{Computational Intelligence}}},
  author = {Pouzols, Federico Montesino and Lopez, Diego R. and Barros, Angel Barriga},
  year = {2011},
  volume = {342},
  pages = {147--189},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-18084-2_4},
  urldate = {2025-02-16},
  collaborator = {Pouzols, Federico Montesino and Lopez, Diego R. and Barros, Angel Barriga},
  isbn = {978-3-642-18083-5 978-3-642-18084-2},
  langid = {english}
}

@article{purichAdaptiveBenchmarkModeling2025,
  title = {An {{Adaptive Benchmark}} for {{Modeling User Exploration}} of {{Large Datasets}}},
  author = {Purich, Joanna and Wise, Anthony and Battle, Leilani},
  year = {2025},
  month = feb,
  journal = {Proceedings of the ACM on Management of Data},
  volume = {3},
  number = {1},
  pages = {1--24},
  issn = {2836-6573},
  doi = {10.1145/3709658},
  urldate = {2025-09-10},
  abstract = {In this paper, we present a new DBMS performance benchmark that can simulate user exploration with any specified dashboard design made of standard visualization and interaction components. The distinguishing feature of our SImulation-BAsed (or SIMBA) benchmark is its ability to model user analysis goals as a set of SQL queries to be generated through a valid sequence of user interactions, as well as measure the completion of analysis goals by testing for equivalence between the user's previous queries and their goal queries. In this way, the SIMBA benchmark can simulate how an analyst opportunistically searches for interesting insights at the beginning of an exploration session and eventually hones in on specific goals towards the end. To demonstrate the versatility of the SIMBA benchmark, we use it to test the performance of four DBMSs with six different dashboard specifications and compare our results with IDEBench. Our results show how goal-driven simulation can reveal gaps in DBMS performance missed by existing benchmarking methods and across a range of data exploration scenarios. CCS Concepts: {$\bullet$} Information systems {$\rightarrow$} Database performance evaluation; {$\bullet$} Human-centered computing {$\rightarrow$} Visualization.},
  copyright = {https://www.acm.org/publications/policies/copyright\_policy\#Background},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/CE9WKGTN/Purich et al. - 2025 - An Adaptive Benchmark for Modeling User Exploration of Large Datasets.pdf}
}

@inproceedings{qinRankingDesiredTuples2021,
  title = {Ranking {{Desired Tuples}} by {{Database Exploration}}},
  booktitle = {2021 {{IEEE}} 37th {{International Conference}} on {{Data Engineering}} ({{ICDE}})},
  author = {Qin, Xuedi and Chai, Chengliang and Luo, Yuyu and Zhao, Tianyu and Tang, Nan and Li, Guoliang and Feng, Jianhua and Yu, Xiang and Ouzzani, Mourad},
  year = {2021},
  month = apr,
  pages = {1973--1978},
  publisher = {IEEE},
  address = {Chania, Greece},
  doi = {10.1109/ICDE51399.2021.00186},
  urldate = {2025-02-05},
  abstract = {Database exploration -- the problem of finding and ranking desired tuples -- is important for data discovery and analysis. Precisely specifying SQL queries is not always feasible in practice, such as ``finding and ranking off-road cars based on a combination of Price, Make, Model, Age, and Mileage.'' -- not only due to the query complexity (e.g., which may have many if-thenelse, and, or and not logic), but also because the user typically does not have the knowledge of all data instances.},
  copyright = {https://doi.org/10.15223/policy-029},
  isbn = {978-1-7281-9184-3},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/UUWTM4IX/Qin et al. - 2021 - Ranking Desired Tuples by Database Exploration.pdf}
}

@article{r.malingapereraDBABanditsSelfdriving2020,
  title = {{{DBA}} Bandits: {{Self-driving}} Index Tuning under Ad-Hoc, Analytical Workloads with Safety Guarantees},
  author = {{R. Malinga Perera} and Perera, R. Malinga and {Bastian Oetomo} and Oetomo, Bastian and {Benjamin I. P. Rubinstein} and Rubinstein, Benjamin I. P. and {Renata Borovica-Gaji{\'c}} and {Borovica-Gajic}, Renata},
  year = {2020},
  journal = {arXiv: Databases},
  abstract = {Automating physical database design has remained a long-term interest in database research due to substantial performance gains afforded by optimised structures. Despite significant progress, a majority of today's commercial solutions are highly manual, requiring offline invocation by database administrators (DBAs) who are expected to identify and supply representative training workloads. Unfortunately, the latest advancements like query stores provide only limited support for dynamic environments. This status quo is untenable: identifying representative static workloads is no longer realistic; and physical design tools remain susceptible to the query optimiser's cost misestimates (stemming from unrealistic assumptions such as attribute value independence and uniformity of data distribution). We propose a self-driving approach to online index selection that eschews the DBA and query optimiser, and instead learns the benefits of viable structures through strategic exploration and direct performance observation. We view the problem as one of sequential decision making under uncertainty, specifically within the bandit learning setting. Multi-armed bandits balance exploration and exploitation to provably guarantee average performance that converges to a fixed policy that is optimal with perfect hindsight. Our comprehensive empirical results demonstrate up to 75\% speed-up on shifting and ad-hoc workloads and 28\% speed-up on static workloads compared against a state-of-the-art commercial tuning tool.},
  annotation = {MAG ID: 3094056345}
}

@article{r.malingapereraNoDBANo2021,
  title = {No {{DBA}}? {{No}} Regret! {{Multi-armed}} Bandits for Index Tuning of Analytical and {{HTAP}} Workloads with Provable Guarantees},
  author = {{R. Malinga Perera} and Perera, R. Malinga and {Bastian Oetomo} and Oetomo, Bastian and {Benjamin I. P. Rubinstein} and Rubinstein, Benjamin I. P. and {Renata Borovica-Gaji{\'c}} and {Borovica-Gajic}, Renata},
  year = {2021},
  month = aug,
  journal = {arXiv: Databases},
  abstract = {Automating physical database design has remained a long-term interest in database research due to substantial performance gains afforded by optimised structures. Despite significant progress, a majority of today's commercial solutions are highly manual, requiring offline invocation by database administrators (DBAs) who are expected to identify and supply representative training workloads. Even the latest advancements like query stores provide only limited support for dynamic environments. This status quo is untenable: identifying representative static workloads is no longer realistic; and physical design tools remain susceptible to the query optimiser's cost misestimates. Furthermore, modern application environments such as hybrid transactional and analytical processing (HTAP) systems render analytical modelling next to impossible.  We propose a self-driving approach to online index selection that eschews the DBA and query optimiser, and instead learns the benefits of viable structures through strategic exploration and direct performance observation. We view the problem as one of sequential decision making under uncertainty, specifically within the bandit learning setting. Multi-armed bandits balance exploration and exploitation to provably guarantee average performance that converges to policies that are optimal with perfect hindsight. Our comprehensive empirical evaluation against a state-of-the-art commercial tuning tool demonstrates up to 75\% speed-up on shifting and ad-hoc workloads and up to 28\% speed-up on static workloads in analytical processing environments. In HTAP environments, our solution provides up to 59\% speed-up on shifting and 51\% speed-up on static workloads. Furthermore, our bandit framework outperforms deep reinforcement learning (RL) in terms of convergence speed and performance volatility (providing up to 58\% speed-up).},
  annotation = {MAG ID: 3194367797}
}

@article{raddickTenYearsSkyserver2014,
  title = {Ten Years of Skyserver i: {{Tracking}} Web and Sql e-Science Usage},
  shorttitle = {Ten Years of Skyserver i},
  author = {Raddick, M. Jordan and Thakar, Ani R. and Szalay, Alexander S. and Santos, Rafael DC},
  year = {2014},
  journal = {Computing in Science \& Engineering},
  volume = {16},
  number = {4},
  pages = {22--31},
  publisher = {IEEE},
  urldate = {2024-11-05},
  file = {/Users/DAADAMS/Zotero/storage/IKI55Y8F/Raddick et al. - 2014 - Ten years of skyserver i Tracking web and sql e-science usage.pdf}
}

@article{radevIntroductionSpecialIssue2002,
  title = {Introduction to the Special Issue on Summarization},
  author = {Radev, Dragomir and Hovy, Eduard and McKeown, Kathleen},
  year = {2002},
  journal = {Computational linguistics},
  volume = {28},
  number = {4},
  pages = {399--408},
  urldate = {2025-02-16},
  file = {/Users/DAADAMS/Zotero/storage/58ZS64B5/Radev et al. - 2002 - Introduction to the special issue on summarization.pdf}
}

@article{raghupathiBigDataAnalytics2014,
  title = {Big Data Analytics in Healthcare: Promise and Potential},
  shorttitle = {Big Data Analytics in Healthcare},
  author = {Raghupathi, Wullianallur and Raghupathi, Viju},
  year = {2014},
  month = feb,
  journal = {Health Information Science and Systems},
  volume = {2},
  number = {1},
  pages = {3},
  issn = {2047-2501},
  doi = {10.1186/2047-2501-2-3},
  urldate = {2024-08-07},
  abstract = {To describe the promise and potential of big data analytics in healthcare.},
  langid = {english},
  keywords = {Analytics,Big data,Framework,Hadoop,Healthcare,Methodology},
  file = {/Users/DAADAMS/Zotero/storage/YXXEKI6Q/Raghupathi and Raghupathi - 2014 - Big data analytics in healthcare promise and pote.pdf}
}

@inproceedings{ramirezPlanRecognitionPlanning2009,
  title = {Plan Recognition as Planning},
  booktitle = {Proceedings of the 21st International Joint Conference on {{Artifical}} Intelligence. {{Morgan Kaufmann Publishers Inc}}},
  author = {Ram{\i}rez, Miquel and Geffner, Hector},
  year = {2009},
  pages = {1778--1783},
  publisher = {Citeseer},
  urldate = {2024-08-08},
  file = {/Users/DAADAMS/Zotero/storage/PYCX8PGJ/Ramırez and Geffner - 2009 - Plan recognition as planning.pdf}
}

@inproceedings{ramirezProbabilisticPlanRecognition2010,
  title = {Probabilistic Plan Recognition Using Off-the-Shelf Classical Planners},
  booktitle = {Proceedings of the {{AAAI}} Conference on Artificial Intelligence},
  author = {Ram{\'i}rez, Miguel and Geffner, Hector},
  year = {2010},
  volume = {24},
  pages = {1121--1126},
  urldate = {2024-08-08},
  file = {/Users/DAADAMS/Zotero/storage/U54MAMH6/Ramírez and Geffner - 2010 - Probabilistic plan recognition using off-the-shelf.pdf}
}

@article{ramonfragapereiraLandmarkBasedHeuristicsGoal2017,
  title = {Landmark-{{Based Heuristics}} for {{Goal Recognition}}},
  author = {{Ramon Fraga Pereira} and Pereira, Ramon Fraga and {Nir Oren} and Oren, Nir and {Felipe Meneguzzi} and Meneguzzi, Felipe},
  year = {2017},
  month = aug,
  pages = {3622--3628},
  abstract = {Automated planning can be used to efficiently recognize goals and plans from partial or full observed action sequences. In this paper, we propose goal recognition heuristics that rely on information from planning landmarks - facts or actions that must occur if a plan is to achieve a goal when starting from some initial state. We develop two such heuristics: the first estimates goal completion by considering the ratio between achieved and extracted landmarks of a candidate goal, while the second takes into account how unique each landmark is among landmarks for all candidate goals. We empirically evaluate these heuristics over both standard goal/plan recognition problems, and a set of very large problems. We show that our heuristics can recognize goals more accurately, and run orders of magnitude faster, than the current state-of-the-art.},
  annotation = {MAG ID: 2557530746}
}

@article{reuthmirskyIntroductionSymbolicPlan2021,
  title = {Introduction to {{Symbolic Plan}} and {{Goal Recognition}}},
  author = {{Reuth Mirsky} and Mirsky, Reuth and {Sarah Keren} and Keren, Sarah and {Christopher W. Geib} and Geib, Christopher W.},
  year = {2021},
  journal = {Synthesis Lectures on Artificial Intelligence and Machine Learning},
  doi = {10.2200/s01062ed1v01y202012aim047},
  abstract = {Abstract Plan recognition, activity recognition, and goal recognition all involve making inferences about other actors based on observations of their interactions with the environment and other age...},
  annotation = {MAG ID: 3125984269}
}

@article{robertj.hildermanApplyingObjectiveInterestingness2000,
  title = {Applying {{Objective Interestingness Measures}} in {{Data Mining Systems}}},
  author = {{Robert J. Hilderman} and Hilderman, Robert J. and {Howard J. Hamilton} and Hamilton, Howard J.},
  year = {2000},
  month = sep,
  journal = {European Conference on Principles of Data Mining and Knowledge Discovery},
  pages = {432--439},
  doi = {10.1007/3-540-45372-5_47},
  abstract = {One of the most important steps in any knowledge discovery task is the interpretation and evaluation of discovered patterns. To address this problem, various techniques, such as the chi-square test for independence, have been suggested to reduce the number of patterns presented to the user and to focus attention on those that are truly statistically significant. However, when mining a large database, the number of patterns discovered can remain large even after adjusting significance thresholds to eliminate spurious patterns. What is needed, then, is an effective measure to further assist in the interpretation and evaluation step that ranks the interestingness of the remaining patterns prior to presenting them to the user. In this paper, we describe a two-step process for ranking the interestingness of discovered patterns that utilizes the chi-square test for independence in the first step and objective measures of interestingness in the second step. We show how this two-step process can be applied to ranking characterized/generalized association rules and data cubes.},
  annotation = {MAG ID: 1541719409\\
S2ID: 0f64ccff1c1c8ca3a2cd08245305f68a23249c2a}
}

@article{robertj.hildermanEvaluationInterestingnessMeasures2001,
  title = {Evaluation of {{Interestingness Measures}} for {{Ranking Discovered Knowledge}}},
  author = {{Robert J. Hilderman} and Hilderman, Robert J. and {Howard J. Hamilton} and Hamilton, Howard J.},
  year = {2001},
  month = apr,
  pages = {247--259},
  doi = {10.1007/3-540-45357-1_28},
  abstract = {When mining a large database, the number of patterns discovered can easily exceed the capabilities of a human user to identify interesting results. To address this problem, various techniques have been suggested to reduce and/or order the patterns prior to presenting them to the user. In this paper, our focus is on ranking summaries generated from a single dataset, where attributes can be generalized in many different ways and to many levels of granularity according to taxonomic hierarchies. We theoretically and empirically evaluate thirteen diversity measures used as heuristic measures of interestingness for ranking summaries generated from databases. The thirteen diversity measures have previously been utilized in various disciplines, such as information theory, statistics, ecology, and economics. We describe five principles that any measure must satisfy to be considered useful for ranking summaries. Theoretical results show that only four of the thirteen diversity measures satisfy all of the principles. We then analyze the distribution of the index values generated by each of the thirteen diversity measures. Empirical results, obtained using synthetic data, show that the distribution of index values generated tend to be highly skewed about the mean, median, and middle index values. The objective of this work is to gain some insight into the behaviour that can be expected from each of the measures in practice.},
  annotation = {MAG ID: 2119254562}
}

@article{robertj.hildermanHeuristicMeasuresInterestingness1999,
  title = {Heuristic {{Measures}} of {{Interestingness}}},
  author = {{Robert J. Hilderman} and Hilderman, Robert J. and {Howard J. Hamilton} and Hamilton, Howard J.},
  year = {1999},
  month = sep,
  pages = {232--241},
  doi = {10.1007/978-3-540-48247-5_25},
  abstract = {The tuples in a generalized relation (i.e., a summary generated from a database) are unique, and therefore, can be considered to be a population with a structure that can be described by some probability distribution. In this paper, we present and empirically compare sixteen heuristic measures that evaluate the structure of a summary to assign a single real-valued index that represents its interestingness relative to other summaries generated from the same database. The heuristics are based upon well-known measures of diversity, dispersion, dominance, and inequality used in several areas of the physical, social, ecological, management, information, and computer sciences. Their use for ranking summaries generated from databases is a new application area. All sixteen heuristics rank less complex summaries (i.e., those with few tuples and/or few non-ANY attributes) as most interesting. We demonstrate that for sample data sets, the order in which some of the measures rank summaries is highly correlated.},
  annotation = {MAG ID: 1547598598}
}

@article{robertj.hildermanInterestingnessFramework2001,
  title = {An {{Interestingness Framework}}},
  author = {{Robert J. Hilderman} and Hilderman, Robert J. and {Howard J. Hamilton} and Hamilton, Howard J.},
  year = {2001},
  month = jan,
  pages = {47--97},
  doi = {10.1007/978-1-4757-3283-2_5},
  abstract = {In this chapter, we develop a theory of interestingness for the ranking of summaries generated from databases. The theory provides the foundation for an intuitive understanding of the term ``interestingness'' when used within this context.},
  annotation = {MAG ID: 112137159},
  file = {/Users/DAADAMS/Zotero/storage/L6YUM9KY/Robert J. Hilderman et al. - 2001 - An Interestingness Framework.pdf}
}

@article{robertj.hildermanKnowledgeDiscoveryInterestingness2012,
  title = {Knowledge {{Discovery}} and {{Interestingness Measures}}: {{A Survey}}},
  author = {{Robert J. Hilderman} and Hilderman, Robert J.},
  year = {2012},
  month = jan,
  abstract = {Knowledge discovery in databases, also known as data mining, is the efficient discovery of previously unknown, valid, novel, potentially useful, and understandable patterns in large databases. It encompasses many different techniques and algorithms which differ in the kinds of data that can be analyzed and the form of knowledge representation used to convey the discovered knowledge. An important problem in the area of data mining is the development of effective measures of interestingness for ranking the discovered knowledge. In this report, we provide a general overview of the more successful and widely known data mining techniques and algorithms, and survey seventeen interestingness measures from the literature that have been successfully employed in data mining applications.},
  annotation = {MAG ID: 48920344}
}

@article{robertj.hildermanKnowledgeDiscoveryMeasures2001,
  title = {Knowledge Discovery and Measures of Interest},
  author = {{Robert J. Hilderman} and Hilderman, Robert J. and {Howard J. Hamilton} and Hamilton, Howard J.},
  year = {2001},
  month = jan,
  abstract = {List of Figures. List of Tables. Preface. Acknowledgments. 1. Introduction. 2. Background and Related Work. 3. A Data Mining Technique. 4. Heuristic Measures of Interestingness. 5. An Interestingness Framework. 6. Experimental Analyses. 7. Conclusion. Appendices. Index.},
  annotation = {MAG ID: 1484126642}
}

@article{robertj.hildermanMeasuringInterestingnessDiscovered2003,
  title = {Measuring the Interestingness of Discovered Knowledge: {{A}} Principled Approach},
  author = {{Robert J. Hilderman} and Hilderman, Robert J. and {Howard J. Hamilton} and Hamilton, Howard J.},
  year = {2003},
  month = sep,
  volume = {7},
  number = {4},
  pages = {347--382},
  doi = {10.3233/ida-2003-7406},
  abstract = {When mining a large database, the number of patterns discovered can easily exceed the capabilities of a human user to identify interesting results. To address this problem, various techniques have been suggested to reduce and/or order the patterns prior to presenting them to the user. In this paper, our focus is on ranking summaries generated from a single dataset, where attributes can be generalized in many different ways and to many levels of granularity according to taxonomic hierarchies. We theoretically and empirically evaluate twelve diversity measures used as heuristic measures of interestingness for ranking summaries generated from databases. The twelve diversity measures have previously been utilized in various disciplines, such as information theory, statistics, ecology, and economics. We describe five principles that any measure must satisfy to be considered useful for ranking summaries. Theoretical results show that the proposed principles define a partial order on the ranked summaries in most cases, and in some cases, define a total order. Theoretical results also show that seven of the twelve diversity measures satisfy all of the five principles. We empirically analyze the rank order of the summaries as determined by each of the twelve measures. These empirical results show that the measures tend to rank the less complex summaries as most interesting. Finally, we analyze the distribution of the index values generated by each of the twelve diversity measures. Empirical results, obtained using synthetic data, show that the distribution of index values generated tend to be highly skewed about the mean, median, and middle index values. Finally, we demonstrate a technique, based upon our principles, for visualizing the relative interestingness of summaries. The objective of this work is to gain some insight into the behaviour that can be expected from our principled approach in practice.},
  annotation = {MAG ID: 1935986945}
}

@article{robertj.hildermanParallelKnowledgeDiscovery1997,
  title = {Parallel {{Knowledge Discovery Using Domain Generalization Graphs}}},
  author = {{Robert J. Hilderman} and Hilderman, Robert J. and {Howard J. Hamilton} and Hamilton, Howard J. and {Robert J. Kowalchuk} and Kowalchuk, Robert J. and {Nick Cercone} and Cercone, Nick},
  year = {1997},
  month = jun,
  pages = {25--35},
  doi = {10.1007/3-540-63223-9_103},
  abstract = {Multi-Attribute Generalization is an algorithm for attribute-oriented induction in relational databases using domain generalization graphs. Each node in a domain generalization graph represents a different way of summarizing the domain values associated with an attribute. When generalizing a set of attributes, we show how a serial implementation of the algorithm generates all possible combinations of nodes from the domain generalization graphs associated with the attributes, resulting in the presentation of all possible generalized relations for the set. We then show how the inherent parallelism in domain generalization graphs is exploited by a parallel implementation of the algorithm. Significant speedups were obtained using our approach when large discovery tasks were partitioned across multiple processors. The results of our work enable a database analyst to quickly and efficiently analyze the contents of a relational database from many different perspectives.},
  annotation = {MAG ID: 1518023234}
}

@article{robertj.hildermanRankingInterestingnessSummaries1999,
  title = {Ranking the {{Interestingness}} of {{Summaries}} from {{Data Mining Systems}}},
  author = {{Robert J. Hilderman} and Hilderman, Robert J. and {Howard J. Hamilton} and Hamilton, Howard J. and {Brock Barber} and Barber, Brock},
  year = {1999},
  month = may,
  pages = {100--106},
  abstract = {We study data rn{\textasciitilde}rdng where the task is description by summarization, the representation language is generalized relations, the evaluation criteria are based on heuristic measures of interestingness, and the method for searching is the Multi-Attribute Generalization algorithm for domain generalization graphs. We present and empirically compare four heuristics for ranking the interestingness of generalized relations (or summaries). The measures are based on common measures of the diversity of a population, statistical variance, the Simpson index, and the Shannon index. All four measures rank less complex summaries (i.e., those with few tuples and/or non-ANY attributes) as most interesting. Highly ranked summaries provide a reasonable starting point for fixrther analysis of discovered knowledge.},
  annotation = {MAG ID: 2120773034}
}

@article{rogergranadaHybridActivityPlan2017,
  title = {Hybrid {{Activity}} and {{Plan Recognition}} for {{Video Streams}}},
  author = {{Roger Granada} and Granada, Roger and {Felipe Meneguzzi} and Meneguzzi, Felipe and {Rodrigo C. Barros} and Barros, Rodrigo C. and {Juarez Monteiro} and Monteiro, Juarez and {Duncan D. Ruiz} and Ruiz, Duncan D. and {Ramon Fraga Pereira} and Pereira, Ramon Fraga},
  year = {2017},
  month = jan,
  annotation = {MAG ID: 2902726747}
}

@article{rokhNewEvolutionaryOptimization2024,
  title = {A New Evolutionary Optimization Based on Multi-Objective Firefly Algorithm for Mining Numerical Association Rules},
  author = {Rokh, Babak and Mirvaziri, Hamid and Olyaee, MohammadHossein},
  year = {2024},
  month = may,
  journal = {Soft Computing},
  volume = {28},
  number = {9},
  pages = {6879--6892},
  issn = {1433-7479},
  doi = {10.1007/s00500-023-09558-y},
  urldate = {2025-01-07},
  abstract = {Association rule mining (ARM) is a widely used technique in data mining for pattern discovery. However, association rule mining in numerical data poses a considerable challenge. In recent years, researchers have turned to optimization-based approaches as a potential solution. One particular area of interest in numerical association rules mining (NARM) is controlling the length of itemset intervals. In this paper, we propose a novel evolutionary algorithm based on the multi-objective firefly algorithm for efficiently mining numerical association rules (MOFNAR). MOFNAR utilizes Balance, square of cosine (SOC) and comprehensibility as objectives of evolutionary algorithm to assess rules and achieve a rule set that is both simple and accurate. We introduce the Balance measure to effectively control the intervals of numerical itemsets and eliminate misleading rules. Furthermore, we suggest a penalty approach, and the crowding-distance method is employed to maintain high diversity. Experimental results on five well-known datasets show the effectiveness of our method in discovering a simple rule set with high confidence that covers a significant percentage of the data.},
  langid = {english},
  keywords = {Artificial Intelligence,Data mining,Firefly algorithm,Multi-objective evolutionary algorithm,Numerical association rule mining},
  file = {/Users/DAADAMS/Zotero/storage/5N39R2NP/Rokh et al. - 2024 - A new evolutionary optimization based on multi-objective firefly algorithm for mining numerical asso.pdf}
}

@article{romanslowinAnalysisMonotonicityProperties2008,
  title = {Analysis of Monotonicity Properties of New Normalized Rule Interestingness Measures},
  author = {{Roman S{\l}owi{\'n}} and S{\l}owi{\'n}, Roman and {Salvatore Greco} and Greco, Salvatore and {Izabela Szcz{\c e}ch} and Szcz{\k e}ch, Izabela},
  year = {2008},
  month = jan,
  abstract = {The paper considers interestingness measures for evaluation of relevance and usefulness of ``if..., then...'' rules induced from data. We propose a way to normalize three popular measures: rule interest function of Piatetsky-Shapiro, gain measure of Fukuda et al. and dependency factor used by Popper and Pawlak. The normalization transforms the measures to the interval [-1, 1], whose bounds correspond to maximal Bayesian confirmation and disconfirmation, respectively, and thus make them more meaningful. The new normalized measures are analyzed with respect to a valuable property M of monotonic dependency on the number of objects in the dataset satisfying or not the premise or the conclusion of the rule. The obtained results have a practical application as they lead to efficiency gains while searching for the best rules.},
  annotation = {MAG ID: 4254789}
}

@book{rosenkrantzIntroductionProbabilityStatistics1997,
  title = {Introduction to Probability and Statistics for Scientists and Engineers},
  author = {Rosenkrantz, Walter A.},
  year = {1997},
  volume = {206},
  publisher = {McGraw-Hill New York},
  urldate = {2024-08-12}
}

@inproceedings{santosLPbasedApproachGoal2021,
  title = {An {{LP-based}} Approach for Goal Recognition as Planning},
  booktitle = {Proceedings of the {{AAAI Conference}} on {{Artificial Intelligence}}},
  author = {Santos, Lu{\'i}sa RA and Meneguzzi, Felipe and Pereira, Ramon Fraga and Pereira, Andr{\'e} Grahl},
  year = {2021},
  volume = {35},
  pages = {11939--11946},
  urldate = {2024-08-12},
  file = {/Users/DAADAMS/Zotero/storage/G6D6QLBC/Santos et al. - 2021 - An LP-based approach for goal recognition as plann.pdf}
}

@incollection{sarawagiDiscoverydrivenExplorationOLAP1998,
  title = {Discovery-Driven Exploration of {{OLAP}} Data Cubes},
  booktitle = {Advances in {{Database Technology}} --- {{EDBT}}'98},
  author = {Sarawagi, Sunita and Agrawal, Rakesh and Megiddo, Nimrod},
  editor = {Goos, Gerhard and Hartmanis, Juris and Van Leeuwen, Jan and Schek, Hans-J{\"o}rg and Alonso, Gustavo and Saltor, Felix and Ramos, Isidro},
  year = {1998},
  volume = {1377},
  pages = {168--182},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/BFb0100984},
  urldate = {2025-02-13},
  isbn = {978-3-540-64264-0 978-3-540-69709-1},
  file = {/Users/DAADAMS/Zotero/storage/IH2CA9SA/Sarawagi et al. - 1998 - Discovery-driven exploration of OLAP data cubes.pdf}
}

@inproceedings{sarawagiUseradaptiveExplorationMultidimensional2000,
  title = {User-Adaptive Exploration of Multidimensional Data},
  booktitle = {{{VLDB}}},
  author = {Sarawagi, Sunita},
  year = {2000},
  pages = {307--316},
  publisher = {ResearchGate GmbH},
  urldate = {2025-02-13},
  file = {/Users/DAADAMS/Zotero/storage/WL3QY2AT/Sarawagi - 2000 - User-adaptive exploration of multidimensional data.pdf}
}

@inproceedings{satheIntelligentRollupsMultidimensional2001,
  title = {Intelligent Rollups in Multidimensional {{OLAP}} Data},
  booktitle = {{{VLDB}}},
  author = {Sathe, Gayatri and Sarawagi, Sunita},
  year = {2001},
  pages = {307--316},
  publisher = {ResearchGate GmbH},
  urldate = {2025-02-13},
  file = {/Users/DAADAMS/Zotero/storage/TVPGGRWR/Sathe and Sarawagi - 2001 - Intelligent rollups in multidimensional OLAP data.pdf}
}

@article{satyanarayanVegaliteGrammarInteractive2016,
  title = {Vega-Lite: {{A}} Grammar of Interactive Graphics},
  shorttitle = {Vega-Lite},
  author = {Satyanarayan, Arvind and Moritz, Dominik and Wongsuphasawat, Kanit and Heer, Jeffrey},
  year = {2016},
  journal = {IEEE transactions on visualization and computer graphics},
  volume = {23},
  number = {1},
  pages = {341--350},
  publisher = {IEEE},
  urldate = {2025-02-16},
  file = {/Users/DAADAMS/Zotero/storage/FJQUCJWQ/Satyanarayan et al. - 2016 - Vega-lite A grammar of interactive graphics.pdf}
}

@incollection{scalaIntervalbasedRelaxationGeneral2016,
  title = {Interval-Based Relaxation for General Numeric Planning},
  booktitle = {{{ECAI}} 2016},
  author = {Scala, Enrico and Haslum, Patrik and Thi{\'e}baux, Sylvie and Ramirez, Miquel},
  year = {2016},
  pages = {655--663},
  publisher = {IOS Press},
  urldate = {2025-01-09},
  annotation = {Read\_Status: In Progress\\
Read\_Status\_Date: 2025-01-09T01:54:12.003Z},
  file = {/Users/DAADAMS/Zotero/storage/GD9BZWDD/Scala et al. - 2016 - Interval-based relaxation for general numeric planning.pdf}
}

@article{schutzMeasurementIncomeInequality1951,
  title = {On the Measurement of Income Inequality},
  author = {Schutz, Robert R.},
  year = {1951},
  journal = {The American Economic Review},
  volume = {41},
  number = {1},
  eprint = {1815968},
  eprinttype = {jstor},
  pages = {107--122},
  publisher = {JSTOR},
  urldate = {2024-08-12},
  file = {/Users/DAADAMS/Zotero/storage/FK67JN8A/sfxlcl41.html}
}

@article{seleznovaGuidedExplorationUser2020,
  title = {Guided Exploration of User Groups},
  author = {Seleznova, Mariia and {Omidvar-Tehrani}, Behrooz and {Amer-Yahia}, Sihem and Simon, Eric},
  year = {2020},
  month = may,
  journal = {Proceedings of the VLDB Endowment},
  volume = {13},
  number = {9},
  pages = {1469--1482},
  issn = {2150-8097},
  doi = {10.14778/3397230.3397242},
  urldate = {2024-12-08},
  abstract = {Finding a set of users of interest serves several applications in behavioral analytics. Often times, identifying users requires to explore the data and gradually choose potential targets. This is a special case of Exploratory Data Analysis (EDA), an iterative and tedious process. In this paper, we formalize and solve the problem of guided exploration of user groups whose purpose is to find target users. We model exploration as an iterative decision-making process, where an agent is shown a set of groups, chooses users from those groups, and selects the best action to move to the next step. To solve our problem, we apply reinforcement learning to discover an efficient exploration strategy from a simulated agent experience, and propose to use the learned strategy to recommend an exploration policy that can be applied to the same task for any dataset. Our framework accepts a wide class of exploration actions and does not need to gather exploration logs. Our experiments show that the agent naturally captures manual exploration by human analysts, and succeeds to learn an interpretable and transferable exploration policy.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/JAFZE724/Seleznova et al. - 2020 - Guided exploration of user groups.pdf}
}

@inproceedings{sellamMeetCharlesBig2013,
  title = {Meet {{Charles}}, Big Data Query Advisor.},
  booktitle = {{{CIDR}}},
  author = {Sellam, Thibault and Kersten, Martin L.},
  year = {2013},
  volume = {13},
  pages = {1--1},
  urldate = {2024-08-13},
  file = {/Users/DAADAMS/Zotero/storage/V2FGXA53/Sellam and Kersten - 2013 - Meet Charles, big data query advisor..pdf}
}

@article{setiawanFunctionInterpolationLearned2020,
  title = {Function {{Interpolation}} for {{Learned Index Structures}}},
  author = {Setiawan, Naufal Fikri and Rubinstein, Benjamin I. P. and {Borovica-Gajic}, Renata},
  year = {2020},
  month = jan,
  abstract = {Range indexes such as B-trees are widely recognised as effective data structures for enabling fast retrieval of records by the query key. While such classical indexes offer optimal worst-case guarantees, recent research suggests that average-case performance might be improved by alternative machine learning-based models such as deep neural networks. This paper explores an alternative approach by modelling the task as one of function approximation via interpolation between compressed subsets of keys. We explore the Chebyshev and Bernstein polynomial bases, and demonstrate substantial benefits over deep neural networks. In particular, our proposed function interpolation models exhibit memory footprint two orders of magnitude smaller compared to neural network models, and 30--40\% accuracy improvement over neural networks trained with the same amount of time, while keeping query time generally on-par with neural network models.},
  annotation = {MAG ID: 3041204249}
}

@article{shannonMathematicalTheoryCommunication1948,
  title = {A Mathematical Theory of Communication},
  author = {Shannon, Claude Elwood},
  year = {1948},
  journal = {The Bell system technical journal},
  volume = {27},
  number = {3},
  pages = {379--423},
  publisher = {Nokia Bell Labs},
  urldate = {2024-08-12},
  file = {/Users/DAADAMS/Zotero/storage/NPHIZA4W/Shannon - 1948 - A mathematical theory of communication.pdf}
}

@article{shawkatOptimizedFPgrowthAlgorithm2022,
  title = {An Optimized {{FP-growth}} Algorithm for Discovery of Association Rules},
  author = {Shawkat, Mai and Badawi, Mahmoud and {El-ghamrawy}, Sally and Arnous, Reham and {El-desoky}, Ali},
  year = {2022},
  month = mar,
  journal = {The Journal of Supercomputing},
  volume = {78},
  number = {4},
  pages = {5479--5506},
  issn = {1573-0484},
  doi = {10.1007/s11227-021-04066-y},
  urldate = {2025-01-07},
  abstract = {Association rule mining (ARM) is a data mining technique to discover interesting associations between datasets. The frequent pattern-growth (FP-growth) is an effective ARM algorithm for compressing information in the tree structure. However, it tends to suffer from the performance gap when processing large databases because of its mining procedure. This study presents a modified FP-growth (MFP-growth) algorithm to enhance the efficiency of the FP-growth by obviating the need for recurrent creation of conditional subtrees. The proposed algorithm uses a header table configuration to reduce the complexity of the whole frequent pattern tree. Four experimental series are conducted using different benchmark datasets to analyze the operating efficiency of the proposed MFP-growth algorithm compared with state-of-the-art machine learning algorithms in terms of runtime, memory consumption, and the effectiveness of generated rules. The experimental results confirm the superiority of the MFP-growth algorithm, which focuses on its potential implementations in various contexts.},
  langid = {english},
  keywords = {Association rule mining,FP-tree. FP-growth,Frequent itemset mining,Particle swarm optimization},
  file = {/Users/DAADAMS/Zotero/storage/QAQBC7WL/Shawkat et al. - 2022 - An optimized FP-growth algorithm for discovery of association rules.pdf}
}

@inproceedings{shvoActiveGoalRecognition2020,
  title = {Active Goal Recognition},
  booktitle = {Proceedings of the {{AAAI Conference}} on {{Artificial Intelligence}}},
  author = {Shvo, Maayan and McIlraith, Sheila A.},
  year = {2020},
  volume = {34},
  pages = {9957--9966},
  urldate = {2024-08-12},
  file = {/Users/DAADAMS/Zotero/storage/Z9TETABX/Shvo and McIlraith - 2020 - Active goal recognition.pdf}
}

@inproceedings{sidirourgosSciborqScientificData2011,
  title = {Sciborq: {{Scientific}} Data Management with Bounds on Runtime and Quality},
  shorttitle = {Sciborq},
  booktitle = {Proceedings of the Biennial {{Conference}} on {{Innovative Data Systems Research}}},
  author = {Sidirourgos, Lefteris and Boncz, P. A. and Kersten, M. L.},
  year = {2011},
  urldate = {2024-08-13},
  file = {/Users/DAADAMS/Zotero/storage/55GEZ4LN/Sidirourgos et al. - 2011 - Sciborq Scientific data management with bounds on.pdf}
}

@article{simeonMiningInterestingContrast2012,
  title = {Mining {{Interesting Contrast Sets}}},
  author = {Simeon, Mondelle and Hilderman, Robert J. and Hamilton, Howard J. and S, Canada},
  year = {2012},
  month = jan,
  abstract = {Contrast set mining has been developed as a data mining task which aims at discerning differences across groups. These groups can be patients, organizations, molecules, and even time-lines. A valid contrast set is a conjunction of attribute-value pairs that differ significantly in their di stri- bution across groups. The search for valid contrast sets can produce a prohibitively large number of results which must be further filtered in order to be examined by a domain expert and have decisions enacted from them. In this paper, we introduce the notion of the minimum support ratio threshold to measure the ratio of maximum and minimum support across groups. We propose a contrast set mining technique to discover maximal valid contrast sets which meet a minimum support ratio threshold. We also introduce five interestingness mea sures and demonstrate how they can be used to rank contrast sets. Our experiments on real datasets demonstrate the efficiency and effectiveness of our approach, and the interestingness of the contrast sets discovered.},
  annotation = {MAG ID: 1762480188}
}

@misc{singhDBExplorerExploratorySearch2016,
  title = {{{DBExplorer}}: {{Exploratory Search}} in {{Databases}}},
  shorttitle = {{{DBExplorer}}},
  author = {Singh, Manish and Cafarella, Michael and Jagadish, Hosagrahar Visvesvar},
  year = {2016},
  publisher = {OpenProceedings.org},
  doi = {10.5441/002/EDBT.2016.11},
  urldate = {2025-02-05},
  abstract = {A traditional relational database can evaluate complex queries but requires users to precisely express their information need. But users often do not know what information is available in a database, and hence cannot correctly express their information need. Traditional databases do not provide convenient means for users to gain familiarity with the data.},
  langid = {english},
  keywords = {Database Technology},
  file = {/Users/DAADAMS/Zotero/storage/X3BZQHEH/Singh et al. - 2016 - DBExplorer Exploratory Search in Databases.pdf}
}

@inproceedings{singhDBExplorerExploratorySearch2016a,
  title = {{{DBExplorer}}: {{Exploratory Search}} in {{Databases}}.},
  shorttitle = {{{DBExplorer}}},
  booktitle = {{{EDBT}}},
  author = {Singh, Manish and Cafarella, Michael J. and Jagadish, H. V.},
  year = {2016},
  pages = {89--100},
  urldate = {2025-02-05},
  file = {/Users/DAADAMS/Zotero/storage/RPCQTX2Q/Singh et al. - 2016 - DBExplorer Exploratory Search in Databases..pdf}
}

@inproceedings{singhDBExplorerExploratorySearch2016b,
  title = {{{DBExplorer}}: {{Exploratory Search}} in {{Databases}}.},
  shorttitle = {{{DBExplorer}}},
  booktitle = {{{EDBT}}},
  author = {Singh, Manish and Cafarella, Michael J. and Jagadish, H. V.},
  year = {2016},
  pages = {89--100},
  urldate = {2025-02-13},
  file = {/Users/DAADAMS/Zotero/storage/FX9HZFX6/Singh et al. - 2016 - DBExplorer Exploratory Search in Databases..pdf}
}

@inproceedings{sohrabiPlanRecognitionPlanning2016,
  title = {Plan {{Recognition}} as {{Planning Revisited}}.},
  booktitle = {{{IJCAI}}},
  author = {Sohrabi, Shirin and Riabov, Anton V. and Udrea, Octavian},
  year = {2016},
  pages = {3258--3264},
  publisher = {New York, NY},
  urldate = {2024-08-08},
  file = {/Users/DAADAMS/Zotero/storage/KEZNNXIK/Sohrabi et al. - 2016 - Plan Recognition as Planning Revisited..pdf}
}

@inproceedings{solankiSurveyAssociationRule2015,
  title = {A {{Survey}} on {{Association Rule Mining}}},
  booktitle = {2015 {{Fifth International Conference}} on {{Advanced Computing}} \& {{Communication Technologies}}},
  author = {Solanki, Surbhi K. and Patel, Jalpa T.},
  year = {2015},
  month = feb,
  pages = {212--216},
  issn = {2327-0659},
  doi = {10.1109/ACCT.2015.69},
  urldate = {2024-12-23},
  abstract = {Task of extracting useful and interesting knowledge from large data is called data mining. It has many aspects like clustering, classification, association mining, outlier detection, regression etc. Among them association rule mining is one of the important aspect for data mining. Best example of association rule mining is market-basket analysis. Applications of association rule mining are stock analysis, web log mining, medical diagnosis, customer market analysis bioinformatics etc. In past, many algorithms were developed by researchers for Boolean and Fuzzy association rule mining such as Apriori, FP-tree, Fuzzy FP-tree etc. We are discussing them in detail in later section of this paper.},
  keywords = {Algorithm design and analysis,Apriori,Association Rule Mining,Association rules,Data Mining,FP-tree,Fuzzy FP-tree,Itemsets,Partitioning algorithms,Pragmatics},
  file = {/Users/DAADAMS/Zotero/storage/EKREMI7R/Solanki and Patel - 2015 - A Survey on Association Rule Mining.pdf;/Users/DAADAMS/Zotero/storage/XMXSQS9X/7079081.html}
}

@misc{somechPredictingWhatInteresting2019,
  title = {Predicting "{{What}} Is {{Interesting}}" by {{Mining Interactive-Data-Analysis Session Logs}}},
  author = {Somech, Amit and Milo, Tova and Ozeri, Chai},
  year = {2019},
  publisher = {OpenProceedings.org},
  doi = {10.5441/002/EDBT.2019.42},
  urldate = {2024-12-02},
  abstract = {Assessing the interestingness of data analysis actions has been the subject of extensive previous work, and a multitude of interestingness measures have been devised, each capturing a different facet of the broad concept. While such measures are a core component in many analysis platforms (e.g., for ranking association rules, recommending visualizations, and query formulation), choosing the most adequate measure for a specific analysis task or an application domain is known to be a difficult task.},
  langid = {english},
  keywords = {Database Technology},
  file = {/Users/DAADAMS/Zotero/storage/44A2R567/Somech et al. - 2019 - Predicting What is Interesting by Mining Interactive-Data-Analysis Session Logs.pdf}
}

@inproceedings{songDiversitydrivenExtensibleHierarchical2019,
  title = {Diversity-Driven Extensible Hierarchical Reinforcement Learning},
  booktitle = {Proceedings of the {{AAAI}} Conference on Artificial Intelligence},
  author = {Song, Yuhang and Wang, Jianyi and Lukasiewicz, Thomas and Xu, Zhenghua and Xu, Mai},
  year = {2019},
  volume = {33},
  pages = {4992--4999},
  urldate = {2024-09-03},
  file = {/Users/DAADAMS/Zotero/storage/8WQI2KNR/Song et al. - 2019 - Diversity-driven extensible hierarchical reinforcement learning.pdf}
}

@inproceedings{srikantMiningQuantitativeAssociation1996,
  title = {Mining Quantitative Association Rules in Large Relational Tables},
  booktitle = {Proceedings of the 1996 {{ACM SIGMOD}} International Conference on {{Management}} of Data  - {{SIGMOD}} '96},
  author = {Srikant, Ramakrishnan and Agrawal, Rakesh},
  year = {1996},
  pages = {1--12},
  publisher = {ACM Press},
  address = {Montreal, Quebec, Canada},
  doi = {10.1145/233269.233311},
  urldate = {2025-02-16},
  isbn = {978-0-89791-794-0},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/QPSFJZDY/Srikant and Agrawal - 1996 - Mining quantitative association rules in large relational tables.pdf}
}

@incollection{stonebrakerOneSizeFits2018,
  title = {"{{One}} Size Fits All": An Idea Whose Time Has Come and Gone},
  shorttitle = {"{{One}} Size Fits All"},
  booktitle = {Making {{Databases Work}}: The {{Pragmatic Wisdom}} of {{Michael Stonebraker}}},
  author = {Stonebraker, Michael and {\c C}etintemel, U{\^g}ur},
  year = {2018},
  month = dec,
  volume = {22},
  pages = {441--462},
  publisher = {{Association for Computing Machinery and Morgan \& Claypool}},
  urldate = {2024-08-06},
  abstract = {The last 25 years of commercial DBMS development can be summed up in a single phrase: "One size fits all". This phrase refers to the fact that the traditional DBMS architecture (originally designed and optimized for business data processing) has been used to support many data-centric applications with widely varying characteristics and requirements.In this paper, we argue that this concept is no longer applicable to the database market, and that the commercial world will fracture into a collection of independent database engines, some of which may be unified by a common front-end parser. We use examples from the stream-processing market and the data-warehouse market to bolster our claims. We also briefly discuss other markets for which the traditional architecture is a poor fit and argue for a critical rethinking of the current factoring of systems services into products.},
  isbn = {978-1-947487-19-2}
}

@inproceedings{svoreEnhancingSingledocumentSummarization2007,
  title = {Enhancing Single-Document Summarization by Combining {{RankNet}} and Third-Party Sources},
  booktitle = {Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning ({{EMNLP-CoNLL}})},
  author = {Svore, Krysta and Vanderwende, Lucy and Burges, Christopher},
  year = {2007},
  pages = {448--457},
  urldate = {2025-02-16},
  file = {/Users/DAADAMS/Zotero/storage/AA7P7KV2/Svore et al. - 2007 - Enhancing single-document summarization by combining RankNet and third-party sources.pdf}
}

@article{t.boultUnifyingFrameworkFormal2021,
  title = {Towards a {{Unifying Framework}} for {{Formal Theories}} of {{Novelty}}},
  author = {{T. Boult} and {Przemyslaw A. Grabowicz} and {D. Prijatelj} and {Roni Stern} and {L. Holder} and {J. Alspector} and {Mohsen Jafarzadeh} and {T. Ahmad} and {A. Dhamija} and {Chunchun Li} and {S. Cruz} and {Abhinav Shrivastava} and {Carl Vondrick} and {W. Scheirer}},
  year = {2021},
  journal = {AAAI Conference on Artificial Intelligence},
  doi = {10.1609/aaai.v35i17.17766},
  abstract = {Managing inputs that are novel, unknown, or out-of-distribution is critical as an agent moves from the lab to the open world. Novelty-related problems include being tolerant to novel perturbations of the normal input, detecting when the input includes novel items, and adapting to novel inputs. While significant research has been undertaken in these areas, a noticeable gap exists in the lack of a formalized definition of novelty that transcends problem domains. As a team of researchers spanning multiple research groups and different domains, we have seen, first hand, the difficulties that arise from ill-specified novelty problems, as well as inconsistent definitions and terminology. Therefore, we present the first unified framework for formal theories of novelty and use the framework to formally define a family of novelty types. Our framework can be applied across a wide range of domains, from symbolic AI to reinforcement learning, and beyond to open world image recognition. Thus, it can be used to help kick-start new research efforts and accelerate ongoing work on these important novelty-related problems.},
  annotation = {S2ID: 357411070c0779e6c29db11532e690db2bb8a64c}
}

@article{takenouchiPATSQLEfficientSynthesis2021,
  title = {{{PATSQL}}: {{Efficient Synthesis}} of {{SQL Queries}} from {{Example Tables}} with {{Quick Inference}} of {{Projected Columns}}},
  shorttitle = {{{PATSQL}}},
  author = {Takenouchi, Keita and Ishio, Takashi and Okada, Joji and Sakata, Yuji},
  year = {2021},
  month = jul,
  journal = {Proceedings of the VLDB Endowment},
  volume = {14},
  number = {11},
  eprint = {2010.05807},
  primaryclass = {cs},
  pages = {1937--1949},
  issn = {2150-8097},
  doi = {10.14778/3476249.3476253},
  urldate = {2025-08-28},
  abstract = {SQL is one of the most popular tools for data analysis, and it is now used by an increasing number of users without having expertise in databases. Several studies have proposed programming-by-example approaches to help such non-experts to write correct SQL queries. While existing methods support a variety of SQL features such as aggregation and nested query, they suffer a significant increase in computational cost as the scale of example tables increases. In this paper, we propose an efficient algorithm utilizing properties known in relational algebra to synthesize SQL queries from input and output tables. Our key insight is that a projection operator in a program sketch can be lifted above other operators by applying transformation rules in relational algebra, while preserving the semantics of the program. This enables a quick inference of appropriate columns in the projection operator, which is an essential component in synthesis but causes combinatorial explosions in prior work. We also introduce a novel form of constraints and its top-down propagation mechanism for efficient sketch completion. We implemented this algorithm in our tool PATSQL and evaluated it on 226 queries from prior benchmarks and Kaggle's tutorials. As a result, PATSQL solved 68\% of the benchmarks and found 89\% of the solutions within a second. Our tool is available at https://naist-se.github.io/patsql/.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Databases,Computer Science - Programming Languages,Computer Science - Software Engineering},
  file = {/Users/DAADAMS/Zotero/storage/DCG8VFHA/Takenouchi et al. - 2021 - PATSQL Efficient Synthesis of SQL Queries from Example Tables with Quick Inference of Projected Col.pdf}
}

@inproceedings{takMonteCarloTree2014,
  title = {Monte {{Carlo Tree Search}} Variants for Simultaneous Move Games},
  booktitle = {2014 {{IEEE Conference}} on {{Computational Intelligence}} and {{Games}}},
  author = {Tak, Mandy J. W. and Lanctot, Marc and Winands, Mark H. M.},
  year = {2014},
  month = aug,
  pages = {1--8},
  publisher = {IEEE},
  address = {Dortmund, Germany},
  doi = {10.1109/CIG.2014.6932889},
  urldate = {2024-03-15},
  abstract = {Monte Carlo Tree Search (MCTS) is a widely-used technique for game-tree search in sequential turn-based games. The extension to simultaneous move games, where all players choose moves simultaneously each turn, is non-trivial due to the complexity of this class of games. In this paper, we describe simultaneous move MCTS and analyze its application in a set of nine disparate simultaneous move games. We use several possible variants, Decoupled UCT, Sequential UCT, Exp3, and Regret Matching. These variants include both deterministic and stochastic selection strategies and we characterize the game-play performance of each one. The results indicate that the relative performance of each variant depends strongly on the game and the opponent, and that parameter tuning can also not be as straightforward as the purely sequential case. Overall, Decoupled UCT performs best despite its theoretical shortcomings.},
  isbn = {978-1-4799-3547-5},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/G7QZR7PW/Tak et al. - 2014 - Monte Carlo Tree Search variants for simultaneous .pdf}
}

@article{tanReverseEngineeringAggregation2017,
  title = {Reverse Engineering Aggregation Queries},
  author = {Tan, Wei Chit and Zhang, Meihui and Elmeleegy, Hazem and Srivastava, Divesh},
  year = {2017},
  month = aug,
  journal = {Proceedings of the VLDB Endowment},
  volume = {10},
  number = {11},
  pages = {1394--1405},
  issn = {2150-8097},
  doi = {10.14778/3137628.3137648},
  urldate = {2025-08-28},
  abstract = {Query reverse engineering seeks to re-generate the SQL query that produced a given query output table from a given database. In this paper, we solve this problem for OLAP queries with group-by and aggregation. We develop a novel three-phase algorithm named REGAL 1 for this problem. First, based on a lattice graph structure, we identify a set of group-by candidates for the desired query. Second, we apply a set of aggregation constraints that are derived from the properties of aggregate operators at both the table-level and the group-level to discover candidate combinations of group-by columns and aggregations that are consistent with the given query output table. Finally, we find a multi-dimensional filter, i.e., a conjunction of selection predicates over the base table attributes, that is needed to generate the exact query output table. We conduct an extensive experimental study over the TPC-H dataset to demonstrate the effectiveness and efficiency of our proposal.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/G9JYP7C4/Tan et al. - 2017 - Reverse engineering aggregation queries.pdf}
}

@article{telikaniSurveyEvolutionaryComputation2020,
  title = {A Survey of Evolutionary Computation for Association Rule Mining},
  author = {Telikani, Akbar and Gandomi, Amir H. and Shahbahrami, Asadollah},
  year = {2020},
  journal = {Information Sciences},
  volume = {524},
  pages = {318--352},
  publisher = {Elsevier},
  urldate = {2024-12-23},
  file = {/Users/DAADAMS/Zotero/storage/5I4UCHHQ/Telikani et al. - 2020 - A survey of evolutionary computation for association rule mining.pdf;/Users/DAADAMS/Zotero/storage/BPCRJH6P/scholar.html}
}

@book{theilEconomicsInformationTheory1967,
  title = {Economics and Information Theory. --},
  author = {Theil, Henri},
  year = {1967},
  publisher = {Amsterdam : North-Holland Pub. Co.; Chicago : Rand McNally},
  urldate = {2024-08-12},
  abstract = {xxii, 488 p. ; 23 cm. --; Bibliography: p. 423-427},
  collaborator = {{Internet Archive}},
  langid = {english},
  keywords = {Information theory in economics}
}

@inproceedings{thilinaIntruderDetectionUsing2016,
  title = {Intruder {{Detection Using Deep Learning}} and {{Association Rule Mining}}},
  booktitle = {2016 {{IEEE International Conference}} on {{Computer}} and {{Information Technology}} ({{CIT}})},
  author = {Thilina, Asantha and Attanayake, Shakthi and Samarakoon, Sacith and Nawodya, Dahami and Rupasinghe, Lakmal and Pathirage, Nadith and Edirisinghe, Tharindu and Krishnadeva, Kesavan},
  year = {2016},
  month = dec,
  pages = {615--620},
  doi = {10.1109/CIT.2016.69},
  urldate = {2024-12-23},
  abstract = {With the upsurge of internet popularity, nowadays there are millions of online transactions that are being processed per minute thus increasing the possibilities of intruder attacks over the recent times. There have been various intruder detection techniques such as using traditional machine learning based algorithms. These algorithms were widely used to identify and prevent intruder activities in the recent past. Furthermore, multilayer neural networks[5] were also used in this regard to perform the detection. Hence multi-layer neural networks inherit fundamental drawbacks due to its inability to perform training due the problems such as overfitting, etc. In contrast, deep learning algorithms were introduced to overcome these issues effectively. We propose a novel framework to perform intruder detection and analysis using deep learning nets and association rule mining. We utilize a recurrent network to predict intruder activities and FP-Growth to perform the analysis. Our results show the effectiveness of our framework in detail.},
  keywords = {Algorithm design and analysis,Association rule mining,Data mining,Deeplearning,FPGrowth,Intruder detection,Machine learning,Machine learning algorithms,Pattern Recognition,Recurrent neural networks,Recurrent Neural Networks,Training},
  file = {/Users/DAADAMS/Zotero/storage/9GUUCCFE/Thilina et al. - 2016 - Intruder Detection Using Deep Learning and Association Rule Mining.pdf;/Users/DAADAMS/Zotero/storage/URYG62KH/7876395.html}
}

@article{tuUnicornUnifiedMultitasking2023,
  title = {Unicorn: {{A Unified Multi-tasking Model}} for {{Supporting Matching Tasks}} in {{Data Integration}}},
  shorttitle = {Unicorn},
  author = {Tu, Jianhong and Fan, Ju and Tang, Nan and Wang, Peng and Li, Guoliang and Du, Xiaoyong and Jia, Xiaofeng and Gao, Song},
  year = {2023},
  month = may,
  journal = {Proceedings of the ACM on Management of Data},
  volume = {1},
  number = {1},
  pages = {1--26},
  issn = {2836-6573},
  doi = {10.1145/3588938},
  urldate = {2025-08-01},
  abstract = {Data matching, which decides whether two data elements (e.g., string, tuple, column, or knowledge graph entity) are the ``same'' (a.k.a. a match), is a key concept in data integration. The widely used practice is to build task-specific or even dataset-specific solutions, which are hard to generalize and disable the opportunities of knowledge sharing that can be learned from di↵erent datasets and multiple tasks. In this paper, we propose Unicorn, a unified model for generally supporting common data matching tasks. Building such a unified model is challenging due to heterogeneous formats of input data elements and various matching semantics of multiple tasks. To address the challenges, Unicorn employs one generic Encoder that converts any pair of data elements (a, b) into a learned representation, and uses a Matcher, which is a binary classifier, to decide whether a matches b. To align matching semantics of multiple tasks, Unicorn adopts a mixture-of-experts model that enhances the learned representation into a better representation. We conduct extensive experiments using 20 datasets on 7 well-studied data matching tasks, and find that our unified model can achieve better performance on most tasks and on average, compared with the state-of-the-art specific models trained for ad-hoc tasks and datasets separately. Moreover, Unicorn can also well serve new matching tasks with zero-shot learning.},
  copyright = {https://www.acm.org/publications/policies/copyright\_policy\#Background},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/48VYB329/Tu et al. - 2023 - Unicorn A Unified Multi-tasking Model for Supporting Matching Tasks in Data Integration.pdf}
}

@article{ugurcetintemelQuerySteeringInteractive2013,
  title = {Query {{Steering}} for {{Interactive Data Exploration}}},
  author = {{U{\v g}ur {\c C}etintemel} and Cetintemel, Ugur and {Mitch Cherniack} and Cherniack, Mitch and {Justin A. DeBrabant} and DeBrabant, Justin and {Yanlei Diao} and Diao, Yanlei and {Kyriaki Dimitriadou} and Dimitriadou, Kyriaki and {Alexander Kalinin} and {Alexander Kalinin} and Kalinin, Alexander and {Olga Papaemmanouil} and Papaemmanouil, Olga and {Stanley B. Zdonik} and Zdonik, Stanley B.},
  year = {2013},
  month = jan,
  abstract = {{\textpm} ABSTRACT Traditional DBSMs are suited for applications in which the structure, meaning and contents of the database, as well as the questions to be asked are already well understood. There is, however, a class of applications that we will collectively refer to as Interactive Data Exploration (IDE) applications, in which this is not the case. IDE is a key ingredient of a diverse set of discovery-oriented applications we are dealing with, including ones from scientific computing, financial analysis, evidence-based medicine, and genomics. The need for effective IDE will only increase as data are being collected at an unprecedented rate. IDE is fundamentally a multi-step, non-linear process with imprecise end-goals. For example, data-driven scientific discovery through IDE often requires non-expert users to iteratively interact with the system to make sense of and to identify interesting patterns and relationships in large, amorphous data sets. To make the most of the increasingly available complex and big data sets, users would need an "expert assistant" who would be able to effectively and efficiently guide them through the data space. Having a human assistant is not only expensive but also unrealistic. Thus, it is essential that we automate this task. We propose database systems be augmented with an automated "database navigator" (DBNav) service that assists as a "tour guide" to facilitate IDE. Just like a car navigation system that offers advice on the routes to be taken and display points of interest, DBNav would similarly steer the user towards interesting "trajectories" through the data, while highlighting relevant features. Like any good tour guide, DBNav should consider many kinds of information; in particular, it should be sensitive to a user's goals and interests, as well as common navigation patterns that applications exhibit. We sketch a general data navigation framework and discuss some specific components and approaches that we believe belong to any such system.},
  annotation = {MAG ID: 2294895571}
}

@misc{urbanEfficientLearnedQuery2024,
  title = {Efficient {{Learned Query Execution}} over {{Text}} and {{Tables}} [{{Technical Report}}]},
  author = {Urban, Matthias and Binnig, Carsten},
  year = {2024},
  month = oct,
  number = {arXiv:2410.22522},
  eprint = {2410.22522},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2410.22522},
  urldate = {2025-09-08},
  abstract = {In this paper, we present ELEET, a novel execution engine that allows one to seamlessly query and process text as a first-class citizen along with tables. To enable such a seamless integration of text and tables, ELEET leverages learned multi-modal operators (MMOps) such as joins and unions that seamlessly combine structured with unstructured textual data. While large language models (LLM) such as GPT-4 are interesting candidates to enable such learned multimodal operations, we deliberately do not follow this trend to enable MMOps, since it would result in high overhead at query runtime. Instead, to enable MMOps, ELEET comes with a more efficient small language model (SLM) that is targeted to extract structured data from text. Thanks to our novel architecture and pre-training procedure, the ELEET-model enables high-accuracy extraction with low overheads. In our evaluation, we compare query execution based on ELEET to baselines leveraging LLMs such as GPT-4 and show that ELEET can speed up multi-modal queries over tables and text by up to 575{\texttimes} without sacrificing accuracy.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Databases},
  file = {/Users/DAADAMS/Zotero/storage/U63NAKI5/Urban and Binnig - 2024 - Efficient Learned Query Execution over Text and Tables [Technical Report].pdf}
}

@inproceedings{vartakSeedbEfficientDatadriven2015,
  title = {Seedb: {{Efficient}} Data-Driven Visualization Recommendations to Support Visual Analytics},
  shorttitle = {Seedb},
  booktitle = {Proceedings of the {{VLDB Endowment International Conference}} on {{Very Large Data Bases}}},
  author = {Vartak, Manasi and Rahman, Sajjadur and Madden, Samuel and Parameswaran, Aditya and Polyzotis, Neoklis},
  year = {2015},
  volume = {8},
  pages = {2182},
  publisher = {NIH Public Access},
  urldate = {2025-02-13},
  file = {/Users/DAADAMS/Zotero/storage/XS7ZYQIB/PMC4714568.html}
}

@misc{veredHeuristicOnlineGoal2017,
  title = {Heuristic {{Online Goal Recognition}} in {{Continuous Domains}}},
  author = {Vered, Mor and Kaminka, Gal A.},
  year = {2017},
  month = sep,
  number = {arXiv:1709.09839},
  eprint = {1709.09839},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1709.09839},
  urldate = {2025-09-04},
  abstract = {Goal recognition is the problem of inferring the goal of an agent, based on its observed actions. An inspiring approach---plan recognition by planning (PRP)---uses off-the-shelf planners to dynamically generate plans for given goals, eliminating the need for the traditional plan library. However, existing PRP formulation is inherently inefficient in online recognition, and cannot be used with motion planners for continuous spaces. In this paper, we utilize a different PRP formulation which allows for online goal recognition, and for application in continuous spaces. We present an online recognition algorithm, where two heuristic decision points may be used to improve run-time significantly over existing work. We specify heuristics for continuous domains, prove guarantees on their use, and empirically evaluate the algorithm over n hundreds of experiments in both a 3D navigational environment and a cooperative robotic team task.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence},
  file = {/Users/DAADAMS/Zotero/storage/4UKIZCKB/Vered and Kaminka - 2017 - Heuristic Online Goal Recognition in Continuous Domains.pdf;/Users/DAADAMS/Zotero/storage/HAQGGCMP/Vered and Kaminka - 2017 - Heuristic Online Goal Recognition in Continuous Domains.pdf;/Users/DAADAMS/Zotero/storage/VKPMRZ4N/1709.html}
}

@inproceedings{veredOnlineRecognitionNavigation2017,
  title = {Online Recognition of Navigation Goals through Goal Mirroring},
  booktitle = {International {{Conference}} on {{Autonomous Agents}} and {{Multiagent Systems}} 2017},
  author = {Vered, Mor and Kaminka, Gal A.},
  year = {2017},
  pages = {1748--1750},
  publisher = {Association for Computing Machinery (ACM)},
  urldate = {2024-08-12},
  file = {/Users/DAADAMS/Zotero/storage/6YQ9T73Y/Vered and Kaminka - 2017 - Online recognition of navigation goals through goa.pdf}
}

@article{vivekanandanNovelWayCompute2024,
  title = {A Novel Way to Compute Association Rules},
  author = {Vivekanandan, S. J. and Gunasekaran, G.},
  year = {2024},
  month = jan,
  journal = {International Journal of System Assurance Engineering and Management},
  volume = {15},
  number = {1},
  pages = {98--109},
  issn = {0976-4348},
  doi = {10.1007/s13198-022-01676-4},
  urldate = {2025-01-07},
  abstract = {Association Rule mining is the prime booming field among researchers. Apriori algorithm is a prime algorithm to compute association rules. Apriori algorithm considers only frequent itemsets and it neglects the non-frequent itemsets. In real-time scenarios, Non-frequent itemsets also have the chance to give more utility. Utility mining is a newish form of data mining study topic that focuses solely on high utility itemsets computed from utility values. To overcome this problem, we proposed an approach that incorporates both frequent and utility values called the Novel Utility Frequent Apriori algorithm. This approach considered both frequent itemsets together with non-frequent itemsets. Utility computed for both frequent itemsets and rare itemsets. Finally, it categorized the itemsets based on utility value and frequent value like High-Profit High Frequency, High-Profit Rare Frequency, Low-Profit High Frequency, and Low-Profit Rare Frequency itemsets. Repeated transactions were handled efficiently by our proposed method. We experimented with different datasets by using python, The Novel Utility Frequent Apriori method surpasses the classic Apriori algorithm in terms of time i.e. average rate of time reduction was 63\% with first experiment and 82\% with second experiment. We found that our approach is effective in categories of itemsets and also this approach will be useful in E-Commerce to make more profit, Medical field to discover new diseases and Banking sector to discover fraud activities.},
  langid = {english},
  keywords = {Apriori,Frequent itemsets,High utility itemsets (HUI),Minimum support (min_sup),Minimum utility (min_util),Utility mining},
  file = {/Users/DAADAMS/Zotero/storage/QXRUW9QX/Vivekanandan and Gunasekaran - 2024 - A novel way to compute association rules.pdf}
}

@inproceedings{wangDeepGraphMutual2022,
  title = {Deep {{Graph Mutual Learning}} for~{{Cross-domain Recommendation}}},
  booktitle = {Database {{Systems}} for {{Advanced Applications}}},
  author = {Wang, Yifan and Li, Yongkang and Li, Shuai and Song, Weiping and Fan, Jiangke and Gao, Shan and Ma, Ling and Cheng, Bing and Cai, Xunliang and Wang, Sheng and Zhang, Ming},
  editor = {Bhattacharya, Arnab and Lee Mong Li, Janice and Agrawal, Divyakant and Reddy, P. Krishna and Mohania, Mukesh and Mondal, Anirban and Goyal, Vikram and Uday Kiran, Rage},
  year = {2022},
  pages = {298--305},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-031-00126-0_22},
  abstract = {Cross-domain recommender systems have been increasingly important for helping users find satisfying items from different domains. However, existing approaches mostly share/map user features among different domains to transfer the knowledge. In fact, user-item interactions can be formulated as a bipartite graph and knowledge transferring through the graph is a more explicit way. Meanwhile, these approaches mostly focus on capturing users' common interests, overlooking domain-specific preferences. In this paper, we propose a novel Deep Graph Mutual Learning framework (DGML) for cross-domain recommendation. In particular, we first separately construct domain-shared and domain-specific interaction graphs, and develop a parallel graph neural network to extract user preference in corresponding graph. Then the mutual learning procedure uses extracted preferences to form a more comprehensive user preference. Our extensive experiments on two real-world datasets demonstrate significant improvements over state-of-the-art approaches.},
  isbn = {978-3-031-00126-0},
  langid = {english},
  keywords = {Collaborative filtering,Cross-domain recommendation,Graph neural networks,Mutual learning},
  file = {/Users/DAADAMS/Zotero/storage/KT3W97HU/Wang et al. - 2022 - Deep Graph Mutual Learning for Cross-domain Recommendation.pdf}
}

@article{wangLeveragingDynamicHeterogeneous2024,
  title = {Leveraging {{Dynamic}} and {{Heterogeneous Workload Knowledge}} to {{Boost}} the {{Performance}} of {{Index Advisors}}},
  author = {Wang, Zijia and Liu, Haoran and Lin, Chen and Bao, Zhifeng and Li, Guoliang and Wang, Tianqing},
  year = {2024},
  month = mar,
  journal = {Proceedings of the VLDB Endowment},
  volume = {17},
  number = {7},
  pages = {1642--1654},
  issn = {2150-8097},
  doi = {10.14778/3654621.3654631},
  urldate = {2025-02-24},
  abstract = {Current index advisors often struggle to balance efficiency and effectiveness when dealing with workload shifts. This arises from ignorance of the continual similarity and distant variety in workloads. This paper proposes a novel learning-based index advisor called BALANCE, which boosts indexing performance by leveraging knowledge obtained from dynamic and heterogeneous workloads. Our approach consists of three components. First, we build separate Lightweight Index Advisors (LIAs) on sequential chunks of similar workloads, where each LIA is trained with a small batch of workloads drawn from the chunk, and it provides direct index recommendations for all workloads in the same chunk. Second, we perform a policy transfer mechanism by adapting the LIA's index selection strategy from historical knowledge, substantially reducing the training overhead. Third, we employ a self-supervised contrastive learning method to provide an off-the-shelf workload representation, enabling the LIA to generate more accurate index recommendations. Extensive experiments across various benchmarks demonstrate that BALANCE improves the state-of-the-art learning-based index advisor, SWIRL, by 10.03\% while reducing training overhead by 35.70\% on average.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/MQAH32QJ/Wang et al. - 2024 - Leveraging Dynamic and Heterogeneous Workload Knowledge to Boost the Performance of Index Advisors.pdf}
}

@misc{wangLGEQRELearningGuided2023,
  title = {{{LGEQRE}}: {{Learning Guided Enumerative Synthesis}} for {{Query Reverse Engineering}}},
  shorttitle = {{{LGEQRE}}},
  author = {Wang, Huixian and Dou, Quansheng and Tang, Huanling and Pan, Hao and Zhang, Shun},
  year = {2023},
  month = sep,
  publisher = {In Review},
  doi = {10.21203/rs.3.rs-3320857/v1},
  urldate = {2025-08-28},
  abstract = {To address the problem of users' lack of SQL query writing skills, Query Reverse Engineering (QRE) was proposed, where the goal of QRE is to generate a SQL statement based on a given database and query output table. SQUARES is one of the state-of-the-art models in the field, which enumerates constraint-compliant programs using a solver-based enumerator, and since the Solver randomly enumerates candidate programs, SQUARES synthesis is not very efficient. In this paper, we propose LGEQRE based on SQUARES, a learning-based approach to guide the enumeration of candidate programs. LGEQRE predicts the operators be required by neural network, sorts and deletes operators based on the prediction, and uses an Optimizer-based enumerator to enumerate programs according to the predicted probability of the operators. Under the same experimental conditions, the experimental results showed that LGEQRE increased the synthesis rate from 80\% to 89.1\% and reduced the average synthesis time from 251s to 117s compared to SQUARES.},
  archiveprefix = {In Review},
  copyright = {https://creativecommons.org/licenses/by/4.0/},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/HH4IZA8V/Wang et al. - 2023 - LGEQRE Learning Guided Enumerative Synthesis for Query Reverse Engineering.pdf}
}

@inproceedings{wangSatnetBridgingDeep2019,
  title = {Satnet: {{Bridging}} Deep Learning and Logical Reasoning Using a Differentiable Satisfiability Solver},
  shorttitle = {Satnet},
  booktitle = {International {{Conference}} on {{Machine Learning}}},
  author = {Wang, Po-Wei and Donti, Priya and Wilder, Bryan and Kolter, Zico},
  year = {2019},
  pages = {6545--6554},
  publisher = {PMLR},
  urldate = {2024-03-19},
  file = {/Users/DAADAMS/Zotero/storage/QWE3AHH4/Wang et al. - 2019 - Satnet Bridging deep learning and logical reasoni.pdf}
}

@inproceedings{wayllaceGoalRecognitionDesign2016,
  title = {Goal Recognition Design with Stochastic Agent Action Outcomes},
  booktitle = {{{IJCAI}}},
  author = {Wayllace, Christabel and Hou, Ping and Yeoh, William and Son, Tran Cao},
  year = {2016},
  urldate = {2024-08-12},
  file = {/Users/DAADAMS/Zotero/storage/HMGKEKQV/Wayllace et al. - 2016 - Goal recognition design with stochastic agent acti.pdf}
}

@incollection{webbGeneralityPredictivePrediction2006,
  title = {Generality {{Is Predictive}} of {{Prediction Accuracy}}},
  booktitle = {Data {{Mining}}},
  author = {Webb, Geoffrey I. and Brain, Damien},
  editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Dough and Vardi, Moshe Y. and Weikum, Gerhard and Williams, Graham J. and Simoff, Simeon J.},
  year = {2006},
  volume = {3755},
  pages = {1--13},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/11677437_1},
  urldate = {2025-02-03},
  isbn = {978-3-540-32547-5 978-3-540-32548-2}
}

@article{whittakerEVOLUTIONMEASUREMENTSPECIES1972,
  title = {{{EVOLUTION AND MEASUREMENT OF SPECIES DIVERSITY}}},
  author = {Whittaker, R. H.},
  year = {1972},
  month = may,
  journal = {TAXON},
  volume = {21},
  number = {2-3},
  pages = {213--251},
  issn = {0040-0262, 1996-8175},
  doi = {10.2307/1218190},
  urldate = {2024-08-12},
  abstract = {Summary             Given a resource gradient (e.g. light intensity, prey size) in a community, species evolve to use different parts of this gradient; competition between them is thereby reduced. Species relationships in the community may be conceived in terms of a multidimensional coordinate system, the axes of which are the various resource gradients (and other aspects of species relationships to space, time, and one another in the community). This coordinate system defines a hyperspace, and the range of the space that a given species occupies is its niche hypervolume, as an abstract characterization of its intra-community position, or niche. Species evolve toward difference in niche, and consequently toward difference in location of their hypervolumes in the niche hyperspace. Through evolutionary time additional species can fit into the community in niche hypervolumes different from those of other species, and the niche hyperspace can become increasingly complex. Its complexity relates to the community's richness in species, its alpha diversity.             Species differ in the proportions of the niche hyperspace they are able to occupy and the share of the community's resources they utilize. The share of resources utilized is expressed in species' productivities, and when species are ranked by relative productivity (or some other measurement) from most to least important, importance-value or dominance-diversity curves are formed. Three types of curves may represent manners in which resources are divided among species: (a) niche pre-emption with strong dominance, expressed in a geometric series, (b) random boundaries between niches, expressed in the MacArthur distribution, and (c) determination of relative importance by many factors, so that species form a frequency distribution on a logarithmic base of importance values, a lognormal distribution. The forms of importance-value curves do not permit strong inference about resource division, but are of interest for their expression of species relationships and bearing on measurement of diversity.},
  langid = {english}
}

@article{yagerNewApproachSummarization1982,
  title = {A New Approach to the Summarization of Data},
  author = {Yager, Ronald R.},
  year = {1982},
  journal = {Information Sciences},
  volume = {28},
  number = {1},
  pages = {69--86},
  publisher = {Elsevier},
  urldate = {2025-02-16}
}

@article{yangMemoryPoolVariational2024,
  title = {A Memory Pool Variational Autoencoder Framework for Cross-Domain Recommendation},
  author = {Yang, Jie and Zhu, Jianxiang and Ding, Xiaofeng and Peng, Yaxin and Zhang, Yangchun},
  year = {2024},
  month = may,
  journal = {Expert Systems with Applications},
  volume = {241},
  pages = {122771},
  issn = {0957-4174},
  doi = {10.1016/j.eswa.2023.122771},
  urldate = {2025-09-08},
  abstract = {Cross-domain recommendation (CDR) leverages knowledge from the source domain to make recommendations for the cold-start users in the target domain. On account of fully utilizing information, various relationships among users and items are taken into account, i.e., the interaction relationship between users and their corresponding items; the relationship among users or items; and the indirect relationship between the user and items related to other users. In order to process these relationships, we propose a novel framework named Memory Pool Variational AutoEncoder (MPVAE). The main advantages of the MPVAE model lie in three aspects: (1) it generates the embedding representations that incorporate more information by a memory pool mechanism in the source and target domains; (2) it involves the relationship among users or items efficiently by the similarity measurement, further, the indirect relationship can be explicitly described, which makes full use of information in the source domain; and (3) it leverages the superiority of the probability model from the perspective of the VAE structure, which ensures generation and robustness. Comprehensive experiments on three real datasets show that the proposed model achieves remarkable superiority over several competitive CDR models.},
  keywords = {Attention mechanism,Cold-start,Cross-domain recommendation,Variational autoencoder},
  file = {/Users/DAADAMS/Zotero/storage/U7WFGKPM/Yang et al. - 2024 - A memory pool variational autoencoder framework for cross-domain recommendation.pdf;/Users/DAADAMS/Zotero/storage/XGLVLT6E/S0957417423032736.html}
}

@inproceedings{yangRecommendingJoinQueries2009,
  title = {Recommending Join Queries via Query Log Analysis},
  booktitle = {2009 {{IEEE}} 25th {{International Conference}} on {{Data Engineering}}},
  author = {Yang, Xiaoyan and Procopiuc, Cecilia M. and Srivastava, Divesh},
  year = {2009},
  pages = {964--975},
  publisher = {IEEE},
  urldate = {2025-02-16}
}

@article{yannicklebrasFormalFrameworkStudy2012,
  title = {Formal {{Framework}} for the {{Study}} of {{Algorithmic Properties}} of {{Objective Interestingness Measures}}},
  author = {{Yannick Le Bras} and Le Bras, Yannick and {Philippe Lenca} and Lenca, Philippe and {St{\'e}phane Lallich} and Lallich, St{\'e}phane},
  year = {2012},
  month = jan,
  volume = {24},
  pages = {77--98},
  doi = {10.1007/978-3-642-23241-1_5},
  abstract = {Association Rules Discovery is an increasing subdomain of Datamining. Many works have focused on the extraction and the evaluation of the association rules, leading to many technical improvments on the algorithms, and many different measures. But few number of them have tried to merge the both. We introduce here a formal framework for the study of association rules and interestingness measures that allows an analytic study of these objects. This framework is based on the contingency table of a rule and let us make a link between analytic properties of the measures and algorithmic properties. We give as example the case of three algorithmic properties for the extraction of association rules that were generalized and applied with the help of this framework. These properties allow a pruning of the search space based on a large number of measures and without any support constraint.},
  annotation = {MAG ID: 32212002}
}

@article{yiyuyaoMeasurementTheoreticFoundationRule2006,
  title = {A {{Measurement-Theoretic Foundation}} of {{Rule Interestingness Evaluation}}.},
  author = {{Yiyu Yao} and Yao, Yiyu and {Yaohua Chen} and Chen, Yaohua and {Xue Yang} and Yang, Xue Dong},
  year = {2006},
  month = jan,
  pages = {41--59},
  abstract = {Many measures have been proposed and studied extensively in data mining for evaluating the interestingness (or usefulness) of discovered rules. They are usually defined based on structural characteristics or statistical information about the rules. The meaningfulness of each measure was interpreted based either on intuitive arguments or mathematical properties. There does not exist a framework in which one is able to represent the user judgment explicitly, precisely, and formally. Since the usefulness of discovered rules must be eventually judged by users, a framework that takes user preference or judgement into consideration will be very valuable. The objective of this paper is to propose such a framework based on the notion of user preference. The results are useful in establishing a measurementtheoretic foundation of rule interestingness evaluation.},
  annotation = {MAG ID: 432065228}
}

@article{yolandae-martinFastGoalRecognition2015,
  title = {A Fast Goal Recognition Technique Based on Interaction Estimates},
  author = {{Yolanda E-Mart{\'i}n} and {E-Mart{\'i}n}, Yolanda and {Mar{\'i}a D. R-Moreno} and {R-Moreno}, Mar{\'i}a D. and {David E. Smith} and Smith, David J. and Smith, David E.},
  year = {2015},
  month = jul,
  pages = {761--768},
  abstract = {Goal Recognition is the task of inferring an actor's goals given some or all of the actor's observed actions. There is considerable interest in Goal Recognition for use in intelligent personal assistants, smart environments, intelligent tutoring systems, and monitoring user's needs. In much of this work, the actor's observed actions are compared against a generated library of plans. Recent work by Ramirez and Geffner makes use of AI planning to determine how closely a sequence of observed actions matches plans for each possible goal. For each goal, this is done by comparing the cost of a plan for that goal with the cost of a plan for that goal that includes the observed actions. This approach yields useful rankings, but is impractical for real-time goal recognition in large domains because of the computational expense of constructing plans for each possible goal. In this paper, we introduce an approach that propagates cost and interaction information in a plan graph, and uses this information to estimate goal probabilities. We show that this approach is much faster, but still yields high quality results.},
  annotation = {MAG ID: 2294614044}
}

@misc{youngmannGuidedExplorationData2022,
  title = {Guided {{Exploration}} of {{Data Summaries}}},
  author = {Youngmann, Brit and {Amer-Yahia}, Sihem and Personnaz, Aur{\'e}lien},
  year = {2022},
  month = may,
  number = {arXiv:2205.13956},
  eprint = {2205.13956},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2205.13956},
  urldate = {2024-12-08},
  abstract = {Data summarization is the process of producing interpretable and representative subsets of an input dataset. It is usually performed following a one-shot process with the purpose of finding the best summary. A useful summary contains {$k$} individually uniform sets that are collectively diverse to be representative. Uniformity addresses interpretability and diversity addresses representativity. Finding such as summary is a difficult task when data is highly diverse and large. We examine the applicability of Exploratory Data Analysis (EDA) to data summarization and formalize Eda4Sum, the problem of guided exploration of data summaries that seeks to sequentially produce connected summaries with the goal of maximizing their cumulative utility. Eda4Sum generalizes one-shot summarization. We propose to solve it with one of two approaches: (i) Top1Sum that chooses the most useful summary at each step; (ii) RLSum that trains a policy with Deep Reinforcement Learning that rewards an agent for finding a diverse and new collection of uniform sets at each step. We compare these approaches with one-shot summarization and top-performing EDA solutions. We run extensive experiments on three large datasets. Our results demonstrate the superiority of our approaches for summarizing very large data, and the need to provide guidance to domain experts.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Databases,Computer Science - Machine Learning},
  file = {/Users/DAADAMS/Zotero/storage/D355XYIU/Youngmann et al. - 2022 - Guided Exploration of Data Summaries.pdf}
}

@inproceedings{yuanDARecDeepDomain2019,
  title = {{{DARec}}: {{Deep Domain Adaptation}} for {{Cross-Domain Recommendation}} via {{Transferring Rating Patterns}}},
  shorttitle = {{{DARec}}},
  booktitle = {Proceedings of the {{Twenty-Eighth International Joint Conference}} on {{Artificial Intelligence}}},
  author = {Yuan, Feng and Yao, Lina and Benatallah, Boualem},
  year = {2019},
  month = aug,
  pages = {4227--4233},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  address = {Macao, China},
  doi = {10.24963/ijcai.2019/587},
  urldate = {2025-09-08},
  abstract = {Cross-domain recommendation has long been one of the major topics in recommender systems.Recently, various deep models have been proposed to transfer the learned knowledge across domains, but most of them focus on extracting abstract transferable features from auxiliary contents, e.g., images and review texts, and the patterns in the rating matrix itself is rarely touched. In this work, inspired by the concept of domain adaptation, we proposed a deep domain adaptation model (DARec) that is capable of extracting and transferring patterns from rating matrices only without relying on any auxillary information. We empirically demonstrate on public datasets that our method achieves the best performance among several state-of-the-art alternative cross-domain recommendation models.},
  isbn = {978-0-9992411-4-1},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/6FGHZ7CV/Yuan et al. - 2019 - DARec Deep Domain Adaptation for Cross-Domain Recommendation via Transferring Rating Patterns.pdf}
}

@inproceedings{yuItTakesVariety2009,
  title = {It Takes Variety to Make a World: Diversification in Recommender Systems},
  shorttitle = {It Takes Variety to Make a World},
  booktitle = {Proceedings of the 12th {{International Conference}} on {{Extending Database Technology}}: {{Advances}} in {{Database Technology}}},
  author = {Yu, Cong and Lakshmanan, Laks and {Amer-Yahia}, Sihem},
  year = {2009},
  month = mar,
  pages = {368--378},
  publisher = {ACM},
  address = {Saint Petersburg Russia},
  doi = {10.1145/1516360.1516404},
  urldate = {2025-02-07},
  isbn = {978-1-60558-422-5},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/VFBWJZ2W/Yu et al. - 2009 - It takes variety to make a world diversification in recommender systems.pdf}
}

@misc{yuYuFangxuDARec2025,
  title = {Yu-{{Fangxu}}/{{DARec}}},
  author = {Yu, Fangxu},
  year = {2025},
  month = jul,
  urldate = {2025-09-08},
  abstract = {Pytorch implementation of DARec: Deep Domain Adaptation for Cross-Domain Recommendation via Transferring Rating Patterns}
}

@misc{zangSurveyCrossdomainRecommendation2022,
  title = {A {{Survey}} on {{Cross-domain Recommendation}}: {{Taxonomies}}, {{Methods}}, and {{Future Directions}}},
  shorttitle = {A {{Survey}} on {{Cross-domain Recommendation}}},
  author = {Zang, Tianzi and Zhu, Yanmin and Liu, Haobing and Zhang, Ruohan and Yu, Jiadi},
  year = {2022},
  month = jul,
  number = {arXiv:2108.03357},
  eprint = {2108.03357},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2108.03357},
  urldate = {2025-09-08},
  abstract = {Traditional recommendation systems are faced with two long-standing obstacles, namely, data sparsity and cold-start problems, which promote the emergence and development of Cross-Domain Recommendation (CDR). The core idea of CDR is to leverage information collected from other domains to alleviate the two problems in one domain. Over the last decade, many efforts have been engaged for cross-domain recommendation. Recently, with the development of deep learning and neural networks, a large number of methods have emerged. However, there is a limited number of systematic surveys on CDR, especially regarding the latest proposed methods as well as the recommendation scenarios and recommendation tasks they address. In this survey paper, we first proposed a two-level taxonomy of cross-domain recommendation which classifies different recommendation scenarios and recommendation tasks. We then introduce and summarize existing cross-domain recommendation approaches under different recommendation scenarios in a structured manner. We also organize datasets commonly used. We conclude this survey by providing several potential research directions about this field.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Information Retrieval,Computer Science - Machine Learning},
  file = {/Users/DAADAMS/Zotero/storage/ZR5WFDHW/Zang et al. - 2022 - A Survey on Cross-domain Recommendation Taxonomies, Methods, and Future Directions.pdf}
}

@misc{zhangAutoMLGPTAutomaticMachine2023,
  title = {{{AutoML-GPT}}: {{Automatic Machine Learning}} with {{GPT}}},
  shorttitle = {{{AutoML-GPT}}},
  author = {Zhang, Shujian and Gong, Chengyue and Wu, Lemeng and Liu, Xingchao and Zhou, Mingyuan},
  year = {2023},
  month = may,
  number = {arXiv:2305.02499},
  eprint = {2305.02499},
  primaryclass = {cs, stat},
  publisher = {arXiv},
  urldate = {2024-03-15},
  abstract = {AI tasks encompass a wide range of domains and fields. While numerous AI models have been designed for specific tasks and applications, they often require considerable human efforts in finding the right model architecture, optimization algorithm, and hyperparameters. Recent advances in large language models (LLMs) like ChatGPT show remarkable capabilities in various aspects of reasoning, comprehension, and interaction. Consequently, we propose developing task-oriented prompts and automatically utilizing LLMs to automate the training pipeline. To implement this concept, we present the AutoML-GPT, which employs GPT as the bridge to diverse AI models and dynamically trains models with optimized hyperparameters. AutoML-GPT dynamically takes user requests from the model and data cards and composes the corresponding prompt paragraph. Ultimately, with this prompt paragraph, AutoML-GPT will automatically conduct the experiments from data processing to model architecture, hyperparameter tuning, and predicted training log. By leveraging AutoML-GPT's robust language capabilities and the available AI models, AutoML-GPT can tackle numerous intricate AI tasks across various tasks and datasets. This approach achieves remarkable results in computer vision, natural language processing, and other challenging areas. Extensive experiments and ablation studies demonstrate that our method can be general, effective, and beneficial for many AI tasks.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/DAADAMS/Zotero/storage/SIDFN4DA/Zhang et al. - 2023 - AutoML-GPT Automatic Machine Learning with GPT.pdf}
}

@article{zhangBIRCHEfficientData1996,
  title = {{{BIRCH}}: An Efficient Data Clustering Method for Very Large Databases},
  shorttitle = {{{BIRCH}}},
  author = {Zhang, Tian and Ramakrishnan, Raghu and Livny, Miron},
  year = {1996},
  month = jun,
  journal = {ACM SIGMOD Record},
  volume = {25},
  number = {2},
  pages = {103--114},
  issn = {0163-5808},
  doi = {10.1145/235968.233324},
  urldate = {2025-02-16},
  abstract = {Finding useful patterns in large datasets has attracted considerable interest recently, and one of the most widely studied problems in this area is the identification of               clusters,               or densely populated regions, in a multi-dimensional dataset. Prior work does not adequately address the problem of large datasets and minimization of I/O costs.This paper presents a data clustering method named               BIRCH               (Balanced Iterative Reducing and Clustering using Hierarchies), and demonstrates that it is especially suitable for very large databases.               BIRCH               incrementally and dynamically clusters incoming multi-dimensional metric data points to try to produce the best quality clustering with the available resources (i.e., available memory and time constraints).               BIRCH               can typically find a good clustering with a single scan of the data, and improve the quality further with a few additional scans.               BIRCH               is also the first clustering algorithm proposed in the database area to handle "noise" (data points that are not part of the underlying pattern) effectively.We evaluate               BIRCH               's time/space efficiency, data input order sensitivity, and clustering quality through several experiments. We also present a performance comparisons of               BIRCH               versus               CLARANS,               a clustering method proposed recently for large datasets, and show that               BIRCH               is consistently superior.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/KIIV39AK/Zhang et al. - 1996 - BIRCH an efficient data clustering method for very large databases.pdf}
}

@misc{zhangDistributionMatchingCollaborative2025,
  title = {Towards {{Distribution Matching}} between {{Collaborative}} and {{Language Spaces}} for {{Generative Recommendation}}},
  author = {Zhang, Yi and Zhang, Yiwen and Wang, Yu and Chen, Tong and Yin, Hongzhi},
  year = {2025},
  month = apr,
  number = {arXiv:2504.07363},
  eprint = {2504.07363},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2504.07363},
  urldate = {2025-09-08},
  abstract = {Generative recommendation aims to learn the underlying generative process over the entire item set to produce recommendations for users. Although it leverages non-linear probabilistic models to surpass the limited modeling capacity of linear factor models, it is often constrained by a trade-off between representation ability and tractability. With the rise of a new generation of generative methods based on pre-trained language models (LMs), incorporating LMs into general recommendation with implicit feedback has gained considerable attention. However, adapting them to generative recommendation remains challenging. The core reason lies in the mismatch between the input-output formats and semantics of generative models and LMs, making it challenging to achieve optimal alignment in the feature space. This work addresses this issue by proposing a model-agnostic generative recommendation framework called DMRec, which introduces a probabilistic meta-network to bridge the outputs of LMs with user interactions, thereby enabling an equivalent probabilistic modeling process. Subsequently, we design three cross-space distribution matching processes aimed at maximizing shared information while preserving the unique semantics of each space and filtering out irrelevant information. We apply DMRec to three different types of generative recommendation methods and conduct extensive experiments on three public datasets. The experimental results demonstrate that DMRec can effectively enhance the recommendation performance of these generative models, and it shows significant advantages over mainstream LM-enhanced recommendation methods.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Information Retrieval},
  file = {/Users/DAADAMS/Zotero/storage/63RLCYS2/Zhang et al. - 2025 - Towards Distribution Matching between Collaborative and Language Spaces for Generative Recommendatio.pdf}
}

@inproceedings{zhangExploringPolicyDiversity2022,
  title = {Exploring {{Policy Diversity}} in {{Parallel Actor-Critic Learning}}},
  booktitle = {2022 {{IEEE}} 34th {{International Conference}} on {{Tools}} with {{Artificial Intelligence}} ({{ICTAI}})},
  author = {Zhang, Yanqiang and Zhai, Yuanzhao and Zhou, Gongqian and Ding, Bo and Feng, Dawei and Liu, Songwang},
  year = {2022},
  pages = {1196--1203},
  publisher = {IEEE},
  urldate = {2024-09-03},
  keywords = {actor-critic,Deep learning,diversity promotion,exploration efficiency,Learning (artificial intelligence),Probability distribution,Reinforcement learning,Task analysis}
}

@article{zhangLeveragingInteractiveUser,
  title = {Leveraging {{Interactive User Feedback}} for {{Personalized Data Visualization Recommendation}}},
  author = {Zhang, Xiaozhong},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/QL9E8ZAX/Zhang - Leveraging Interactive User Feedback for Personalized Data Visualization Recommendation.pdf}
}

@article{zhangTaskagnosticExplorationReinforcement2020,
  title = {Task-Agnostic Exploration in Reinforcement Learning},
  author = {Zhang, Xuezhou and Ma, Yuzhe and Singla, Adish},
  year = {2020},
  journal = {Advances in Neural Information Processing Systems},
  volume = {33},
  pages = {11734--11743},
  urldate = {2024-09-03},
  file = {/Users/DAADAMS/Zotero/storage/RLFNWA29/Zhang et al. - 2020 - Task-agnostic exploration in reinforcement learnin.pdf}
}

@article{zhangVAEBasedUserPreference2023,
  title = {A {{VAE-Based User Preference Learning}} and {{Transfer Framework}} for {{Cross-Domain Recommendation}}},
  author = {Zhang, Tong and Chen, Chen and Wang, Dan and Guo, Jie and Song, Bin},
  year = {2023},
  month = oct,
  journal = {IEEE Transactions on Knowledge and Data Engineering},
  volume = {35},
  number = {10},
  pages = {10383--10396},
  issn = {1558-2191},
  doi = {10.1109/TKDE.2023.3253168},
  urldate = {2025-09-04},
  abstract = {The core idea of cross-domain recommendation is to alleviate the problem of data scarcity. Previous methods have made brilliant successes. However, many of them mainly focus on learning an ideal mapping function across-domains, ignoring the user preferences within a specific domain, which leads to suboptimal results. In this paper, we propose a Cross-Domain Recommendation Variational AutoEncoder framework (CDRVAE), a novel extension of a variational autoencoder on cross-domain recommendations for user behaviour distribution modeling. It applies a new hybrid architecture of VAE as the backbone and simultaneously constructs two information flows, within-domain and cross-domain modeling. For the former, an asymmetric codec structure is designed to reconstruct preference distribution from domain-specific latent factors. To relieve the posterior collapse dilemma, a combined prior is employed to increase the distribution complexity. The equivalent transition by a transformation matrix and the unobserved interaction generation by cross-domain reconstruction contribute to the latter. We combine all the above components for the more accurate and reliable user features. Extensive experiments are conducted on three public benchmark datasets to validate the effectiveness of the proposed CDRVAE. Experimental results demonstrate that CDRVAE is consistently superior to other state-of-the-art alternative baseline models.},
  keywords = {Bayes methods,Collaboration,Cross-domain recommendation,Data models,Decoding,deep learning,Knowledge transfer,recommendation system,Sparse matrices,Training,variational autoencoder},
  file = {/Users/DAADAMS/Zotero/storage/NSUC3APZ/Zhang et al. - 2023 - A VAE-Based User Preference Learning and Transfer Framework for Cross-Domain Recommendation.pdf}
}

@misc{zhaoCrossdomainRecommendationUser2023,
  title = {Cross-Domain Recommendation via User Interest Alignment},
  author = {Zhao, Chuang and Zhao, Hongke and He, Ming and Zhang, Jian and Fan, Jianping},
  year = {2023},
  month = jan,
  number = {arXiv:2301.11467},
  eprint = {2301.11467},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2301.11467},
  urldate = {2025-09-08},
  abstract = {Cross-domain recommendation aims to leverage knowledge from multiple domains to alleviate the data sparsity and cold-start problems in traditional recommender systems. One popular paradigm is to employ overlapping user representations to establish domain connections, thereby improving recommendation performance in all scenarios. Nevertheless, the general practice of this approach is to train user embeddings in each domain separately and then aggregate them in a plain manner, often ignoring potential cross-domain similarities between users and items. Furthermore, considering that their training objective is recommendation task-oriented without specific regularizations, the optimized embeddings disregard the interest alignment among user's views, and even violate the user's original interest distribution. To address these challenges, we propose a novel cross-domain recommendation framework, namely COAST, to improve recommendation performance on dual domains by perceiving the cross-domain similarity between entities and aligning user interests. Specifically, we first construct a unified cross-domain heterogeneous graph and redefine the message passing mechanism of graph convolutional networks to capture high-order similarity of users and items across domains. Targeted at user interest alignment, we develop deep insights from two more fine-grained perspectives of user-user and user-item interest invariance across domains by virtue of affluent unsupervised and semantic signals. We conduct intensive experiments on multiple tasks, constructed from two large recommendation data sets. Extensive results show COAST consistently and significantly outperforms state-of-the-art cross-domain recommendation algorithms as well as classic single-domain recommendation methods.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Information Retrieval},
  file = {/Users/DAADAMS/Zotero/storage/L4GDV9QU/Zhao et al. - 2023 - Cross-domain recommendation via user interest alignment.pdf}
}

@article{zhi-xuanOnlineBayesianGoal2020,
  title = {Online Bayesian Goal Inference for Boundedly Rational Planning Agents},
  author = {{Zhi-Xuan}, Tan and Mann, Jordyn and Silver, Tom and Tenenbaum, Josh and Mansinghka, Vikash},
  year = {2020},
  journal = {Advances in neural information processing systems},
  volume = {33},
  pages = {19238--19250},
  urldate = {2024-08-08},
  file = {/Users/DAADAMS/Zotero/storage/52JQ8Y59/Zhi-Xuan et al. - 2020 - Online bayesian goal inference for boundedly ratio.pdf}
}

@inproceedings{zhouDataBubblesNonvector2003,
  title = {Data Bubbles for Non-Vector Data: {{Speeding-up}} Hierarchical Clustering in Arbitrary Metric Spaces},
  shorttitle = {Data Bubbles for Non-Vector Data},
  booktitle = {Proceedings 2003 {{VLDB Conference}}},
  author = {Zhou, Jianjun and Sander, J{\"o}rg},
  year = {2003},
  pages = {452--463},
  publisher = {Elsevier},
  urldate = {2025-02-16},
  file = {/Users/DAADAMS/Zotero/storage/NSGZQT6K/Zhou and Sander - 2003 - Data bubbles for non-vector data Speeding-up hierarchical clustering in arbitrary metric spaces.pdf}
}

@misc{zhuCrossDomainRecommendationChallenges2021,
  title = {Cross-{{Domain Recommendation}}: {{Challenges}}, {{Progress}}, and {{Prospects}}},
  shorttitle = {Cross-{{Domain Recommendation}}},
  author = {Zhu, Feng and Wang, Yan and Chen, Chaochao and Zhou, Jun and Li, Longfei and Liu, Guanfeng},
  year = {2021},
  month = mar,
  number = {arXiv:2103.01696},
  eprint = {2103.01696},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2103.01696},
  urldate = {2025-09-04},
  abstract = {To address the long-standing data sparsity problem in recommender systems (RSs), cross-domain recommendation (CDR) has been proposed to leverage the relatively richer information from a richer domain to improve the recommendation performance in a sparser domain. Although CDR has been extensively studied in recent years, there is a lack of a systematic review of the existing CDR approaches. To fill this gap, in this paper, we provide a comprehensive review of existing CDR approaches, including challenges, research progress, and prospects. Specifically, we first summarize existing CDR approaches into four types, including single-target CDR, multi-domain recommendation, dual-target CDR, and multi-target CDR. We then present the definitions and challenges of these CDR approaches. Next, we propose a full-view categorization and new taxonomies on these approaches and report their research progress in detail. In the end, we share several promising prospects in CDR.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Information Retrieval,Computer Science - Machine Learning},
  file = {/Users/DAADAMS/Zotero/storage/3PEX6F94/Zhu et al. - 2021 - Cross-Domain Recommendation Challenges, Progress, and Prospects.pdf}
}

@article{zhuoLearningHierarchicalTask2014,
  title = {Learning Hierarchical Task Network Domains from Partially Observed Plan Traces},
  author = {Zhuo, Hankz Hankui and {Mu{\~n}oz-Avila}, H{\'e}ctor and Yang, Qiang},
  year = {2014},
  month = jul,
  journal = {Artificial Intelligence},
  volume = {212},
  pages = {134--157},
  issn = {0004-3702},
  doi = {10.1016/j.artint.2014.04.003},
  urldate = {2024-03-18},
  abstract = {Hierarchical Task Network (HTN) planning is an effective yet knowledge intensive problem-solving technique. It requires humans to encode knowledge in the form of methods and action models. Methods describe how to decompose tasks into subtasks and the preconditions under which those methods are applicable whereas action models describe how actions change the world. Encoding such knowledge is a difficult and time-consuming process, even for domain experts. In this paper, we propose a new learning algorithm, called HTNLearn, to help acquire HTN methods and action models. HTNLearn receives as input a collection of plan traces with partially annotated intermediate state information, and a set of annotated tasks that specify the conditions before and after the tasks' completion. In addition, plan traces are annotated with potentially empty partial decomposition trees that record the processes of decomposing tasks to subtasks. HTNLearn outputs are a collection of methods and action models. HTNLearn first encodes constraints about the methods and action models as a constraint satisfaction problem, and then solves the problem using a weighted MAX-SAT solver. HTNLearn can learn methods and action models simultaneously from partially observed plan traces (i.e., plan traces where the intermediate states are partially observable). We test HTNLearn in several HTN domains. The experimental results show that our algorithm HTNLearn is both effective and efficient.},
  keywords = {Action model learning,HTN planning,Learning HTNs,Weighted MAX-SAT},
  file = {/Users/DAADAMS/Zotero/storage/TB6FAN9Y/Zhuo et al. - 2014 - Learning hierarchical task network domains from pa.pdf;/Users/DAADAMS/Zotero/storage/34IYLLZ8/S0004370214000447.html}
}

@article{zhuoMultiAgentPlanRecognition,
  title = {Multi-{{Agent Plan Recognition}} with {{Partial Team Traces}} and {{Plan Libraries}}},
  author = {Zhuo, Hankz Hankui and Li, Lei},
  abstract = {Multi-Agent Plan Recognition (MAPR) seeks to identify the dynamic team structures and team behaviors from the observed activity sequences (team traces) of a set of intelligent agents, based on a library of known team activity sequences (team plans). Previous MAPR systems require that team traces and team plans are fully observed. In this paper we relax this constraint, i.e., team traces and team plans are allowed to be partial. This is an important task in applying MAPR to real-world domains, since in many applications it is often difficult to collect full team traces or team plans due to environment limitations, e.g., military operation. This is also a hard problem since the information available is limited. We propose a novel approach to recognizing team plans from partial team traces and team plans. We encode the MAPR problem as a satisfaction problem and solve the problem using a state-of-the-art weighted MAX-SAT solver. We empirically show that our algorithm is both effective and efficient.},
  langid = {english},
  file = {/Users/DAADAMS/Zotero/storage/IRAUBG7Y/Zhuo and Li - Multi-Agent Plan Recognition with Partial Team Tra.pdf}
}

@misc{zirakSeLePLearningBased2023,
  title = {{{SeLeP}}: {{Learning Based Semantic Prefetching}} for {{Exploratory Database Workloads}}},
  shorttitle = {{{SeLeP}}},
  author = {Zirak, Farzaneh and Choudhury, Farhana and {Borovica-Gajic}, Renata},
  year = {2023},
  month = oct,
  number = {arXiv:2310.14666},
  eprint = {2310.14666},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2310.14666},
  urldate = {2024-03-15},
  abstract = {Prefetching is a crucial technique employed in traditional databases to enhance interactivity, particularly in the context of data exploitation. Data exploration is a query processing paradigm in which users search for insights buried in the data, often not knowing what exactly they are looking for. Data exploratory tools deal with multiple challenges such as the need for interactivity with no a priori knowledge being present to help with the system tuning. The state-of-the-art prefetchers are specifically designed for navigational workloads only, where the number of possible actions is limited. The prefetchers that work with SQL-based workloads, on the other hand, mainly rely on data logical addresses rather than the data semantics. They fail to predict complex access patterns in cases where the database size is substantial, resulting in an extensive address space, or when there is frequent co-accessing of data. In this paper, we propose SeLeP, a semantic prefetcher that makes prefetching decisions for both types of workloads, based on the encoding of the data values contained inside the accessed blocks. Following the popular path of using machine learning approaches to automatically learn the hidden patterns, we formulate the prefetching task as a time-series forecasting problem and use an encoder-decoder LSTM architecture to learn the data access pattern. Our extensive experiments, across real-life exploratory workloads, demonstrate that SeLeP improves the hit ratio up to 40\% and reduces I/O time up to 45\% compared to the state-of-the-art, attaining impressive 95\% hit ratio and 80\% I/O reduction on average.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Databases},
  file = {/Users/DAADAMS/Zotero/storage/MJ7NMZ6W/Zirak et al. - 2023 - SeLeP Learning Based Semantic Prefetching for Exp.pdf;/Users/DAADAMS/Zotero/storage/7YGXGPX2/2310.html}
}

@article{zloofQuerybyexampleDataBase1977,
  title = {Query-by-Example: {{A}} Data Base Language},
  shorttitle = {Query-by-Example},
  author = {Zloof, Moshe M.},
  year = {1977},
  journal = {IBM systems Journal},
  volume = {16},
  number = {4},
  pages = {324--343},
  publisher = {IBM},
  urldate = {2024-08-12},
  file = {/Users/DAADAMS/Zotero/storage/AWVLPM5N/Zloof - 1977 - Query-by-example A data base language.pdf}
}
